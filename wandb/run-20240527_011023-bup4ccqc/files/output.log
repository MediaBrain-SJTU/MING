/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
  0%|          | 0/3844 [00:00<?, ?it/s]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.678, 'grad_norm': 0.7056452130723917, 'learning_rate': 1.724137931034483e-06, 'epoch': 0.0}

  0%|          | 2/3844 [01:31<43:02:47, 40.34s/it]
{'loss': 1.6763, 'grad_norm': 0.7506724574415268, 'learning_rate': 3.448275862068966e-06, 'epoch': 0.0}

  0%|          | 3/3844 [01:47<31:30:01, 29.52s/it]

  0%|          | 4/3844 [02:04<26:09:03, 24.52s/it]

  0%|          | 5/3844 [02:22<23:29:53, 22.04s/it]

  0%|          | 6/3844 [02:38<21:19:04, 20.00s/it]

  0%|          | 7/3844 [02:57<20:59:45, 19.70s/it]

  0%|          | 8/3844 [03:14<20:12:49, 18.97s/it]


  0%|          | 10/3844 [03:47<18:44:01, 17.59s/it]
{'loss': 1.55, 'grad_norm': 0.5981795584979983, 'learning_rate': 1.7241379310344828e-05, 'epoch': 0.0}

  0%|          | 11/3844 [04:07<19:24:12, 18.22s/it]

  0%|          | 12/3844 [04:25<19:28:11, 18.29s/it]


  0%|          | 14/3844 [04:53<17:12:56, 16.18s/it]
{'loss': 1.4742, 'grad_norm': 0.5289288255381575, 'learning_rate': 2.413793103448276e-05, 'epoch': 0.0}

  0%|          | 15/3844 [05:05<15:58:22, 15.02s/it]

  0%|          | 16/3844 [05:17<15:03:35, 14.16s/it]

  0%|          | 17/3844 [05:32<15:10:13, 14.27s/it]

  0%|          | 18/3844 [05:44<14:35:29, 13.73s/it]

  0%|          | 19/3844 [06:04<16:33:05, 15.58s/it]

  1%|          | 20/3844 [06:21<16:50:37, 15.86s/it]

  1%|          | 21/3844 [06:34<15:52:34, 14.95s/it]

  1%|          | 22/3844 [06:49<16:00:48, 15.08s/it]

  1%|          | 23/3844 [07:07<16:58:58, 16.00s/it]

  1%|          | 24/3844 [07:24<17:12:08, 16.21s/it]

  1%|          | 25/3844 [07:45<18:49:02, 17.74s/it]

  1%|          | 26/3844 [08:06<19:54:44, 18.78s/it]

  1%|          | 27/3844 [08:20<18:13:46, 17.19s/it]

  1%|          | 28/3844 [08:35<17:33:11, 16.56s/it]

  1%|          | 29/3844 [08:49<16:55:12, 15.97s/it]

  1%|          | 30/3844 [09:02<15:42:03, 14.82s/it]

  1%|          | 31/3844 [09:13<14:36:28, 13.79s/it]

  1%|          | 32/3844 [09:25<14:07:09, 13.33s/it]

  1%|          | 33/3844 [09:41<14:54:16, 14.08s/it]

  1%|          | 34/3844 [09:56<15:10:28, 14.34s/it]

  1%|          | 35/3844 [10:15<16:41:08, 15.77s/it]

  1%|          | 36/3844 [10:37<18:29:08, 17.48s/it]

  1%|          | 37/3844 [10:53<18:06:57, 17.13s/it]

  1%|          | 38/3844 [11:10<18:01:13, 17.05s/it]

  1%|          | 39/3844 [11:24<17:13:13, 16.29s/it]

  1%|          | 40/3844 [11:39<16:38:39, 15.75s/it]

  1%|          | 41/3844 [11:52<15:51:33, 15.01s/it]

  1%|          | 42/3844 [12:06<15:37:16, 14.79s/it]

  1%|          | 43/3844 [12:24<16:26:58, 15.58s/it]

  1%|          | 44/3844 [12:40<16:29:31, 15.62s/it]

  1%|          | 45/3844 [12:54<15:57:43, 15.13s/it]

  1%|          | 46/3844 [13:09<16:01:18, 15.19s/it]

  1%|          | 47/3844 [13:23<15:44:19, 14.92s/it]

  1%|          | 48/3844 [13:37<15:17:25, 14.50s/it]

  1%|▏         | 49/3844 [13:51<15:18:00, 14.51s/it]

  1%|▏         | 50/3844 [14:05<15:05:11, 14.32s/it]

  1%|▏         | 51/3844 [14:22<15:48:27, 15.00s/it]

  1%|▏         | 52/3844 [14:40<16:55:10, 16.06s/it]


  1%|▏         | 54/3844 [15:17<18:23:33, 17.47s/it]

  1%|▏         | 55/3844 [15:31<17:28:28, 16.60s/it]

  1%|▏         | 56/3844 [15:46<16:46:08, 15.94s/it]

  1%|▏         | 57/3844 [16:05<17:50:01, 16.95s/it]

  2%|▏         | 58/3844 [16:17<16:23:14, 15.58s/it]

  2%|▏         | 59/3844 [16:29<15:15:51, 14.52s/it]

  2%|▏         | 60/3844 [16:42<14:39:33, 13.95s/it]

  2%|▏         | 61/3844 [16:55<14:16:21, 13.58s/it]

  2%|▏         | 62/3844 [17:09<14:22:02, 13.68s/it]

  2%|▏         | 63/3844 [17:25<15:14:18, 14.51s/it]
{'loss': 1.2172, 'grad_norm': 0.16654187713285604, 'learning_rate': 0.00010862068965517242, 'epoch': 0.02}


  2%|▏         | 65/3844 [17:54<15:19:12, 14.59s/it]

  2%|▏         | 66/3844 [18:09<15:25:54, 14.70s/it]

  2%|▏         | 67/3844 [18:24<15:28:21, 14.75s/it]

  2%|▏         | 68/3844 [18:37<14:54:06, 14.21s/it]
{'loss': 1.2389, 'grad_norm': 0.16907004282508095, 'learning_rate': 0.00011724137931034482, 'epoch': 0.02}


  2%|▏         | 70/3844 [19:12<16:50:38, 16.07s/it]

  2%|▏         | 71/3844 [19:25<15:47:25, 15.07s/it]

  2%|▏         | 72/3844 [19:36<14:34:17, 13.91s/it]

  2%|▏         | 73/3844 [19:53<15:21:19, 14.66s/it]

  2%|▏         | 74/3844 [20:08<15:27:53, 14.77s/it]

  2%|▏         | 75/3844 [20:22<15:19:41, 14.64s/it]

  2%|▏         | 76/3844 [20:35<14:42:06, 14.05s/it]

  2%|▏         | 77/3844 [20:57<17:18:42, 16.54s/it]

  2%|▏         | 78/3844 [21:17<18:18:03, 17.49s/it]

  2%|▏         | 79/3844 [21:29<16:41:46, 15.96s/it]

  2%|▏         | 80/3844 [21:41<15:25:44, 14.76s/it]
{'loss': 1.1967, 'grad_norm': 0.1755085459374581, 'learning_rate': 0.00013793103448275863, 'epoch': 0.02}


  2%|▏         | 82/3844 [22:18<17:17:55, 16.55s/it]

  2%|▏         | 83/3844 [22:39<18:50:11, 18.03s/it]

  2%|▏         | 84/3844 [22:57<18:57:11, 18.15s/it]

  2%|▏         | 85/3844 [23:17<19:26:12, 18.61s/it]

  2%|▏         | 86/3844 [23:31<18:02:18, 17.28s/it]
{'loss': 1.273, 'grad_norm': 0.18324241100762723, 'learning_rate': 0.00014827586206896554, 'epoch': 0.02}


  2%|▏         | 88/3844 [23:58<15:47:07, 15.13s/it]

  2%|▏         | 89/3844 [24:14<16:10:32, 15.51s/it]

  2%|▏         | 90/3844 [24:32<17:03:08, 16.35s/it]

  2%|▏         | 91/3844 [24:46<16:08:47, 15.49s/it]

  2%|▏         | 92/3844 [25:03<16:37:44, 15.96s/it]

  2%|▏         | 93/3844 [25:18<16:28:44, 15.82s/it]
{'loss': 1.2764, 'grad_norm': 0.19168694516589094, 'learning_rate': 0.0001603448275862069, 'epoch': 0.02}


  2%|▏         | 95/3844 [25:50<16:39:36, 16.00s/it]

  2%|▏         | 96/3844 [26:07<17:10:50, 16.50s/it]

  3%|▎         | 97/3844 [26:23<17:06:24, 16.44s/it]

  3%|▎         | 98/3844 [26:38<16:38:42, 16.00s/it]

  3%|▎         | 99/3844 [26:54<16:38:10, 15.99s/it]

  3%|▎         | 100/3844 [27:15<18:02:32, 17.35s/it]

  3%|▎         | 101/3844 [27:33<18:22:00, 17.66s/it]

  3%|▎         | 102/3844 [27:46<16:47:59, 16.16s/it]

  3%|▎         | 103/3844 [28:01<16:23:03, 15.77s/it]
{'loss': 1.2136, 'grad_norm': 0.18536043423582926, 'learning_rate': 0.00017758620689655173, 'epoch': 0.03}


  3%|▎         | 105/3844 [28:33<16:49:25, 16.20s/it]

  3%|▎         | 106/3844 [28:49<16:42:18, 16.09s/it]
{'loss': 1.2382, 'grad_norm': 0.19856581760962003, 'learning_rate': 0.00018275862068965518, 'epoch': 0.03}


  3%|▎         | 108/3844 [29:16<15:15:02, 14.70s/it]

  3%|▎         | 109/3844 [29:33<15:58:43, 15.40s/it]

  3%|▎         | 110/3844 [29:49<16:10:37, 15.60s/it]

  3%|▎         | 111/3844 [30:08<17:00:05, 16.40s/it]

  3%|▎         | 112/3844 [30:25<17:18:03, 16.69s/it]

  3%|▎         | 113/3844 [30:44<17:59:34, 17.36s/it]

  3%|▎         | 114/3844 [31:00<17:40:32, 17.06s/it]

  3%|▎         | 115/3844 [31:15<16:50:44, 16.26s/it]

  3%|▎         | 116/3844 [31:32<17:05:37, 16.51s/it]

  3%|▎         | 117/3844 [31:44<15:51:15, 15.31s/it]

  3%|▎         | 118/3844 [32:01<16:10:34, 15.63s/it]

  3%|▎         | 119/3844 [32:16<16:00:03, 15.46s/it]

  3%|▎         | 120/3844 [32:33<16:38:06, 16.08s/it]

  3%|▎         | 121/3844 [32:48<16:13:37, 15.69s/it]

  3%|▎         | 122/3844 [33:03<15:59:24, 15.47s/it]

  3%|▎         | 123/3844 [33:16<15:12:43, 14.72s/it]

  3%|▎         | 124/3844 [33:33<15:54:12, 15.39s/it]

  3%|▎         | 125/3844 [33:49<16:00:26, 15.50s/it]

  3%|▎         | 126/3844 [34:05<16:21:27, 15.84s/it]

  3%|▎         | 127/3844 [34:27<18:16:01, 17.69s/it]

  3%|▎         | 128/3844 [34:47<19:02:19, 18.44s/it]

  3%|▎         | 129/3844 [35:07<19:22:50, 18.78s/it]

  3%|▎         | 130/3844 [35:19<17:25:26, 16.89s/it]

  3%|▎         | 131/3844 [35:35<17:02:25, 16.52s/it]

  3%|▎         | 132/3844 [35:48<15:50:14, 15.36s/it]

  3%|▎         | 133/3844 [36:08<17:24:11, 16.88s/it]

  3%|▎         | 134/3844 [36:24<17:05:05, 16.58s/it]

  4%|▎         | 135/3844 [36:39<16:37:38, 16.14s/it]

  4%|▎         | 136/3844 [36:56<16:54:20, 16.41s/it]

  4%|▎         | 137/3844 [37:13<16:53:48, 16.41s/it]

  4%|▎         | 138/3844 [37:29<16:54:10, 16.42s/it]

  4%|▎         | 139/3844 [37:44<16:23:34, 15.93s/it]

  4%|▎         | 140/3844 [37:58<15:41:36, 15.25s/it]

  4%|▎         | 141/3844 [38:11<15:10:50, 14.76s/it]

  4%|▎         | 142/3844 [38:27<15:36:56, 15.19s/it]

  4%|▎         | 143/3844 [38:50<17:49:34, 17.34s/it]

  4%|▎         | 144/3844 [39:08<18:03:30, 17.57s/it]

  4%|▍         | 145/3844 [39:20<16:31:53, 16.09s/it]

  4%|▍         | 146/3844 [39:35<16:02:01, 15.61s/it]

  4%|▍         | 147/3844 [39:51<16:08:17, 15.71s/it]

  4%|▍         | 148/3844 [40:05<15:43:19, 15.31s/it]

  4%|▍         | 149/3844 [40:19<15:08:29, 14.75s/it]

  4%|▍         | 150/3844 [40:38<16:37:08, 16.20s/it]

  4%|▍         | 151/3844 [40:54<16:31:06, 16.10s/it]

  4%|▍         | 152/3844 [41:08<15:41:25, 15.30s/it]

  4%|▍         | 153/3844 [41:23<15:49:46, 15.44s/it]

  4%|▍         | 154/3844 [41:41<16:33:58, 16.16s/it]

  4%|▍         | 155/3844 [42:01<17:38:21, 17.21s/it]

  4%|▍         | 156/3844 [42:15<16:36:42, 16.22s/it]

  4%|▍         | 157/3844 [42:30<16:11:40, 15.81s/it]

  4%|▍         | 158/3844 [42:44<15:52:55, 15.51s/it]

  4%|▍         | 159/3844 [42:57<14:52:25, 14.53s/it]

  4%|▍         | 160/3844 [43:12<15:03:47, 14.72s/it]

  4%|▍         | 161/3844 [43:27<15:04:16, 14.73s/it]
{'loss': 1.1911, 'grad_norm': 0.17653622238866234, 'learning_rate': 0.00019992810628517601, 'epoch': 0.04}


  4%|▍         | 163/3844 [43:59<15:35:02, 15.24s/it]

  4%|▍         | 164/3844 [44:12<14:53:38, 14.57s/it]

  4%|▍         | 165/3844 [44:26<14:55:21, 14.60s/it]

  4%|▍         | 166/3844 [44:43<15:35:56, 15.27s/it]

  4%|▍         | 167/3844 [44:59<15:47:33, 15.46s/it]

  4%|▍         | 168/3844 [45:14<15:37:16, 15.30s/it]

  4%|▍         | 169/3844 [45:29<15:35:57, 15.28s/it]

  4%|▍         | 170/3844 [45:40<14:16:45, 13.99s/it]

  4%|▍         | 171/3844 [45:59<15:52:12, 15.55s/it]

  4%|▍         | 172/3844 [46:15<15:47:39, 15.48s/it]

  5%|▍         | 173/3844 [46:29<15:24:04, 15.10s/it]

  5%|▍         | 174/3844 [46:49<17:02:07, 16.71s/it]

  5%|▍         | 175/3844 [47:07<17:19:02, 16.99s/it]
{'loss': 1.2687, 'grad_norm': 0.15611454390042948, 'learning_rate': 0.00019987642446526327, 'epoch': 0.05}


  5%|▍         | 177/3844 [47:41<17:01:53, 16.72s/it]

  5%|▍         | 178/3844 [47:56<16:33:51, 16.27s/it]
{'loss': 1.2452, 'grad_norm': 0.18371276206807638, 'learning_rate': 0.00019986354089320457, 'epoch': 0.05}

  5%|▍         | 179/3844 [48:13<16:41:43, 16.40s/it]


  5%|▍         | 181/3844 [48:48<17:06:21, 16.81s/it]

  5%|▍         | 182/3844 [49:00<15:44:20, 15.47s/it]
{'loss': 1.3996, 'grad_norm': 0.1867498614386954, 'learning_rate': 0.00019984536996408778, 'epoch': 0.05}


  5%|▍         | 184/3844 [49:35<17:00:11, 16.72s/it]

  5%|▍         | 185/3844 [49:52<17:15:24, 16.98s/it]

  5%|▍         | 186/3844 [50:04<15:44:03, 15.48s/it]

  5%|▍         | 187/3844 [50:22<16:12:02, 15.95s/it]

  5%|▍         | 188/3844 [50:36<15:46:45, 15.54s/it]

  5%|▍         | 189/3844 [50:56<17:00:59, 16.76s/it]

  5%|▍         | 190/3844 [51:10<16:23:22, 16.15s/it]

  5%|▍         | 191/3844 [51:25<15:51:41, 15.63s/it]

  5%|▍         | 192/3844 [51:40<15:49:02, 15.59s/it]

  5%|▌         | 193/3844 [51:51<14:28:47, 14.28s/it]

  5%|▌         | 194/3844 [52:08<15:15:52, 15.06s/it]
{'loss': 1.2644, 'grad_norm': 0.16101763591647233, 'learning_rate': 0.00019978405120904847, 'epoch': 0.05}


  5%|▌         | 196/3844 [52:42<16:21:54, 16.15s/it]

  5%|▌         | 197/3844 [53:00<16:47:07, 16.57s/it]

  5%|▌         | 198/3844 [53:14<16:16:26, 16.07s/it]

  5%|▌         | 199/3844 [53:29<15:46:05, 15.57s/it]

  5%|▌         | 200/3844 [53:42<15:04:00, 14.88s/it]

  5%|▌         | 201/3844 [53:56<14:44:51, 14.57s/it]
{'loss': 1.1435, 'grad_norm': 0.1725920873362035, 'learning_rate': 0.00019974356925405573, 'epoch': 0.05}


  5%|▌         | 203/3844 [54:24<14:38:29, 14.48s/it]

  5%|▌         | 204/3844 [54:42<15:34:49, 15.41s/it]

  5%|▌         | 205/3844 [54:56<15:06:39, 14.95s/it]
{'loss': 1.2753, 'grad_norm': 0.174872222049965, 'learning_rate': 0.000199718878301554, 'epoch': 0.05}


  5%|▌         | 207/3844 [55:30<16:10:03, 16.00s/it]

  5%|▌         | 208/3844 [55:48<16:41:02, 16.52s/it]

  5%|▌         | 209/3844 [56:00<15:28:25, 15.32s/it]

  5%|▌         | 210/3844 [56:12<14:21:48, 14.23s/it]
{'loss': 1.3262, 'grad_norm': 0.17329551603521043, 'learning_rate': 0.0001996864213088061, 'epoch': 0.05}

  5%|▌         | 211/3844 [56:26<14:08:42, 14.02s/it]


  6%|▌         | 213/3844 [56:58<15:16:02, 15.14s/it]

  6%|▌         | 214/3844 [57:14<15:34:46, 15.45s/it]

  6%|▌         | 215/3844 [57:32<16:18:32, 16.18s/it]
{'loss': 1.3149, 'grad_norm': 0.17241323711229697, 'learning_rate': 0.0001996521945196495, 'epoch': 0.06}


  6%|▌         | 217/3844 [58:00<15:00:10, 14.89s/it]

  6%|▌         | 218/3844 [58:20<16:36:03, 16.48s/it]

  6%|▌         | 219/3844 [58:34<15:56:41, 15.83s/it]

  6%|▌         | 220/3844 [58:48<15:18:57, 15.21s/it]

  6%|▌         | 221/3844 [59:03<15:18:15, 15.21s/it]

  6%|▌         | 222/3844 [59:23<16:41:28, 16.59s/it]

  6%|▌         | 223/3844 [59:36<15:37:16, 15.53s/it]
{'loss': 1.1529, 'grad_norm': 0.163698798358695, 'learning_rate': 0.00019959375200892304, 'epoch': 0.06}


  6%|▌         | 225/3844 [1:00:07<15:37:35, 15.54s/it]
{'loss': 1.1714, 'grad_norm': 0.17293350070627828, 'learning_rate': 0.00019957843401411935, 'epoch': 0.06}


  6%|▌         | 227/3844 [1:00:37<15:11:47, 15.13s/it]

  6%|▌         | 228/3844 [1:00:53<15:32:43, 15.48s/it]

  6%|▌         | 229/3844 [1:01:07<15:06:04, 15.04s/it]

  6%|▌         | 230/3844 [1:01:20<14:37:54, 14.58s/it]

  6%|▌         | 231/3844 [1:01:36<15:01:30, 14.97s/it]
{'loss': 1.2261, 'grad_norm': 0.1637491412157621, 'learning_rate': 0.0001995307830415927, 'epoch': 0.06}


  6%|▌         | 233/3844 [1:02:07<15:10:58, 15.14s/it]

  6%|▌         | 234/3844 [1:02:29<17:14:56, 17.20s/it]

  6%|▌         | 235/3844 [1:02:43<16:08:17, 16.10s/it]

  6%|▌         | 236/3844 [1:03:01<16:56:50, 16.91s/it]

  6%|▌         | 237/3844 [1:03:21<17:49:25, 17.79s/it]
{'loss': 1.1846, 'grad_norm': 0.1658426567305526, 'learning_rate': 0.0001994805875428228, 'epoch': 0.06}


  6%|▌         | 239/3844 [1:03:48<15:42:40, 15.69s/it]

  6%|▌         | 240/3844 [1:04:04<15:47:42, 15.78s/it]

  6%|▋         | 241/3844 [1:04:21<15:58:17, 15.96s/it]

  6%|▋         | 242/3844 [1:04:38<16:31:56, 16.52s/it]

  6%|▋         | 243/3844 [1:04:55<16:26:34, 16.44s/it]

  6%|▋         | 244/3844 [1:05:13<16:55:37, 16.93s/it]

  6%|▋         | 245/3844 [1:05:29<16:44:57, 16.75s/it]

  6%|▋         | 246/3844 [1:05:45<16:22:19, 16.38s/it]

  6%|▋         | 247/3844 [1:06:05<17:29:19, 17.50s/it]

  6%|▋         | 248/3844 [1:06:19<16:31:55, 16.55s/it]

  6%|▋         | 249/3844 [1:06:32<15:25:23, 15.44s/it]
{'loss': 1.2338, 'grad_norm': 0.1804505251741155, 'learning_rate': 0.00019937256816460747, 'epoch': 0.06}


  7%|▋         | 251/3844 [1:07:00<14:31:04, 14.55s/it]

  7%|▋         | 252/3844 [1:07:14<14:37:26, 14.66s/it]
{'loss': 1.2807, 'grad_norm': 0.18704008097838737, 'learning_rate': 0.00019934397507496865, 'epoch': 0.07}


  7%|▋         | 254/3844 [1:07:45<15:01:21, 15.06s/it]

  7%|▋         | 255/3844 [1:08:01<15:17:33, 15.34s/it]

  7%|▋         | 256/3844 [1:08:22<16:46:33, 16.83s/it]

  7%|▋         | 257/3844 [1:08:34<15:16:47, 15.34s/it]

  7%|▋         | 258/3844 [1:08:47<14:47:16, 14.85s/it]
{'loss': 1.215, 'grad_norm': 0.1750201910023322, 'learning_rate': 0.0001992848842666104, 'epoch': 0.07}


  7%|▋         | 260/3844 [1:09:21<15:45:57, 15.84s/it]
{'loss': 1.1695, 'grad_norm': 0.17298906722258425, 'learning_rate': 0.00019926462320073429, 'epoch': 0.07}


  7%|▋         | 262/3844 [1:09:59<17:30:10, 17.59s/it]

  7%|▋         | 263/3844 [1:10:11<15:53:10, 15.97s/it]

  7%|▋         | 264/3844 [1:10:24<14:48:02, 14.88s/it]

  7%|▋         | 265/3844 [1:10:43<16:06:14, 16.20s/it]

  7%|▋         | 266/3844 [1:10:58<15:52:15, 15.97s/it]

  7%|▋         | 267/3844 [1:11:14<15:51:54, 15.97s/it]

  7%|▋         | 268/3844 [1:11:31<16:12:04, 16.31s/it]
{'loss': 1.0977, 'grad_norm': 0.1647163191074707, 'learning_rate': 0.00019918075982853793, 'epoch': 0.07}


  7%|▋         | 270/3844 [1:12:00<15:11:30, 15.30s/it]
{'loss': 1.2073, 'grad_norm': 0.16593756094340664, 'learning_rate': 0.0001991590895060922, 'epoch': 0.07}

  7%|▋         | 271/3844 [1:12:15<14:56:54, 15.06s/it]

  7%|▋         | 272/3844 [1:12:33<15:44:51, 15.87s/it]


  7%|▋         | 274/3844 [1:13:02<15:04:54, 15.21s/it]

  7%|▋         | 275/3844 [1:13:16<14:36:22, 14.73s/it]

  7%|▋         | 276/3844 [1:13:32<14:54:30, 15.04s/it]

  7%|▋         | 277/3844 [1:13:46<14:47:38, 14.93s/it]

  7%|▋         | 278/3844 [1:13:58<13:58:34, 14.11s/it]

  7%|▋         | 279/3844 [1:14:14<14:25:36, 14.57s/it]

  7%|▋         | 280/3844 [1:14:31<15:13:03, 15.37s/it]

  7%|▋         | 281/3844 [1:14:46<14:59:12, 15.14s/it]

  7%|▋         | 282/3844 [1:15:01<15:03:36, 15.22s/it]
{'loss': 1.1487, 'grad_norm': 0.1573456214792439, 'learning_rate': 0.00019902315471511571, 'epoch': 0.07}


  7%|▋         | 284/3844 [1:15:36<16:00:46, 16.19s/it]

  7%|▋         | 285/3844 [1:15:51<15:36:18, 15.79s/it]
{'loss': 1.1233, 'grad_norm': 0.16808589395774012, 'learning_rate': 0.00019898758824383922, 'epoch': 0.07}


  7%|▋         | 287/3844 [1:16:22<15:29:42, 15.68s/it]

  7%|▋         | 288/3844 [1:16:37<15:15:27, 15.45s/it]

  8%|▊         | 289/3844 [1:16:51<14:50:21, 15.03s/it]

  8%|▊         | 290/3844 [1:17:09<15:40:45, 15.88s/it]
{'loss': 1.2777, 'grad_norm': 0.17148723795309276, 'learning_rate': 0.00019892690499280125, 'epoch': 0.08}


  8%|▊         | 292/3844 [1:17:45<16:41:54, 16.92s/it]

  8%|▊         | 293/3844 [1:18:02<16:44:39, 16.98s/it]

  8%|▊         | 294/3844 [1:18:16<15:39:07, 15.87s/it]
{'loss': 1.1058, 'grad_norm': 0.1606383341789717, 'learning_rate': 0.00019887709379440272, 'epoch': 0.08}


  8%|▊         | 296/3844 [1:18:45<15:10:05, 15.39s/it]

  8%|▊         | 297/3844 [1:19:02<15:30:46, 15.74s/it]

  8%|▊         | 298/3844 [1:19:16<15:02:39, 15.27s/it]

  8%|▊         | 299/3844 [1:19:30<14:47:05, 15.01s/it]

  8%|▊         | 300/3844 [1:19:47<15:14:21, 15.48s/it]
  8%|▊         | 300/3844 [1:19:47<15:14:21, 15.48s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  8%|▊         | 301/3844 [1:20:35<24:54:18, 25.31s/it]

  8%|▊         | 302/3844 [1:20:57<23:54:49, 24.31s/it]

  8%|▊         | 303/3844 [1:21:15<21:57:07, 22.32s/it]

  8%|▊         | 304/3844 [1:21:30<19:57:12, 20.29s/it]

  8%|▊         | 305/3844 [1:21:46<18:42:30, 19.03s/it]

  8%|▊         | 306/3844 [1:22:02<17:37:12, 17.93s/it]

  8%|▊         | 307/3844 [1:22:21<17:58:52, 18.30s/it]

  8%|▊         | 308/3844 [1:22:35<16:42:46, 17.02s/it]

  8%|▊         | 309/3844 [1:22:48<15:37:15, 15.91s/it]

  8%|▊         | 310/3844 [1:23:07<16:21:17, 16.66s/it]
{'loss': 1.3099, 'grad_norm': 0.16520922307551497, 'learning_rate': 0.00019866662010740034, 'epoch': 0.08}


  8%|▊         | 312/3844 [1:23:39<16:02:09, 16.34s/it]

  8%|▊         | 313/3844 [1:23:52<15:08:32, 15.44s/it]

  8%|▊         | 314/3844 [1:24:14<16:57:57, 17.30s/it]

  8%|▊         | 315/3844 [1:24:33<17:37:14, 17.98s/it]

  8%|▊         | 316/3844 [1:24:48<16:38:16, 16.98s/it]

  8%|▊         | 317/3844 [1:25:07<17:11:49, 17.55s/it]
{'loss': 1.1805, 'grad_norm': 0.16256640425874727, 'learning_rate': 0.00019856889512745714, 'epoch': 0.08}

  8%|▊         | 318/3844 [1:25:23<16:52:00, 17.22s/it]


  8%|▊         | 320/3844 [1:26:00<17:49:02, 18.20s/it]

  8%|▊         | 321/3844 [1:26:21<18:30:28, 18.91s/it]

  8%|▊         | 322/3844 [1:26:34<16:55:49, 17.31s/it]

  8%|▊         | 323/3844 [1:26:49<16:08:18, 16.50s/it]

  8%|▊         | 324/3844 [1:27:07<16:31:29, 16.90s/it]
{'loss': 1.1207, 'grad_norm': 0.15717229026587656, 'learning_rate': 0.00019846774023812364, 'epoch': 0.08}

  8%|▊         | 325/3844 [1:27:22<15:59:29, 16.36s/it]

  8%|▊         | 326/3844 [1:27:34<14:37:35, 14.97s/it]


  9%|▊         | 328/3844 [1:28:01<14:16:28, 14.62s/it]

  9%|▊         | 329/3844 [1:28:19<15:02:02, 15.40s/it]

  9%|▊         | 330/3844 [1:28:35<15:21:27, 15.73s/it]
{'loss': 1.1113, 'grad_norm': 0.17148049428186718, 'learning_rate': 0.00019837830878429726, 'epoch': 0.09}


  9%|▊         | 332/3844 [1:29:06<15:20:00, 15.72s/it]
{'loss': 1.2152, 'grad_norm': 0.17796555722788773, 'learning_rate': 0.00019834793928204435, 'epoch': 0.09}


  9%|▊         | 334/3844 [1:29:40<15:35:40, 15.99s/it]

  9%|▊         | 335/3844 [1:29:53<14:33:23, 14.93s/it]
{'loss': 1.2393, 'grad_norm': 0.16491790878574153, 'learning_rate': 0.00019830186124514355, 'epoch': 0.09}


  9%|▉         | 337/3844 [1:30:27<15:40:54, 16.10s/it]
{'loss': 1.1061, 'grad_norm': 0.1630643886505064, 'learning_rate': 0.00019827079349211483, 'epoch': 0.09}

  9%|▉         | 338/3844 [1:30:40<14:54:49, 15.31s/it]

  9%|▉         | 339/3844 [1:30:58<15:41:30, 16.12s/it]

  9%|▉         | 340/3844 [1:31:14<15:41:01, 16.11s/it]

  9%|▉         | 341/3844 [1:31:30<15:30:01, 15.93s/it]

  9%|▉         | 342/3844 [1:31:42<14:29:14, 14.89s/it]


  9%|▉         | 344/3844 [1:32:11<14:16:45, 14.69s/it]

  9%|▉         | 345/3844 [1:32:27<14:39:13, 15.08s/it]
{'loss': 1.1172, 'grad_norm': 0.16124892647724454, 'learning_rate': 0.00019814373190874047, 'epoch': 0.09}


  9%|▉         | 347/3844 [1:33:03<16:00:12, 16.47s/it]

  9%|▉         | 348/3844 [1:33:18<15:25:30, 15.88s/it]

  9%|▉         | 349/3844 [1:33:31<14:45:03, 15.19s/it]

  9%|▉         | 350/3844 [1:33:44<14:12:29, 14.64s/it]

  9%|▉         | 351/3844 [1:34:02<15:06:21, 15.57s/it]

  9%|▉         | 352/3844 [1:34:18<15:03:02, 15.52s/it]

  9%|▉         | 353/3844 [1:34:34<15:13:11, 15.70s/it]
{'loss': 1.1279, 'grad_norm': 0.16072282197831866, 'learning_rate': 0.00019801220977101936, 'epoch': 0.09}


  9%|▉         | 355/3844 [1:35:04<15:00:49, 15.49s/it]

  9%|▉         | 356/3844 [1:35:20<15:04:48, 15.56s/it]

  9%|▉         | 357/3844 [1:35:32<14:06:36, 14.57s/it]

  9%|▉         | 358/3844 [1:35:47<14:17:12, 14.75s/it]

  9%|▉         | 359/3844 [1:36:04<14:42:13, 15.19s/it]

  9%|▉         | 360/3844 [1:36:15<13:44:59, 14.21s/it]

  9%|▉         | 361/3844 [1:36:31<14:15:48, 14.74s/it]

  9%|▉         | 362/3844 [1:36:49<15:07:57, 15.65s/it]
{'loss': 1.0737, 'grad_norm': 0.1631699626251288, 'learning_rate': 0.00019785892306037797, 'epoch': 0.09}


  9%|▉         | 364/3844 [1:37:20<15:16:02, 15.79s/it]

  9%|▉         | 365/3844 [1:37:36<15:12:56, 15.74s/it]

 10%|▉         | 366/3844 [1:37:49<14:31:13, 15.03s/it]

 10%|▉         | 367/3844 [1:38:05<14:45:38, 15.28s/it]

 10%|▉         | 368/3844 [1:38:19<14:23:13, 14.90s/it]

 10%|▉         | 369/3844 [1:38:34<14:15:55, 14.78s/it]

 10%|▉         | 370/3844 [1:38:51<15:03:27, 15.60s/it]

 10%|▉         | 371/3844 [1:39:07<15:14:59, 15.81s/it]
{'loss': 1.0938, 'grad_norm': 0.15963478512606633, 'learning_rate': 0.00019770000734897853, 'epoch': 0.1}


 10%|▉         | 373/3844 [1:39:31<13:25:39, 13.93s/it]

 10%|▉         | 374/3844 [1:39:48<14:04:39, 14.61s/it]

 10%|▉         | 375/3844 [1:40:00<13:19:00, 13.82s/it]

 10%|▉         | 376/3844 [1:40:13<13:19:00, 13.82s/it]
{'loss': 1.2453, 'grad_norm': 0.16597023671784328, 'learning_rate': 0.0001976092919098282, 'epoch': 0.1}


 10%|▉         | 378/3844 [1:40:44<14:02:53, 14.59s/it]

 10%|▉         | 379/3844 [1:41:02<15:07:11, 15.71s/it]

 10%|▉         | 380/3844 [1:41:19<15:31:07, 16.13s/it]

 10%|▉         | 381/3844 [1:41:32<14:31:02, 15.09s/it]

 10%|▉         | 382/3844 [1:41:48<14:41:16, 15.27s/it]
{'loss': 1.2526, 'grad_norm': 0.16635422658238674, 'learning_rate': 0.00019749814607259122, 'epoch': 0.1}


 10%|▉         | 384/3844 [1:42:22<15:31:29, 16.15s/it]
{'loss': 1.178, 'grad_norm': 0.15949860682173697, 'learning_rate': 0.00019746054341548218, 'epoch': 0.1}


 10%|█         | 386/3844 [1:43:00<16:48:11, 17.49s/it]

 10%|█         | 387/3844 [1:43:20<17:31:01, 18.24s/it]

 10%|█         | 388/3844 [1:43:38<17:26:15, 18.16s/it]

 10%|█         | 389/3844 [1:43:50<15:45:51, 16.43s/it]

 10%|█         | 390/3844 [1:44:04<14:55:38, 15.56s/it]

 10%|█         | 391/3844 [1:44:17<14:13:57, 14.84s/it]

 10%|█         | 392/3844 [1:44:32<14:17:51, 14.91s/it]
{'loss': 1.1532, 'grad_norm': 0.1668483888174465, 'learning_rate': 0.00019730736541716164, 'epoch': 0.1}


 10%|█         | 394/3844 [1:45:02<14:26:49, 15.08s/it]

 10%|█         | 395/3844 [1:45:18<14:46:30, 15.42s/it]

 10%|█         | 396/3844 [1:45:36<15:30:20, 16.19s/it]

 10%|█         | 397/3844 [1:45:51<15:05:16, 15.76s/it]

 10%|█         | 398/3844 [1:46:06<14:53:43, 15.56s/it]

 10%|█         | 399/3844 [1:46:20<14:30:49, 15.17s/it]

 10%|█         | 400/3844 [1:46:39<15:29:37, 16.20s/it]

 10%|█         | 401/3844 [1:46:54<15:17:57, 16.00s/it]
{'loss': 1.188, 'grad_norm': 0.16214091672737901, 'learning_rate': 0.00019712975420368363, 'epoch': 0.1}

 10%|█         | 402/3844 [1:47:07<14:20:27, 15.00s/it]

 10%|█         | 403/3844 [1:47:29<16:27:05, 17.21s/it]


 11%|█         | 405/3844 [1:48:06<17:05:20, 17.89s/it]

 11%|█         | 406/3844 [1:48:21<16:04:44, 16.84s/it]

 11%|█         | 407/3844 [1:48:37<15:47:35, 16.54s/it]

 11%|█         | 408/3844 [1:48:51<15:05:01, 15.80s/it]

 11%|█         | 409/3844 [1:49:03<13:58:29, 14.65s/it]
{'loss': 1.2289, 'grad_norm': 0.168916705014455, 'learning_rate': 0.00019696718687508527, 'epoch': 0.11}


 11%|█         | 411/3844 [1:49:32<14:05:09, 14.77s/it]

 11%|█         | 412/3844 [1:49:51<15:05:16, 15.83s/it]

 11%|█         | 413/3844 [1:50:07<15:16:24, 16.03s/it]
{'loss': 1.0592, 'grad_norm': 0.17636959916784412, 'learning_rate': 0.00019688425008568077, 'epoch': 0.11}

 11%|█         | 414/3844 [1:50:20<14:11:41, 14.90s/it]


 11%|█         | 416/3844 [1:50:53<15:05:29, 15.85s/it]

 11%|█         | 417/3844 [1:51:07<14:39:18, 15.40s/it]
{'loss': 1.0541, 'grad_norm': 0.1606349756158843, 'learning_rate': 0.00019680021246517367, 'epoch': 0.11}


 11%|█         | 419/3844 [1:51:37<14:23:00, 15.12s/it]

 11%|█         | 420/3844 [1:51:55<15:07:11, 15.90s/it]
{'loss': 1.2107, 'grad_norm': 0.17705204566615132, 'learning_rate': 0.00019673646240332232, 'epoch': 0.11}


 11%|█         | 422/3844 [1:52:25<14:52:03, 15.64s/it]

 11%|█         | 423/3844 [1:52:39<14:10:32, 14.92s/it]

 11%|█         | 424/3844 [1:52:54<14:25:20, 15.18s/it]
{'loss': 1.1454, 'grad_norm': 0.16089774103363128, 'learning_rate': 0.0001966505006335441, 'epoch': 0.11}

 11%|█         | 425/3844 [1:53:08<13:52:34, 14.61s/it]


 11%|█         | 427/3844 [1:53:43<15:14:10, 16.05s/it]

 11%|█         | 428/3844 [1:53:59<15:12:07, 16.02s/it]
{'loss': 1.1894, 'grad_norm': 0.15922113019210873, 'learning_rate': 0.00019656344068860233, 'epoch': 0.11}

 11%|█         | 429/3844 [1:54:12<14:27:19, 15.24s/it]


 11%|█         | 431/3844 [1:54:51<16:20:29, 17.24s/it]
{'loss': 1.1752, 'grad_norm': 0.15787382867002442, 'learning_rate': 0.00019649742564704426, 'epoch': 0.11}


 11%|█▏        | 433/3844 [1:55:21<15:13:37, 16.07s/it]
{'loss': 1.2062, 'grad_norm': 0.1694339257521898, 'learning_rate': 0.00019645307295677926, 'epoch': 0.11}

 11%|█▏        | 434/3844 [1:55:36<15:05:16, 15.93s/it]

 11%|█▏        | 435/3844 [1:55:58<16:43:31, 17.66s/it]


 11%|█▏        | 437/3844 [1:56:31<16:11:29, 17.11s/it]
{'loss': 1.3237, 'grad_norm': 0.1745112070201902, 'learning_rate': 0.00019636354575348807, 'epoch': 0.11}


 11%|█▏        | 439/3844 [1:57:01<15:03:11, 15.92s/it]

 11%|█▏        | 440/3844 [1:57:17<15:12:03, 16.08s/it]

 11%|█▏        | 441/3844 [1:57:35<15:40:04, 16.57s/it]

 11%|█▏        | 442/3844 [1:57:48<14:35:33, 15.44s/it]

 12%|█▏        | 443/3844 [1:58:04<14:44:20, 15.60s/it]

 12%|█▏        | 444/3844 [1:58:16<13:43:09, 14.53s/it]

 12%|█▏        | 445/3844 [1:58:31<14:03:48, 14.90s/it]
{'loss': 1.0779, 'grad_norm': 0.17362850002974015, 'learning_rate': 0.00019618120763252453, 'epoch': 0.12}

 12%|█▏        | 446/3844 [1:58:50<15:09:32, 16.06s/it]

 12%|█▏        | 447/3844 [1:59:05<14:44:21, 15.62s/it]


 12%|█▏        | 449/3844 [1:59:37<15:03:16, 15.96s/it]

 12%|█▏        | 450/3844 [1:59:56<15:45:49, 16.72s/it]

 12%|█▏        | 451/3844 [2:00:10<14:57:47, 15.88s/it]
{'loss': 1.2076, 'grad_norm': 0.1732665052748768, 'learning_rate': 0.00019604158487666247, 'epoch': 0.12}

 12%|█▏        | 452/3844 [2:00:25<14:48:38, 15.72s/it]


 12%|█▏        | 454/3844 [2:00:59<15:28:32, 16.43s/it]

 12%|█▏        | 455/3844 [2:01:17<15:52:32, 16.86s/it]
{'loss': 1.1817, 'grad_norm': 0.17602484906219412, 'learning_rate': 0.0001959471387475378, 'epoch': 0.12}

 12%|█▏        | 456/3844 [2:01:30<14:48:40, 15.74s/it]

 12%|█▏        | 457/3844 [2:01:49<15:35:51, 16.58s/it]


 12%|█▏        | 459/3844 [2:02:18<14:25:47, 15.35s/it]
{'loss': 1.1838, 'grad_norm': 0.16328355496862218, 'learning_rate': 0.0001958516024350815, 'epoch': 0.12}

 12%|█▏        | 460/3844 [2:02:37<15:33:17, 16.55s/it]


 12%|█▏        | 462/3844 [2:03:09<15:32:36, 16.55s/it]

 12%|█▏        | 463/3844 [2:03:24<15:02:26, 16.02s/it]
{'loss': 1.249, 'grad_norm': 0.15640593278233864, 'learning_rate': 0.00019575497702480906, 'epoch': 0.12}

 12%|█▏        | 464/3844 [2:03:41<15:11:37, 16.18s/it]


 12%|█▏        | 466/3844 [2:04:06<13:32:35, 14.43s/it]
{'loss': 1.2998, 'grad_norm': 0.16000131485931773, 'learning_rate': 0.00019568179390664744, 'epoch': 0.12}


 12%|█▏        | 468/3844 [2:04:42<15:29:15, 16.52s/it]

 12%|█▏        | 469/3844 [2:05:00<15:53:04, 16.94s/it]
{'loss': 0.9792, 'grad_norm': 0.1631334158555422, 'learning_rate': 0.0001956079992560102, 'epoch': 0.12}


 12%|█▏        | 471/3844 [2:05:32<15:16:48, 16.31s/it]

 12%|█▏        | 472/3844 [2:05:50<15:46:37, 16.84s/it]
{'loss': 1.1138, 'grad_norm': 0.15779920343341683, 'learning_rate': 0.0001955335935445422, 'epoch': 0.12}


 12%|█▏        | 474/3844 [2:06:24<16:02:06, 17.13s/it]
{'loss': 1.1502, 'grad_norm': 0.1576622672654245, 'learning_rate': 0.00019548365049333656, 'epoch': 0.12}


 12%|█▏        | 476/3844 [2:06:58<15:58:55, 17.08s/it]
{'loss': 1.1283, 'grad_norm': 0.15588883712870386, 'learning_rate': 0.00019543343621268244, 'epoch': 0.12}


 12%|█▏        | 478/3844 [2:07:29<15:23:41, 16.47s/it]
{'loss': 1.2625, 'grad_norm': 0.1723499853181193, 'learning_rate': 0.00019538295084521766, 'epoch': 0.12}

 12%|█▏        | 479/3844 [2:07:46<15:36:02, 16.69s/it]

 12%|█▏        | 480/3844 [2:08:01<15:08:42, 16.21s/it]

 13%|█▎        | 481/3844 [2:08:20<15:52:44, 17.00s/it]

 13%|█▎        | 482/3844 [2:08:35<15:20:33, 16.43s/it]

 13%|█▎        | 483/3844 [2:08:53<15:48:28, 16.93s/it]

 13%|█▎        | 484/3844 [2:09:08<15:15:07, 16.34s/it]

 13%|█▎        | 485/3844 [2:09:23<14:58:59, 16.06s/it]

 13%|█▎        | 486/3844 [2:09:45<16:33:58, 17.76s/it]

 13%|█▎        | 487/3844 [2:10:02<16:11:20, 17.36s/it]

 13%|█▎        | 488/3844 [2:10:18<15:54:22, 17.06s/it]


 13%|█▎        | 490/3844 [2:10:47<14:30:52, 15.58s/it]
{'loss': 1.1299, 'grad_norm': 0.16270120109528677, 'learning_rate': 0.00019507435390210553, 'epoch': 0.13}


 13%|█▎        | 492/3844 [2:11:18<14:42:55, 15.80s/it]
{'loss': 1.0879, 'grad_norm': 0.16008593020257114, 'learning_rate': 0.0001950219749854612, 'epoch': 0.13}

 13%|█▎        | 493/3844 [2:11:34<14:37:02, 15.70s/it]

 13%|█▎        | 494/3844 [2:11:48<14:05:38, 15.15s/it]

 13%|█▎        | 495/3844 [2:12:05<14:49:30, 15.94s/it]

 13%|█▎        | 496/3844 [2:12:26<16:00:35, 17.21s/it]

 13%|█▎        | 497/3844 [2:12:42<15:45:54, 16.96s/it]


 13%|█▎        | 499/3844 [2:13:11<14:29:08, 15.59s/it]
{'loss': 1.001, 'grad_norm': 0.15925752993019945, 'learning_rate': 0.00019483652415612976, 'epoch': 0.13}

 13%|█▎        | 500/3844 [2:13:24<13:46:36, 14.83s/it]

 13%|█▎        | 501/3844 [2:13:40<13:59:32, 15.07s/it]


 13%|█▎        | 503/3844 [2:14:09<13:49:11, 14.89s/it]

 13%|█▎        | 504/3844 [2:14:25<14:17:03, 15.40s/it]

 13%|█▎        | 505/3844 [2:14:41<14:22:46, 15.50s/it]
{'loss': 1.1236, 'grad_norm': 0.1572495362085629, 'learning_rate': 0.0001946749394972192, 'epoch': 0.13}


 13%|█▎        | 507/3844 [2:15:11<14:13:19, 15.34s/it]

 13%|█▎        | 508/3844 [2:15:29<15:06:21, 16.30s/it]
{'loss': 1.193, 'grad_norm': 0.17259009034072345, 'learning_rate': 0.00019459323926258366, 'epoch': 0.13}

 13%|█▎        | 509/3844 [2:15:44<14:31:18, 15.68s/it]

 13%|█▎        | 510/3844 [2:16:00<14:37:16, 15.79s/it]

 13%|█▎        | 511/3844 [2:16:12<13:39:55, 14.76s/it]

 13%|█▎        | 512/3844 [2:16:28<14:03:00, 15.18s/it]

 13%|█▎        | 513/3844 [2:16:48<15:21:22, 16.60s/it]

 13%|█▎        | 514/3844 [2:17:04<15:17:53, 16.54s/it]

 13%|█▎        | 515/3844 [2:17:22<15:29:59, 16.76s/it]


 13%|█▎        | 517/3844 [2:17:55<15:40:56, 16.97s/it]

 13%|█▎        | 518/3844 [2:18:11<15:19:37, 16.59s/it]

 14%|█▎        | 519/3844 [2:18:30<15:52:55, 17.20s/it]
{'loss': 1.0319, 'grad_norm': 0.16962743821586118, 'learning_rate': 0.0001942885032717488, 'epoch': 0.13}


 14%|█▎        | 521/3844 [2:18:54<13:20:30, 14.45s/it]
{'loss': 1.2748, 'grad_norm': 0.16636504713190778, 'learning_rate': 0.00019423222549336564, 'epoch': 0.14}


 14%|█▎        | 523/3844 [2:19:22<13:22:09, 14.49s/it]
{'loss': 1.1365, 'grad_norm': 0.1572407122524847, 'learning_rate': 0.00019417568004031336, 'epoch': 0.14}

 14%|█▎        | 524/3844 [2:19:37<13:33:19, 14.70s/it]

 14%|█▎        | 525/3844 [2:19:48<12:30:08, 13.56s/it]


 14%|█▎        | 527/3844 [2:20:18<13:11:12, 14.31s/it]
{'loss': 1.0981, 'grad_norm': 0.1609485615556212, 'learning_rate': 0.0001940617867534499, 'epoch': 0.14}

 14%|█▎        | 528/3844 [2:20:35<13:59:23, 15.19s/it]

 14%|█▍        | 529/3844 [2:20:53<14:42:05, 15.97s/it]


 14%|█▍        | 531/3844 [2:21:22<14:03:12, 15.27s/it]
{'loss': 1.1404, 'grad_norm': 0.16179061950188017, 'learning_rate': 0.00019394682470525183, 'epoch': 0.14}


 14%|█▍        | 533/3844 [2:21:58<15:20:14, 16.68s/it]
{'loss': 1.0393, 'grad_norm': 0.15834720474628886, 'learning_rate': 0.00019388894330337746, 'epoch': 0.14}

 14%|█▍        | 534/3844 [2:22:14<15:20:54, 16.69s/it]


 14%|█▍        | 536/3844 [2:22:46<14:50:19, 16.15s/it]

 14%|█▍        | 537/3844 [2:23:00<14:14:48, 15.51s/it]
{'loss': 1.265, 'grad_norm': 0.15733760197957364, 'learning_rate': 0.00019377238056616283, 'epoch': 0.14}


 14%|█▍        | 539/3844 [2:23:28<13:37:07, 14.83s/it]

 14%|█▍        | 540/3844 [2:23:44<13:59:49, 15.25s/it]
{'loss': 1.1535, 'grad_norm': 0.16526781869225557, 'learning_rate': 0.00019368425922370748, 'epoch': 0.14}


 14%|█▍        | 542/3844 [2:24:16<14:09:28, 15.44s/it]

 14%|█▍        | 543/3844 [2:24:30<13:46:58, 15.03s/it]

 14%|█▍        | 544/3844 [2:24:46<14:04:53, 15.36s/it]

 14%|█▍        | 545/3844 [2:25:02<14:10:23, 15.47s/it]
{'loss': 1.1634, 'grad_norm': 0.1687903994661842, 'learning_rate': 0.00019353606000924907, 'epoch': 0.14}

 14%|█▍        | 546/3844 [2:25:16<13:55:40, 15.20s/it]


 14%|█▍        | 548/3844 [2:25:42<12:54:27, 14.10s/it]
{'loss': 1.078, 'grad_norm': 0.17735099296888998, 'learning_rate': 0.00019344634322049356, 'epoch': 0.14}

 14%|█▍        | 549/3844 [2:25:59<13:34:01, 14.82s/it]


 14%|█▍        | 551/3844 [2:26:28<13:47:52, 15.08s/it]
{'loss': 1.0713, 'grad_norm': 0.16359606808764407, 'learning_rate': 0.0001933560291867317, 'epoch': 0.14}

 14%|█▍        | 552/3844 [2:26:46<14:22:47, 15.73s/it]

 14%|█▍        | 553/3844 [2:27:04<15:01:23, 16.43s/it]

 14%|█▍        | 554/3844 [2:27:17<14:15:04, 15.59s/it]

 14%|█▍        | 555/3844 [2:27:32<13:54:00, 15.21s/it]

 14%|█▍        | 556/3844 [2:27:46<13:34:48, 14.87s/it]

 14%|█▍        | 557/3844 [2:28:05<14:44:46, 16.15s/it]

 15%|█▍        | 558/3844 [2:28:25<15:43:27, 17.23s/it]


 15%|█▍        | 560/3844 [2:28:50<13:39:46, 14.98s/it]
{'loss': 1.322, 'grad_norm': 0.16486479515938807, 'learning_rate': 0.00019308150940672633, 'epoch': 0.15}

 15%|█▍        | 561/3844 [2:29:08<14:24:45, 15.80s/it]


 15%|█▍        | 563/3844 [2:29:40<14:20:42, 15.74s/it]
{'loss': 1.2217, 'grad_norm': 0.1655170139291281, 'learning_rate': 0.00019298881220330985, 'epoch': 0.15}

 15%|█▍        | 564/3844 [2:29:56<14:17:40, 15.69s/it]

 15%|█▍        | 565/3844 [2:30:09<13:33:13, 14.88s/it]

 15%|█▍        | 566/3844 [2:30:24<13:37:30, 14.96s/it]

 15%|█▍        | 567/3844 [2:30:38<13:22:14, 14.69s/it]


 15%|█▍        | 569/3844 [2:31:14<15:13:00, 16.73s/it]
{'loss': 1.1862, 'grad_norm': 0.15234388015097747, 'learning_rate': 0.00019280163543038787, 'epoch': 0.15}


 15%|█▍        | 571/3844 [2:31:48<15:06:08, 16.61s/it]
{'loss': 1.1196, 'grad_norm': 0.1560917599226891, 'learning_rate': 0.000192738715713778, 'epoch': 0.15}

 15%|█▍        | 572/3844 [2:32:04<14:50:28, 16.33s/it]


 15%|█▍        | 574/3844 [2:32:37<14:44:27, 16.23s/it]

 15%|█▍        | 575/3844 [2:32:51<14:04:48, 15.51s/it]
{'loss': 1.0996, 'grad_norm': 0.15436870874537942, 'learning_rate': 0.0001926120861633535, 'epoch': 0.15}


 15%|█▌        | 577/3844 [2:33:23<14:13:17, 15.67s/it]

 15%|█▌        | 578/3844 [2:33:36<13:42:09, 15.10s/it]
{'loss': 1.3256, 'grad_norm': 0.1651359143694371, 'learning_rate': 0.00019251642335651217, 'epoch': 0.15}

 15%|█▌        | 579/3844 [2:33:51<13:34:35, 14.97s/it]

 15%|█▌        | 580/3844 [2:34:04<12:53:57, 14.23s/it]

 15%|█▌        | 581/3844 [2:34:20<13:31:44, 14.93s/it]

 15%|█▌        | 582/3844 [2:34:34<13:20:34, 14.73s/it]


 15%|█▌        | 584/3844 [2:35:05<13:43:53, 15.16s/it]

 15%|█▌        | 585/3844 [2:35:21<13:56:40, 15.40s/it]

 15%|█▌        | 586/3844 [2:35:41<15:07:18, 16.71s/it]
{'loss': 1.0782, 'grad_norm': 0.15822543075415085, 'learning_rate': 0.00019225843340306412, 'epoch': 0.15}

 15%|█▌        | 587/3844 [2:35:59<15:42:01, 17.35s/it]

 15%|█▌        | 588/3844 [2:36:13<14:44:35, 16.30s/it]


 15%|█▌        | 590/3844 [2:36:45<14:32:14, 16.08s/it]

 15%|█▌        | 591/3844 [2:37:03<14:55:42, 16.52s/it]
{'loss': 1.2371, 'grad_norm': 0.16073535460505067, 'learning_rate': 0.00019209505963543557, 'epoch': 0.15}

 15%|█▌        | 592/3844 [2:37:21<15:29:46, 17.15s/it]

 15%|█▌        | 593/3844 [2:37:33<14:06:31, 15.62s/it]

 15%|█▌        | 594/3844 [2:37:46<13:21:09, 14.79s/it]


 16%|█▌        | 596/3844 [2:38:19<14:00:25, 15.52s/it]
{'loss': 1.1729, 'grad_norm': 0.1749310935347881, 'learning_rate': 0.00019193005084566797, 'epoch': 0.16}

 16%|█▌        | 597/3844 [2:38:36<14:23:11, 15.95s/it]


 16%|█▌        | 599/3844 [2:39:03<13:13:53, 14.68s/it]
{'loss': 1.2188, 'grad_norm': 0.1674066902446729, 'learning_rate': 0.00019183026197864915, 'epoch': 0.16}

 16%|█▌        | 600/3844 [2:39:22<14:12:23, 15.77s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.203, 'grad_norm': 0.15628315160247708, 'learning_rate': 0.00019176340996326726, 'epoch': 0.16}

 16%|█▌        | 602/3844 [2:40:21<19:45:51, 21.95s/it]
{'loss': 1.0652, 'grad_norm': 0.15462877243804343, 'learning_rate': 0.0001917298861955081, 'epoch': 0.16}

 16%|█▌        | 603/3844 [2:40:34<17:10:03, 19.07s/it]

 16%|█▌        | 604/3844 [2:40:48<15:57:47, 17.74s/it]

 16%|█▌        | 605/3844 [2:41:02<15:00:16, 16.68s/it]


 16%|█▌        | 607/3844 [2:41:33<14:20:42, 15.95s/it]
{'loss': 1.0699, 'grad_norm': 0.15311512387131265, 'learning_rate': 0.00019156129070968937, 'epoch': 0.16}

 16%|█▌        | 608/3844 [2:41:50<14:28:39, 16.11s/it]


 16%|█▌        | 610/3844 [2:42:21<14:30:26, 16.15s/it]
{'loss': 1.1035, 'grad_norm': 0.18126851180133527, 'learning_rate': 0.00019145935296344924, 'epoch': 0.16}


 16%|█▌        | 612/3844 [2:42:56<14:54:12, 16.60s/it]
{'loss': 1.1477, 'grad_norm': 0.15078840023500564, 'learning_rate': 0.00019139106967807062, 'epoch': 0.16}

 16%|█▌        | 613/3844 [2:43:08<13:45:12, 15.32s/it]

 16%|█▌        | 614/3844 [2:43:24<13:58:13, 15.57s/it]

 16%|█▌        | 615/3844 [2:43:41<14:15:00, 15.89s/it]

 16%|█▌        | 616/3844 [2:43:59<14:57:12, 16.68s/it]

 16%|█▌        | 617/3844 [2:44:14<14:32:48, 16.23s/it]

 16%|█▌        | 618/3844 [2:44:29<14:06:57, 15.75s/it]

 16%|█▌        | 619/3844 [2:44:47<14:39:20, 16.36s/it]

 16%|█▌        | 620/3844 [2:45:07<15:34:33, 17.39s/it]


 16%|█▌        | 622/3844 [2:45:39<15:09:11, 16.93s/it]
{'loss': 1.0913, 'grad_norm': 0.15854195268318713, 'learning_rate': 0.00019104576309440744, 'epoch': 0.16}

 16%|█▌        | 623/3844 [2:46:01<16:22:52, 18.31s/it]

 16%|█▌        | 624/3844 [2:46:14<15:04:51, 16.86s/it]


 16%|█▋        | 626/3844 [2:46:46<14:33:01, 16.28s/it]
{'loss': 1.0862, 'grad_norm': 0.15531756337360764, 'learning_rate': 0.0001909058287198092, 'epoch': 0.16}

 16%|█▋        | 627/3844 [2:46:58<13:30:48, 15.12s/it]

 16%|█▋        | 628/3844 [2:47:15<13:51:32, 15.51s/it]

 16%|█▋        | 629/3844 [2:47:31<13:57:12, 15.62s/it]

 16%|█▋        | 630/3844 [2:47:47<14:15:17, 15.97s/it]

 16%|█▋        | 631/3844 [2:48:03<14:08:19, 15.84s/it]

 16%|█▋        | 632/3844 [2:48:19<14:02:34, 15.74s/it]

 16%|█▋        | 633/3844 [2:48:35<14:16:52, 16.01s/it]

 16%|█▋        | 634/3844 [2:48:49<13:34:13, 15.22s/it]

 17%|█▋        | 635/3844 [2:49:07<14:27:21, 16.22s/it]


 17%|█▋        | 637/3844 [2:49:36<13:29:57, 15.15s/it]
{'loss': 1.1254, 'grad_norm': 0.16428705939687202, 'learning_rate': 0.00019051568811151128, 'epoch': 0.17}


 17%|█▋        | 639/3844 [2:50:08<13:37:35, 15.31s/it]
{'loss': 1.1158, 'grad_norm': 0.157653128047752, 'learning_rate': 0.000190443916836293, 'epoch': 0.17}

 17%|█▋        | 640/3844 [2:50:22<13:08:35, 14.77s/it]

 17%|█▋        | 641/3844 [2:50:36<13:09:01, 14.78s/it]

 17%|█▋        | 642/3844 [2:50:51<13:02:18, 14.66s/it]

 17%|█▋        | 643/3844 [2:51:07<13:27:37, 15.14s/it]

 17%|█▋        | 644/3844 [2:51:19<12:37:55, 14.21s/it]

 17%|█▋        | 645/3844 [2:51:33<12:37:49, 14.21s/it]

 17%|█▋        | 646/3844 [2:51:50<13:11:15, 14.85s/it]

 17%|█▋        | 647/3844 [2:52:06<13:27:59, 15.16s/it]

 17%|█▋        | 648/3844 [2:52:23<14:08:02, 15.92s/it]

 17%|█▋        | 649/3844 [2:52:41<14:42:48, 16.58s/it]

 17%|█▋        | 650/3844 [2:52:57<14:28:00, 16.31s/it]

 17%|█▋        | 651/3844 [2:53:11<13:58:31, 15.76s/it]


 17%|█▋        | 653/3844 [2:53:48<14:50:52, 16.75s/it]
{'loss': 1.1249, 'grad_norm': 0.16094895900955203, 'learning_rate': 0.0001899343358361464, 'epoch': 0.17}

 17%|█▋        | 654/3844 [2:54:05<14:51:07, 16.76s/it]

 17%|█▋        | 655/3844 [2:54:24<15:23:51, 17.38s/it]


 17%|█▋        | 657/3844 [2:54:54<14:33:03, 16.44s/it]

 17%|█▋        | 658/3844 [2:55:06<13:25:10, 15.16s/it]
{'loss': 1.1044, 'grad_norm': 0.15532890459148727, 'learning_rate': 0.00018974930525901028, 'epoch': 0.17}


 17%|█▋        | 660/3844 [2:55:36<13:11:23, 14.91s/it]
{'loss': 1.1287, 'grad_norm': 0.15761991099506759, 'learning_rate': 0.00018967484669783492, 'epoch': 0.17}


 17%|█▋        | 662/3844 [2:56:04<12:50:35, 14.53s/it]
{'loss': 1.3473, 'grad_norm': 0.17162467735472836, 'learning_rate': 0.00018960013340761335, 'epoch': 0.17}

 17%|█▋        | 663/3844 [2:56:19<12:50:45, 14.54s/it]

 17%|█▋        | 664/3844 [2:56:36<13:32:45, 15.34s/it]

 17%|█▋        | 665/3844 [2:56:55<14:32:27, 16.47s/it]

 17%|█▋        | 666/3844 [2:57:11<14:21:09, 16.26s/it]


 17%|█▋        | 668/3844 [2:57:45<14:48:34, 16.79s/it]

 17%|█▋        | 669/3844 [2:57:59<14:04:57, 15.97s/it]
{'loss': 1.0724, 'grad_norm': 0.15527123247061497, 'learning_rate': 0.00018933663397118408, 'epoch': 0.17}

 17%|█▋        | 670/3844 [2:58:16<14:20:30, 16.27s/it]

 17%|█▋        | 671/3844 [2:58:30<13:47:20, 15.64s/it]

 17%|█▋        | 672/3844 [2:58:50<14:55:15, 16.93s/it]

 18%|█▊        | 673/3844 [2:59:10<15:39:28, 17.78s/it]


 18%|█▊        | 675/3844 [2:59:39<14:03:14, 15.97s/it]

 18%|█▊        | 676/3844 [2:59:53<13:33:16, 15.40s/it]

 18%|█▊        | 677/3844 [3:00:07<13:06:51, 14.91s/it]
{'loss': 1.2204, 'grad_norm': 0.16839238414563432, 'learning_rate': 0.0001890316857829916, 'epoch': 0.18}


 18%|█▊        | 679/3844 [3:00:41<14:01:48, 15.96s/it]
{'loss': 1.136, 'grad_norm': 0.17265683880831226, 'learning_rate': 0.00018895481593751798, 'epoch': 0.18}

 18%|█▊        | 680/3844 [3:00:56<13:47:03, 15.68s/it]

 18%|█▊        | 681/3844 [3:01:10<13:18:02, 15.14s/it]


 18%|█▊        | 683/3844 [3:01:43<13:53:45, 15.83s/it]
{'loss': 1.0945, 'grad_norm': 0.16621628345541561, 'learning_rate': 0.00018880031841443152, 'epoch': 0.18}

 18%|█▊        | 684/3844 [3:02:00<14:06:42, 16.08s/it]

 18%|█▊        | 685/3844 [3:02:16<14:12:55, 16.20s/it]

 18%|█▊        | 686/3844 [3:02:31<14:00:36, 15.97s/it]


 18%|█▊        | 688/3844 [3:03:03<13:50:46, 15.79s/it]
{'loss': 1.2323, 'grad_norm': 0.15969373213576563, 'learning_rate': 0.00018860577784097333, 'epoch': 0.18}

 18%|█▊        | 689/3844 [3:03:16<13:06:52, 14.96s/it]

 18%|█▊        | 690/3844 [3:03:34<13:58:33, 15.95s/it]


 18%|█▊        | 692/3844 [3:04:03<13:14:15, 15.12s/it]
{'loss': 1.1534, 'grad_norm': 0.15241332156214188, 'learning_rate': 0.0001884490126017005, 'epoch': 0.18}

 18%|█▊        | 693/3844 [3:04:16<12:43:06, 14.53s/it]

 18%|█▊        | 694/3844 [3:04:32<12:52:40, 14.72s/it]

 18%|█▊        | 695/3844 [3:04:48<13:26:09, 15.36s/it]


 18%|█▊        | 697/3844 [3:05:25<15:10:01, 17.35s/it]
{'loss': 1.0164, 'grad_norm': 0.1579059690113342, 'learning_rate': 0.00018825164299928745, 'epoch': 0.18}

 18%|█▊        | 698/3844 [3:05:38<14:03:07, 16.08s/it]


 18%|█▊        | 700/3844 [3:06:12<14:08:48, 16.20s/it]

 18%|█▊        | 701/3844 [3:06:24<13:04:33, 14.98s/it]
{'loss': 1.1002, 'grad_norm': 0.16387651003162818, 'learning_rate': 0.00018809261906121397, 'epoch': 0.18}

 18%|█▊        | 702/3844 [3:06:37<12:35:50, 14.43s/it]

 18%|█▊        | 703/3844 [3:06:57<14:03:41, 16.12s/it]

 18%|█▊        | 704/3844 [3:07:16<14:47:56, 16.97s/it]

 18%|█▊        | 705/3844 [3:07:32<14:39:51, 16.82s/it]

 18%|█▊        | 706/3844 [3:07:49<14:38:57, 16.81s/it]

 18%|█▊        | 707/3844 [3:08:04<14:12:41, 16.31s/it]


 18%|█▊        | 709/3844 [3:08:40<14:48:10, 17.00s/it]
{'loss': 1.1412, 'grad_norm': 0.16669234419175855, 'learning_rate': 0.00018777157019033049, 'epoch': 0.18}


 18%|█▊        | 711/3844 [3:09:09<13:39:17, 15.69s/it]
{'loss': 1.2041, 'grad_norm': 0.1610394634610425, 'learning_rate': 0.0001876906840942892, 'epoch': 0.18}

 19%|█▊        | 712/3844 [3:09:21<12:29:22, 14.36s/it]

 19%|█▊        | 713/3844 [3:09:35<12:32:39, 14.42s/it]

 19%|█▊        | 714/3844 [3:09:53<13:26:13, 15.45s/it]


 19%|█▊        | 716/3844 [3:10:19<12:23:10, 14.26s/it]
{'loss': 1.1854, 'grad_norm': 0.16514098493327276, 'learning_rate': 0.00018748737957725904, 'epoch': 0.19}

 19%|█▊        | 717/3844 [3:10:33<12:16:17, 14.13s/it]


 19%|█▊        | 719/3844 [3:11:02<12:16:26, 14.14s/it]
{'loss': 1.2591, 'grad_norm': 0.16677309013122257, 'learning_rate': 0.0001873646510897402, 'epoch': 0.19}

 19%|█▊        | 720/3844 [3:11:20<13:22:09, 15.41s/it]


 19%|█▉        | 722/3844 [3:11:52<13:20:48, 15.39s/it]
{'loss': 1.2099, 'grad_norm': 0.1648231528104314, 'learning_rate': 0.0001872413642272246, 'epoch': 0.19}

 19%|█▉        | 723/3844 [3:12:07<13:15:01, 15.28s/it]

 19%|█▉        | 724/3844 [3:12:23<13:21:11, 15.41s/it]

 19%|█▉        | 725/3844 [3:12:39<13:29:46, 15.58s/it]

 19%|█▉        | 726/3844 [3:12:54<13:33:56, 15.66s/it]

 19%|█▉        | 727/3844 [3:13:08<13:06:20, 15.14s/it]

 19%|█▉        | 728/3844 [3:13:28<14:21:41, 16.59s/it]


 19%|█▉        | 730/3844 [3:13:54<12:40:26, 14.65s/it]

 19%|█▉        | 731/3844 [3:14:10<13:05:22, 15.14s/it]

 19%|█▉        | 732/3844 [3:14:24<12:40:25, 14.66s/it]
{'loss': 1.1879, 'grad_norm': 0.16495836493218416, 'learning_rate': 0.00018682638545429407, 'epoch': 0.19}


 19%|█▉        | 734/3844 [3:14:56<13:16:08, 15.36s/it]
{'loss': 1.2367, 'grad_norm': 0.1670973846607104, 'learning_rate': 0.0001867426488399233, 'epoch': 0.19}


 19%|█▉        | 736/3844 [3:15:30<14:00:06, 16.22s/it]
{'loss': 1.1781, 'grad_norm': 0.17111816308212335, 'learning_rate': 0.0001866586658256643, 'epoch': 0.19}

 19%|█▉        | 737/3844 [3:15:44<13:19:56, 15.45s/it]


 19%|█▉        | 739/3844 [3:16:10<12:14:47, 14.20s/it]

 19%|█▉        | 740/3844 [3:16:26<12:38:56, 14.67s/it]
{'loss': 1.2267, 'grad_norm': 0.16787375733572707, 'learning_rate': 0.0001864899615524244, 'epoch': 0.19}

 19%|█▉        | 741/3844 [3:16:45<13:38:55, 15.83s/it]

 19%|█▉        | 742/3844 [3:17:03<14:20:31, 16.64s/it]


 19%|█▉        | 744/3844 [3:17:36<14:35:01, 16.94s/it]

 19%|█▉        | 745/3844 [3:17:52<14:16:51, 16.59s/it]
{'loss': 1.0603, 'grad_norm': 0.1623212852717344, 'learning_rate': 0.00018627769947569304, 'epoch': 0.19}

 19%|█▉        | 746/3844 [3:18:08<14:05:28, 16.37s/it]

 19%|█▉        | 747/3844 [3:18:25<14:14:19, 16.55s/it]


 19%|█▉        | 749/3844 [3:18:54<13:22:28, 15.56s/it]

 20%|█▉        | 750/3844 [3:19:12<14:01:25, 16.32s/it]
{'loss': 1.1424, 'grad_norm': 0.16780096968010666, 'learning_rate': 0.00018606390565611562, 'epoch': 0.2}


 20%|█▉        | 752/3844 [3:19:41<13:06:23, 15.26s/it]

 20%|█▉        | 753/3844 [3:19:51<11:47:17, 13.73s/it]

 20%|█▉        | 754/3844 [3:20:09<12:54:33, 15.04s/it]
{'loss': 1.2502, 'grad_norm': 0.152206914112513, 'learning_rate': 0.0001858917702953476, 'epoch': 0.2}

 20%|█▉        | 755/3844 [3:20:26<13:20:06, 15.54s/it]

 20%|█▉        | 756/3844 [3:20:41<13:24:58, 15.64s/it]

 20%|█▉        | 757/3844 [3:20:56<13:06:43, 15.29s/it]

 20%|█▉        | 758/3844 [3:21:10<12:45:38, 14.89s/it]

 20%|█▉        | 759/3844 [3:21:25<12:58:09, 15.13s/it]

 20%|█▉        | 760/3844 [3:21:39<12:38:37, 14.76s/it]

 20%|█▉        | 761/3844 [3:21:58<13:36:50, 15.90s/it]

 20%|█▉        | 762/3844 [3:22:16<14:15:14, 16.65s/it]

 20%|█▉        | 763/3844 [3:22:34<14:31:34, 16.97s/it]

 20%|█▉        | 764/3844 [3:22:50<14:22:13, 16.80s/it]

 20%|█▉        | 765/3844 [3:23:07<14:19:28, 16.75s/it]


 20%|█▉        | 767/3844 [3:23:43<15:06:57, 17.69s/it]
{'loss': 1.1541, 'grad_norm': 0.15221030851110082, 'learning_rate': 0.00018532560055624543, 'epoch': 0.2}


 20%|██        | 769/3844 [3:24:09<13:02:20, 15.27s/it]
{'loss': 0.9924, 'grad_norm': 0.16896171851549152, 'learning_rate': 0.00018523758690580072, 'epoch': 0.2}

 20%|██        | 770/3844 [3:24:22<12:27:26, 14.59s/it]

 20%|██        | 771/3844 [3:24:35<12:11:38, 14.29s/it]

 20%|██        | 772/3844 [3:24:52<12:50:21, 15.05s/it]

 20%|██        | 773/3844 [3:25:07<12:52:23, 15.09s/it]

 20%|██        | 774/3844 [3:25:21<12:23:46, 14.54s/it]

 20%|██        | 775/3844 [3:25:37<12:45:33, 14.97s/it]


 20%|██        | 777/3844 [3:26:13<14:13:03, 16.69s/it]
{'loss': 1.2, 'grad_norm': 0.16629135287692856, 'learning_rate': 0.00018488311356812184, 'epoch': 0.2}

 20%|██        | 778/3844 [3:26:27<13:38:02, 16.01s/it]

 20%|██        | 779/3844 [3:26:47<14:26:54, 16.97s/it]

 20%|██        | 780/3844 [3:26:58<13:09:29, 15.46s/it]

 20%|██        | 781/3844 [3:27:10<12:16:30, 14.43s/it]


 20%|██        | 783/3844 [3:27:39<12:15:49, 14.42s/it]

 20%|██        | 784/3844 [3:27:57<13:09:14, 15.48s/it]
{'loss': 1.0662, 'grad_norm': 0.15006645087278792, 'learning_rate': 0.00018456978418385304, 'epoch': 0.2}

 20%|██        | 785/3844 [3:28:15<13:44:23, 16.17s/it]

 20%|██        | 786/3844 [3:28:30<13:27:47, 15.85s/it]

 20%|██        | 787/3844 [3:28:44<12:56:32, 15.24s/it]


 21%|██        | 789/3844 [3:29:21<14:30:50, 17.10s/it]

 21%|██        | 790/3844 [3:29:35<13:37:58, 16.07s/it]
{'loss': 1.0493, 'grad_norm': 0.16376604394262048, 'learning_rate': 0.00018429887351053637, 'epoch': 0.21}

 21%|██        | 791/3844 [3:29:51<13:28:29, 15.89s/it]

 21%|██        | 792/3844 [3:30:04<12:51:17, 15.16s/it]

 21%|██        | 793/3844 [3:30:18<12:27:18, 14.70s/it]

 21%|██        | 794/3844 [3:30:36<13:21:50, 15.77s/it]

 21%|██        | 795/3844 [3:30:55<14:06:12, 16.65s/it]

 21%|██        | 796/3844 [3:31:18<15:51:27, 18.73s/it]

 21%|██        | 797/3844 [3:31:31<14:19:42, 16.93s/it]

 21%|██        | 798/3844 [3:31:45<13:32:56, 16.01s/it]


 21%|██        | 800/3844 [3:32:15<13:16:38, 15.70s/it]
{'loss': 1.1857, 'grad_norm': 0.15886367950944474, 'learning_rate': 0.00018384257001316135, 'epoch': 0.21}

 21%|██        | 801/3844 [3:32:32<13:30:03, 15.97s/it]


 21%|██        | 803/3844 [3:33:00<12:29:36, 14.79s/it]
{'loss': 1.183, 'grad_norm': 0.17039878955568477, 'learning_rate': 0.00018370451644548872, 'epoch': 0.21}

 21%|██        | 804/3844 [3:33:23<14:37:25, 17.32s/it]

 21%|██        | 805/3844 [3:33:37<13:44:23, 16.28s/it]

 21%|██        | 806/3844 [3:33:50<13:00:24, 15.41s/it]

 21%|██        | 807/3844 [3:34:09<13:52:39, 16.45s/it]

 21%|██        | 808/3844 [3:34:25<13:52:18, 16.45s/it]

 21%|██        | 809/3844 [3:34:43<14:15:05, 16.90s/it]

 21%|██        | 810/3844 [3:34:59<13:52:08, 16.46s/it]

 21%|██        | 811/3844 [3:35:15<13:44:00, 16.30s/it]


 21%|██        | 813/3844 [3:35:50<14:15:03, 16.93s/it]

 21%|██        | 814/3844 [3:36:06<14:03:31, 16.70s/it]

 21%|██        | 815/3844 [3:36:28<15:18:47, 18.20s/it]

 21%|██        | 816/3844 [3:36:40<13:50:30, 16.46s/it]

 21%|██▏       | 817/3844 [3:36:54<13:13:43, 15.73s/it]
{'loss': 1.0965, 'grad_norm': 0.16167171011001186, 'learning_rate': 0.0001830532071642619, 'epoch': 0.21}

 21%|██▏       | 818/3844 [3:37:09<13:05:55, 15.58s/it]

 21%|██▏       | 819/3844 [3:37:23<12:38:08, 15.04s/it]

 21%|██▏       | 820/3844 [3:37:36<12:11:11, 14.51s/it]

 21%|██▏       | 821/3844 [3:37:49<11:40:38, 13.91s/it]

 21%|██▏       | 822/3844 [3:38:01<11:13:27, 13.37s/it]

 21%|██▏       | 823/3844 [3:38:20<12:39:19, 15.08s/it]

 21%|██▏       | 824/3844 [3:38:32<11:55:01, 14.21s/it]

 21%|██▏       | 825/3844 [3:38:47<11:57:09, 14.25s/it]

 21%|██▏       | 826/3844 [3:39:02<12:12:26, 14.56s/it]

 22%|██▏       | 827/3844 [3:39:15<11:48:39, 14.09s/it]


 22%|██▏       | 829/3844 [3:39:44<11:59:29, 14.32s/it]
{'loss': 1.1908, 'grad_norm': 0.1733835566367475, 'learning_rate': 0.00018248573782224078, 'epoch': 0.22}

 22%|██▏       | 830/3844 [3:39:59<12:03:29, 14.40s/it]

 22%|██▏       | 831/3844 [3:40:17<12:55:23, 15.44s/it]

 22%|██▏       | 832/3844 [3:40:33<13:06:46, 15.67s/it]

 22%|██▏       | 833/3844 [3:40:49<13:17:09, 15.88s/it]

 22%|██▏       | 834/3844 [3:41:04<13:04:55, 15.65s/it]

 22%|██▏       | 835/3844 [3:41:21<13:17:50, 15.91s/it]

 22%|██▏       | 836/3844 [3:41:35<12:51:07, 15.38s/it]

 22%|██▏       | 837/3844 [3:41:54<13:35:34, 16.27s/it]

 22%|██▏       | 838/3844 [3:42:11<13:50:44, 16.58s/it]

 22%|██▏       | 839/3844 [3:42:25<13:16:34, 15.91s/it]

 22%|██▏       | 840/3844 [3:42:44<14:02:10, 16.82s/it]

 22%|██▏       | 841/3844 [3:43:00<13:54:00, 16.66s/it]

 22%|██▏       | 842/3844 [3:43:14<13:08:22, 15.76s/it]

 22%|██▏       | 843/3844 [3:43:29<12:57:04, 15.54s/it]

 22%|██▏       | 844/3844 [3:43:46<13:20:25, 16.01s/it]

 22%|██▏       | 845/3844 [3:44:03<13:36:03, 16.33s/it]

 22%|██▏       | 846/3844 [3:44:18<13:14:17, 15.90s/it]

 22%|██▏       | 847/3844 [3:44:34<13:18:52, 15.99s/it]

 22%|██▏       | 848/3844 [3:44:51<13:23:44, 16.10s/it]

 22%|██▏       | 849/3844 [3:45:05<12:49:01, 15.41s/it]

 22%|██▏       | 850/3844 [3:45:21<13:13:02, 15.89s/it]

 22%|██▏       | 851/3844 [3:45:37<13:13:42, 15.91s/it]

 22%|██▏       | 852/3844 [3:46:02<15:23:04, 18.51s/it]

 22%|██▏       | 853/3844 [3:46:16<14:09:01, 17.03s/it]

 22%|██▏       | 854/3844 [3:46:32<13:58:01, 16.82s/it]

 22%|██▏       | 855/3844 [3:46:49<14:07:25, 17.01s/it]

 22%|██▏       | 856/3844 [3:47:12<15:32:48, 18.73s/it]


 22%|██▏       | 858/3844 [3:47:45<14:40:51, 17.70s/it]
{'loss': 1.1689, 'grad_norm': 0.16218341699164282, 'learning_rate': 0.0001810796448628491, 'epoch': 0.22}

 22%|██▏       | 859/3844 [3:48:00<13:55:26, 16.79s/it]


 22%|██▏       | 861/3844 [3:48:31<13:19:31, 16.08s/it]
{'loss': 1.0252, 'grad_norm': 0.1614814998660353, 'learning_rate': 0.0001809314087595122, 'epoch': 0.22}


 22%|██▏       | 863/3844 [3:49:01<12:55:22, 15.61s/it]
{'loss': 1.1471, 'grad_norm': 0.17013442862918043, 'learning_rate': 0.00018083229726638012, 'epoch': 0.22}

 22%|██▏       | 864/3844 [3:49:19<13:22:23, 16.16s/it]

 23%|██▎       | 865/3844 [3:49:33<13:03:40, 15.78s/it]

 23%|██▎       | 866/3844 [3:49:48<12:48:34, 15.48s/it]

 23%|██▎       | 867/3844 [3:50:01<12:04:44, 14.61s/it]

 23%|██▎       | 868/3844 [3:50:17<12:32:43, 15.18s/it]

 23%|██▎       | 869/3844 [3:50:30<11:50:49, 14.34s/it]

 23%|██▎       | 870/3844 [3:50:45<12:12:17, 14.77s/it]

 23%|██▎       | 871/3844 [3:50:58<11:40:18, 14.13s/it]

 23%|██▎       | 872/3844 [3:51:14<12:11:44, 14.77s/it]


 23%|██▎       | 874/3844 [3:51:43<12:08:48, 14.72s/it]
{'loss': 1.1538, 'grad_norm': 0.1688322456157164, 'learning_rate': 0.00018028308733838774, 'epoch': 0.23}

 23%|██▎       | 875/3844 [3:51:59<12:21:50, 14.99s/it]

 23%|██▎       | 876/3844 [3:52:14<12:23:03, 15.02s/it]

 23%|██▎       | 877/3844 [3:52:30<12:32:19, 15.21s/it]

 23%|██▎       | 878/3844 [3:52:45<12:34:23, 15.26s/it]

 23%|██▎       | 879/3844 [3:52:59<12:07:27, 14.72s/it]


 23%|██▎       | 881/3844 [3:53:29<12:30:05, 15.19s/it]
{'loss': 1.2104, 'grad_norm': 0.1733484000625262, 'learning_rate': 0.00017992999533082831, 'epoch': 0.23}

 23%|██▎       | 882/3844 [3:53:45<12:29:16, 15.18s/it]

 23%|██▎       | 883/3844 [3:54:01<12:50:43, 15.62s/it]

 23%|██▎       | 884/3844 [3:54:15<12:19:29, 14.99s/it]

 23%|██▎       | 885/3844 [3:54:34<13:21:29, 16.25s/it]


 23%|██▎       | 887/3844 [3:55:05<13:10:52, 16.05s/it]
{'loss': 1.1303, 'grad_norm': 0.16381622376790583, 'learning_rate': 0.00017962513085857434, 'epoch': 0.23}

 23%|██▎       | 888/3844 [3:55:27<14:25:12, 17.56s/it]

 23%|██▎       | 889/3844 [3:55:46<14:54:58, 18.17s/it]

 23%|██▎       | 890/3844 [3:56:02<14:21:41, 17.50s/it]

 23%|██▎       | 891/3844 [3:56:14<12:58:30, 15.82s/it]


 23%|██▎       | 893/3844 [3:56:43<12:33:59, 15.33s/it]

 23%|██▎       | 894/3844 [3:56:57<12:16:48, 14.99s/it]

 23%|██▎       | 895/3844 [3:57:15<13:03:13, 15.94s/it]

 23%|██▎       | 896/3844 [3:57:30<12:37:28, 15.42s/it]

 23%|██▎       | 897/3844 [3:57:48<13:26:59, 16.43s/it]

 23%|██▎       | 898/3844 [3:58:02<12:44:41, 15.57s/it]

 23%|██▎       | 899/3844 [3:58:23<14:12:49, 17.38s/it]

 23%|██▎       | 900/3844 [3:58:37<13:21:04, 16.33s/it]
 23%|██▎       | 900/3844 [3:58:37<13:21:04, 16.33s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 23%|██▎       | 901/3844 [3:59:18<19:17:12, 23.59s/it]

 23%|██▎       | 902/3844 [3:59:35<17:35:32, 21.53s/it]

 23%|██▎       | 903/3844 [3:59:49<15:43:31, 19.25s/it]

 24%|██▎       | 904/3844 [4:00:06<15:23:09, 18.84s/it]

 24%|██▎       | 905/3844 [4:00:20<14:00:06, 17.15s/it]

 24%|██▎       | 906/3844 [4:00:35<13:39:14, 16.73s/it]

 24%|██▎       | 907/3844 [4:00:54<14:08:06, 17.33s/it]

 24%|██▎       | 908/3844 [4:01:16<15:19:33, 18.79s/it]

 24%|██▎       | 909/3844 [4:01:29<13:50:41, 16.98s/it]

 24%|██▎       | 910/3844 [4:01:42<12:47:15, 15.69s/it]

 24%|██▎       | 911/3844 [4:01:56<12:22:14, 15.18s/it]

 24%|██▎       | 912/3844 [4:02:10<12:06:54, 14.88s/it]

 24%|██▍       | 913/3844 [4:02:23<11:41:13, 14.35s/it]

 24%|██▍       | 914/3844 [4:02:42<12:40:54, 15.58s/it]

 24%|██▍       | 915/3844 [4:02:56<12:23:03, 15.22s/it]

 24%|██▍       | 916/3844 [4:03:10<12:06:58, 14.90s/it]

 24%|██▍       | 917/3844 [4:03:29<13:01:55, 16.03s/it]

 24%|██▍       | 918/3844 [4:03:46<13:13:18, 16.27s/it]

 24%|██▍       | 919/3844 [4:04:03<13:25:15, 16.52s/it]

 24%|██▍       | 920/3844 [4:04:20<13:41:10, 16.85s/it]

 24%|██▍       | 921/3844 [4:04:33<12:37:17, 15.54s/it]

 24%|██▍       | 922/3844 [4:04:47<12:13:24, 15.06s/it]

 24%|██▍       | 923/3844 [4:05:05<12:54:05, 15.90s/it]

 24%|██▍       | 924/3844 [4:05:20<12:45:07, 15.72s/it]

 24%|██▍       | 925/3844 [4:05:36<12:48:49, 15.80s/it]

 24%|██▍       | 926/3844 [4:05:52<12:59:19, 16.02s/it]

 24%|██▍       | 927/3844 [4:06:13<14:09:18, 17.47s/it]

 24%|██▍       | 928/3844 [4:06:30<14:03:53, 17.36s/it]

 24%|██▍       | 929/3844 [4:06:46<13:32:10, 16.72s/it]

 24%|██▍       | 930/3844 [4:07:03<13:39:32, 16.87s/it]

 24%|██▍       | 931/3844 [4:07:18<13:17:22, 16.42s/it]

 24%|██▍       | 932/3844 [4:07:31<12:24:15, 15.33s/it]

 24%|██▍       | 933/3844 [4:07:46<12:18:17, 15.22s/it]

 24%|██▍       | 934/3844 [4:08:04<12:58:00, 16.04s/it]

 24%|██▍       | 935/3844 [4:08:18<12:22:59, 15.32s/it]

 24%|██▍       | 936/3844 [4:08:36<13:08:52, 16.28s/it]

 24%|██▍       | 937/3844 [4:08:52<13:04:23, 16.19s/it]

 24%|██▍       | 938/3844 [4:09:05<12:24:47, 15.38s/it]

 24%|██▍       | 939/3844 [4:09:21<12:31:07, 15.51s/it]

 24%|██▍       | 940/3844 [4:09:39<13:01:36, 16.15s/it]

 24%|██▍       | 941/3844 [4:09:52<12:18:55, 15.27s/it]

 25%|██▍       | 942/3844 [4:10:07<12:07:24, 15.04s/it]

 25%|██▍       | 943/3844 [4:10:24<12:41:33, 15.75s/it]

 25%|██▍       | 944/3844 [4:10:42<13:10:12, 16.35s/it]

 25%|██▍       | 945/3844 [4:10:56<12:44:35, 15.82s/it]

 25%|██▍       | 946/3844 [4:11:13<12:58:05, 16.11s/it]

 25%|██▍       | 947/3844 [4:11:31<13:27:16, 16.72s/it]

 25%|██▍       | 948/3844 [4:11:47<13:10:55, 16.39s/it]

 25%|██▍       | 949/3844 [4:12:04<13:23:43, 16.66s/it]

 25%|██▍       | 950/3844 [4:12:21<13:28:36, 16.76s/it]

 25%|██▍       | 951/3844 [4:12:37<13:16:25, 16.52s/it]

 25%|██▍       | 952/3844 [4:12:53<13:01:46, 16.22s/it]

 25%|██▍       | 953/3844 [4:13:08<12:49:16, 15.97s/it]

 25%|██▍       | 954/3844 [4:13:22<12:21:32, 15.40s/it]

 25%|██▍       | 955/3844 [4:13:41<13:04:25, 16.29s/it]

 25%|██▍       | 956/3844 [4:13:52<11:54:21, 14.84s/it]

 25%|██▍       | 957/3844 [4:14:08<12:03:47, 15.04s/it]

 25%|██▍       | 958/3844 [4:14:22<12:01:31, 15.00s/it]

 25%|██▍       | 959/3844 [4:14:39<12:17:59, 15.35s/it]

 25%|██▍       | 960/3844 [4:14:55<12:30:09, 15.61s/it]

 25%|██▌       | 961/3844 [4:15:07<11:47:48, 14.73s/it]

 25%|██▌       | 962/3844 [4:15:21<11:23:42, 14.23s/it]

 25%|██▌       | 963/3844 [4:15:42<13:12:30, 16.50s/it]

 25%|██▌       | 964/3844 [4:16:01<13:49:30, 17.28s/it]

 25%|██▌       | 965/3844 [4:16:20<14:11:35, 17.75s/it]

 25%|██▌       | 966/3844 [4:16:33<13:02:53, 16.32s/it]

 25%|██▌       | 967/3844 [4:16:48<12:46:53, 15.99s/it]

 25%|██▌       | 968/3844 [4:17:02<12:09:28, 15.22s/it]

 25%|██▌       | 969/3844 [4:17:21<13:03:57, 16.36s/it]

 25%|██▌       | 970/3844 [4:17:39<13:27:48, 16.86s/it]
{'loss': 1.1402, 'grad_norm': 0.1562323955776071, 'learning_rate': 0.00017520249884698218, 'epoch': 0.25}


 25%|██▌       | 972/3844 [4:18:08<12:40:31, 15.89s/it]

 25%|██▌       | 973/3844 [4:18:25<12:57:57, 16.26s/it]

 25%|██▌       | 974/3844 [4:18:40<12:30:05, 15.68s/it]

 25%|██▌       | 975/3844 [4:18:53<12:05:40, 15.18s/it]

 25%|██▌       | 976/3844 [4:19:08<11:49:13, 14.84s/it]

 25%|██▌       | 977/3844 [4:19:24<12:13:16, 15.35s/it]

 25%|██▌       | 978/3844 [4:19:38<11:50:02, 14.86s/it]

 25%|██▌       | 979/3844 [4:20:00<13:30:51, 16.98s/it]

 25%|██▌       | 980/3844 [4:20:17<13:30:08, 16.97s/it]

 26%|██▌       | 981/3844 [4:20:27<11:58:59, 15.07s/it]

 26%|██▌       | 982/3844 [4:20:43<12:03:38, 15.17s/it]

 26%|██▌       | 983/3844 [4:21:04<13:34:44, 17.09s/it]

 26%|██▌       | 984/3844 [4:21:20<13:11:33, 16.61s/it]

 26%|██▌       | 985/3844 [4:21:41<14:23:48, 18.13s/it]

 26%|██▌       | 986/3844 [4:22:00<14:31:57, 18.31s/it]
{'loss': 1.1609, 'grad_norm': 0.16832193734639347, 'learning_rate': 0.00017430696371027805, 'epoch': 0.26}

 26%|██▌       | 987/3844 [4:22:20<14:48:50, 18.67s/it]


 26%|██▌       | 989/3844 [4:22:53<13:48:53, 17.42s/it]

 26%|██▌       | 990/3844 [4:23:05<12:31:31, 15.80s/it]

 26%|██▌       | 991/3844 [4:23:17<11:26:30, 14.44s/it]

 26%|██▌       | 992/3844 [4:23:28<10:47:20, 13.62s/it]

 26%|██▌       | 993/3844 [4:23:42<10:53:28, 13.75s/it]
{'loss': 1.2076, 'grad_norm': 0.16393147531325772, 'learning_rate': 0.00017391090957415758, 'epoch': 0.26}


 26%|██▌       | 995/3844 [4:24:08<10:36:40, 13.41s/it]

 26%|██▌       | 996/3844 [4:24:21<10:34:37, 13.37s/it]

 26%|██▌       | 997/3844 [4:24:37<11:05:18, 14.02s/it]

 26%|██▌       | 998/3844 [4:24:55<12:08:02, 15.35s/it]

 26%|██▌       | 999/3844 [4:25:11<12:19:33, 15.60s/it]

 26%|██▌       | 1000/3844 [4:25:28<12:34:33, 15.92s/it]

 26%|██▌       | 1001/3844 [4:25:45<12:53:17, 16.32s/it]

 26%|██▌       | 1002/3844 [4:26:04<13:22:45, 16.95s/it]

 26%|██▌       | 1003/3844 [4:26:18<12:45:06, 16.16s/it]

 26%|██▌       | 1004/3844 [4:26:30<11:41:23, 14.82s/it]

 26%|██▌       | 1005/3844 [4:26:43<11:15:01, 14.27s/it]

 26%|██▌       | 1006/3844 [4:27:01<12:12:29, 15.49s/it]

 26%|██▌       | 1007/3844 [4:27:20<12:53:42, 16.36s/it]

 26%|██▌       | 1008/3844 [4:27:33<12:12:17, 15.49s/it]

 26%|██▌       | 1009/3844 [4:27:47<11:47:08, 14.97s/it]

 26%|██▋       | 1010/3844 [4:28:02<11:55:06, 15.14s/it]

 26%|██▋       | 1011/3844 [4:28:16<11:35:51, 14.74s/it]

 26%|██▋       | 1012/3844 [4:28:27<10:48:27, 13.74s/it]

 26%|██▋       | 1013/3844 [4:28:43<11:16:20, 14.33s/it]

 26%|██▋       | 1014/3844 [4:28:55<10:44:14, 13.66s/it]

 26%|██▋       | 1015/3844 [4:29:09<10:46:03, 13.70s/it]
{'loss': 1.3345, 'grad_norm': 0.17128020049093057, 'learning_rate': 0.00017264948913702733, 'epoch': 0.26}


 26%|██▋       | 1017/3844 [4:29:36<10:46:38, 13.72s/it]

 26%|██▋       | 1018/3844 [4:29:52<11:17:20, 14.38s/it]

 27%|██▋       | 1019/3844 [4:30:08<11:39:30, 14.86s/it]

 27%|██▋       | 1020/3844 [4:30:22<11:30:20, 14.67s/it]
{'loss': 1.1438, 'grad_norm': 0.1698054756747566, 'learning_rate': 0.0001723593045818418, 'epoch': 0.27}

 27%|██▋       | 1021/3844 [4:30:36<11:27:45, 14.62s/it]

 27%|██▋       | 1022/3844 [4:30:58<13:09:38, 16.79s/it]


 27%|██▋       | 1024/3844 [4:31:32<12:54:19, 16.47s/it]

 27%|██▋       | 1025/3844 [4:31:46<12:21:52, 15.79s/it]

 27%|██▋       | 1026/3844 [4:32:03<12:42:21, 16.23s/it]

 27%|██▋       | 1027/3844 [4:32:14<11:19:30, 14.47s/it]

 27%|██▋       | 1028/3844 [4:32:29<11:31:27, 14.73s/it]

 27%|██▋       | 1029/3844 [4:32:44<11:37:21, 14.86s/it]
{'loss': 1.1668, 'grad_norm': 0.17165303954237804, 'learning_rate': 0.00017183373856445222, 'epoch': 0.27}


 27%|██▋       | 1031/3844 [4:33:16<12:04:02, 15.44s/it]
{'loss': 1.0527, 'grad_norm': 0.16840150474094895, 'learning_rate': 0.0001717163839125422, 'epoch': 0.27}

 27%|██▋       | 1032/3844 [4:33:31<11:51:56, 15.19s/it]


 27%|██▋       | 1034/3844 [4:34:00<11:40:13, 14.95s/it]
{'loss': 1.1471, 'grad_norm': 0.16565553161986857, 'learning_rate': 0.00017153997007056818, 'epoch': 0.27}

 27%|██▋       | 1035/3844 [4:34:15<11:33:09, 14.81s/it]

 27%|██▋       | 1036/3844 [4:34:27<10:53:02, 13.95s/it]


 27%|██▋       | 1038/3844 [4:34:56<11:09:43, 14.32s/it]

 27%|██▋       | 1039/3844 [4:35:13<11:56:13, 15.32s/it]

 27%|██▋       | 1040/3844 [4:35:30<12:19:56, 15.83s/it]
{'loss': 1.1187, 'grad_norm': 0.17718226251565336, 'learning_rate': 0.00017118577181362773, 'epoch': 0.27}

 27%|██▋       | 1041/3844 [4:35:45<12:01:31, 15.44s/it]


 27%|██▋       | 1043/3844 [4:36:21<13:04:48, 16.81s/it]
{'loss': 1.0471, 'grad_norm': 0.15829668509585118, 'learning_rate': 0.00017100798966245386, 'epoch': 0.27}

 27%|██▋       | 1044/3844 [4:36:35<12:29:09, 16.05s/it]


 27%|██▋       | 1046/3844 [4:37:07<12:15:29, 15.77s/it]
{'loss': 1.1495, 'grad_norm': 0.1693534896175858, 'learning_rate': 0.00017082975367685722, 'epoch': 0.27}


 27%|██▋       | 1048/3844 [4:37:39<12:14:29, 15.76s/it]

 27%|██▋       | 1049/3844 [4:37:52<11:46:22, 15.16s/it]
{'loss': 1.0634, 'grad_norm': 0.1752062402380231, 'learning_rate': 0.00017065106499600016, 'epoch': 0.27}


 27%|██▋       | 1051/3844 [4:38:20<11:14:40, 14.49s/it]
{'loss': 1.3392, 'grad_norm': 0.18865433677902566, 'learning_rate': 0.00017053168827525444, 'epoch': 0.27}

 27%|██▋       | 1052/3844 [4:38:33<10:51:08, 13.99s/it]

 27%|██▋       | 1053/3844 [4:38:49<11:19:48, 14.61s/it]


 27%|██▋       | 1055/3844 [4:39:19<11:16:11, 14.55s/it]

 27%|██▋       | 1056/3844 [4:39:32<11:04:33, 14.30s/it]

 27%|██▋       | 1057/3844 [4:39:49<11:35:10, 14.97s/it]

 28%|██▊       | 1058/3844 [4:40:03<11:17:14, 14.59s/it]

 28%|██▊       | 1059/3844 [4:40:20<11:53:07, 15.36s/it]

 28%|██▊       | 1060/3844 [4:40:36<12:06:47, 15.66s/it]

 28%|██▊       | 1061/3844 [4:40:52<12:13:21, 15.81s/it]

 28%|██▊       | 1062/3844 [4:41:08<12:09:48, 15.74s/it]
{'loss': 1.1008, 'grad_norm': 0.1666507130903808, 'learning_rate': 0.00016987154415283956, 'epoch': 0.28}

 28%|██▊       | 1063/3844 [4:41:23<12:05:02, 15.64s/it]

 28%|██▊       | 1064/3844 [4:41:43<13:05:21, 16.95s/it]


 28%|██▊       | 1066/3844 [4:42:15<12:54:15, 16.72s/it]
{'loss': 1.056, 'grad_norm': 0.16426795930990498, 'learning_rate': 0.0001696300001850887, 'epoch': 0.28}


 28%|██▊       | 1068/3844 [4:42:46<12:42:39, 16.48s/it]

 28%|██▊       | 1069/3844 [4:43:00<12:03:35, 15.65s/it]
{'loss': 1.1439, 'grad_norm': 0.16670916704142608, 'learning_rate': 0.0001694483228605946, 'epoch': 0.28}


 28%|██▊       | 1071/3844 [4:43:30<11:51:25, 15.39s/it]
{'loss': 1.045, 'grad_norm': 0.1609906209932653, 'learning_rate': 0.00016932695798019365, 'epoch': 0.28}


 28%|██▊       | 1073/3844 [4:44:01<11:55:35, 15.49s/it]

 28%|██▊       | 1074/3844 [4:44:14<11:28:25, 14.91s/it]
{'loss': 1.0413, 'grad_norm': 0.15726495871006987, 'learning_rate': 0.00016914454152535286, 'epoch': 0.28}
[2024-05-27 05:55:13,731] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 28%|██▊       | 1076/3844 [4:44:56<13:48:58, 17.97s/it]

 28%|██▊       | 1077/3844 [4:45:11<12:58:33, 16.88s/it]

 28%|██▊       | 1078/3844 [4:45:26<12:45:10, 16.60s/it]

 28%|██▊       | 1079/3844 [4:45:44<12:51:13, 16.74s/it]
{'loss': 1.2072, 'grad_norm': 0.16744968741930594, 'learning_rate': 0.00016883953262310982, 'epoch': 0.28}


 28%|██▊       | 1081/3844 [4:46:19<13:21:08, 17.40s/it]

 28%|██▊       | 1082/3844 [4:46:35<12:54:23, 16.82s/it]

 28%|██▊       | 1083/3844 [4:46:46<11:46:44, 15.36s/it]
{'loss': 1.1656, 'grad_norm': 0.15588241146823556, 'learning_rate': 0.00016859464529123602, 'epoch': 0.28}

 28%|██▊       | 1084/3844 [4:47:00<11:23:08, 14.85s/it]


 28%|██▊       | 1086/3844 [4:47:35<12:18:11, 16.06s/it]

 28%|██▊       | 1087/3844 [4:47:46<11:07:27, 14.53s/it]
{'loss': 1.0461, 'grad_norm': 0.16809656222435643, 'learning_rate': 0.00016834897856416703, 'epoch': 0.28}

 28%|██▊       | 1088/3844 [4:48:02<11:29:39, 15.01s/it]

 28%|██▊       | 1089/3844 [4:48:16<11:19:07, 14.79s/it]


 28%|██▊       | 1091/3844 [4:48:49<12:05:02, 15.80s/it]

 28%|██▊       | 1092/3844 [4:49:07<12:31:22, 16.38s/it]
{'loss': 1.1646, 'grad_norm': 0.16449225472309167, 'learning_rate': 0.00016804080338412108, 'epoch': 0.28}

 28%|██▊       | 1093/3844 [4:49:26<13:05:23, 17.13s/it]


 28%|██▊       | 1095/3844 [4:49:59<12:39:35, 16.58s/it]

 29%|██▊       | 1096/3844 [4:50:12<11:50:47, 15.52s/it]
{'loss': 1.0881, 'grad_norm': 0.16225437410953356, 'learning_rate': 0.0001677933932371657, 'epoch': 0.29}


 29%|██▊       | 1098/3844 [4:50:41<11:26:49, 15.01s/it]

 29%|██▊       | 1099/3844 [4:50:56<11:27:50, 15.03s/it]

 29%|██▊       | 1100/3844 [4:51:11<11:30:31, 15.10s/it]

 29%|██▊       | 1101/3844 [4:51:28<11:47:32, 15.48s/it]

 29%|██▊       | 1102/3844 [4:51:41<11:23:19, 14.95s/it]

 29%|██▊       | 1103/3844 [4:51:57<11:36:41, 15.25s/it]

 29%|██▊       | 1104/3844 [4:52:13<11:49:47, 15.54s/it]

 29%|██▊       | 1105/3844 [4:52:31<12:14:11, 16.08s/it]

 29%|██▉       | 1106/3844 [4:52:48<12:29:40, 16.43s/it]

 29%|██▉       | 1107/3844 [4:53:04<12:20:47, 16.24s/it]

 29%|██▉       | 1108/3844 [4:53:19<12:12:17, 16.06s/it]
{'loss': 1.0739, 'grad_norm': 0.16964261001463574, 'learning_rate': 0.00016704655233803912, 'epoch': 0.29}


 29%|██▉       | 1110/3844 [4:53:50<11:49:46, 15.58s/it]

 29%|██▉       | 1111/3844 [4:54:04<11:35:03, 15.26s/it]

 29%|██▉       | 1112/3844 [4:54:22<12:11:16, 16.06s/it]

 29%|██▉       | 1113/3844 [4:54:37<11:54:00, 15.69s/it]
{'loss': 1.1261, 'grad_norm': 0.15687045161647806, 'learning_rate': 0.00016673334069296144, 'epoch': 0.29}


 29%|██▉       | 1115/3844 [4:55:05<11:21:56, 14.99s/it]
{'loss': 1.2603, 'grad_norm': 0.16254549480068614, 'learning_rate': 0.00016660772399018878, 'epoch': 0.29}

 29%|██▉       | 1116/3844 [4:55:29<13:13:40, 17.46s/it]

 29%|██▉       | 1117/3844 [4:55:43<12:25:28, 16.40s/it]


 29%|██▉       | 1119/3844 [4:56:19<12:58:04, 17.13s/it]

 29%|██▉       | 1120/3844 [4:56:35<12:40:19, 16.75s/it]

 29%|██▉       | 1121/3844 [4:56:55<13:22:29, 17.68s/it]
{'loss': 1.2205, 'grad_norm': 0.16978533733551546, 'learning_rate': 0.00016622974008234978, 'epoch': 0.29}


 29%|██▉       | 1123/3844 [4:57:21<11:21:08, 15.02s/it]

 29%|██▉       | 1124/3844 [4:57:36<11:28:47, 15.19s/it]

 29%|██▉       | 1125/3844 [4:57:53<11:53:38, 15.75s/it]

 29%|██▉       | 1126/3844 [4:58:10<12:11:58, 16.16s/it]

 29%|██▉       | 1127/3844 [4:58:29<12:40:53, 16.80s/it]

 29%|██▉       | 1128/3844 [4:58:39<11:19:29, 15.01s/it]
{'loss': 1.1809, 'grad_norm': 0.18037208815121103, 'learning_rate': 0.00016578661954885933, 'epoch': 0.29}


 29%|██▉       | 1130/3844 [4:59:13<12:00:34, 15.93s/it]

 29%|██▉       | 1131/3844 [4:59:26<11:21:06, 15.06s/it]

 29%|██▉       | 1132/3844 [4:59:40<11:00:01, 14.60s/it]

 29%|██▉       | 1133/3844 [4:59:57<11:31:56, 15.31s/it]

 30%|██▉       | 1134/3844 [5:00:13<11:39:20, 15.48s/it]

 30%|██▉       | 1135/3844 [5:00:32<12:25:50, 16.52s/it]
{'loss': 1.0708, 'grad_norm': 0.1540430913971773, 'learning_rate': 0.00016534120983333167, 'epoch': 0.3}


 30%|██▉       | 1137/3844 [5:01:06<12:30:36, 16.64s/it]

 30%|██▉       | 1138/3844 [5:01:23<12:31:15, 16.66s/it]

 30%|██▉       | 1139/3844 [5:01:43<13:17:16, 17.68s/it]

 30%|██▉       | 1140/3844 [5:01:56<12:20:46, 16.44s/it]

 30%|██▉       | 1141/3844 [5:02:12<12:05:14, 16.10s/it]

 30%|██▉       | 1142/3844 [5:02:31<12:48:15, 17.06s/it]

 30%|██▉       | 1143/3844 [5:02:48<12:43:28, 16.96s/it]

 30%|██▉       | 1144/3844 [5:03:06<13:00:42, 17.35s/it]

 30%|██▉       | 1145/3844 [5:03:20<12:19:11, 16.43s/it]

 30%|██▉       | 1146/3844 [5:03:35<11:57:14, 15.95s/it]

 30%|██▉       | 1147/3844 [5:03:50<11:45:47, 15.70s/it]

 30%|██▉       | 1148/3844 [5:04:05<11:33:45, 15.44s/it]
{'loss': 1.131, 'grad_norm': 0.16490871261198659, 'learning_rate': 0.00016450799994753966, 'epoch': 0.3}


 30%|██▉       | 1150/3844 [5:04:39<12:04:29, 16.14s/it]

 30%|██▉       | 1151/3844 [5:04:53<11:32:15, 15.42s/it]
{'loss': 1.1133, 'grad_norm': 0.17215535555179698, 'learning_rate': 0.0001643146176508696, 'epoch': 0.3}


 30%|██▉       | 1153/3844 [5:05:26<12:03:50, 16.14s/it]

 30%|███       | 1154/3844 [5:05:43<12:13:54, 16.37s/it]
{'loss': 1.048, 'grad_norm': 0.15526532065789636, 'learning_rate': 0.00016412082429922512, 'epoch': 0.3}


 30%|███       | 1156/3844 [5:06:20<13:05:29, 17.53s/it]

 30%|███       | 1157/3844 [5:06:35<12:31:13, 16.77s/it]

 30%|███       | 1158/3844 [5:06:46<11:15:44, 15.09s/it]

 30%|███       | 1159/3844 [5:07:04<11:56:44, 16.02s/it]

 30%|███       | 1160/3844 [5:07:19<11:37:35, 15.59s/it]
{'loss': 1.1305, 'grad_norm': 0.17365970197376487, 'learning_rate': 0.00016373200938800934, 'epoch': 0.3}


 30%|███       | 1162/3844 [5:07:50<11:37:04, 15.59s/it]
{'loss': 1.0806, 'grad_norm': 0.1720712839450592, 'learning_rate': 0.0001636020418538056, 'epoch': 0.3}


 30%|███       | 1164/3844 [5:08:24<11:46:31, 15.82s/it]
{'loss': 0.9639, 'grad_norm': 0.16501060236130113, 'learning_rate': 0.00016347189365258034, 'epoch': 0.3}


 30%|███       | 1166/3844 [5:08:49<10:36:42, 14.27s/it]

 30%|███       | 1167/3844 [5:09:05<10:52:51, 14.63s/it]

 30%|███       | 1168/3844 [5:09:21<11:08:45, 14.99s/it]
{'loss': 1.205, 'grad_norm': 0.17269869757070153, 'learning_rate': 0.0001632110567283657, 'epoch': 0.3}


 30%|███       | 1170/3844 [5:09:53<11:44:59, 15.82s/it]

 30%|███       | 1171/3844 [5:10:11<12:15:30, 16.51s/it]

 30%|███       | 1172/3844 [5:10:29<12:35:21, 16.96s/it]

 31%|███       | 1173/3844 [5:10:50<13:28:27, 18.16s/it]
{'loss': 1.2064, 'grad_norm': 0.17069608652673202, 'learning_rate': 0.00016288400091718104, 'epoch': 0.31}


 31%|███       | 1175/3844 [5:11:19<11:52:08, 16.01s/it]
{'loss': 1.0213, 'grad_norm': 0.16040573993184792, 'learning_rate': 0.0001627528656693797, 'epoch': 0.31}


 31%|███       | 1177/3844 [5:11:52<11:57:24, 16.14s/it]

 31%|███       | 1178/3844 [5:12:07<11:55:00, 16.09s/it]

 31%|███       | 1179/3844 [5:12:24<11:54:05, 16.08s/it]
{'loss': 1.2215, 'grad_norm': 0.16560667425897113, 'learning_rate': 0.00016249006078219167, 'epoch': 0.31}

 31%|███       | 1180/3844 [5:12:38<11:31:17, 15.57s/it]


 31%|███       | 1182/3844 [5:13:10<11:30:57, 15.57s/it]

 31%|███       | 1183/3844 [5:13:25<11:20:47, 15.35s/it]

 31%|███       | 1184/3844 [5:13:40<11:16:17, 15.25s/it]

 31%|███       | 1185/3844 [5:13:54<11:10:36, 15.13s/it]

 31%|███       | 1186/3844 [5:14:09<10:59:07, 14.88s/it]

 31%|███       | 1187/3844 [5:14:25<11:19:19, 15.34s/it]
{'loss': 1.225, 'grad_norm': 0.16886136005293198, 'learning_rate': 0.00016196232390333856, 'epoch': 0.31}


 31%|███       | 1189/3844 [5:15:10<13:52:58, 18.82s/it]

 31%|███       | 1190/3844 [5:15:21<12:18:16, 16.69s/it]

 31%|███       | 1191/3844 [5:15:35<11:40:25, 15.84s/it]

 31%|███       | 1192/3844 [5:15:53<12:07:15, 16.45s/it]
{'loss': 1.1765, 'grad_norm': 0.1676380681046203, 'learning_rate': 0.00016163105675602853, 'epoch': 0.31}

 31%|███       | 1193/3844 [5:16:08<11:50:22, 16.08s/it]


 31%|███       | 1195/3844 [5:16:40<11:29:22, 15.61s/it]
{'loss': 1.1138, 'grad_norm': 0.1753297249844085, 'learning_rate': 0.00016143177088627833, 'epoch': 0.31}

 31%|███       | 1196/3844 [5:16:56<11:41:54, 15.90s/it]

 31%|███       | 1197/3844 [5:17:12<11:46:45, 16.02s/it]

 31%|███       | 1198/3844 [5:17:29<11:49:41, 16.09s/it]


 31%|███       | 1200/3844 [5:17:58<11:10:07, 15.21s/it]
 31%|███       | 1200/3844 [5:17:58<11:10:07, 15.21s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 31%|███       | 1201/3844 [5:18:43<17:49:16, 24.27s/it]

 31%|███▏      | 1202/3844 [5:19:02<16:34:43, 22.59s/it]
{'loss': 1.07, 'grad_norm': 0.16678730043610385, 'learning_rate': 0.00016096524583604087, 'epoch': 0.31}


 31%|███▏      | 1204/3844 [5:19:30<13:23:37, 18.26s/it]
{'loss': 1.1501, 'grad_norm': 0.17968626618334824, 'learning_rate': 0.00016083156260560387, 'epoch': 0.31}

 31%|███▏      | 1205/3844 [5:19:47<12:59:15, 17.72s/it]


 31%|███▏      | 1207/3844 [5:20:20<12:42:00, 17.34s/it]

 31%|███▏      | 1208/3844 [5:20:36<12:28:55, 17.05s/it]

 31%|███▏      | 1209/3844 [5:20:54<12:39:15, 17.29s/it]

 31%|███▏      | 1210/3844 [5:21:11<12:37:38, 17.26s/it]

 32%|███▏      | 1211/3844 [5:21:25<11:55:18, 16.30s/it]

 32%|███▏      | 1212/3844 [5:21:44<12:26:45, 17.02s/it]
{'loss': 1.006, 'grad_norm': 0.16052194126265326, 'learning_rate': 0.00016029510551620777, 'epoch': 0.32}

 32%|███▏      | 1213/3844 [5:22:03<12:51:56, 17.60s/it]


 32%|███▏      | 1215/3844 [5:22:28<10:58:53, 15.04s/it]

 32%|███▏      | 1216/3844 [5:22:41<10:38:09, 14.57s/it]
{'loss': 1.2523, 'grad_norm': 0.16764508686539362, 'learning_rate': 0.00016002584780611194, 'epoch': 0.32}


 32%|███▏      | 1218/3844 [5:23:12<10:48:54, 14.83s/it]
{'loss': 0.9664, 'grad_norm': 0.16931730326382913, 'learning_rate': 0.0001598909629969241, 'epoch': 0.32}

 32%|███▏      | 1219/3844 [5:23:27<10:57:12, 15.02s/it]


 32%|███▏      | 1221/3844 [5:23:56<10:50:08, 14.87s/it]

 32%|███▏      | 1222/3844 [5:24:12<10:56:43, 15.03s/it]

 32%|███▏      | 1223/3844 [5:24:26<10:40:30, 14.66s/it]
{'loss': 1.0335, 'grad_norm': 0.17390966226553925, 'learning_rate': 0.00015955300751472568, 'epoch': 0.32}


 32%|███▏      | 1225/3844 [5:25:04<12:22:17, 17.01s/it]

 32%|███▏      | 1226/3844 [5:25:18<11:53:44, 16.36s/it]

 32%|███▏      | 1227/3844 [5:25:36<12:09:25, 16.72s/it]

 32%|███▏      | 1228/3844 [5:25:54<12:22:32, 17.03s/it]

 32%|███▏      | 1229/3844 [5:26:10<12:09:53, 16.75s/it]
{'loss': 1.2562, 'grad_norm': 0.15760298278347207, 'learning_rate': 0.000159146065852636, 'epoch': 0.32}


 32%|███▏      | 1231/3844 [5:26:36<10:50:16, 14.93s/it]

 32%|███▏      | 1232/3844 [5:26:48<10:05:21, 13.91s/it]

 32%|███▏      | 1233/3844 [5:27:07<11:12:44, 15.46s/it]
{'loss': 0.9808, 'grad_norm': 0.17805179032616858, 'learning_rate': 0.0001588739307218361, 'epoch': 0.32}


 32%|███▏      | 1235/3844 [5:27:39<11:28:37, 15.84s/it]

 32%|███▏      | 1236/3844 [5:27:58<12:18:15, 16.98s/it]
{'loss': 0.9038, 'grad_norm': 0.16844182053980858, 'learning_rate': 0.00015866939020906377, 'epoch': 0.32}


 32%|███▏      | 1238/3844 [5:28:33<12:23:10, 17.11s/it]

 32%|███▏      | 1239/3844 [5:28:50<12:22:36, 17.10s/it]

 32%|███▏      | 1240/3844 [5:29:04<11:42:00, 16.18s/it]
{'loss': 1.0099, 'grad_norm': 0.15978469111464721, 'learning_rate': 0.00015839608645792125, 'epoch': 0.32}

 32%|███▏      | 1241/3844 [5:29:18<11:10:12, 15.45s/it]


 32%|███▏      | 1243/3844 [5:29:55<12:13:25, 16.92s/it]

 32%|███▏      | 1244/3844 [5:30:08<11:28:33, 15.89s/it]

 32%|███▏      | 1245/3844 [5:30:21<10:46:06, 14.92s/it]

 32%|███▏      | 1246/3844 [5:30:36<10:50:19, 15.02s/it]

 32%|███▏      | 1247/3844 [5:30:52<11:01:46, 15.29s/it]

 32%|███▏      | 1248/3844 [5:31:08<11:12:27, 15.54s/it]
{'loss': 1.0433, 'grad_norm': 0.1571479999544464, 'learning_rate': 0.00015784749152121972, 'epoch': 0.32}

 32%|███▏      | 1249/3844 [5:31:22<10:45:34, 14.93s/it]

 33%|███▎      | 1250/3844 [5:31:33<10:05:13, 14.00s/it]


 33%|███▎      | 1252/3844 [5:32:06<11:02:53, 15.34s/it]

 33%|███▎      | 1253/3844 [5:32:21<10:58:13, 15.24s/it]

 33%|███▎      | 1254/3844 [5:32:37<11:10:56, 15.54s/it]
{'loss': 1.164, 'grad_norm': 0.16247040494461273, 'learning_rate': 0.000157434318589109, 'epoch': 0.33}


 33%|███▎      | 1256/3844 [5:33:05<10:34:38, 14.71s/it]
{'loss': 1.1887, 'grad_norm': 0.1621965432405318, 'learning_rate': 0.00015729626746216122, 'epoch': 0.33}

 33%|███▎      | 1257/3844 [5:33:22<11:00:02, 15.31s/it]


 33%|███▎      | 1259/3844 [5:33:47<9:55:42, 13.83s/it]

 33%|███▎      | 1260/3844 [5:34:04<10:35:48, 14.76s/it]

 33%|███▎      | 1261/3844 [5:34:20<10:53:04, 15.17s/it]

 33%|███▎      | 1262/3844 [5:34:37<11:25:23, 15.93s/it]
{'loss': 0.9487, 'grad_norm': 0.15636313903743168, 'learning_rate': 0.00015688113912262126, 'epoch': 0.33}

 33%|███▎      | 1263/3844 [5:34:52<11:07:11, 15.51s/it]


 33%|███▎      | 1265/3844 [5:35:21<10:34:55, 14.77s/it]
{'loss': 1.1426, 'grad_norm': 0.17478552270449765, 'learning_rate': 0.0001566730289710558, 'epoch': 0.33}

 33%|███▎      | 1266/3844 [5:35:36<10:33:31, 14.74s/it]


 33%|███▎      | 1268/3844 [5:36:07<10:53:04, 15.21s/it]
{'loss': 1.0759, 'grad_norm': 0.16661801436036697, 'learning_rate': 0.00015646455660431552, 'epoch': 0.33}

 33%|███▎      | 1269/3844 [5:36:20<10:34:23, 14.78s/it]

 33%|███▎      | 1270/3844 [5:36:36<10:41:01, 14.94s/it]


 33%|███▎      | 1272/3844 [5:37:03<10:17:04, 14.40s/it]

 33%|███▎      | 1273/3844 [5:37:15<9:46:55, 13.70s/it]
{'loss': 1.2624, 'grad_norm': 0.17161306322779593, 'learning_rate': 0.00015611630135708028, 'epoch': 0.33}


 33%|███▎      | 1275/3844 [5:37:44<10:03:42, 14.10s/it]
{'loss': 1.1271, 'grad_norm': 0.17212770325007296, 'learning_rate': 0.0001559767199562101, 'epoch': 0.33}

 33%|███▎      | 1276/3844 [5:37:56<9:46:37, 13.71s/it]


 33%|███▎      | 1278/3844 [5:38:32<11:04:14, 15.53s/it]

 33%|███▎      | 1279/3844 [5:38:50<11:35:44, 16.27s/it]
{'loss': 1.0801, 'grad_norm': 0.15873885328176138, 'learning_rate': 0.00015569708053148027, 'epoch': 0.33}

 33%|███▎      | 1280/3844 [5:39:03<10:51:53, 15.25s/it]


 33%|███▎      | 1282/3844 [5:39:35<11:22:37, 15.99s/it]

 33%|███▎      | 1283/3844 [5:39:47<10:31:46, 14.80s/it]
{'loss': 1.0774, 'grad_norm': 0.1746389091934017, 'learning_rate': 0.00015541680825797966, 'epoch': 0.33}

 33%|███▎      | 1284/3844 [5:40:00<10:11:17, 14.33s/it]

 33%|███▎      | 1285/3844 [5:40:18<10:57:51, 15.42s/it]

 33%|███▎      | 1286/3844 [5:40:32<10:41:33, 15.05s/it]


 34%|███▎      | 1288/3844 [5:40:57<9:54:57, 13.97s/it]
{'loss': 1.1959, 'grad_norm': 0.16547677938786018, 'learning_rate': 0.0001550655828246599, 'epoch': 0.34}

 34%|███▎      | 1289/3844 [5:41:14<10:30:31, 14.81s/it]

 34%|███▎      | 1290/3844 [5:41:29<10:27:09, 14.73s/it]


 34%|███▎      | 1292/3844 [5:42:02<11:01:04, 15.54s/it]
{'loss': 1.1844, 'grad_norm': 0.1706878117075104, 'learning_rate': 0.00015478389829582057, 'epoch': 0.34}


 34%|███▎      | 1294/3844 [5:42:33<11:06:32, 15.68s/it]

 34%|███▎      | 1295/3844 [5:42:50<11:15:27, 15.90s/it]

 34%|███▎      | 1296/3844 [5:43:02<10:24:40, 14.71s/it]

 34%|███▎      | 1297/3844 [5:43:19<11:02:45, 15.61s/it]

 34%|███▍      | 1298/3844 [5:43:32<10:24:29, 14.72s/it]
{'loss': 1.0983, 'grad_norm': 0.17421045721248593, 'learning_rate': 0.00015436020536801278, 'epoch': 0.34}

 34%|███▍      | 1299/3844 [5:43:45<10:01:24, 14.18s/it]

 34%|███▍      | 1300/3844 [5:44:00<10:17:37, 14.57s/it]


 34%|███▍      | 1302/3844 [5:44:32<10:38:22, 15.07s/it]
{'loss': 0.9571, 'grad_norm': 0.1645426863606802, 'learning_rate': 0.00015407697067352225, 'epoch': 0.34}


 34%|███▍      | 1304/3844 [5:45:04<10:55:28, 15.48s/it]

 34%|███▍      | 1305/3844 [5:45:18<10:35:25, 15.02s/it]
{'loss': 1.1501, 'grad_norm': 0.17378489973983538, 'learning_rate': 0.00015386414124978935, 'epoch': 0.34}


 34%|███▍      | 1307/3844 [5:45:49<11:04:31, 15.72s/it]
{'loss': 1.0372, 'grad_norm': 0.1703321634300911, 'learning_rate': 0.00015372206362619407, 'epoch': 0.34}


 34%|███▍      | 1309/3844 [5:46:18<10:30:43, 14.93s/it]

 34%|███▍      | 1310/3844 [5:46:36<11:10:31, 15.88s/it]

 34%|███▍      | 1311/3844 [5:46:50<10:46:59, 15.33s/it]

 34%|███▍      | 1312/3844 [5:47:06<10:54:56, 15.52s/it]

 34%|███▍      | 1313/3844 [5:47:22<10:57:00, 15.58s/it]

 34%|███▍      | 1314/3844 [5:47:36<10:44:23, 15.28s/it]
{'loss': 1.141, 'grad_norm': 0.1794039048660968, 'learning_rate': 0.00015322359285448967, 'epoch': 0.34}

 34%|███▍      | 1315/3844 [5:47:53<10:56:27, 15.57s/it]

 34%|███▍      | 1316/3844 [5:48:05<10:12:54, 14.55s/it]

 34%|███▍      | 1317/3844 [5:48:21<10:32:33, 15.02s/it]

 34%|███▍      | 1318/3844 [5:48:37<10:51:04, 15.46s/it]


 34%|███▍      | 1320/3844 [5:49:06<10:14:50, 14.62s/it]
{'loss': 1.1306, 'grad_norm': 0.16883704015536105, 'learning_rate': 0.0001527948574728165, 'epoch': 0.34}


 34%|███▍      | 1322/3844 [5:49:40<11:03:45, 15.79s/it]
{'loss': 1.2636, 'grad_norm': 0.1614107710882444, 'learning_rate': 0.00015265164520064084, 'epoch': 0.34}

 34%|███▍      | 1323/3844 [5:50:03<12:36:09, 18.00s/it]

 34%|███▍      | 1324/3844 [5:50:21<12:32:57, 17.93s/it]

 34%|███▍      | 1325/3844 [5:50:39<12:38:09, 18.06s/it]


 35%|███▍      | 1327/3844 [5:51:08<11:24:48, 16.32s/it]
{'loss': 1.2676, 'grad_norm': 0.17260378505762733, 'learning_rate': 0.00015229296107963355, 'epoch': 0.35}

 35%|███▍      | 1328/3844 [5:51:23<11:02:44, 15.80s/it]

 35%|███▍      | 1329/3844 [5:51:39<11:02:14, 15.80s/it]

 35%|███▍      | 1330/3844 [5:51:56<11:13:54, 16.08s/it]

 35%|███▍      | 1331/3844 [5:52:11<11:02:38, 15.82s/it]


 35%|███▍      | 1333/3844 [5:52:43<11:05:03, 15.89s/it]
{'loss': 1.1298, 'grad_norm': 0.15950008611431027, 'learning_rate': 0.0001518613152209269, 'epoch': 0.35}

 35%|███▍      | 1334/3844 [5:52:58<10:51:38, 15.58s/it]


 35%|███▍      | 1336/3844 [5:53:26<10:22:15, 14.89s/it]
{'loss': 1.0936, 'grad_norm': 0.17995545773008034, 'learning_rate': 0.00015164499440835008, 'epoch': 0.35}

 35%|███▍      | 1337/3844 [5:53:41<10:22:11, 14.89s/it]


 35%|███▍      | 1339/3844 [5:54:18<11:41:05, 16.79s/it]
{'loss': 1.1107, 'grad_norm': 0.16536966278719684, 'learning_rate': 0.0001514283435163507, 'epoch': 0.35}


 35%|███▍      | 1341/3844 [5:54:52<11:54:15, 17.12s/it]

 35%|███▍      | 1342/3844 [5:55:04<10:45:36, 15.48s/it]
{'loss': 1.1387, 'grad_norm': 0.17446714409646186, 'learning_rate': 0.00015121136392961282, 'epoch': 0.35}


 35%|███▍      | 1344/3844 [5:55:33<10:23:36, 14.97s/it]
{'loss': 1.2454, 'grad_norm': 0.16819204847142555, 'learning_rate': 0.00015106652894834535, 'epoch': 0.35}

 35%|███▍      | 1345/3844 [5:55:49<10:41:50, 15.41s/it]

 35%|███▌      | 1346/3844 [5:56:08<11:18:35, 16.30s/it]

 35%|███▌      | 1347/3844 [5:56:20<10:25:51, 15.04s/it]


 35%|███▌      | 1349/3844 [5:56:52<11:02:53, 15.94s/it]

 35%|███▌      | 1350/3844 [5:57:08<11:00:23, 15.89s/it]

 35%|███▌      | 1351/3844 [5:57:27<11:31:21, 16.64s/it]

 35%|███▌      | 1352/3844 [5:57:41<11:02:15, 15.95s/it]
{'loss': 1.1998, 'grad_norm': 0.17271238924999152, 'learning_rate': 0.0001504857425553249, 'epoch': 0.35}

 35%|███▌      | 1353/3844 [5:57:56<10:52:31, 15.72s/it]


 35%|███▌      | 1355/3844 [5:58:29<11:05:52, 16.05s/it]
{'loss': 1.0184, 'grad_norm': 0.16927944728442434, 'learning_rate': 0.00015026735467658258, 'epoch': 0.35}


 35%|███▌      | 1357/3844 [5:58:59<10:35:45, 15.34s/it]
{'loss': 1.0774, 'grad_norm': 0.16443833358896157, 'learning_rate': 0.00015012158418534725, 'epoch': 0.35}


 35%|███▌      | 1359/3844 [5:59:27<10:02:18, 14.54s/it]
{'loss': 1.1285, 'grad_norm': 0.1756878110064814, 'learning_rate': 0.00014997567131947953, 'epoch': 0.35}

 35%|███▌      | 1360/3844 [5:59:40<9:37:17, 13.94s/it]


 35%|███▌      | 1362/3844 [6:00:13<10:29:12, 15.21s/it]
{'loss': 0.9658, 'grad_norm': 0.15219131828083277, 'learning_rate': 0.00014975653597502298, 'epoch': 0.35}

 35%|███▌      | 1363/3844 [6:00:28<10:20:24, 15.00s/it]

 35%|███▌      | 1364/3844 [6:00:44<10:34:33, 15.35s/it]


 36%|███▌      | 1366/3844 [6:01:15<10:31:57, 15.30s/it]

 36%|███▌      | 1367/3844 [6:01:27<10:00:40, 14.55s/it]
{'loss': 1.2318, 'grad_norm': 0.17723980265860967, 'learning_rate': 0.00014939060440528502, 'epoch': 0.36}


 36%|███▌      | 1369/3844 [6:01:57<10:01:09, 14.57s/it]
{'loss': 1.223, 'grad_norm': 0.1663415057741622, 'learning_rate': 0.00014924398589147167, 'epoch': 0.36}


 36%|███▌      | 1371/3844 [6:02:31<11:07:38, 16.20s/it]

 36%|███▌      | 1372/3844 [6:02:47<11:01:11, 16.05s/it]

 36%|███▌      | 1373/3844 [6:02:59<10:13:13, 14.89s/it]

 36%|███▌      | 1374/3844 [6:03:14<10:06:26, 14.73s/it]

 36%|███▌      | 1375/3844 [6:03:27<9:49:31, 14.33s/it]
{'loss': 1.2502, 'grad_norm': 0.16912222492900034, 'learning_rate': 0.00014880329272750874, 'epoch': 0.36}

 36%|███▌      | 1376/3844 [6:03:42<9:59:18, 14.57s/it]


 36%|███▌      | 1378/3844 [6:04:13<10:16:31, 15.00s/it]

 36%|███▌      | 1379/3844 [6:04:31<10:50:02, 15.82s/it]

 36%|███▌      | 1380/3844 [6:04:45<10:29:32, 15.33s/it]
{'loss': 1.1115, 'grad_norm': 0.1700444905918135, 'learning_rate': 0.0001484350948662703, 'epoch': 0.36}

 36%|███▌      | 1381/3844 [6:04:58<10:04:50, 14.73s/it]

 36%|███▌      | 1382/3844 [6:05:16<10:44:54, 15.72s/it]


 36%|███▌      | 1384/3844 [6:05:47<10:30:04, 15.37s/it]

 36%|███▌      | 1385/3844 [6:06:06<11:10:40, 16.36s/it]

 36%|███▌      | 1386/3844 [6:06:24<11:30:25, 16.85s/it]

 36%|███▌      | 1387/3844 [6:06:42<11:44:35, 17.21s/it]
{'loss': 1.1308, 'grad_norm': 0.17271456718890416, 'learning_rate': 0.00014791817469733052, 'epoch': 0.36}


 36%|███▌      | 1389/3844 [6:07:15<11:38:54, 17.08s/it]
[2024-05-27 07:17:53,486] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 36%|███▌      | 1390/3844 [6:07:29<10:55:52, 16.04s/it]

 36%|███▌      | 1391/3844 [6:07:46<11:02:32, 16.21s/it]
{'loss': 1.1264, 'grad_norm': 0.1605859818437789, 'learning_rate': 0.00014762204195340996, 'epoch': 0.36}


 36%|███▌      | 1393/3844 [6:08:22<11:20:20, 16.65s/it]

 36%|███▋      | 1394/3844 [6:08:36<10:55:40, 16.06s/it]
{'loss': 1.1914, 'grad_norm': 0.16703971364861395, 'learning_rate': 0.00014739958711599717, 'epoch': 0.36}


 36%|███▋      | 1396/3844 [6:09:04<10:10:53, 14.97s/it]

 36%|███▋      | 1397/3844 [6:09:20<10:29:28, 15.43s/it]

 36%|███▋      | 1398/3844 [6:09:36<10:29:54, 15.45s/it]
{'loss': 0.9317, 'grad_norm': 0.17237314225239278, 'learning_rate': 0.00014710250966328461, 'epoch': 0.36}


 36%|███▋      | 1400/3844 [6:10:04<10:10:14, 14.98s/it]
{'loss': 1.1765, 'grad_norm': 0.1675741497934335, 'learning_rate': 0.00014695377002782375, 'epoch': 0.36}


 36%|███▋      | 1402/3844 [6:10:38<10:32:19, 15.54s/it]
{'loss': 1.0881, 'grad_norm': 0.1780933385662466, 'learning_rate': 0.00014680489701617667, 'epoch': 0.36}


 37%|███▋      | 1404/3844 [6:11:08<10:17:38, 15.19s/it]

 37%|███▋      | 1405/3844 [6:11:26<11:00:39, 16.25s/it]

 37%|███▋      | 1406/3844 [6:11:45<11:36:43, 17.15s/it]

 37%|███▋      | 1407/3844 [6:12:00<11:02:02, 16.30s/it]
{'loss': 1.0492, 'grad_norm': 0.17734317253097373, 'learning_rate': 0.00014643213374236573, 'epoch': 0.37}


 37%|███▋      | 1409/3844 [6:12:34<11:06:55, 16.43s/it]
{'loss': 1.124, 'grad_norm': 0.17403717186731862, 'learning_rate': 0.00014628279724677326, 'epoch': 0.37}

 37%|███▋      | 1410/3844 [6:12:47<10:27:33, 15.47s/it]


 37%|███▋      | 1412/3844 [6:13:18<10:27:20, 15.48s/it]

 37%|███▋      | 1413/3844 [6:13:38<11:32:07, 17.08s/it]
{'loss': 1.1364, 'grad_norm': 0.15891873103151816, 'learning_rate': 0.0001459837302694722, 'epoch': 0.37}


 37%|███▋      | 1415/3844 [6:14:06<10:17:44, 15.26s/it]

 37%|███▋      | 1416/3844 [6:14:22<10:32:09, 15.62s/it]
{'loss': 1.0924, 'grad_norm': 0.16896941027816073, 'learning_rate': 0.00014575908697133058, 'epoch': 0.37}


 37%|███▋      | 1418/3844 [6:14:52<10:16:12, 15.24s/it]
{'loss': 1.0297, 'grad_norm': 0.17368297717947975, 'learning_rate': 0.000145609162205679, 'epoch': 0.37}

 37%|███▋      | 1419/3844 [6:15:07<10:16:52, 15.26s/it]

 37%|███▋      | 1420/3844 [6:15:21<9:57:42, 14.79s/it]

 37%|███▋      | 1421/3844 [6:15:37<10:18:52, 15.32s/it]


 37%|███▋      | 1423/3844 [6:16:12<11:04:54, 16.48s/it]
{'loss': 1.1403, 'grad_norm': 0.1559546397169529, 'learning_rate': 0.00014523378441343515, 'epoch': 0.37}


 37%|███▋      | 1425/3844 [6:16:36<9:32:29, 14.20s/it]

 37%|███▋      | 1426/3844 [6:16:48<9:00:25, 13.41s/it]

 37%|███▋      | 1427/3844 [6:17:04<9:34:43, 14.27s/it]

 37%|███▋      | 1428/3844 [6:17:17<9:13:31, 13.75s/it]
{'loss': 0.959, 'grad_norm': 0.17973398649654632, 'learning_rate': 0.00014485760355706123, 'epoch': 0.37}


 37%|███▋      | 1430/3844 [6:17:44<9:13:09, 13.75s/it]
{'loss': 1.0748, 'grad_norm': 0.15895332518863442, 'learning_rate': 0.00014470690785208033, 'epoch': 0.37}


 37%|███▋      | 1432/3844 [6:18:11<9:10:11, 13.69s/it]
{'loss': 1.1233, 'grad_norm': 0.16783660949207235, 'learning_rate': 0.00014455608515331675, 'epoch': 0.37}


 37%|███▋      | 1434/3844 [6:18:40<9:21:08, 13.97s/it]

 37%|███▋      | 1435/3844 [6:18:52<9:00:52, 13.47s/it]

 37%|███▋      | 1436/3844 [6:19:04<8:42:43, 13.02s/it]
{'loss': 1.1651, 'grad_norm': 0.16709118396797995, 'learning_rate': 0.0001442540604884999, 'epoch': 0.37}

 37%|███▋      | 1437/3844 [6:19:18<8:47:32, 13.15s/it]

 37%|███▋      | 1438/3844 [6:19:29<8:26:44, 12.64s/it]


 37%|███▋      | 1440/3844 [6:19:59<9:03:46, 13.57s/it]

 37%|███▋      | 1441/3844 [6:20:09<8:22:46, 12.55s/it]
{'loss': 1.0995, 'grad_norm': 0.16402651566647306, 'learning_rate': 0.00014387582295637808, 'epoch': 0.37}


 38%|███▊      | 1443/3844 [6:20:35<8:26:07, 12.65s/it]
{'loss': 1.1038, 'grad_norm': 0.1624692034901262, 'learning_rate': 0.00014372430945951272, 'epoch': 0.38}

 38%|███▊      | 1444/3844 [6:20:51<9:11:37, 13.79s/it]

 38%|███▊      | 1445/3844 [6:21:06<9:20:32, 14.02s/it]

 38%|███▊      | 1446/3844 [6:21:18<8:50:26, 13.27s/it]


 38%|███▊      | 1448/3844 [6:21:43<8:40:06, 13.02s/it]
{'loss': 1.1588, 'grad_norm': 0.17273009869542033, 'learning_rate': 0.00014334498327319036, 'epoch': 0.38}


 38%|███▊      | 1450/3844 [6:22:09<8:44:35, 13.15s/it]
{'loss': 1.1744, 'grad_norm': 0.15763546582867533, 'learning_rate': 0.00014319303695238168, 'epoch': 0.38}

 38%|███▊      | 1451/3844 [6:22:23<8:48:40, 13.26s/it]


 38%|███▊      | 1453/3844 [6:22:45<8:04:24, 12.16s/it]

 38%|███▊      | 1454/3844 [6:22:55<7:41:12, 11.58s/it]
{'loss': 1.1609, 'grad_norm': 0.16888009075401983, 'learning_rate': 0.0001428887766622192, 'epoch': 0.38}

 38%|███▊      | 1455/3844 [6:23:07<7:39:53, 11.55s/it]


 38%|███▊      | 1457/3844 [6:23:29<7:34:32, 11.43s/it]
{'loss': 1.0081, 'grad_norm': 0.16624835194586962, 'learning_rate': 0.00014266026145383687, 'epoch': 0.38}

 38%|███▊      | 1458/3844 [6:23:43<8:01:36, 12.11s/it]

 38%|███▊      | 1459/3844 [6:23:55<8:08:28, 12.29s/it]


 38%|███▊      | 1461/3844 [6:24:17<7:42:12, 11.64s/it]

 38%|███▊      | 1462/3844 [6:24:31<8:12:38, 12.41s/it]
{'loss': 1.1187, 'grad_norm': 0.17034127866233828, 'learning_rate': 0.00014227879759486317, 'epoch': 0.38}


 38%|███▊      | 1464/3844 [6:24:59<8:43:34, 13.20s/it]

 38%|███▊      | 1464/3844 [6:25:00<8:43:34, 13.20s/it]

 38%|███▊      | 1465/3844 [6:25:10<8:08:02, 12.31s/it]

 38%|███▊      | 1466/3844 [6:25:20<7:47:49, 11.80s/it]

 38%|███▊      | 1467/3844 [6:25:34<8:05:01, 12.24s/it]

 38%|███▊      | 1468/3844 [6:25:49<8:36:35, 13.05s/it]


 38%|███▊      | 1470/3844 [6:26:13<8:17:19, 12.57s/it]

 38%|███▊      | 1471/3844 [6:26:23<7:43:52, 11.73s/it]

 38%|███▊      | 1472/3844 [6:26:33<7:26:30, 11.29s/it]
{'loss': 1.1437, 'grad_norm': 0.17064146515937806, 'learning_rate': 0.00014151362485550033, 'epoch': 0.38}

 38%|███▊      | 1473/3844 [6:26:46<7:40:02, 11.64s/it]

 38%|███▊      | 1474/3844 [6:27:01<8:19:39, 12.65s/it]

 38%|███▊      | 1475/3844 [6:27:12<8:05:47, 12.30s/it]

 38%|███▊      | 1476/3844 [6:27:23<7:42:57, 11.73s/it]

 38%|███▊      | 1477/3844 [6:27:34<7:41:38, 11.70s/it]


 38%|███▊      | 1479/3844 [6:27:58<7:32:28, 11.48s/it]

 39%|███▊      | 1480/3844 [6:28:11<7:58:40, 12.15s/it]

 39%|███▊      | 1481/3844 [6:28:23<7:58:20, 12.15s/it]
{'loss': 1.0501, 'grad_norm': 0.16161102374320052, 'learning_rate': 0.00014082244724749856, 'epoch': 0.39}

 39%|███▊      | 1482/3844 [6:28:35<7:47:15, 11.87s/it]


 39%|███▊      | 1484/3844 [6:29:00<7:53:54, 12.05s/it]
{'loss': 1.0534, 'grad_norm': 0.1627554376914324, 'learning_rate': 0.0001405915309282373, 'epoch': 0.39}

 39%|███▊      | 1485/3844 [6:29:14<8:25:01, 12.85s/it]

 39%|███▊      | 1486/3844 [6:29:28<8:39:19, 13.21s/it]

 39%|███▊      | 1487/3844 [6:29:41<8:27:56, 12.93s/it]


 39%|███▊      | 1489/3844 [6:30:00<7:19:47, 11.20s/it]

 39%|███▉      | 1490/3844 [6:30:14<7:49:53, 11.98s/it]
{'loss': 1.0866, 'grad_norm': 0.15895115026713144, 'learning_rate': 0.0001401289214674618, 'epoch': 0.39}


 39%|███▉      | 1492/3844 [6:30:40<8:13:29, 12.59s/it]
{'loss': 1.1492, 'grad_norm': 0.15699028829139297, 'learning_rate': 0.00013997448975026382, 'epoch': 0.39}


 39%|███▉      | 1494/3844 [6:31:06<8:16:32, 12.68s/it]
{'loss': 1.0007, 'grad_norm': 0.16048186788494054, 'learning_rate': 0.00013981994448212016, 'epoch': 0.39}


 39%|███▉      | 1496/3844 [6:31:32<8:31:06, 13.06s/it]
{'loss': 1.0991, 'grad_norm': 0.15124155777090648, 'learning_rate': 0.00013966528610202982, 'epoch': 0.39}


 39%|███▉      | 1498/3844 [6:31:58<8:23:41, 12.88s/it]
{'loss': 1.1053, 'grad_norm': 0.1663665345872835, 'learning_rate': 0.00013951051504931312, 'epoch': 0.39}


 39%|███▉      | 1500/3844 [6:32:28<9:11:26, 14.12s/it]
 39%|███▉      | 1500/3844 [6:32:28<9:11:26, 14.12s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.2889, 'grad_norm': 0.17006119776455786, 'learning_rate': 0.00013927814817086412, 'epoch': 0.39}
 39%|███▉      | 1501/3844 [6:32:59<12:35:44, 19.35s/it]

 39%|███▉      | 1502/3844 [6:33:11<11:06:05, 17.06s/it]

 39%|███▉      | 1503/3844 [6:33:21<9:42:21, 14.93s/it]


 39%|███▉      | 1505/3844 [6:33:42<8:11:34, 12.61s/it]
{'loss': 1.0704, 'grad_norm': 0.16328845961906652, 'learning_rate': 0.00013896793541805322, 'epoch': 0.39}


 39%|███▉      | 1507/3844 [6:34:08<8:23:16, 12.92s/it]
{'loss': 1.0531, 'grad_norm': 0.1752442574974446, 'learning_rate': 0.00013881266278365894, 'epoch': 0.39}


 39%|███▉      | 1509/3844 [6:34:32<8:10:14, 12.60s/it]
{'loss': 1.0773, 'grad_norm': 0.17692983124992626, 'learning_rate': 0.00013865727989858747, 'epoch': 0.39}

 39%|███▉      | 1510/3844 [6:34:44<8:11:15, 12.63s/it]

 39%|███▉      | 1511/3844 [6:35:00<8:47:58, 13.58s/it]

 39%|███▉      | 1512/3844 [6:35:11<8:19:36, 12.85s/it]

 39%|███▉      | 1513/3844 [6:35:23<7:59:12, 12.33s/it]

 39%|███▉      | 1514/3844 [6:35:33<7:34:56, 11.72s/it]

 39%|███▉      | 1515/3844 [6:35:43<7:14:00, 11.18s/it]

 39%|███▉      | 1516/3844 [6:35:55<7:29:53, 11.60s/it]

 39%|███▉      | 1517/3844 [6:36:07<7:25:52, 11.50s/it]

 39%|███▉      | 1518/3844 [6:36:18<7:29:22, 11.59s/it]


 40%|███▉      | 1520/3844 [6:36:46<8:25:39, 13.05s/it]
{'loss': 0.9407, 'grad_norm': 0.16423555344350924, 'learning_rate': 0.00013780072303957197, 'epoch': 0.4}

 40%|███▉      | 1521/3844 [6:36:59<8:21:16, 12.95s/it]


 40%|███▉      | 1523/3844 [6:37:22<7:57:33, 12.35s/it]
{'loss': 1.0247, 'grad_norm': 0.16896288330652195, 'learning_rate': 0.00013756654979905114, 'epoch': 0.4}


 40%|███▉      | 1525/3844 [6:37:48<8:13:40, 12.77s/it]
{'loss': 1.1199, 'grad_norm': 0.18358264510159863, 'learning_rate': 0.0001374103008242257, 'epoch': 0.4}

 40%|███▉      | 1526/3844 [6:37:59<7:44:10, 12.01s/it]

 40%|███▉      | 1527/3844 [6:38:12<7:57:43, 12.37s/it]


 40%|███▉      | 1529/3844 [6:38:34<7:36:48, 11.84s/it]
{'loss': 1.0208, 'grad_norm': 0.1652556351964382, 'learning_rate': 0.0001370974845172699, 'epoch': 0.4}

 40%|███▉      | 1530/3844 [6:38:46<7:33:52, 11.77s/it]

 40%|███▉      | 1531/3844 [6:38:59<7:49:53, 12.19s/it]

 40%|███▉      | 1532/3844 [6:39:09<7:25:43, 11.57s/it]


 40%|███▉      | 1534/3844 [6:39:32<7:22:18, 11.49s/it]

 40%|███▉      | 1535/3844 [6:39:42<7:04:37, 11.03s/it]
{'loss': 0.9561, 'grad_norm': 0.15618456921055823, 'learning_rate': 0.00013662747083018095, 'epoch': 0.4}

 40%|███▉      | 1536/3844 [6:39:53<7:11:27, 11.22s/it]

 40%|███▉      | 1537/3844 [6:40:05<7:15:19, 11.32s/it]

 40%|████      | 1538/3844 [6:40:17<7:17:41, 11.39s/it]


 40%|████      | 1540/3844 [6:40:44<8:07:48, 12.70s/it]

 40%|████      | 1541/3844 [6:40:58<8:22:19, 13.09s/it]

 40%|████      | 1542/3844 [6:41:12<8:31:38, 13.34s/it]
{'loss': 0.9875, 'grad_norm': 0.18009541354959183, 'learning_rate': 0.00013607793888158887, 'epoch': 0.4}


 40%|████      | 1544/3844 [6:41:33<7:27:51, 11.68s/it]
{'loss': 1.1457, 'grad_norm': 0.1633325658771585, 'learning_rate': 0.00013592069833115594, 'epoch': 0.4}


 40%|████      | 1546/3844 [6:41:56<7:37:33, 11.95s/it]
{'loss': 1.142, 'grad_norm': 0.16235072927058866, 'learning_rate': 0.00013576335574491742, 'epoch': 0.4}

 40%|████      | 1547/3844 [6:42:07<7:19:50, 11.49s/it]
[2024-05-27 07:53:03,154] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 40%|████      | 1549/3844 [6:42:36<8:09:03, 12.79s/it]

 40%|████      | 1550/3844 [6:42:48<7:59:32, 12.54s/it]
{'loss': 1.1421, 'grad_norm': 0.16261253893201064, 'learning_rate': 0.00013544836625309226, 'epoch': 0.4}


 40%|████      | 1552/3844 [6:43:16<8:34:42, 13.47s/it]
{'loss': 1.0669, 'grad_norm': 0.16700685232345272, 'learning_rate': 0.0001352907202422601, 'epoch': 0.4}

 40%|████      | 1553/3844 [6:43:31<8:55:24, 14.02s/it]

 40%|████      | 1554/3844 [6:43:42<8:13:45, 12.94s/it]

 40%|████      | 1555/3844 [6:43:55<8:15:42, 12.99s/it]

 40%|████      | 1556/3844 [6:44:05<7:43:17, 12.15s/it]

 41%|████      | 1557/3844 [6:44:19<8:04:12, 12.70s/it]

 41%|████      | 1558/3844 [6:44:29<7:31:34, 11.85s/it]


 41%|████      | 1560/3844 [6:44:54<7:41:16, 12.12s/it]

 41%|████      | 1561/3844 [6:45:05<7:20:41, 11.58s/it]

 41%|████      | 1562/3844 [6:45:15<7:04:22, 11.16s/it]
{'loss': 0.9748, 'grad_norm': 0.1671270190964243, 'learning_rate': 0.0001345009954596908, 'epoch': 0.41}


 41%|████      | 1564/3844 [6:45:36<6:57:52, 11.00s/it]
{'loss': 1.0924, 'grad_norm': 0.17513832742665095, 'learning_rate': 0.00013434275469808974, 'epoch': 0.41}


 41%|████      | 1566/3844 [6:46:04<7:51:51, 12.43s/it]

 41%|████      | 1567/3844 [6:46:15<7:26:04, 11.75s/it]
{'loss': 1.0363, 'grad_norm': 0.15812069566804113, 'learning_rate': 0.00013410521078337752, 'epoch': 0.41}


 41%|████      | 1569/3844 [6:46:36<7:10:30, 11.35s/it]
{'loss': 1.1044, 'grad_norm': 0.16315222480851116, 'learning_rate': 0.0001339467269813825, 'epoch': 0.41}


 41%|████      | 1571/3844 [6:46:57<6:46:10, 10.72s/it]
{'loss': 1.1558, 'grad_norm': 0.15919619737627402, 'learning_rate': 0.00013378814675081582, 'epoch': 0.41}

 41%|████      | 1572/3844 [6:47:08<6:51:09, 10.86s/it]

 41%|████      | 1573/3844 [6:47:21<7:19:39, 11.62s/it]

 41%|████      | 1574/3844 [6:47:32<7:10:33, 11.38s/it]

 41%|████      | 1575/3844 [6:47:44<7:19:55, 11.63s/it]

 41%|████      | 1576/3844 [6:48:01<8:23:37, 13.32s/it]

 41%|████      | 1577/3844 [6:48:13<8:04:17, 12.82s/it]

 41%|████      | 1578/3844 [6:48:23<7:34:20, 12.03s/it]

 41%|████      | 1579/3844 [6:48:40<8:31:16, 13.54s/it]

 41%|████      | 1580/3844 [6:48:50<7:50:51, 12.48s/it]

 41%|████      | 1581/3844 [6:49:01<7:34:23, 12.05s/it]

 41%|████      | 1582/3844 [6:49:12<7:17:05, 11.59s/it]

 41%|████      | 1583/3844 [6:49:21<6:53:44, 10.98s/it]

 41%|████      | 1584/3844 [6:49:32<6:48:25, 10.84s/it]

 41%|████      | 1585/3844 [6:49:43<6:54:41, 11.01s/it]


 41%|████▏     | 1587/3844 [6:50:09<7:30:33, 11.98s/it]
{'loss': 1.1537, 'grad_norm': 0.16019983509752822, 'learning_rate': 0.00013251608758991018, 'epoch': 0.41}


 41%|████▏     | 1589/3844 [6:50:33<7:24:54, 11.84s/it]
{'loss': 1.0843, 'grad_norm': 0.1665426163358603, 'learning_rate': 0.0001323566598053749, 'epoch': 0.41}

 41%|████▏     | 1590/3844 [6:50:46<7:44:11, 12.36s/it]

 41%|████▏     | 1591/3844 [6:51:00<8:00:43, 12.80s/it]

 41%|████▏     | 1592/3844 [6:51:18<8:58:05, 14.34s/it]


 41%|████▏     | 1594/3844 [6:51:39<7:45:34, 12.42s/it]

 41%|████▏     | 1595/3844 [6:51:51<7:36:15, 12.17s/it]
{'loss': 1.0761, 'grad_norm': 0.16567054733265568, 'learning_rate': 0.00013187782679344377, 'epoch': 0.41}


 42%|████▏     | 1597/3844 [6:52:13<7:15:38, 11.63s/it]

 42%|████▏     | 1598/3844 [6:52:23<6:57:42, 11.16s/it]
{'loss': 1.1694, 'grad_norm': 0.1747479028245328, 'learning_rate': 0.00013163810391021277, 'epoch': 0.42}


 42%|████▏     | 1600/3844 [6:52:47<7:19:13, 11.74s/it]

 42%|████▏     | 1601/3844 [6:52:59<7:28:15, 11.99s/it]

 42%|████▏     | 1602/3844 [6:53:09<7:00:56, 11.27s/it]

 42%|████▏     | 1603/3844 [6:53:19<6:47:27, 10.91s/it]
{'loss': 1.1709, 'grad_norm': 0.17490458802882616, 'learning_rate': 0.0001312381171751718, 'epoch': 0.42}

 42%|████▏     | 1604/3844 [6:53:34<7:33:23, 12.14s/it]

 42%|████▏     | 1605/3844 [6:53:46<7:28:10, 12.01s/it]

 42%|████▏     | 1606/3844 [6:53:56<7:09:18, 11.51s/it]


 42%|████▏     | 1608/3844 [6:54:21<7:26:24, 11.98s/it]

 42%|████▏     | 1609/3844 [6:54:31<7:00:11, 11.28s/it]

 42%|████▏     | 1610/3844 [6:54:45<7:30:41, 12.10s/it]

 42%|████▏     | 1611/3844 [6:54:55<7:08:43, 11.52s/it]

 42%|████▏     | 1612/3844 [6:55:07<7:14:09, 11.67s/it]
{'loss': 1.1283, 'grad_norm': 0.16941844878681564, 'learning_rate': 0.00013051674826322176, 'epoch': 0.42}


 42%|████▏     | 1614/3844 [6:55:29<7:03:40, 11.40s/it]
{'loss': 1.0653, 'grad_norm': 0.15849987713189284, 'learning_rate': 0.0001303562042138099, 'epoch': 0.42}

 42%|████▏     | 1615/3844 [6:55:40<7:02:56, 11.38s/it]


 42%|████▏     | 1617/3844 [6:56:12<8:22:11, 13.53s/it]
{'loss': 1.172, 'grad_norm': 0.16145468452015718, 'learning_rate': 0.00013011522660217304, 'epoch': 0.42}


 42%|████▏     | 1619/3844 [6:56:39<8:27:25, 13.68s/it]
{'loss': 1.0099, 'grad_norm': 0.1682205559147692, 'learning_rate': 0.00012995446783490558, 'epoch': 0.42}


 42%|████▏     | 1621/3844 [6:57:01<7:37:52, 12.36s/it]
{'loss': 1.2066, 'grad_norm': 0.16512331662940616, 'learning_rate': 0.0001297936239794187, 'epoch': 0.42}


 42%|████▏     | 1623/3844 [6:57:27<7:56:45, 12.88s/it]
{'loss': 0.9877, 'grad_norm': 0.16153566127555222, 'learning_rate': 0.00012963269549260334, 'epoch': 0.42}


 42%|████▏     | 1625/3844 [6:57:53<7:51:14, 12.74s/it]

 42%|████▏     | 1626/3844 [6:58:03<7:20:17, 11.91s/it]
{'loss': 1.1386, 'grad_norm': 0.1794871012975043, 'learning_rate': 0.00012939114507867872, 'epoch': 0.42}


 42%|████▏     | 1628/3844 [6:58:25<6:58:28, 11.33s/it]
{'loss': 1.123, 'grad_norm': 0.16364640211540668, 'learning_rate': 0.00012923000701401297, 'epoch': 0.42}

 42%|████▏     | 1629/3844 [6:58:36<6:59:02, 11.35s/it]

 42%|████▏     | 1630/3844 [6:58:46<6:40:45, 10.86s/it]

 42%|████▏     | 1631/3844 [6:58:58<6:54:03, 11.23s/it]

 42%|████▏     | 1632/3844 [6:59:10<7:00:51, 11.42s/it]

 42%|████▏     | 1633/3844 [6:59:24<7:26:35, 12.12s/it]


 43%|████▎     | 1635/3844 [6:59:53<8:14:13, 13.42s/it]
{'loss': 0.9776, 'grad_norm': 0.15613862419572513, 'learning_rate': 0.00012866537292981515, 'epoch': 0.43}


 43%|████▎     | 1637/3844 [7:00:22<8:23:37, 13.69s/it]
{'loss': 0.9735, 'grad_norm': 0.15097093245166518, 'learning_rate': 0.00012850386483666864, 'epoch': 0.43}

 43%|████▎     | 1638/3844 [7:00:33<7:56:40, 12.96s/it]


 43%|████▎     | 1640/3844 [7:00:53<7:06:59, 11.62s/it]

 43%|████▎     | 1641/3844 [7:01:03<6:48:35, 11.13s/it]

 43%|████▎     | 1642/3844 [7:01:15<6:58:02, 11.39s/it]
{'loss': 0.9579, 'grad_norm': 0.16325241376174573, 'learning_rate': 0.00012809974137444088, 'epoch': 0.43}

 43%|████▎     | 1643/3844 [7:01:27<7:02:08, 11.51s/it]


 43%|████▎     | 1645/3844 [7:01:57<8:09:27, 13.36s/it]

 43%|████▎     | 1646/3844 [7:02:09<7:53:36, 12.93s/it]
{'loss': 1.019, 'grad_norm': 0.16963934413201964, 'learning_rate': 0.00012777608307172465, 'epoch': 0.43}

 43%|████▎     | 1647/3844 [7:02:23<7:56:06, 13.00s/it]

 43%|████▎     | 1648/3844 [7:02:33<7:27:04, 12.22s/it]

 43%|████▎     | 1649/3844 [7:02:42<6:56:27, 11.38s/it]

 43%|████▎     | 1650/3844 [7:02:57<7:30:58, 12.33s/it]

 43%|████▎     | 1651/3844 [7:03:07<7:08:02, 11.71s/it]


 43%|████▎     | 1653/3844 [7:03:33<7:27:20, 12.25s/it]
{'loss': 1.233, 'grad_norm': 0.17348133178932543, 'learning_rate': 0.00012720892384109574, 'epoch': 0.43}

 43%|████▎     | 1654/3844 [7:03:43<6:56:20, 11.41s/it]

 43%|████▎     | 1655/3844 [7:03:54<6:55:46, 11.40s/it]

 43%|████▎     | 1656/3844 [7:04:07<7:10:10, 11.80s/it]

 43%|████▎     | 1657/3844 [7:04:18<7:03:24, 11.62s/it]


 43%|████▎     | 1659/3844 [7:04:42<7:02:36, 11.60s/it]
{'loss': 1.1371, 'grad_norm': 0.16301439700277642, 'learning_rate': 0.00012672203304045954, 'epoch': 0.43}

 43%|████▎     | 1660/3844 [7:04:52<6:51:52, 11.32s/it]

 43%|████▎     | 1661/3844 [7:05:03<6:41:16, 11.03s/it]

 43%|████▎     | 1662/3844 [7:05:17<7:13:46, 11.93s/it]


 43%|████▎     | 1664/3844 [7:05:42<7:28:43, 12.35s/it]
{'loss': 0.9796, 'grad_norm': 0.15810334429227135, 'learning_rate': 0.0001263157683235955, 'epoch': 0.43}

 43%|████▎     | 1665/3844 [7:05:54<7:28:22, 12.35s/it]

 43%|████▎     | 1666/3844 [7:06:06<7:13:48, 11.95s/it]

 43%|████▎     | 1667/3844 [7:06:17<7:08:18, 11.80s/it]

 43%|████▎     | 1668/3844 [7:06:26<6:42:35, 11.10s/it]

 43%|████▎     | 1669/3844 [7:06:37<6:35:28, 10.91s/it]

 43%|████▎     | 1670/3844 [7:06:51<7:11:41, 11.91s/it]


 43%|████▎     | 1672/3844 [7:07:18<7:37:09, 12.63s/it]

 44%|████▎     | 1673/3844 [7:07:28<7:06:43, 11.79s/it]

 44%|████▎     | 1674/3844 [7:07:38<6:47:03, 11.26s/it]

 44%|████▎     | 1675/3844 [7:07:48<6:33:05, 10.87s/it]
{'loss': 1.0917, 'grad_norm': 0.16510481612462077, 'learning_rate': 0.0001254203515682114, 'epoch': 0.44}

 44%|████▎     | 1676/3844 [7:07:58<6:19:20, 10.50s/it]

 44%|████▎     | 1677/3844 [7:08:14<7:19:19, 12.16s/it]


 44%|████▎     | 1679/3844 [7:08:36<7:01:50, 11.69s/it]
{'loss': 1.15, 'grad_norm': 0.1729933093491567, 'learning_rate': 0.00012509419986166603, 'epoch': 0.44}

 44%|████▎     | 1680/3844 [7:08:49<7:15:23, 12.07s/it]

 44%|████▎     | 1681/3844 [7:09:00<7:08:35, 11.89s/it]

 44%|████▍     | 1682/3844 [7:09:11<6:53:13, 11.47s/it]

 44%|████▍     | 1683/3844 [7:09:27<7:46:34, 12.95s/it]

 44%|████▍     | 1684/3844 [7:09:37<7:10:12, 11.95s/it]

 44%|████▍     | 1685/3844 [7:09:47<6:49:18, 11.38s/it]


 44%|████▍     | 1687/3844 [7:10:12<7:21:52, 12.29s/it]
{'loss': 1.0941, 'grad_norm': 0.1680741348591297, 'learning_rate': 0.00012444104477170103, 'epoch': 0.44}

 44%|████▍     | 1688/3844 [7:10:23<7:08:08, 11.91s/it]

 44%|████▍     | 1689/3844 [7:10:39<7:52:29, 13.16s/it]


 44%|████▍     | 1691/3844 [7:11:02<7:25:35, 12.42s/it]

 44%|████▍     | 1692/3844 [7:11:13<6:59:51, 11.71s/it]
{'loss': 1.0072, 'grad_norm': 0.1694777857301223, 'learning_rate': 0.00012403225686270384, 'epoch': 0.44}


 44%|████▍     | 1694/3844 [7:11:34<6:41:57, 11.22s/it]
{'loss': 1.0469, 'grad_norm': 0.18179145301515087, 'learning_rate': 0.00012386862182764925, 'epoch': 0.44}

 44%|████▍     | 1695/3844 [7:11:45<6:37:17, 11.09s/it]

 44%|████▍     | 1696/3844 [7:11:55<6:32:06, 10.95s/it]

 44%|████▍     | 1697/3844 [7:12:10<7:08:37, 11.98s/it]

 44%|████▍     | 1698/3844 [7:12:23<7:23:48, 12.41s/it]

 44%|████▍     | 1699/3844 [7:12:35<7:18:43, 12.27s/it]


 44%|████▍     | 1701/3844 [7:12:58<6:56:18, 11.66s/it]
{'loss': 1.2821, 'grad_norm': 0.17242635898348238, 'learning_rate': 0.0001232953683253363, 'epoch': 0.44}


 44%|████▍     | 1703/3844 [7:13:20<6:49:03, 11.46s/it]
{'loss': 1.0673, 'grad_norm': 0.1792180597887004, 'learning_rate': 0.00012313143184965487, 'epoch': 0.44}

 44%|████▍     | 1704/3844 [7:13:31<6:45:46, 11.38s/it]

 44%|████▍     | 1705/3844 [7:13:42<6:32:28, 11.01s/it]

 44%|████▍     | 1706/3844 [7:13:51<6:16:31, 10.57s/it]

 44%|████▍     | 1707/3844 [7:14:04<6:40:42, 11.25s/it]

 44%|████▍     | 1708/3844 [7:14:16<6:46:52, 11.43s/it]

 44%|████▍     | 1709/3844 [7:14:31<7:28:46, 12.61s/it]

 44%|████▍     | 1710/3844 [7:14:47<8:01:16, 13.53s/it]


 45%|████▍     | 1712/3844 [7:15:09<7:10:43, 12.12s/it]

 45%|████▍     | 1713/3844 [7:15:19<6:50:06, 11.55s/it]

 45%|████▍     | 1714/3844 [7:15:28<6:29:59, 10.99s/it]

 45%|████▍     | 1715/3844 [7:15:38<6:19:49, 10.70s/it]
{'loss': 1.2313, 'grad_norm': 0.17737503045475467, 'learning_rate': 0.00012214644946431785, 'epoch': 0.45}

 45%|████▍     | 1716/3844 [7:15:52<6:46:18, 11.46s/it]

 45%|████▍     | 1717/3844 [7:16:03<6:49:34, 11.55s/it]

 45%|████▍     | 1718/3844 [7:16:14<6:40:28, 11.30s/it]

 45%|████▍     | 1719/3844 [7:16:25<6:39:25, 11.28s/it]

 45%|████▍     | 1720/3844 [7:16:38<6:51:00, 11.61s/it]

 45%|████▍     | 1721/3844 [7:16:47<6:29:06, 11.00s/it]

 45%|████▍     | 1722/3844 [7:16:59<6:37:27, 11.24s/it]


 45%|████▍     | 1724/3844 [7:17:24<7:00:30, 11.90s/it]

 45%|████▍     | 1725/3844 [7:17:36<7:01:40, 11.94s/it]

 45%|████▍     | 1726/3844 [7:17:47<6:45:29, 11.49s/it]

 45%|████▍     | 1727/3844 [7:17:59<6:47:39, 11.55s/it]

 45%|████▍     | 1728/3844 [7:18:09<6:34:48, 11.20s/it]

 45%|████▍     | 1729/3844 [7:18:22<7:00:02, 11.92s/it]
{'loss': 0.991, 'grad_norm': 0.16433619819764916, 'learning_rate': 0.00012099444810332487, 'epoch': 0.45}

 45%|████▌     | 1730/3844 [7:18:32<6:36:31, 11.25s/it]


 45%|████▌     | 1732/3844 [7:18:55<6:38:09, 11.31s/it]
{'loss': 1.11, 'grad_norm': 0.16103988308980893, 'learning_rate': 0.00012074720501890484, 'epoch': 0.45}


 45%|████▌     | 1734/3844 [7:19:17<6:33:40, 11.19s/it]
{'loss': 1.2019, 'grad_norm': 0.17429240321461728, 'learning_rate': 0.00012058230253064571, 'epoch': 0.45}

 45%|████▌     | 1735/3844 [7:19:27<6:26:47, 11.00s/it]

 45%|████▌     | 1736/3844 [7:19:38<6:20:15, 10.82s/it]


 45%|████▌     | 1738/3844 [7:20:05<7:10:33, 12.27s/it]
{'loss': 0.9144, 'grad_norm': 0.15806286214488927, 'learning_rate': 0.00012025232262535864, 'epoch': 0.45}

 45%|████▌     | 1739/3844 [7:20:18<7:26:22, 12.72s/it]

 45%|████▌     | 1740/3844 [7:20:30<7:16:23, 12.44s/it]


 45%|████▌     | 1742/3844 [7:20:51<6:37:03, 11.33s/it]

 45%|████▌     | 1743/3844 [7:21:01<6:22:59, 10.94s/it]
{'loss': 1.057, 'grad_norm': 0.17037223766577334, 'learning_rate': 0.00011983952458608066, 'epoch': 0.45}

 45%|████▌     | 1744/3844 [7:21:11<6:20:07, 10.86s/it]

 45%|████▌     | 1745/3844 [7:21:21<6:10:26, 10.59s/it]

 45%|████▌     | 1746/3844 [7:21:34<6:30:45, 11.18s/it]

 45%|████▌     | 1747/3844 [7:21:50<7:25:33, 12.75s/it]


 45%|████▌     | 1749/3844 [7:22:11<6:46:11, 11.63s/it]
{'loss': 1.1151, 'grad_norm': 0.1569830221064236, 'learning_rate': 0.00011934370264903783, 'epoch': 0.45}


 46%|████▌     | 1751/3844 [7:22:31<6:19:33, 10.88s/it]
{'loss': 1.1613, 'grad_norm': 0.17113519250871354, 'learning_rate': 0.00011917831814902651, 'epoch': 0.46}


 46%|████▌     | 1753/3844 [7:22:57<6:56:33, 11.95s/it]
{'loss': 1.173, 'grad_norm': 0.1693480688056927, 'learning_rate': 0.00011901287917136772, 'epoch': 0.46}

 46%|████▌     | 1754/3844 [7:23:08<6:42:01, 11.54s/it]

 46%|████▌     | 1755/3844 [7:23:18<6:24:43, 11.05s/it]

 46%|████▌     | 1756/3844 [7:23:27<6:12:22, 10.70s/it]

 46%|████▌     | 1757/3844 [7:23:37<6:04:38, 10.48s/it]


 46%|████▌     | 1759/3844 [7:23:59<6:07:57, 10.59s/it]
{'loss': 1.1919, 'grad_norm': 0.17613812820393535, 'learning_rate': 0.00011851624007270704, 'epoch': 0.46}

 46%|████▌     | 1760/3844 [7:24:10<6:11:07, 10.68s/it]


 46%|████▌     | 1762/3844 [7:24:35<6:40:01, 11.53s/it]

 46%|████▌     | 1763/3844 [7:24:45<6:26:17, 11.14s/it]
{'loss': 1.0761, 'grad_norm': 0.17789226588442045, 'learning_rate': 0.00011818488357172535, 'epoch': 0.46}

 46%|████▌     | 1764/3844 [7:24:58<6:48:56, 11.80s/it]


 46%|████▌     | 1766/3844 [7:25:21<6:38:24, 11.50s/it]

 46%|████▌     | 1767/3844 [7:25:37<7:28:16, 12.95s/it]

 46%|████▌     | 1768/3844 [7:25:47<6:58:31, 12.10s/it]

 46%|████▌     | 1769/3844 [7:25:59<6:53:51, 11.97s/it]
{'loss': 1.0574, 'grad_norm': 0.17103495169064184, 'learning_rate': 0.00011768746257988884, 'epoch': 0.46}

 46%|████▌     | 1770/3844 [7:26:10<6:45:55, 11.74s/it]

 46%|████▌     | 1771/3844 [7:26:21<6:32:19, 11.36s/it]


 46%|████▌     | 1773/3844 [7:26:41<6:12:12, 10.78s/it]
{'loss': 1.073, 'grad_norm': 0.166305224972075, 'learning_rate': 0.00011735559658662158, 'epoch': 0.46}


 46%|████▌     | 1775/3844 [7:27:09<6:55:32, 12.05s/it]
{'loss': 1.0786, 'grad_norm': 0.16251175613891936, 'learning_rate': 0.00011718958940420186, 'epoch': 0.46}

 46%|████▌     | 1776/3844 [7:27:20<6:41:57, 11.66s/it]

 46%|████▌     | 1777/3844 [7:27:31<6:36:23, 11.51s/it]

 46%|████▋     | 1778/3844 [7:27:42<6:35:14, 11.48s/it]

 46%|████▋     | 1779/3844 [7:27:54<6:36:06, 11.51s/it]

 46%|████▋     | 1780/3844 [7:28:09<7:10:05, 12.50s/it]


 46%|████▋     | 1782/3844 [7:28:33<7:03:09, 12.31s/it]
{'loss': 1.114, 'grad_norm': 0.1755119366398115, 'learning_rate': 0.00011660818283718706, 'epoch': 0.46}

 46%|████▋     | 1783/3844 [7:28:44<6:45:48, 11.81s/it]

 46%|████▋     | 1784/3844 [7:28:55<6:32:37, 11.44s/it]


 46%|████▋     | 1786/3844 [7:29:17<6:33:51, 11.48s/it]
{'loss': 1.0824, 'grad_norm': 0.18014271996306483, 'learning_rate': 0.00011627568974212607, 'epoch': 0.46}


 47%|████▋     | 1788/3844 [7:29:41<6:43:57, 11.79s/it]

 47%|████▋     | 1789/3844 [7:29:51<6:24:33, 11.23s/it]
{'loss': 1.0456, 'grad_norm': 0.1645107236586017, 'learning_rate': 0.00011602619835396253, 'epoch': 0.47}

 47%|████▋     | 1790/3844 [7:30:04<6:39:55, 11.68s/it]


 47%|████▋     | 1792/3844 [7:30:27<6:41:55, 11.75s/it]

 47%|████▋     | 1793/3844 [7:30:38<6:26:17, 11.30s/it]

 47%|████▋     | 1794/3844 [7:30:56<7:34:31, 13.30s/it]
[2024-05-27 08:41:33,742] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9576, 'grad_norm': 0.16406622421513445, 'learning_rate': 0.0001156101525425872, 'epoch': 0.47}


 47%|████▋     | 1796/3844 [7:31:20<7:09:45, 12.59s/it]
{'loss': 1.1152, 'grad_norm': 0.15891671189136153, 'learning_rate': 0.00011544365620588688, 'epoch': 0.47}


 47%|████▋     | 1798/3844 [7:31:46<7:16:04, 12.79s/it]

 47%|████▋     | 1799/3844 [7:31:56<6:46:39, 11.93s/it]
{'loss': 1.1293, 'grad_norm': 0.18378033273621197, 'learning_rate': 0.00011519382959425033, 'epoch': 0.47}

 47%|████▋     | 1800/3844 [7:32:06<6:31:13, 11.48s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 47%|████▋     | 1801/3844 [7:32:42<10:38:05, 18.74s/it]

 47%|████▋     | 1802/3844 [7:32:54<9:25:53, 16.63s/it]
{'loss': 1.0831, 'grad_norm': 0.1673228151869264, 'learning_rate': 0.00011494390587406422, 'epoch': 0.47}

 47%|████▋     | 1803/3844 [7:33:03<8:13:21, 14.50s/it]


 47%|████▋     | 1805/3844 [7:33:29<7:50:03, 13.83s/it]
{'loss': 1.1745, 'grad_norm': 0.16337880976861935, 'learning_rate': 0.00011469388664266977, 'epoch': 0.47}

 47%|████▋     | 1806/3844 [7:33:43<7:46:26, 13.73s/it]

 47%|████▋     | 1807/3844 [7:33:57<7:51:45, 13.90s/it]


 47%|████▋     | 1809/3844 [7:34:23<7:48:54, 13.83s/it]
{'loss': 1.0117, 'grad_norm': 0.16536392449483692, 'learning_rate': 0.00011436038185646477, 'epoch': 0.47}

 47%|████▋     | 1810/3844 [7:34:35<7:24:54, 13.12s/it]

 47%|████▋     | 1811/3844 [7:34:45<6:53:10, 12.19s/it]

 47%|████▋     | 1812/3844 [7:34:56<6:43:44, 11.92s/it]

 47%|████▋     | 1813/3844 [7:35:09<6:50:33, 12.13s/it]


 47%|████▋     | 1815/3844 [7:35:28<6:06:44, 10.84s/it]
{'loss': 1.102, 'grad_norm': 0.1707806357765264, 'learning_rate': 0.0001138598199229018, 'epoch': 0.47}

 47%|████▋     | 1816/3844 [7:35:39<6:02:41, 10.73s/it]

 47%|████▋     | 1817/3844 [7:35:51<6:23:59, 11.37s/it]


 47%|████▋     | 1819/3844 [7:36:18<7:09:06, 12.71s/it]
{'loss': 1.1085, 'grad_norm': 0.17075199106429353, 'learning_rate': 0.0001135259143272531, 'epoch': 0.47}

 47%|████▋     | 1820/3844 [7:36:30<7:05:21, 12.61s/it]


 47%|████▋     | 1822/3844 [7:36:56<7:12:27, 12.83s/it]

 47%|████▋     | 1823/3844 [7:37:08<7:05:30, 12.63s/it]
{'loss': 1.1368, 'grad_norm': 0.17514671842690294, 'learning_rate': 0.00011319185504566298, 'epoch': 0.47}

 47%|████▋     | 1824/3844 [7:37:21<7:08:22, 12.72s/it]

 47%|████▋     | 1825/3844 [7:37:33<7:04:15, 12.61s/it]


 48%|████▊     | 1827/3844 [7:37:56<6:48:42, 12.16s/it]
{'loss': 1.219, 'grad_norm': 0.17434497553139336, 'learning_rate': 0.00011285764587382425, 'epoch': 0.48}


 48%|████▊     | 1829/3844 [7:38:22<6:52:12, 12.27s/it]

 48%|████▊     | 1830/3844 [7:38:34<6:48:32, 12.17s/it]
{'loss': 1.0651, 'grad_norm': 0.17032980425338276, 'learning_rate': 0.00011260689291377767, 'epoch': 0.48}

 48%|████▊     | 1831/3844 [7:38:45<6:42:59, 12.01s/it]


 48%|████▊     | 1833/3844 [7:39:10<6:54:29, 12.37s/it]

 48%|████▊     | 1834/3844 [7:39:22<6:49:23, 12.22s/it]
{'loss': 1.1037, 'grad_norm': 0.16808246120293552, 'learning_rate': 0.00011227243057248779, 'epoch': 0.48}

 48%|████▊     | 1835/3844 [7:39:33<6:31:02, 11.68s/it]


 48%|████▊     | 1837/3844 [7:39:56<6:27:14, 11.58s/it]
{'loss': 1.1715, 'grad_norm': 0.17790169400817032, 'learning_rate': 0.00011202149209887438, 'epoch': 0.48}


 48%|████▊     | 1839/3844 [7:40:20<6:27:00, 11.58s/it]
{'loss': 1.2985, 'grad_norm': 0.17792470003371644, 'learning_rate': 0.00011185415699903148, 'epoch': 0.48}

 48%|████▊     | 1840/3844 [7:40:35<7:05:44, 12.75s/it]

 48%|████▊     | 1841/3844 [7:40:53<7:53:38, 14.19s/it]

 48%|████▊     | 1842/3844 [7:41:07<7:49:31, 14.07s/it]

 48%|████▊     | 1843/3844 [7:41:20<7:36:09, 13.68s/it]


 48%|████▊     | 1845/3844 [7:41:44<7:12:19, 12.98s/it]
{'loss': 1.2223, 'grad_norm': 0.1760172548393728, 'learning_rate': 0.0001113519515648374, 'epoch': 0.48}

 48%|████▊     | 1846/3844 [7:41:55<6:51:47, 12.37s/it]

 48%|████▊     | 1847/3844 [7:42:06<6:31:12, 11.75s/it]

 48%|████▊     | 1848/3844 [7:42:15<6:10:01, 11.12s/it]


 48%|████▊     | 1850/3844 [7:42:44<7:08:44, 12.90s/it]
{'loss': 1.0428, 'grad_norm': 0.15542184437287934, 'learning_rate': 0.0001109332247991428, 'epoch': 0.48}

 48%|████▊     | 1851/3844 [7:42:55<6:48:41, 12.30s/it]


 48%|████▊     | 1853/3844 [7:43:16<6:17:22, 11.37s/it]
{'loss': 1.1513, 'grad_norm': 0.1714205104139659, 'learning_rate': 0.00011068189509365483, 'epoch': 0.48}

 48%|████▊     | 1854/3844 [7:43:29<6:29:43, 11.75s/it]

 48%|████▊     | 1855/3844 [7:43:39<6:18:25, 11.42s/it]

 48%|████▊     | 1856/3844 [7:43:49<6:00:24, 10.88s/it]

 48%|████▊     | 1857/3844 [7:44:00<5:59:57, 10.87s/it]

 48%|████▊     | 1858/3844 [7:44:09<5:44:57, 10.42s/it]


 48%|████▊     | 1860/3844 [7:44:38<6:40:56, 12.13s/it]
{'loss': 1.1663, 'grad_norm': 0.17119770213172644, 'learning_rate': 0.00011009519639165162, 'epoch': 0.48}

 48%|████▊     | 1861/3844 [7:44:51<6:51:31, 12.45s/it]

 48%|████▊     | 1862/3844 [7:45:04<6:50:41, 12.43s/it]

 48%|████▊     | 1863/3844 [7:45:17<6:58:02, 12.66s/it]


 49%|████▊     | 1865/3844 [7:45:41<6:46:07, 12.31s/it]
{'loss': 1.1089, 'grad_norm': 0.17087072670714204, 'learning_rate': 0.0001096759096279061, 'epoch': 0.49}

 49%|████▊     | 1866/3844 [7:45:52<6:36:56, 12.04s/it]

 49%|████▊     | 1867/3844 [7:46:02<6:15:38, 11.40s/it]


 49%|████▊     | 1869/3844 [7:46:23<5:56:07, 10.82s/it]
{'loss': 1.155, 'grad_norm': 0.1720460457736219, 'learning_rate': 0.00010934035617604687, 'epoch': 0.49}


 49%|████▊     | 1871/3844 [7:46:46<6:14:50, 11.40s/it]
{'loss': 0.9274, 'grad_norm': 0.15809554447032637, 'learning_rate': 0.00010917253941368915, 'epoch': 0.49}

 49%|████▊     | 1872/3844 [7:46:58<6:16:31, 11.46s/it]


 49%|████▉     | 1874/3844 [7:47:23<6:26:05, 11.76s/it]
{'loss': 1.1429, 'grad_norm': 0.18385233176626994, 'learning_rate': 0.00010892076556530324, 'epoch': 0.49}


 49%|████▉     | 1876/3844 [7:47:49<6:50:32, 12.52s/it]

 49%|████▉     | 1877/3844 [7:48:01<6:48:42, 12.47s/it]

 49%|████▉     | 1878/3844 [7:48:13<6:43:01, 12.30s/it]

 49%|████▉     | 1879/3844 [7:48:23<6:19:29, 11.59s/it]
{'loss': 1.23, 'grad_norm': 0.17853365560772327, 'learning_rate': 0.00010850101657853756, 'epoch': 0.49}

 49%|████▉     | 1880/3844 [7:48:37<6:50:22, 12.54s/it]

 49%|████▉     | 1881/3844 [7:48:55<7:43:20, 14.16s/it]


 49%|████▉     | 1883/3844 [7:49:21<7:19:04, 13.43s/it]
{'loss': 0.9753, 'grad_norm': 0.17195689079989848, 'learning_rate': 0.00010816510836608946, 'epoch': 0.49}

 49%|████▉     | 1884/3844 [7:49:34<7:11:17, 13.20s/it]

 49%|████▉     | 1885/3844 [7:49:48<7:24:14, 13.61s/it]


 49%|████▉     | 1887/3844 [7:50:09<6:26:54, 11.86s/it]
{'loss': 1.2486, 'grad_norm': 0.17055587900143002, 'learning_rate': 0.0001078291073789619, 'epoch': 0.49}


 49%|████▉     | 1889/3844 [7:50:36<7:07:53, 13.13s/it]
{'loss': 1.0045, 'grad_norm': 0.16094681013387668, 'learning_rate': 0.0001076610732879018, 'epoch': 0.49}

 49%|████▉     | 1890/3844 [7:50:48<6:54:36, 12.73s/it]

 49%|████▉     | 1891/3844 [7:51:06<7:41:17, 14.17s/it]

 49%|████▉     | 1892/3844 [7:51:15<6:57:12, 12.82s/it]

 49%|████▉     | 1893/3844 [7:51:25<6:29:01, 11.96s/it]

 49%|████▉     | 1894/3844 [7:51:36<6:11:44, 11.44s/it]

 49%|████▉     | 1895/3844 [7:51:48<6:19:13, 11.67s/it]

 49%|████▉     | 1896/3844 [7:51:58<6:01:57, 11.15s/it]

 49%|████▉     | 1897/3844 [7:52:07<5:47:32, 10.71s/it]

 49%|████▉     | 1898/3844 [7:52:18<5:45:01, 10.64s/it]


 49%|████▉     | 1900/3844 [7:52:37<5:28:24, 10.14s/it]

 49%|████▉     | 1901/3844 [7:52:47<5:25:06, 10.04s/it]

 49%|████▉     | 1902/3844 [7:52:57<5:25:52, 10.07s/it]

 50%|████▉     | 1903/3844 [7:53:07<5:23:49, 10.01s/it]
{'loss': 0.9944, 'grad_norm': 0.17833494389453164, 'learning_rate': 0.00010648425205365973, 'epoch': 0.49}

 50%|████▉     | 1904/3844 [7:53:20<5:51:34, 10.87s/it]

 50%|████▉     | 1905/3844 [7:53:34<6:23:40, 11.87s/it]

 50%|████▉     | 1906/3844 [7:53:44<6:03:47, 11.26s/it]

 50%|████▉     | 1907/3844 [7:53:56<6:07:43, 11.39s/it]

 50%|████▉     | 1908/3844 [7:54:08<6:15:08, 11.63s/it]


 50%|████▉     | 1910/3844 [7:54:27<5:43:05, 10.64s/it]

 50%|████▉     | 1911/3844 [7:54:37<5:34:54, 10.40s/it]

 50%|████▉     | 1912/3844 [7:54:51<6:07:38, 11.42s/it]
{'loss': 1.0928, 'grad_norm': 0.17322147879076477, 'learning_rate': 0.00010572723722675849, 'epoch': 0.5}

 50%|████▉     | 1913/3844 [7:55:02<6:00:31, 11.20s/it]


 50%|████▉     | 1915/3844 [7:55:29<6:38:42, 12.40s/it]
{'loss': 1.0811, 'grad_norm': 0.18334510735042775, 'learning_rate': 0.00010547482359135805, 'epoch': 0.5}

 50%|████▉     | 1916/3844 [7:55:44<7:03:07, 13.17s/it]

 50%|████▉     | 1917/3844 [7:55:58<7:14:19, 13.52s/it]

 50%|████▉     | 1918/3844 [7:56:10<6:57:57, 13.02s/it]


 50%|████▉     | 1920/3844 [7:56:31<6:14:41, 11.69s/it]

 50%|████▉     | 1921/3844 [7:56:42<5:59:03, 11.20s/it]
{'loss': 1.0758, 'grad_norm': 0.1734677234376439, 'learning_rate': 0.00010496989296007103, 'epoch': 0.5}

 50%|█████     | 1922/3844 [7:56:54<6:10:55, 11.58s/it]

 50%|█████     | 1923/3844 [7:57:09<6:40:34, 12.51s/it]

 50%|█████     | 1924/3844 [7:57:20<6:32:36, 12.27s/it]

 50%|█████     | 1925/3844 [7:57:36<7:08:22, 13.39s/it]

 50%|█████     | 1926/3844 [7:57:47<6:37:08, 12.42s/it]


 50%|█████     | 1928/3844 [7:58:13<6:48:10, 12.78s/it]
{'loss': 0.9863, 'grad_norm': 0.16552422095813127, 'learning_rate': 0.00010438064754497512, 'epoch': 0.5}

 50%|█████     | 1929/3844 [7:58:24<6:29:08, 12.19s/it]

 50%|█████     | 1930/3844 [7:58:36<6:29:59, 12.23s/it]


 50%|█████     | 1932/3844 [7:59:00<6:22:58, 12.02s/it]

 50%|█████     | 1933/3844 [7:59:13<6:37:37, 12.48s/it]
{'loss': 1.0701, 'grad_norm': 0.17315733789307006, 'learning_rate': 0.00010395966344020483, 'epoch': 0.5}

 50%|█████     | 1934/3844 [7:59:23<6:10:16, 11.63s/it]

 50%|█████     | 1935/3844 [7:59:34<6:11:10, 11.67s/it]

 50%|█████     | 1936/3844 [7:59:46<6:05:12, 11.48s/it]

 50%|█████     | 1937/3844 [8:00:02<6:56:30, 13.10s/it]

 50%|█████     | 1938/3844 [8:00:18<7:18:41, 13.81s/it]


 50%|█████     | 1940/3844 [8:00:41<6:41:25, 12.65s/it]
{'loss': 1.0181, 'grad_norm': 0.17291433510886858, 'learning_rate': 0.00010337016926659333, 'epoch': 0.5}

 50%|█████     | 1941/3844 [8:00:56<7:02:28, 13.32s/it]

 51%|█████     | 1942/3844 [8:01:06<6:33:46, 12.42s/it]

 51%|█████     | 1943/3844 [8:01:18<6:27:35, 12.23s/it]

 51%|█████     | 1944/3844 [8:01:28<6:08:15, 11.63s/it]

 51%|█████     | 1945/3844 [8:01:41<6:12:11, 11.76s/it]

 51%|█████     | 1946/3844 [8:01:55<6:35:35, 12.51s/it]


 51%|█████     | 1948/3844 [8:02:16<6:03:23, 11.50s/it]

 51%|█████     | 1949/3844 [8:02:25<5:45:42, 10.95s/it]
{'loss': 1.1064, 'grad_norm': 0.17056650725434894, 'learning_rate': 0.00010261207873919819, 'epoch': 0.51}

 51%|█████     | 1950/3844 [8:02:40<6:21:33, 12.09s/it]

 51%|█████     | 1951/3844 [8:02:52<6:22:31, 12.12s/it]


 51%|█████     | 1953/3844 [8:03:12<5:43:15, 10.89s/it]
{'loss': 1.0846, 'grad_norm': 0.17768636015508868, 'learning_rate': 0.0001022750987948101, 'epoch': 0.51}

 51%|█████     | 1954/3844 [8:03:24<5:58:58, 11.40s/it]


 51%|█████     | 1956/3844 [8:03:48<5:58:29, 11.39s/it]
{'loss': 1.1816, 'grad_norm': 0.17675165394340434, 'learning_rate': 0.00010202234666277115, 'epoch': 0.51}

 51%|█████     | 1957/3844 [8:03:59<5:53:41, 11.25s/it]

 51%|█████     | 1958/3844 [8:04:10<5:54:18, 11.27s/it]


 51%|█████     | 1960/3844 [8:04:37<6:28:20, 12.37s/it]
{'loss': 0.946, 'grad_norm': 0.18023799496450557, 'learning_rate': 0.00010168532399301047, 'epoch': 0.51}

 51%|█████     | 1961/3844 [8:04:49<6:24:23, 12.25s/it]

 51%|█████     | 1962/3844 [8:05:03<6:35:07, 12.60s/it]

 51%|█████     | 1963/3844 [8:05:15<6:33:02, 12.54s/it]

 51%|█████     | 1964/3844 [8:05:26<6:19:46, 12.12s/it]

 51%|█████     | 1965/3844 [8:05:45<7:20:26, 14.06s/it]

 51%|█████     | 1966/3844 [8:05:57<7:02:33, 13.50s/it]

 51%|█████     | 1967/3844 [8:06:11<7:02:51, 13.52s/it]

 51%|█████     | 1968/3844 [8:06:22<6:47:25, 13.03s/it]


 51%|█████     | 1970/3844 [8:06:42<5:55:35, 11.38s/it]
{'loss': 1.13, 'grad_norm': 0.19155118667332044, 'learning_rate': 0.00010084269191806308, 'epoch': 0.51}

 51%|█████▏    | 1971/3844 [8:06:52<5:43:03, 10.99s/it]

 51%|█████▏    | 1972/3844 [8:07:05<5:56:07, 11.41s/it]

 51%|█████▏    | 1973/3844 [8:07:15<5:46:55, 11.13s/it]

 51%|█████▏    | 1974/3844 [8:07:25<5:31:18, 10.63s/it]

 51%|█████▏    | 1975/3844 [8:07:35<5:26:44, 10.49s/it]

 51%|█████▏    | 1976/3844 [8:07:47<5:43:37, 11.04s/it]

 51%|█████▏    | 1977/3844 [8:08:01<6:06:49, 11.79s/it]

 51%|█████▏    | 1978/3844 [8:08:15<6:27:09, 12.45s/it]

 51%|█████▏    | 1979/3844 [8:08:24<6:02:26, 11.66s/it]


 52%|█████▏    | 1981/3844 [8:08:46<5:48:00, 11.21s/it]
{'loss': 1.0393, 'grad_norm': 0.18150370872584118, 'learning_rate': 9.991572982076832e-05, 'epoch': 0.52}


 52%|█████▏    | 1983/3844 [8:09:08<5:40:34, 10.98s/it]
{'loss': 1.038, 'grad_norm': 0.17585129944674263, 'learning_rate': 9.97471897016815e-05, 'epoch': 0.52}

 52%|█████▏    | 1984/3844 [8:09:18<5:32:05, 10.71s/it]

 52%|█████▏    | 1985/3844 [8:09:28<5:25:58, 10.52s/it]


 52%|█████▏    | 1987/3844 [8:09:50<5:34:03, 10.79s/it]
{'loss': 1.0435, 'grad_norm': 0.1752334486530909, 'learning_rate': 9.94101120966461e-05, 'epoch': 0.52}

 52%|█████▏    | 1988/3844 [8:10:01<5:35:53, 10.86s/it]


 52%|█████▏    | 1990/3844 [8:10:22<5:30:14, 10.69s/it]

 52%|█████▏    | 1991/3844 [8:10:34<5:40:14, 11.02s/it]

 52%|█████▏    | 1992/3844 [8:10:48<6:09:36, 11.97s/it]

 52%|█████▏    | 1993/3844 [8:10:58<5:48:10, 11.29s/it]
{'loss': 1.1395, 'grad_norm': 0.17656932765230554, 'learning_rate': 9.89045094531372e-05, 'epoch': 0.52}


 52%|█████▏    | 1995/3844 [8:11:22<6:06:07, 11.88s/it]

 52%|█████▏    | 1996/3844 [8:11:34<6:11:28, 12.06s/it]
{'loss': 1.0349, 'grad_norm': 0.1724039748303725, 'learning_rate': 9.865171782596252e-05, 'epoch': 0.52}

 52%|█████▏    | 1997/3844 [8:11:45<5:55:07, 11.54s/it]

 52%|█████▏    | 1998/3844 [8:11:55<5:45:36, 11.23s/it]


 52%|█████▏    | 2000/3844 [8:12:16<5:34:13, 10.87s/it]
{'loss': 1.1212, 'grad_norm': 0.17347361364174405, 'learning_rate': 9.831467600698954e-05, 'epoch': 0.52}


 52%|█████▏    | 2002/3844 [8:12:40<5:57:08, 11.63s/it]
{'loss': 1.116, 'grad_norm': 0.16785078692971034, 'learning_rate': 9.814616203911684e-05, 'epoch': 0.52}

 52%|█████▏    | 2003/3844 [8:12:57<6:40:37, 13.06s/it]

 52%|█████▏    | 2004/3844 [8:13:07<6:20:27, 12.41s/it]

 52%|█████▏    | 2005/3844 [8:13:20<6:18:13, 12.34s/it]

 52%|█████▏    | 2006/3844 [8:13:30<5:56:22, 11.63s/it]

 52%|█████▏    | 2007/3844 [8:13:41<5:54:45, 11.59s/it]

 52%|█████▏    | 2008/3844 [8:13:53<6:00:14, 11.77s/it]

 52%|█████▏    | 2009/3844 [8:14:04<5:47:23, 11.36s/it]

 52%|█████▏    | 2010/3844 [8:14:18<6:09:50, 12.10s/it]

 52%|█████▏    | 2011/3844 [8:14:34<6:46:37, 13.31s/it]

 52%|█████▏    | 2012/3844 [8:14:45<6:26:39, 12.66s/it]


 52%|█████▏    | 2014/3844 [8:15:06<5:56:29, 11.69s/it]
{'loss': 1.2308, 'grad_norm': 0.16376349690015826, 'learning_rate': 9.713520557017727e-05, 'epoch': 0.52}

 52%|█████▏    | 2015/3844 [8:15:21<6:25:10, 12.64s/it]

 52%|█████▏    | 2016/3844 [8:15:33<6:18:22, 12.42s/it]

 52%|█████▏    | 2017/3844 [8:15:43<5:56:31, 11.71s/it]

 52%|█████▏    | 2018/3844 [8:15:56<6:05:45, 12.02s/it]


 53%|█████▎    | 2020/3844 [8:16:15<5:26:27, 10.74s/it]

 53%|█████▎    | 2021/3844 [8:16:25<5:18:07, 10.47s/it]

 53%|█████▎    | 2022/3844 [8:16:34<5:11:30, 10.26s/it]

 53%|█████▎    | 2023/3844 [8:16:45<5:12:18, 10.29s/it]
{'loss': 1.2156, 'grad_norm': 0.18132638472351265, 'learning_rate': 9.637717481727039e-05, 'epoch': 0.53}


 53%|█████▎    | 2025/3844 [8:17:04<5:04:53, 10.06s/it]
{'loss': 1.1417, 'grad_norm': 0.17950863651283774, 'learning_rate': 9.620875030384882e-05, 'epoch': 0.53}


 53%|█████▎    | 2027/3844 [8:17:29<5:33:12, 11.00s/it]

 53%|█████▎    | 2028/3844 [8:17:45<6:17:12, 12.46s/it]

 53%|█████▎    | 2029/3844 [8:17:54<5:51:45, 11.63s/it]

 53%|█████▎    | 2030/3844 [8:18:08<6:13:08, 12.34s/it]

 53%|█████▎    | 2031/3844 [8:18:20<6:10:26, 12.26s/it]

 53%|█████▎    | 2032/3844 [8:18:31<5:52:47, 11.68s/it]
{'loss': 1.0039, 'grad_norm': 0.1678164057746301, 'learning_rate': 9.56193524550249e-05, 'epoch': 0.53}

 53%|█████▎    | 2033/3844 [8:18:46<6:22:19, 12.67s/it]

 53%|█████▎    | 2034/3844 [8:18:57<6:12:56, 12.36s/it]

 53%|█████▎    | 2035/3844 [8:19:11<6:28:12, 12.88s/it]


 53%|█████▎    | 2037/3844 [8:19:33<5:53:12, 11.73s/it]
{'loss': 1.1741, 'grad_norm': 0.16692554680751615, 'learning_rate': 9.519844612267525e-05, 'epoch': 0.53}


 53%|█████▎    | 2039/3844 [8:19:53<5:26:42, 10.86s/it]
{'loss': 1.0923, 'grad_norm': 0.16709334115413743, 'learning_rate': 9.5030107039929e-05, 'epoch': 0.53}

 53%|█████▎    | 2040/3844 [8:20:03<5:17:32, 10.56s/it]

 53%|█████▎    | 2041/3844 [8:20:13<5:18:32, 10.60s/it]

 53%|█████▎    | 2042/3844 [8:20:25<5:23:27, 10.77s/it]

 53%|█████▎    | 2043/3844 [8:20:38<5:47:46, 11.59s/it]

 53%|█████▎    | 2044/3844 [8:20:50<5:51:38, 11.72s/it]

 53%|█████▎    | 2045/3844 [8:21:03<6:04:06, 12.14s/it]

 53%|█████▎    | 2046/3844 [8:21:15<5:58:33, 11.97s/it]


 53%|█████▎    | 2048/3844 [8:21:37<5:43:13, 11.47s/it]
{'loss': 1.2253, 'grad_norm': 0.18225788318549246, 'learning_rate': 9.427276277324155e-05, 'epoch': 0.53}

 53%|█████▎    | 2049/3844 [8:21:47<5:32:10, 11.10s/it]

 53%|█████▎    | 2050/3844 [8:22:01<5:57:16, 11.95s/it]


 53%|█████▎    | 2052/3844 [8:22:23<5:43:50, 11.51s/it]
{'loss': 0.9627, 'grad_norm': 0.17348368382524743, 'learning_rate': 9.393626847862763e-05, 'epoch': 0.53}

 53%|█████▎    | 2053/3844 [8:22:34<5:35:45, 11.25s/it]

 53%|█████▎    | 2054/3844 [8:22:47<5:51:26, 11.78s/it]

 53%|█████▎    | 2055/3844 [8:22:57<5:34:53, 11.23s/it]

 53%|█████▎    | 2056/3844 [8:23:07<5:24:20, 10.88s/it]

 54%|█████▎    | 2057/3844 [8:23:19<5:38:42, 11.37s/it]

 54%|█████▎    | 2058/3844 [8:23:30<5:28:31, 11.04s/it]

 54%|█████▎    | 2059/3844 [8:23:46<6:14:20, 12.58s/it]

 54%|█████▎    | 2060/3844 [8:23:57<6:00:49, 12.14s/it]


 54%|█████▎    | 2062/3844 [8:24:19<5:45:09, 11.62s/it]
{'loss': 1.3261, 'grad_norm': 0.17525706612858485, 'learning_rate': 9.309534253310177e-05, 'epoch': 0.54}

 54%|█████▎    | 2063/3844 [8:24:37<6:39:05, 13.45s/it]

 54%|█████▎    | 2064/3844 [8:24:48<6:21:52, 12.87s/it]

 54%|█████▎    | 2065/3844 [8:24:58<5:54:47, 11.97s/it]

 54%|█████▎    | 2066/3844 [8:25:16<6:43:14, 13.61s/it]

 54%|█████▍    | 2067/3844 [8:25:31<6:58:02, 14.12s/it]

 54%|█████▍    | 2068/3844 [8:25:42<6:27:32, 13.09s/it]


 54%|█████▍    | 2070/3844 [8:26:05<6:03:37, 12.30s/it]
{'loss': 1.183, 'grad_norm': 0.1848828337966108, 'learning_rate': 9.242295194818729e-05, 'epoch': 0.54}

 54%|█████▍    | 2071/3844 [8:26:15<5:40:12, 11.51s/it]

 54%|█████▍    | 2072/3844 [8:26:28<5:53:19, 11.96s/it]

 54%|█████▍    | 2073/3844 [8:26:39<5:42:37, 11.61s/it]

 54%|█████▍    | 2074/3844 [8:26:51<5:45:31, 11.71s/it]

 54%|█████▍    | 2075/3844 [8:27:02<5:42:35, 11.62s/it]

 54%|█████▍    | 2076/3844 [8:27:13<5:32:12, 11.27s/it]

 54%|█████▍    | 2077/3844 [8:27:22<5:17:02, 10.77s/it]

 54%|█████▍    | 2078/3844 [8:27:32<5:05:51, 10.39s/it]

 54%|█████▍    | 2079/3844 [8:27:41<4:59:13, 10.17s/it]


 54%|█████▍    | 2081/3844 [8:28:11<6:17:08, 12.84s/it]
{'loss': 1.0909, 'grad_norm': 0.17292179496583596, 'learning_rate': 9.149898342146248e-05, 'epoch': 0.54}

 54%|█████▍    | 2082/3844 [8:28:26<6:29:55, 13.28s/it]


 54%|█████▍    | 2084/3844 [8:28:51<6:19:00, 12.92s/it]
{'loss': 1.1298, 'grad_norm': 0.17639806096765911, 'learning_rate': 9.12471154415348e-05, 'epoch': 0.54}

 54%|█████▍    | 2085/3844 [8:29:01<5:51:29, 11.99s/it]

 54%|█████▍    | 2086/3844 [8:29:12<5:39:34, 11.59s/it]

 54%|█████▍    | 2087/3844 [8:29:24<5:44:49, 11.78s/it]

 54%|█████▍    | 2088/3844 [8:29:34<5:32:33, 11.36s/it]


 54%|█████▍    | 2090/3844 [8:29:59<5:53:58, 12.11s/it]

 54%|█████▍    | 2091/3844 [8:30:10<5:37:06, 11.54s/it]
{'loss': 1.0923, 'grad_norm': 0.1767992850317656, 'learning_rate': 9.065964382395315e-05, 'epoch': 0.54}

 54%|█████▍    | 2092/3844 [8:30:20<5:28:27, 11.25s/it]

 54%|█████▍    | 2093/3844 [8:30:32<5:31:05, 11.34s/it]

 54%|█████▍    | 2094/3844 [8:30:43<5:27:20, 11.22s/it]

 55%|█████▍    | 2095/3844 [8:30:57<5:49:29, 11.99s/it]


 55%|█████▍    | 2097/3844 [8:31:20<5:46:01, 11.88s/it]
{'loss': 1.1686, 'grad_norm': 0.1774115971036785, 'learning_rate': 9.015635463576063e-05, 'epoch': 0.55}

 55%|█████▍    | 2098/3844 [8:31:35<6:19:49, 13.05s/it]


 55%|█████▍    | 2100/3844 [8:31:56<5:38:01, 11.63s/it]
 55%|█████▍    | 2100/3844 [8:31:56<5:38:01, 11.63s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1487, 'grad_norm': 0.16856445798398215, 'learning_rate': 8.98209675246235e-05, 'epoch': 0.55}
 55%|█████▍    | 2101/3844 [8:32:32<9:16:04, 19.14s/it]

 55%|█████▍    | 2102/3844 [8:32:45<8:14:47, 17.04s/it]

 55%|█████▍    | 2103/3844 [8:32:59<7:53:55, 16.33s/it]

 55%|█████▍    | 2104/3844 [8:33:13<7:31:34, 15.57s/it]

 55%|█████▍    | 2105/3844 [8:33:23<6:45:23, 13.99s/it]

 55%|█████▍    | 2106/3844 [8:33:34<6:16:21, 12.99s/it]

 55%|█████▍    | 2107/3844 [8:33:46<6:06:42, 12.67s/it]

 55%|█████▍    | 2108/3844 [8:33:59<6:12:05, 12.86s/it]

 55%|█████▍    | 2109/3844 [8:34:11<6:00:25, 12.46s/it]

 55%|█████▍    | 2110/3844 [8:34:21<5:42:09, 11.84s/it]

 55%|█████▍    | 2111/3844 [8:34:31<5:27:35, 11.34s/it]

 55%|█████▍    | 2112/3844 [8:34:42<5:19:14, 11.06s/it]


 55%|█████▍    | 2114/3844 [8:35:06<5:38:15, 11.73s/it]
{'loss': 0.877, 'grad_norm': 0.17113353788446037, 'learning_rate': 8.873177790306334e-05, 'epoch': 0.55}


 55%|█████▌    | 2116/3844 [8:35:30<5:36:37, 11.69s/it]
{'loss': 1.2947, 'grad_norm': 0.1782743171791659, 'learning_rate': 8.856432702880984e-05, 'epoch': 0.55}

 55%|█████▌    | 2117/3844 [8:35:40<5:24:09, 11.26s/it]

 55%|█████▌    | 2118/3844 [8:35:52<5:31:25, 11.52s/it]

 55%|█████▌    | 2119/3844 [8:36:03<5:19:45, 11.12s/it]

 55%|█████▌    | 2120/3844 [8:36:13<5:13:24, 10.91s/it]

 55%|█████▌    | 2121/3844 [8:36:24<5:11:43, 10.86s/it]

 55%|█████▌    | 2122/3844 [8:36:35<5:15:43, 11.00s/it]

 55%|█████▌    | 2123/3844 [8:36:48<5:28:41, 11.46s/it]

 55%|█████▌    | 2124/3844 [8:36:57<5:11:10, 10.85s/it]

 55%|█████▌    | 2125/3844 [8:37:09<5:20:02, 11.17s/it]

 55%|█████▌    | 2126/3844 [8:37:20<5:17:48, 11.10s/it]


 55%|█████▌    | 2128/3844 [8:37:44<5:27:44, 11.46s/it]
{'loss': 1.1253, 'grad_norm': 0.17369919686435004, 'learning_rate': 8.756032058888242e-05, 'epoch': 0.55}


 55%|█████▌    | 2130/3844 [8:38:06<5:17:15, 11.11s/it]
{'loss': 0.9795, 'grad_norm': 0.18634026684497426, 'learning_rate': 8.739310708622234e-05, 'epoch': 0.55}

 55%|█████▌    | 2131/3844 [8:38:20<5:44:10, 12.06s/it]

 55%|█████▌    | 2132/3844 [8:38:33<5:47:30, 12.18s/it]

 55%|█████▌    | 2133/3844 [8:38:43<5:29:27, 11.55s/it]

 56%|█████▌    | 2134/3844 [8:38:59<6:10:01, 12.98s/it]

 56%|█████▌    | 2135/3844 [8:39:09<5:41:51, 12.00s/it]


 56%|█████▌    | 2137/3844 [8:39:30<5:20:52, 11.28s/it]
{'loss': 1.11, 'grad_norm': 0.17799207752199733, 'learning_rate': 8.680814495433704e-05, 'epoch': 0.56}

 56%|█████▌    | 2138/3844 [8:39:41<5:16:19, 11.12s/it]

 56%|█████▌    | 2139/3844 [8:39:52<5:12:14, 10.99s/it]

 56%|█████▌    | 2140/3844 [8:40:01<4:58:28, 10.51s/it]

 56%|█████▌    | 2141/3844 [8:40:17<5:47:02, 12.23s/it]


 56%|█████▌    | 2143/3844 [8:40:46<6:25:57, 13.61s/it]
{'loss': 1.0695, 'grad_norm': 0.15978548411674953, 'learning_rate': 8.63071134270168e-05, 'epoch': 0.56}

 56%|█████▌    | 2144/3844 [8:40:57<5:58:09, 12.64s/it]

 56%|█████▌    | 2145/3844 [8:41:09<5:56:39, 12.60s/it]


 56%|█████▌    | 2147/3844 [8:41:30<5:26:34, 11.55s/it]
{'loss': 1.1169, 'grad_norm': 0.1693439675217811, 'learning_rate': 8.597328609717961e-05, 'epoch': 0.56}

 56%|█████▌    | 2148/3844 [8:41:42<5:32:25, 11.76s/it]


 56%|█████▌    | 2150/3844 [8:42:04<5:18:50, 11.29s/it]
{'loss': 1.1447, 'grad_norm': 0.17730464015662373, 'learning_rate': 8.572301998306313e-05, 'epoch': 0.56}

 56%|█████▌    | 2151/3844 [8:42:14<5:05:39, 10.83s/it]

 56%|█████▌    | 2152/3844 [8:42:28<5:30:20, 11.71s/it]

 56%|█████▌    | 2153/3844 [8:42:41<5:43:50, 12.20s/it]

 56%|█████▌    | 2154/3844 [8:42:54<5:47:52, 12.35s/it]

 56%|█████▌    | 2155/3844 [8:43:07<5:49:54, 12.43s/it]

 56%|█████▌    | 2156/3844 [8:43:19<5:49:43, 12.43s/it]

 56%|█████▌    | 2157/3844 [8:43:29<5:26:24, 11.61s/it]

 56%|█████▌    | 2158/3844 [8:43:38<5:07:52, 10.96s/it]

 56%|█████▌    | 2159/3844 [8:43:48<4:56:13, 10.55s/it]

 56%|█████▌    | 2160/3844 [8:43:59<5:05:44, 10.89s/it]

 56%|█████▌    | 2161/3844 [8:44:11<5:10:25, 11.07s/it]

 56%|█████▌    | 2162/3844 [8:44:21<5:02:37, 10.80s/it]

 56%|█████▋    | 2163/3844 [8:44:34<5:23:10, 11.54s/it]


 56%|█████▋    | 2165/3844 [8:44:59<5:26:13, 11.66s/it]
{'loss': 1.1764, 'grad_norm': 0.1813370927859307, 'learning_rate': 8.447309011257313e-05, 'epoch': 0.56}

 56%|█████▋    | 2166/3844 [8:45:10<5:23:35, 11.57s/it]

 56%|█████▋    | 2167/3844 [8:45:22<5:31:37, 11.86s/it]

 56%|█████▋    | 2168/3844 [8:45:33<5:20:25, 11.47s/it]

 56%|█████▋    | 2169/3844 [8:45:46<5:33:01, 11.93s/it]

 56%|█████▋    | 2170/3844 [8:45:59<5:40:56, 12.22s/it]

 56%|█████▋    | 2171/3844 [8:46:13<6:00:36, 12.93s/it]

 57%|█████▋    | 2172/3844 [8:46:27<6:07:49, 13.20s/it]

 57%|█████▋    | 2173/3844 [8:46:38<5:50:53, 12.60s/it]

 57%|█████▋    | 2174/3844 [8:46:48<5:28:06, 11.79s/it]

 57%|█████▋    | 2175/3844 [8:47:03<5:52:08, 12.66s/it]

 57%|█████▋    | 2176/3844 [8:47:13<5:27:55, 11.80s/it]

 57%|█████▋    | 2177/3844 [8:47:24<5:21:21, 11.57s/it]

 57%|█████▋    | 2178/3844 [8:47:39<5:49:43, 12.60s/it]

 57%|█████▋    | 2179/3844 [8:47:50<5:36:13, 12.12s/it]

 57%|█████▋    | 2180/3844 [8:48:02<5:36:26, 12.13s/it]

 57%|█████▋    | 2181/3844 [8:48:19<6:16:27, 13.58s/it]

 57%|█████▋    | 2182/3844 [8:48:30<5:58:10, 12.93s/it]

 57%|█████▋    | 2183/3844 [8:48:42<5:44:44, 12.45s/it]

 57%|█████▋    | 2184/3844 [8:48:55<5:50:20, 12.66s/it]

 57%|█████▋    | 2185/3844 [8:49:04<5:23:46, 11.71s/it]

 57%|█████▋    | 2186/3844 [8:49:16<5:21:21, 11.63s/it]

 57%|█████▋    | 2187/3844 [8:49:30<5:43:07, 12.42s/it]

 57%|█████▋    | 2188/3844 [8:49:42<5:34:17, 12.11s/it]

 57%|█████▋    | 2189/3844 [8:49:53<5:25:31, 11.80s/it]

 57%|█████▋    | 2190/3844 [8:50:09<6:00:39, 13.08s/it]

 57%|█████▋    | 2191/3844 [8:50:19<5:39:31, 12.32s/it]

 57%|█████▋    | 2192/3844 [8:50:31<5:35:51, 12.20s/it]

 57%|█████▋    | 2193/3844 [8:50:42<5:21:18, 11.68s/it]

 57%|█████▋    | 2194/3844 [8:50:54<5:26:44, 11.88s/it]


 57%|█████▋    | 2196/3844 [8:51:19<5:31:51, 12.08s/it]

 57%|█████▋    | 2197/3844 [8:51:29<5:15:46, 11.50s/it]
{'loss': 1.135, 'grad_norm': 0.18003190690614024, 'learning_rate': 8.181511642827466e-05, 'epoch': 0.57}

 57%|█████▋    | 2198/3844 [8:51:40<5:13:03, 11.41s/it]

 57%|█████▋    | 2199/3844 [8:51:57<5:53:15, 12.88s/it]

 57%|█████▋    | 2200/3844 [8:52:08<5:40:56, 12.44s/it]

 57%|█████▋    | 2201/3844 [8:52:21<5:43:26, 12.54s/it]

 57%|█████▋    | 2202/3844 [8:52:32<5:36:25, 12.29s/it]

 57%|█████▋    | 2203/3844 [8:52:44<5:31:16, 12.11s/it]


 57%|█████▋    | 2205/3844 [8:53:05<5:08:45, 11.30s/it]
{'loss': 1.1204, 'grad_norm': 0.1838013181035091, 'learning_rate': 8.115261381399515e-05, 'epoch': 0.57}

 57%|█████▋    | 2206/3844 [8:53:15<4:59:12, 10.96s/it]

 57%|█████▋    | 2207/3844 [8:53:30<5:26:00, 11.95s/it]

 57%|█████▋    | 2208/3844 [8:53:40<5:13:33, 11.50s/it]

 57%|█████▋    | 2209/3844 [8:53:53<5:23:33, 11.87s/it]

 57%|█████▋    | 2210/3844 [8:54:02<5:05:27, 11.22s/it]

 58%|█████▊    | 2211/3844 [8:54:17<5:34:58, 12.31s/it]

 58%|█████▊    | 2212/3844 [8:54:27<5:13:29, 11.53s/it]

 58%|█████▊    | 2213/3844 [8:54:43<5:49:32, 12.86s/it]

 58%|█████▊    | 2214/3844 [8:54:55<5:39:31, 12.50s/it]

 58%|█████▊    | 2215/3844 [8:55:08<5:42:30, 12.62s/it]

 58%|█████▊    | 2216/3844 [8:55:18<5:25:26, 11.99s/it]


 58%|█████▊    | 2218/3844 [8:55:45<5:50:32, 12.93s/it]
{'loss': 1.0343, 'grad_norm': 0.16702362180934793, 'learning_rate': 8.007788739356022e-05, 'epoch': 0.58}

 58%|█████▊    | 2219/3844 [8:56:00<6:01:33, 13.35s/it]

 58%|█████▊    | 2220/3844 [8:56:09<5:33:00, 12.30s/it]

 58%|█████▊    | 2221/3844 [8:56:19<5:08:45, 11.41s/it]

 58%|█████▊    | 2222/3844 [8:56:29<4:55:29, 10.93s/it]


 58%|█████▊    | 2224/3844 [8:56:53<5:15:15, 11.68s/it]
{'loss': 1.012, 'grad_norm': 0.1775360948263176, 'learning_rate': 7.958265842339825e-05, 'epoch': 0.58}

 58%|█████▊    | 2225/3844 [8:57:03<5:02:49, 11.22s/it]

 58%|█████▊    | 2226/3844 [8:57:14<4:55:46, 10.97s/it]

 58%|█████▊    | 2227/3844 [8:57:24<4:50:34, 10.78s/it]

 58%|█████▊    | 2228/3844 [8:57:34<4:44:19, 10.56s/it]


 58%|█████▊    | 2230/3844 [8:58:01<5:26:25, 12.13s/it]
{'loss': 1.0595, 'grad_norm': 0.16551253705720412, 'learning_rate': 7.908795142704045e-05, 'epoch': 0.58}


 58%|█████▊    | 2232/3844 [8:58:32<5:57:07, 13.29s/it]
{'loss': 1.0858, 'grad_norm': 0.17115584358376484, 'learning_rate': 7.892316727544236e-05, 'epoch': 0.58}

 58%|█████▊    | 2233/3844 [8:58:42<5:31:27, 12.34s/it]

 58%|█████▊    | 2234/3844 [8:58:53<5:20:56, 11.96s/it]

 58%|█████▊    | 2235/3844 [8:59:03<5:07:51, 11.48s/it]

 58%|█████▊    | 2236/3844 [8:59:17<5:28:24, 12.25s/it]

 58%|█████▊    | 2237/3844 [8:59:28<5:17:07, 11.84s/it]

 58%|█████▊    | 2238/3844 [8:59:38<4:59:21, 11.18s/it]

 58%|█████▊    | 2239/3844 [8:59:49<5:00:29, 11.23s/it]

 58%|█████▊    | 2240/3844 [9:00:00<5:00:35, 11.24s/it]

 58%|█████▊    | 2241/3844 [9:00:11<4:52:51, 10.96s/it]

 58%|█████▊    | 2242/3844 [9:00:21<4:51:15, 10.91s/it]

 58%|█████▊    | 2243/3844 [9:00:33<4:55:15, 11.07s/it]

 58%|█████▊    | 2244/3844 [9:00:47<5:23:51, 12.14s/it]

 58%|█████▊    | 2245/3844 [9:00:59<5:18:29, 11.95s/it]

 58%|█████▊    | 2246/3844 [9:01:12<5:24:50, 12.20s/it]

 58%|█████▊    | 2247/3844 [9:01:28<5:59:25, 13.50s/it]

 58%|█████▊    | 2248/3844 [9:01:39<5:40:57, 12.82s/it]

 59%|█████▊    | 2249/3844 [9:01:52<5:38:40, 12.74s/it]

 59%|█████▊    | 2250/3844 [9:02:08<6:06:09, 13.78s/it]

 59%|█████▊    | 2251/3844 [9:02:21<5:57:25, 13.46s/it]

 59%|█████▊    | 2252/3844 [9:02:32<5:36:53, 12.70s/it]

 59%|█████▊    | 2253/3844 [9:02:45<5:40:59, 12.86s/it]

 59%|█████▊    | 2254/3844 [9:02:55<5:19:38, 12.06s/it]

 59%|█████▊    | 2255/3844 [9:03:06<5:08:17, 11.64s/it]

 59%|█████▊    | 2256/3844 [9:03:17<4:59:58, 11.33s/it]

 59%|█████▊    | 2257/3844 [9:03:28<5:01:05, 11.38s/it]

 59%|█████▊    | 2258/3844 [9:03:38<4:46:04, 10.82s/it]

 59%|█████▉    | 2259/3844 [9:03:48<4:41:34, 10.66s/it]

 59%|█████▉    | 2260/3844 [9:04:00<4:50:02, 10.99s/it]

 59%|█████▉    | 2261/3844 [9:04:10<4:45:43, 10.83s/it]


 59%|█████▉    | 2263/3844 [9:04:34<4:59:56, 11.38s/it]

 59%|█████▉    | 2264/3844 [9:04:44<4:48:28, 10.95s/it]
{'loss': 1.0947, 'grad_norm': 0.17432263331626754, 'learning_rate': 7.629508100826028e-05, 'epoch': 0.59}

 59%|█████▉    | 2265/3844 [9:04:53<4:38:49, 10.59s/it]

 59%|█████▉    | 2266/3844 [9:05:13<5:47:48, 13.22s/it]

 59%|█████▉    | 2267/3844 [9:05:28<6:04:16, 13.86s/it]

 59%|█████▉    | 2268/3844 [9:05:44<6:21:35, 14.53s/it]

 59%|█████▉    | 2269/3844 [9:05:59<6:21:08, 14.52s/it]

 59%|█████▉    | 2270/3844 [9:06:10<5:55:23, 13.55s/it]

 59%|█████▉    | 2271/3844 [9:06:25<6:08:41, 14.06s/it]

 59%|█████▉    | 2272/3844 [9:06:35<5:36:28, 12.84s/it]


 59%|█████▉    | 2274/3844 [9:07:00<5:31:41, 12.68s/it]
{'loss': 1.1313, 'grad_norm': 0.1737280443438612, 'learning_rate': 7.547724948448384e-05, 'epoch': 0.59}

 59%|█████▉    | 2275/3844 [9:07:11<5:14:21, 12.02s/it]

 59%|█████▉    | 2276/3844 [9:07:22<5:10:54, 11.90s/it]

 59%|█████▉    | 2277/3844 [9:07:35<5:17:12, 12.15s/it]

 59%|█████▉    | 2278/3844 [9:07:50<5:37:21, 12.93s/it]

 59%|█████▉    | 2279/3844 [9:08:04<5:51:04, 13.46s/it]

 59%|█████▉    | 2280/3844 [9:08:14<5:23:07, 12.40s/it]

 59%|█████▉    | 2281/3844 [9:08:27<5:27:41, 12.58s/it]

 59%|█████▉    | 2282/3844 [9:08:41<5:36:20, 12.92s/it]
[2024-05-27 10:19:38,514] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 59%|█████▉    | 2283/3844 [9:09:00<6:26:53, 14.87s/it]

 59%|█████▉    | 2284/3844 [9:09:15<6:25:41, 14.83s/it]

 59%|█████▉    | 2285/3844 [9:09:25<5:45:36, 13.30s/it]


 59%|█████▉    | 2287/3844 [9:09:50<5:37:26, 13.00s/it]

 60%|█████▉    | 2288/3844 [9:10:00<5:13:34, 12.09s/it]
{'loss': 1.1266, 'grad_norm': 0.1775901969715483, 'learning_rate': 7.433522399697795e-05, 'epoch': 0.6}

 60%|█████▉    | 2289/3844 [9:10:13<5:20:16, 12.36s/it]

 60%|█████▉    | 2290/3844 [9:10:23<4:59:34, 11.57s/it]

 60%|█████▉    | 2291/3844 [9:10:33<4:46:14, 11.06s/it]

 60%|█████▉    | 2292/3844 [9:10:46<5:03:34, 11.74s/it]

 60%|█████▉    | 2293/3844 [9:10:59<5:10:52, 12.03s/it]

 60%|█████▉    | 2294/3844 [9:11:09<4:59:32, 11.60s/it]

 60%|█████▉    | 2295/3844 [9:11:20<4:49:49, 11.23s/it]

 60%|█████▉    | 2296/3844 [9:11:31<4:49:12, 11.21s/it]

 60%|█████▉    | 2297/3844 [9:11:41<4:44:04, 11.02s/it]

 60%|█████▉    | 2298/3844 [9:11:52<4:39:14, 10.84s/it]

 60%|█████▉    | 2299/3844 [9:12:04<4:48:51, 11.22s/it]

 60%|█████▉    | 2300/3844 [9:12:19<5:16:46, 12.31s/it]

 60%|█████▉    | 2301/3844 [9:12:29<4:59:16, 11.64s/it]

 60%|█████▉    | 2302/3844 [9:12:39<4:51:02, 11.32s/it]

 60%|█████▉    | 2303/3844 [9:12:56<5:29:36, 12.83s/it]

 60%|█████▉    | 2304/3844 [9:13:06<5:06:44, 11.95s/it]

 60%|█████▉    | 2305/3844 [9:13:17<4:58:36, 11.64s/it]

 60%|█████▉    | 2306/3844 [9:13:27<4:47:42, 11.22s/it]

 60%|██████    | 2307/3844 [9:13:43<5:24:29, 12.67s/it]

 60%|██████    | 2308/3844 [9:13:53<5:05:58, 11.95s/it]

 60%|██████    | 2309/3844 [9:14:06<5:13:20, 12.25s/it]


 60%|██████    | 2311/3844 [9:14:28<4:56:56, 11.62s/it]
{'loss': 1.1241, 'grad_norm': 0.18158900814311404, 'learning_rate': 7.246686796978537e-05, 'epoch': 0.6}


 60%|██████    | 2313/3844 [9:14:54<5:06:57, 12.03s/it]
{'loss': 1.2246, 'grad_norm': 0.18920141384818637, 'learning_rate': 7.230488096035868e-05, 'epoch': 0.6}

 60%|██████    | 2314/3844 [9:15:06<5:00:59, 11.80s/it]

 60%|██████    | 2315/3844 [9:15:17<4:58:28, 11.71s/it]

 60%|██████    | 2316/3844 [9:15:27<4:45:15, 11.20s/it]

 60%|██████    | 2317/3844 [9:15:39<4:52:41, 11.50s/it]

 60%|██████    | 2318/3844 [9:15:54<5:12:39, 12.29s/it]

 60%|██████    | 2319/3844 [9:16:05<5:08:45, 12.15s/it]


 60%|██████    | 2321/3844 [9:16:27<4:46:56, 11.30s/it]
{'loss': 1.052, 'grad_norm': 0.17347130997322133, 'learning_rate': 7.165772422413571e-05, 'epoch': 0.6}

 60%|██████    | 2322/3844 [9:16:41<5:11:06, 12.26s/it]


 60%|██████    | 2324/3844 [9:17:01<4:37:04, 10.94s/it]
{'loss': 1.1642, 'grad_norm': 0.18700005910445183, 'learning_rate': 7.14153709671219e-05, 'epoch': 0.6}

 60%|██████    | 2325/3844 [9:17:10<4:26:47, 10.54s/it]
[2024-05-27 10:28:04,485] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 61%|██████    | 2326/3844 [9:17:26<5:09:55, 12.25s/it]

 61%|██████    | 2327/3844 [9:17:38<5:03:54, 12.02s/it]

 61%|██████    | 2328/3844 [9:17:50<5:03:16, 12.00s/it]

 61%|██████    | 2329/3844 [9:18:04<5:17:46, 12.58s/it]

 61%|██████    | 2330/3844 [9:18:14<5:00:00, 11.89s/it]

 61%|██████    | 2331/3844 [9:18:25<4:55:00, 11.70s/it]

 61%|██████    | 2332/3844 [9:18:37<4:57:08, 11.79s/it]

 61%|██████    | 2333/3844 [9:18:51<5:11:22, 12.36s/it]

 61%|██████    | 2334/3844 [9:19:03<5:05:40, 12.15s/it]
[2024-05-27 10:29:57,076] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 61%|██████    | 2335/3844 [9:19:19<5:37:05, 13.40s/it]

 61%|██████    | 2336/3844 [9:19:30<5:19:29, 12.71s/it]


 61%|██████    | 2338/3844 [9:19:53<5:05:45, 12.18s/it]

 61%|██████    | 2339/3844 [9:20:09<5:34:23, 13.33s/it]
{'loss': 0.9343, 'grad_norm': 0.1686229917910052, 'learning_rate': 7.020637602058129e-05, 'epoch': 0.61}


 61%|██████    | 2341/3844 [9:20:29<4:50:24, 11.59s/it]
{'loss': 1.1602, 'grad_norm': 0.17691917265051504, 'learning_rate': 7.004553216509446e-05, 'epoch': 0.61}

 61%|██████    | 2342/3844 [9:20:38<4:34:36, 10.97s/it]

 61%|██████    | 2343/3844 [9:20:51<4:50:31, 11.61s/it]

 61%|██████    | 2344/3844 [9:21:04<4:54:57, 11.80s/it]


 61%|██████    | 2346/3844 [9:21:23<4:28:01, 10.74s/it]
{'loss': 1.1883, 'grad_norm': 0.18475709201907067, 'learning_rate': 6.964379578619014e-05, 'epoch': 0.61}

 61%|██████    | 2347/3844 [9:21:37<4:54:53, 11.82s/it]

 61%|██████    | 2348/3844 [9:21:47<4:40:05, 11.23s/it]

 61%|██████    | 2349/3844 [9:21:58<4:37:51, 11.15s/it]

 61%|██████    | 2350/3844 [9:22:08<4:25:22, 10.66s/it]


 61%|██████    | 2352/3844 [9:22:39<5:29:03, 13.23s/it]
{'loss': 1.1319, 'grad_norm': 0.1744655448166255, 'learning_rate': 6.916242415002166e-05, 'epoch': 0.61}

 61%|██████    | 2353/3844 [9:22:50<5:14:27, 12.65s/it]

 61%|██████    | 2354/3844 [9:23:03<5:13:36, 12.63s/it]

 61%|██████▏   | 2355/3844 [9:23:14<4:58:36, 12.03s/it]

 61%|██████▏   | 2356/3844 [9:23:30<5:28:23, 13.24s/it]


 61%|██████▏   | 2358/3844 [9:23:51<4:55:45, 11.94s/it]

 61%|██████▏   | 2359/3844 [9:24:01<4:39:57, 11.31s/it]
{'loss': 1.1772, 'grad_norm': 0.19162847595600777, 'learning_rate': 6.860182118210337e-05, 'epoch': 0.61}

 61%|██████▏   | 2360/3844 [9:24:12<4:36:50, 11.19s/it]

 61%|██████▏   | 2361/3844 [9:24:21<4:23:51, 10.68s/it]

 61%|██████▏   | 2362/3844 [9:24:33<4:33:31, 11.07s/it]

 61%|██████▏   | 2363/3844 [9:24:44<4:32:41, 11.05s/it]

 61%|██████▏   | 2364/3844 [9:24:54<4:22:56, 10.66s/it]


 62%|██████▏   | 2366/3844 [9:25:17<4:36:06, 11.21s/it]
{'loss': 1.0276, 'grad_norm': 0.165555173444235, 'learning_rate': 6.804231077901733e-05, 'epoch': 0.62}


 62%|██████▏   | 2368/3844 [9:25:41<4:42:43, 11.49s/it]

 62%|██████▏   | 2369/3844 [9:25:55<5:01:54, 12.28s/it]

 62%|██████▏   | 2370/3844 [9:26:07<4:59:37, 12.20s/it]
{'loss': 1.1552, 'grad_norm': 0.1813527323747976, 'learning_rate': 6.772308858215118e-05, 'epoch': 0.62}

 62%|██████▏   | 2371/3844 [9:26:17<4:38:42, 11.35s/it]


 62%|██████▏   | 2373/3844 [9:26:45<5:10:54, 12.68s/it]
{'loss': 1.0876, 'grad_norm': 0.16304700770165223, 'learning_rate': 6.748391241008984e-05, 'epoch': 0.62}


 62%|██████▏   | 2375/3844 [9:27:07<4:48:34, 11.79s/it]
{'loss': 1.0074, 'grad_norm': 0.15821511951533418, 'learning_rate': 6.732457699027309e-05, 'epoch': 0.62}

 62%|██████▏   | 2376/3844 [9:27:17<4:32:35, 11.14s/it]

 62%|██████▏   | 2377/3844 [9:27:28<4:30:19, 11.06s/it]

 62%|██████▏   | 2378/3844 [9:27:45<5:13:53, 12.85s/it]

 62%|██████▏   | 2379/3844 [9:27:59<5:21:52, 13.18s/it]

 62%|██████▏   | 2380/3844 [9:28:10<5:07:02, 12.58s/it]

 62%|██████▏   | 2381/3844 [9:28:24<5:15:33, 12.94s/it]

 62%|██████▏   | 2382/3844 [9:28:33<4:49:57, 11.90s/it]

 62%|██████▏   | 2383/3844 [9:28:48<5:13:33, 12.88s/it]

 62%|██████▏   | 2384/3844 [9:29:02<5:15:45, 12.98s/it]

 62%|██████▏   | 2385/3844 [9:29:11<4:48:48, 11.88s/it]

 62%|██████▏   | 2386/3844 [9:29:21<4:38:14, 11.45s/it]

 62%|██████▏   | 2387/3844 [9:29:33<4:36:49, 11.40s/it]

 62%|██████▏   | 2388/3844 [9:29:46<4:49:02, 11.91s/it]

 62%|██████▏   | 2389/3844 [9:29:57<4:45:12, 11.76s/it]

 62%|██████▏   | 2390/3844 [9:30:08<4:42:16, 11.65s/it]

 62%|██████▏   | 2391/3844 [9:30:20<4:43:38, 11.71s/it]

 62%|██████▏   | 2392/3844 [9:30:32<4:43:05, 11.70s/it]

 62%|██████▏   | 2393/3844 [9:30:44<4:46:31, 11.85s/it]

 62%|██████▏   | 2394/3844 [9:30:57<4:51:36, 12.07s/it]

 62%|██████▏   | 2395/3844 [9:31:13<5:18:42, 13.20s/it]

 62%|██████▏   | 2396/3844 [9:31:23<5:01:05, 12.48s/it]

 62%|██████▏   | 2397/3844 [9:31:33<4:41:17, 11.66s/it]

 62%|██████▏   | 2398/3844 [9:31:43<4:29:53, 11.20s/it]


 62%|██████▏   | 2400/3844 [9:32:10<4:54:00, 12.22s/it]
 62%|██████▏   | 2400/3844 [9:32:10<4:54:00, 12.22s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.0223, 'grad_norm': 0.18546720964601016, 'learning_rate': 6.526182729395907e-05, 'epoch': 0.62}
 62%|██████▏   | 2401/3844 [9:32:51<8:27:16, 21.09s/it]

 62%|██████▏   | 2402/3844 [9:33:02<7:14:59, 18.10s/it]

 63%|██████▎   | 2403/3844 [9:33:13<6:20:35, 15.85s/it]

 63%|██████▎   | 2404/3844 [9:33:23<5:39:42, 14.15s/it]


 63%|██████▎   | 2406/3844 [9:33:50<5:30:29, 13.79s/it]

 63%|██████▎   | 2407/3844 [9:34:08<6:01:56, 15.11s/it]
{'loss': 1.0949, 'grad_norm': 0.18011056817076718, 'learning_rate': 6.478814038351723e-05, 'epoch': 0.63}

 63%|██████▎   | 2408/3844 [9:34:21<5:45:44, 14.45s/it]

 63%|██████▎   | 2409/3844 [9:34:34<5:38:51, 14.17s/it]

 63%|██████▎   | 2410/3844 [9:34:46<5:23:12, 13.52s/it]


 63%|██████▎   | 2412/3844 [9:35:14<5:21:57, 13.49s/it]
{'loss': 1.0297, 'grad_norm': 0.167466076085722, 'learning_rate': 6.43940884301817e-05, 'epoch': 0.63}

 63%|██████▎   | 2413/3844 [9:35:24<4:59:06, 12.54s/it]

 63%|██████▎   | 2414/3844 [9:35:35<4:47:20, 12.06s/it]


 63%|██████▎   | 2416/3844 [9:35:58<4:41:51, 11.84s/it]
{'loss': 1.0852, 'grad_norm': 0.1848548415227949, 'learning_rate': 6.407930166884409e-05, 'epoch': 0.63}

 63%|██████▎   | 2417/3844 [9:36:11<4:49:34, 12.18s/it]

 63%|██████▎   | 2418/3844 [9:36:23<4:46:41, 12.06s/it]

 63%|██████▎   | 2419/3844 [9:36:34<4:42:38, 11.90s/it]

 63%|██████▎   | 2420/3844 [9:36:48<4:54:04, 12.39s/it]


 63%|██████▎   | 2422/3844 [9:37:18<5:25:52, 13.75s/it]
{'loss': 1.048, 'grad_norm': 0.16943820333499712, 'learning_rate': 6.360788791129175e-05, 'epoch': 0.63}

 63%|██████▎   | 2423/3844 [9:37:33<5:34:40, 14.13s/it]

 63%|██████▎   | 2424/3844 [9:37:53<6:15:30, 15.87s/it]

 63%|██████▎   | 2425/3844 [9:38:08<6:06:33, 15.50s/it]

 63%|██████▎   | 2426/3844 [9:38:22<5:58:09, 15.15s/it]

 63%|██████▎   | 2427/3844 [9:38:35<5:40:04, 14.40s/it]

 63%|██████▎   | 2428/3844 [9:38:48<5:36:10, 14.24s/it]

 63%|██████▎   | 2429/3844 [9:39:03<5:38:56, 14.37s/it]

 63%|██████▎   | 2430/3844 [9:39:17<5:37:56, 14.34s/it]


 63%|██████▎   | 2432/3844 [9:39:47<5:43:18, 14.59s/it]

 63%|██████▎   | 2433/3844 [9:40:00<5:33:23, 14.18s/it]

 63%|██████▎   | 2434/3844 [9:40:15<5:40:47, 14.50s/it]

 63%|██████▎   | 2435/3844 [9:40:28<5:26:41, 13.91s/it]

 63%|██████▎   | 2436/3844 [9:40:39<5:10:28, 13.23s/it]

 63%|██████▎   | 2437/3844 [9:40:51<4:57:33, 12.69s/it]

 63%|██████▎   | 2438/3844 [9:41:02<4:45:13, 12.17s/it]

 63%|██████▎   | 2439/3844 [9:41:15<4:54:37, 12.58s/it]

 63%|██████▎   | 2440/3844 [9:41:26<4:43:42, 12.12s/it]

 64%|██████▎   | 2441/3844 [9:41:38<4:38:11, 11.90s/it]

 64%|██████▎   | 2442/3844 [9:41:47<4:21:12, 11.18s/it]

 64%|██████▎   | 2443/3844 [9:41:58<4:17:44, 11.04s/it]

 64%|██████▎   | 2444/3844 [9:42:08<4:12:53, 10.84s/it]

 64%|██████▎   | 2445/3844 [9:42:21<4:27:54, 11.49s/it]

 64%|██████▎   | 2446/3844 [9:42:31<4:16:30, 11.01s/it]

 64%|██████▎   | 2447/3844 [9:42:44<4:30:23, 11.61s/it]

 64%|██████▎   | 2448/3844 [9:43:01<5:02:49, 13.02s/it]

 64%|██████▎   | 2449/3844 [9:43:10<4:39:13, 12.01s/it]

 64%|██████▎   | 2450/3844 [9:43:21<4:29:09, 11.58s/it]

 64%|██████▍   | 2451/3844 [9:43:32<4:24:56, 11.41s/it]

 64%|██████▍   | 2452/3844 [9:43:44<4:33:01, 11.77s/it]

 64%|██████▍   | 2453/3844 [9:43:55<4:22:32, 11.32s/it]

 64%|██████▍   | 2454/3844 [9:44:07<4:29:14, 11.62s/it]

 64%|██████▍   | 2455/3844 [9:44:17<4:14:53, 11.01s/it]

 64%|██████▍   | 2456/3844 [9:44:27<4:09:53, 10.80s/it]

 64%|██████▍   | 2457/3844 [9:44:37<4:04:24, 10.57s/it]

 64%|██████▍   | 2458/3844 [9:44:49<4:11:50, 10.90s/it]

 64%|██████▍   | 2459/3844 [9:45:00<4:15:58, 11.09s/it]

 64%|██████▍   | 2460/3844 [9:45:12<4:18:49, 11.22s/it]

 64%|██████▍   | 2461/3844 [9:45:22<4:14:53, 11.06s/it]

 64%|██████▍   | 2462/3844 [9:45:34<4:16:19, 11.13s/it]

 64%|██████▍   | 2463/3844 [9:45:45<4:21:04, 11.34s/it]

 64%|██████▍   | 2464/3844 [9:45:57<4:24:16, 11.49s/it]

 64%|██████▍   | 2465/3844 [9:46:11<4:38:56, 12.14s/it]

 64%|██████▍   | 2466/3844 [9:46:26<4:58:19, 12.99s/it]

 64%|██████▍   | 2467/3844 [9:46:37<4:43:25, 12.35s/it]

 64%|██████▍   | 2468/3844 [9:46:50<4:49:04, 12.60s/it]

 64%|██████▍   | 2469/3844 [9:47:04<5:01:02, 13.14s/it]

 64%|██████▍   | 2470/3844 [9:47:16<4:49:44, 12.65s/it]

 64%|██████▍   | 2471/3844 [9:47:26<4:29:57, 11.80s/it]

 64%|██████▍   | 2472/3844 [9:47:38<4:30:01, 11.81s/it]

 64%|██████▍   | 2473/3844 [9:47:48<4:19:01, 11.34s/it]

 64%|██████▍   | 2474/3844 [9:48:00<4:27:48, 11.73s/it]

 64%|██████▍   | 2475/3844 [9:48:10<4:11:46, 11.03s/it]

 64%|██████▍   | 2476/3844 [9:48:21<4:13:01, 11.10s/it]

 64%|██████▍   | 2477/3844 [9:48:38<4:53:51, 12.90s/it]

 64%|██████▍   | 2478/3844 [9:48:52<4:58:19, 13.10s/it]

 64%|██████▍   | 2479/3844 [9:49:04<4:49:00, 12.70s/it]

 65%|██████▍   | 2480/3844 [9:49:18<5:02:17, 13.30s/it]

 65%|██████▍   | 2481/3844 [9:49:28<4:37:21, 12.21s/it]

 65%|██████▍   | 2482/3844 [9:49:40<4:38:11, 12.26s/it]

 65%|██████▍   | 2483/3844 [9:49:52<4:33:02, 12.04s/it]

 65%|██████▍   | 2484/3844 [9:50:06<4:49:44, 12.78s/it]

 65%|██████▍   | 2485/3844 [9:50:18<4:43:01, 12.50s/it]

 65%|██████▍   | 2486/3844 [9:50:30<4:37:29, 12.26s/it]

 65%|██████▍   | 2487/3844 [9:50:43<4:44:17, 12.57s/it]

 65%|██████▍   | 2488/3844 [9:50:58<4:57:02, 13.14s/it]

 65%|██████▍   | 2489/3844 [9:51:10<4:51:46, 12.92s/it]

 65%|██████▍   | 2490/3844 [9:51:21<4:36:07, 12.24s/it]

 65%|██████▍   | 2491/3844 [9:51:33<4:38:49, 12.36s/it]

 65%|██████▍   | 2492/3844 [9:51:46<4:43:02, 12.56s/it]

 65%|██████▍   | 2493/3844 [9:51:59<4:44:01, 12.61s/it]

 65%|██████▍   | 2494/3844 [9:52:15<5:05:11, 13.56s/it]

 65%|██████▍   | 2495/3844 [9:52:25<4:39:31, 12.43s/it]

 65%|██████▍   | 2496/3844 [9:52:36<4:30:24, 12.04s/it]

 65%|██████▍   | 2497/3844 [9:52:48<4:33:58, 12.20s/it]

 65%|██████▍   | 2498/3844 [9:52:59<4:25:29, 11.83s/it]

 65%|██████▌   | 2499/3844 [9:53:09<4:09:54, 11.15s/it]

 65%|██████▌   | 2500/3844 [9:53:21<4:18:09, 11.52s/it]

 65%|██████▌   | 2501/3844 [9:53:33<4:22:21, 11.72s/it]

 65%|██████▌   | 2502/3844 [9:53:44<4:17:11, 11.50s/it]

 65%|██████▌   | 2503/3844 [9:53:56<4:20:09, 11.64s/it]

 65%|██████▌   | 2504/3844 [9:54:06<4:08:37, 11.13s/it]

 65%|██████▌   | 2505/3844 [9:54:16<3:58:58, 10.71s/it]

 65%|██████▌   | 2506/3844 [9:54:26<3:56:33, 10.61s/it]

 65%|██████▌   | 2507/3844 [9:54:37<3:53:52, 10.50s/it]

 65%|██████▌   | 2508/3844 [9:54:47<3:54:03, 10.51s/it]

 65%|██████▌   | 2509/3844 [9:54:57<3:47:25, 10.22s/it]

 65%|██████▌   | 2510/3844 [9:55:14<4:33:32, 12.30s/it]

 65%|██████▌   | 2511/3844 [9:55:25<4:24:25, 11.90s/it]

 65%|██████▌   | 2512/3844 [9:55:37<4:26:57, 12.03s/it]

 65%|██████▌   | 2513/3844 [9:55:53<4:53:31, 13.23s/it]

 65%|██████▌   | 2514/3844 [9:56:09<5:07:08, 13.86s/it]

 65%|██████▌   | 2515/3844 [9:56:26<5:33:43, 15.07s/it]

 65%|██████▌   | 2516/3844 [9:56:39<5:19:53, 14.45s/it]

 65%|██████▌   | 2517/3844 [9:56:52<5:07:22, 13.90s/it]

 66%|██████▌   | 2518/3844 [9:57:06<5:04:33, 13.78s/it]

 66%|██████▌   | 2519/3844 [9:57:19<5:01:26, 13.65s/it]

 66%|██████▌   | 2520/3844 [9:57:32<4:58:33, 13.53s/it]

 66%|██████▌   | 2521/3844 [9:57:44<4:50:19, 13.17s/it]

 66%|██████▌   | 2522/3844 [9:57:54<4:28:15, 12.18s/it]

 66%|██████▌   | 2523/3844 [9:58:04<4:10:43, 11.39s/it]

 66%|██████▌   | 2524/3844 [9:58:15<4:05:47, 11.17s/it]

 66%|██████▌   | 2525/3844 [9:58:26<4:05:41, 11.18s/it]

 66%|██████▌   | 2526/3844 [9:58:37<4:03:31, 11.09s/it]

 66%|██████▌   | 2527/3844 [9:58:52<4:30:48, 12.34s/it]

 66%|██████▌   | 2528/3844 [9:59:03<4:19:54, 11.85s/it]

 66%|██████▌   | 2529/3844 [9:59:13<4:13:04, 11.55s/it]

 66%|██████▌   | 2530/3844 [9:59:25<4:12:23, 11.52s/it]

 66%|██████▌   | 2531/3844 [9:59:37<4:17:20, 11.76s/it]

 66%|██████▌   | 2532/3844 [9:59:49<4:17:44, 11.79s/it]

 66%|██████▌   | 2533/3844 [10:00:00<4:10:18, 11.46s/it]

 66%|██████▌   | 2534/3844 [10:00:12<4:16:06, 11.73s/it]

 66%|██████▌   | 2535/3844 [10:00:22<4:06:16, 11.29s/it]

 66%|██████▌   | 2536/3844 [10:00:33<4:00:34, 11.04s/it]

 66%|██████▌   | 2537/3844 [10:00:45<4:06:25, 11.31s/it]

 66%|██████▌   | 2538/3844 [10:00:59<4:22:01, 12.04s/it]

 66%|██████▌   | 2539/3844 [10:01:12<4:28:24, 12.34s/it]

 66%|██████▌   | 2540/3844 [10:01:25<4:37:57, 12.79s/it]

 66%|██████▌   | 2541/3844 [10:01:37<4:32:30, 12.55s/it]

 66%|██████▌   | 2542/3844 [10:01:48<4:22:19, 12.09s/it]

 66%|██████▌   | 2543/3844 [10:02:06<4:56:43, 13.68s/it]

 66%|██████▌   | 2544/3844 [10:02:16<4:31:25, 12.53s/it]
{'loss': 0.918, 'grad_norm': 0.1750681549496453, 'learning_rate': 5.424091302866946e-05, 'epoch': 0.66}


 66%|██████▌   | 2546/3844 [10:02:37<4:10:17, 11.57s/it]

 66%|██████▋   | 2547/3844 [10:02:54<4:44:48, 13.18s/it]

 66%|██████▋   | 2548/3844 [10:03:08<4:49:39, 13.41s/it]

 66%|██████▋   | 2549/3844 [10:03:21<4:42:42, 13.10s/it]
{'loss': 1.1257, 'grad_norm': 0.1840659225272673, 'learning_rate': 5.386667071905009e-05, 'epoch': 0.66}


 66%|██████▋   | 2551/3844 [10:03:45<4:36:13, 12.82s/it]

 66%|██████▋   | 2552/3844 [10:03:56<4:19:59, 12.07s/it]

 66%|██████▋   | 2553/3844 [10:04:07<4:14:07, 11.81s/it]

 66%|██████▋   | 2554/3844 [10:04:20<4:24:06, 12.28s/it]

 66%|██████▋   | 2555/3844 [10:04:34<4:30:38, 12.60s/it]
{'loss': 1.0583, 'grad_norm': 0.17724700746186453, 'learning_rate': 5.341866165647572e-05, 'epoch': 0.66}

 66%|██████▋   | 2556/3844 [10:04:44<4:17:02, 11.97s/it]


 67%|██████▋   | 2558/3844 [10:05:09<4:17:02, 11.99s/it]

 67%|██████▋   | 2559/3844 [10:05:20<4:12:36, 11.80s/it]

 67%|██████▋   | 2560/3844 [10:05:35<4:32:29, 12.73s/it]

 67%|██████▋   | 2561/3844 [10:05:45<4:12:14, 11.80s/it]

 67%|██████▋   | 2562/3844 [10:05:59<4:28:25, 12.56s/it]
{'loss': 1.2409, 'grad_norm': 0.18526028064216954, 'learning_rate': 5.2897490336715416e-05, 'epoch': 0.67}


 67%|██████▋   | 2564/3844 [10:06:23<4:21:11, 12.24s/it]

 67%|██████▋   | 2565/3844 [10:06:34<4:08:30, 11.66s/it]

 67%|██████▋   | 2566/3844 [10:06:44<4:00:05, 11.27s/it]

 67%|██████▋   | 2567/3844 [10:06:59<4:20:53, 12.26s/it]

 67%|██████▋   | 2568/3844 [10:07:13<4:34:58, 12.93s/it]

 67%|██████▋   | 2569/3844 [10:07:27<4:40:19, 13.19s/it]

 67%|██████▋   | 2570/3844 [10:07:40<4:39:52, 13.18s/it]

 67%|██████▋   | 2571/3844 [10:07:53<4:40:44, 13.23s/it]

 67%|██████▋   | 2572/3844 [10:08:06<4:36:30, 13.04s/it]

 67%|██████▋   | 2573/3844 [10:08:20<4:40:46, 13.25s/it]

 67%|██████▋   | 2574/3844 [10:08:36<5:01:08, 14.23s/it]

 67%|██████▋   | 2575/3844 [10:08:51<5:03:44, 14.36s/it]

 67%|██████▋   | 2576/3844 [10:09:02<4:40:49, 13.29s/it]

 67%|██████▋   | 2577/3844 [10:09:13<4:27:38, 12.67s/it]
{'loss': 1.2204, 'grad_norm': 0.18489060321901352, 'learning_rate': 5.1786237021001914e-05, 'epoch': 0.67}


 67%|██████▋   | 2579/3844 [10:09:32<3:54:09, 11.11s/it]

 67%|██████▋   | 2580/3844 [10:09:42<3:48:58, 10.87s/it]

 67%|██████▋   | 2581/3844 [10:09:52<3:43:11, 10.60s/it]

 67%|██████▋   | 2582/3844 [10:10:02<3:38:53, 10.41s/it]

 67%|██████▋   | 2583/3844 [10:10:16<4:00:59, 11.47s/it]

 67%|██████▋   | 2584/3844 [10:10:30<4:16:45, 12.23s/it]

 67%|██████▋   | 2585/3844 [10:10:43<4:19:08, 12.35s/it]

 67%|██████▋   | 2586/3844 [10:10:55<4:19:41, 12.39s/it]

 67%|██████▋   | 2587/3844 [10:11:06<4:05:39, 11.73s/it]

 67%|██████▋   | 2588/3844 [10:11:16<3:54:32, 11.20s/it]

 67%|██████▋   | 2589/3844 [10:11:30<4:17:41, 12.32s/it]

 67%|██████▋   | 2590/3844 [10:11:41<4:03:46, 11.66s/it]

 67%|██████▋   | 2591/3844 [10:11:51<3:52:57, 11.16s/it]

 67%|██████▋   | 2592/3844 [10:12:02<3:55:03, 11.26s/it]

 67%|██████▋   | 2593/3844 [10:12:14<3:59:46, 11.50s/it]
{'loss': 1.0355, 'grad_norm': 0.17095983022061187, 'learning_rate': 5.060939559471497e-05, 'epoch': 0.67}


 68%|██████▊   | 2595/3844 [10:12:42<4:29:45, 12.96s/it]

 68%|██████▊   | 2596/3844 [10:12:57<4:37:41, 13.35s/it]

 68%|██████▊   | 2597/3844 [10:13:10<4:38:35, 13.40s/it]

 68%|██████▊   | 2598/3844 [10:13:22<4:28:17, 12.92s/it]

 68%|██████▊   | 2599/3844 [10:13:33<4:15:09, 12.30s/it]

 68%|██████▊   | 2600/3844 [10:13:46<4:18:50, 12.48s/it]

 68%|██████▊   | 2601/3844 [10:14:06<5:07:51, 14.86s/it]

 68%|██████▊   | 2602/3844 [10:14:18<4:46:30, 13.84s/it]

 68%|██████▊   | 2603/3844 [10:14:27<4:20:21, 12.59s/it]
{'loss': 1.0659, 'grad_norm': 0.17296867699809898, 'learning_rate': 4.9878415814652756e-05, 'epoch': 0.68}


 68%|██████▊   | 2605/3844 [10:14:54<4:25:46, 12.87s/it]

 68%|██████▊   | 2606/3844 [10:15:06<4:22:11, 12.71s/it]

 68%|██████▊   | 2607/3844 [10:15:17<4:12:11, 12.23s/it]

 68%|██████▊   | 2608/3844 [10:15:28<4:03:25, 11.82s/it]

 68%|██████▊   | 2609/3844 [10:15:41<4:11:44, 12.23s/it]

 68%|██████▊   | 2610/3844 [10:15:54<4:16:10, 12.46s/it]

 68%|██████▊   | 2611/3844 [10:16:06<4:09:11, 12.13s/it]

 68%|██████▊   | 2612/3844 [10:16:18<4:11:49, 12.26s/it]

 68%|██████▊   | 2613/3844 [10:16:29<4:04:56, 11.94s/it]
{'loss': 1.154, 'grad_norm': 0.1773005595811901, 'learning_rate': 4.915099538017917e-05, 'epoch': 0.68}


 68%|██████▊   | 2615/3844 [10:16:59<4:39:49, 13.66s/it]

 68%|██████▊   | 2616/3844 [10:17:10<4:20:53, 12.75s/it]

 68%|██████▊   | 2617/3844 [10:17:20<4:04:29, 11.96s/it]

 68%|██████▊   | 2618/3844 [10:17:34<4:15:58, 12.53s/it]

 68%|██████▊   | 2619/3844 [10:17:45<4:03:20, 11.92s/it]

 68%|██████▊   | 2620/3844 [10:17:54<3:48:58, 11.22s/it]

 68%|██████▊   | 2621/3844 [10:18:06<3:49:51, 11.28s/it]

 68%|██████▊   | 2622/3844 [10:18:21<4:17:57, 12.67s/it]
{'loss': 0.9386, 'grad_norm': 0.16536222244746954, 'learning_rate': 4.849940292958918e-05, 'epoch': 0.68}

 68%|██████▊   | 2623/3844 [10:18:35<4:24:43, 13.01s/it]


 68%|██████▊   | 2625/3844 [10:18:57<4:06:11, 12.12s/it]

 68%|██████▊   | 2626/3844 [10:19:12<4:23:52, 13.00s/it]

 68%|██████▊   | 2627/3844 [10:19:27<4:35:39, 13.59s/it]

 68%|██████▊   | 2628/3844 [10:19:39<4:24:16, 13.04s/it]

 68%|██████▊   | 2629/3844 [10:19:52<4:23:52, 13.03s/it]

 68%|██████▊   | 2630/3844 [10:20:05<4:21:36, 12.93s/it]

 68%|██████▊   | 2631/3844 [10:20:18<4:21:49, 12.95s/it]
{'loss': 1.1644, 'grad_norm': 0.1656184632962187, 'learning_rate': 4.785077287518014e-05, 'epoch': 0.68}


 68%|██████▊   | 2633/3844 [10:20:41<4:08:13, 12.30s/it]
{'loss': 1.1855, 'grad_norm': 0.18332558388470663, 'learning_rate': 4.770703892036648e-05, 'epoch': 0.68}


 69%|██████▊   | 2635/3844 [10:21:07<4:08:46, 12.35s/it]

 69%|██████▊   | 2636/3844 [10:21:18<4:04:24, 12.14s/it]

 69%|██████▊   | 2637/3844 [10:21:28<3:50:13, 11.44s/it]

 69%|██████▊   | 2638/3844 [10:21:43<4:08:54, 12.38s/it]

 69%|██████▊   | 2639/3844 [10:21:55<4:07:57, 12.35s/it]

 69%|██████▊   | 2640/3844 [10:22:08<4:13:00, 12.61s/it]

 69%|██████▊   | 2641/3844 [10:22:24<4:30:20, 13.48s/it]

 69%|██████▊   | 2642/3844 [10:22:40<4:47:57, 14.37s/it]

 69%|██████▉   | 2643/3844 [10:22:51<4:28:09, 13.40s/it]

 69%|██████▉   | 2644/3844 [10:23:03<4:16:39, 12.83s/it]

 69%|██████▉   | 2645/3844 [10:23:14<4:09:56, 12.51s/it]

 69%|██████▉   | 2646/3844 [10:23:24<3:53:58, 11.72s/it]

 69%|██████▉   | 2647/3844 [10:23:35<3:46:31, 11.35s/it]

 69%|██████▉   | 2648/3844 [10:23:48<3:54:27, 11.76s/it]
{'loss': 1.1158, 'grad_norm': 0.18903128807132588, 'learning_rate': 4.663379718308114e-05, 'epoch': 0.69}


 69%|██████▉   | 2650/3844 [10:24:12<3:54:55, 11.81s/it]

 69%|██████▉   | 2651/3844 [10:24:23<3:52:57, 11.72s/it]

 69%|██████▉   | 2652/3844 [10:24:35<3:50:48, 11.62s/it]

 69%|██████▉   | 2653/3844 [10:24:51<4:19:49, 13.09s/it]

 69%|██████▉   | 2654/3844 [10:25:07<4:31:51, 13.71s/it]

 69%|██████▉   | 2655/3844 [10:25:21<4:35:17, 13.89s/it]

 69%|██████▉   | 2656/3844 [10:25:33<4:22:39, 13.27s/it]

 69%|██████▉   | 2657/3844 [10:25:47<4:27:08, 13.50s/it]
{'loss': 0.9933, 'grad_norm': 0.1798370920331553, 'learning_rate': 4.599393413230016e-05, 'epoch': 0.69}


 69%|██████▉   | 2659/3844 [10:26:12<4:19:52, 13.16s/it]

 69%|██████▉   | 2660/3844 [10:26:24<4:08:02, 12.57s/it]

 69%|██████▉   | 2661/3844 [10:26:34<3:57:29, 12.05s/it]

 69%|██████▉   | 2662/3844 [10:26:45<3:46:55, 11.52s/it]

 69%|██████▉   | 2663/3844 [10:26:59<4:02:39, 12.33s/it]

 69%|██████▉   | 2664/3844 [10:27:10<3:55:27, 11.97s/it]

 69%|██████▉   | 2665/3844 [10:27:23<3:58:18, 12.13s/it]

 69%|██████▉   | 2666/3844 [10:27:34<3:54:38, 11.95s/it]

 69%|██████▉   | 2667/3844 [10:27:51<4:20:52, 13.30s/it]

 69%|██████▉   | 2668/3844 [10:28:06<4:32:34, 13.91s/it]

 69%|██████▉   | 2669/3844 [10:28:17<4:17:58, 13.17s/it]

 69%|██████▉   | 2670/3844 [10:28:30<4:13:15, 12.94s/it]

 69%|██████▉   | 2671/3844 [10:28:44<4:17:40, 13.18s/it]

 70%|██████▉   | 2672/3844 [10:28:54<4:04:00, 12.49s/it]
{'loss': 1.0676, 'grad_norm': 0.16578808028801711, 'learning_rate': 4.4934417175340104e-05, 'epoch': 0.7}


 70%|██████▉   | 2674/3844 [10:29:14<3:38:12, 11.19s/it]

 70%|██████▉   | 2675/3844 [10:29:24<3:31:32, 10.86s/it]

 70%|██████▉   | 2676/3844 [10:29:35<3:28:26, 10.71s/it]

 70%|██████▉   | 2677/3844 [10:29:51<4:03:49, 12.54s/it]

 70%|██████▉   | 2678/3844 [10:30:02<3:54:43, 12.08s/it]

 70%|██████▉   | 2679/3844 [10:30:12<3:41:08, 11.39s/it]

 70%|██████▉   | 2680/3844 [10:30:26<3:52:38, 11.99s/it]

 70%|██████▉   | 2681/3844 [10:30:35<3:37:32, 11.22s/it]

 70%|██████▉   | 2682/3844 [10:30:45<3:30:12, 10.85s/it]

 70%|██████▉   | 2683/3844 [10:30:56<3:28:24, 10.77s/it]

 70%|██████▉   | 2684/3844 [10:31:11<3:55:01, 12.16s/it]

 70%|██████▉   | 2685/3844 [10:31:21<3:43:24, 11.57s/it]

 70%|██████▉   | 2686/3844 [10:31:33<3:42:31, 11.53s/it]

 70%|██████▉   | 2687/3844 [10:31:46<3:53:30, 12.11s/it]

 70%|██████▉   | 2688/3844 [10:31:58<3:51:02, 11.99s/it]

 70%|██████▉   | 2689/3844 [10:32:08<3:43:00, 11.58s/it]

 70%|██████▉   | 2690/3844 [10:32:21<3:45:54, 11.75s/it]

 70%|███████   | 2691/3844 [10:32:32<3:41:46, 11.54s/it]

 70%|███████   | 2692/3844 [10:32:43<3:40:01, 11.46s/it]

 70%|███████   | 2693/3844 [10:32:55<3:44:07, 11.68s/it]

 70%|███████   | 2694/3844 [10:33:08<3:51:18, 12.07s/it]

 70%|███████   | 2695/3844 [10:33:21<3:55:23, 12.29s/it]

 70%|███████   | 2696/3844 [10:33:35<4:07:45, 12.95s/it]

 70%|███████   | 2697/3844 [10:33:48<4:05:51, 12.86s/it]

 70%|███████   | 2698/3844 [10:34:04<4:21:55, 13.71s/it]

 70%|███████   | 2699/3844 [10:34:17<4:17:09, 13.48s/it]

 70%|███████   | 2700/3844 [10:34:33<4:31:58, 14.26s/it]
 70%|███████   | 2700/3844 [10:34:33<4:31:58, 14.26s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 70%|███████   | 2701/3844 [10:35:23<7:56:19, 25.00s/it]

 70%|███████   | 2702/3844 [10:35:36<6:46:58, 21.38s/it]

 70%|███████   | 2703/3844 [10:35:52<6:16:50, 19.82s/it]

 70%|███████   | 2704/3844 [10:36:06<5:45:38, 18.19s/it]

 70%|███████   | 2705/3844 [10:36:19<5:15:02, 16.60s/it]

 70%|███████   | 2706/3844 [10:36:31<4:47:21, 15.15s/it]

 70%|███████   | 2707/3844 [10:36:44<4:36:54, 14.61s/it]

 70%|███████   | 2708/3844 [10:36:56<4:22:15, 13.85s/it]

 70%|███████   | 2709/3844 [10:37:07<4:05:24, 12.97s/it]

 70%|███████   | 2710/3844 [10:37:17<3:48:15, 12.08s/it]

 71%|███████   | 2711/3844 [10:37:28<3:42:35, 11.79s/it]

 71%|███████   | 2712/3844 [10:37:41<3:45:51, 11.97s/it]

 71%|███████   | 2713/3844 [10:37:51<3:33:16, 11.31s/it]

 71%|███████   | 2714/3844 [10:38:01<3:27:09, 11.00s/it]

 71%|███████   | 2715/3844 [10:38:12<3:25:52, 10.94s/it]

 71%|███████   | 2716/3844 [10:38:24<3:35:50, 11.48s/it]

 71%|███████   | 2717/3844 [10:38:38<3:45:17, 11.99s/it]

 71%|███████   | 2718/3844 [10:38:48<3:34:37, 11.44s/it]

 71%|███████   | 2719/3844 [10:38:58<3:28:46, 11.13s/it]

 71%|███████   | 2720/3844 [10:39:09<3:27:12, 11.06s/it]

 71%|███████   | 2721/3844 [10:39:23<3:43:34, 11.95s/it]

 71%|███████   | 2722/3844 [10:39:35<3:41:17, 11.83s/it]

 71%|███████   | 2723/3844 [10:39:46<3:39:52, 11.77s/it]

 71%|███████   | 2724/3844 [10:39:59<3:47:41, 12.20s/it]

 71%|███████   | 2725/3844 [10:40:12<3:48:50, 12.27s/it]

 71%|███████   | 2726/3844 [10:40:22<3:35:32, 11.57s/it]

 71%|███████   | 2727/3844 [10:40:32<3:25:27, 11.04s/it]

 71%|███████   | 2728/3844 [10:40:41<3:17:04, 10.60s/it]

 71%|███████   | 2729/3844 [10:40:52<3:19:51, 10.75s/it]

 71%|███████   | 2730/3844 [10:41:03<3:17:54, 10.66s/it]
{'loss': 1.2419, 'grad_norm': 0.17508579144354613, 'learning_rate': 4.092190504722257e-05, 'epoch': 0.71}


 71%|███████   | 2732/3844 [10:41:24<3:18:47, 10.73s/it]

 71%|███████   | 2733/3844 [10:41:39<3:38:36, 11.81s/it]

 71%|███████   | 2734/3844 [10:41:48<3:25:30, 11.11s/it]

 71%|███████   | 2735/3844 [10:41:58<3:17:54, 10.71s/it]

 71%|███████   | 2736/3844 [10:42:08<3:16:36, 10.65s/it]

 71%|███████   | 2737/3844 [10:42:19<3:15:02, 10.57s/it]

 71%|███████   | 2738/3844 [10:42:32<3:28:11, 11.29s/it]

 71%|███████▏  | 2739/3844 [10:42:45<3:38:10, 11.85s/it]

 71%|███████▏  | 2740/3844 [10:42:55<3:30:16, 11.43s/it]

 71%|███████▏  | 2741/3844 [10:43:08<3:35:29, 11.72s/it]

 71%|███████▏  | 2742/3844 [10:43:20<3:37:26, 11.84s/it]

 71%|███████▏  | 2743/3844 [10:43:35<3:58:24, 12.99s/it]

 71%|███████▏  | 2744/3844 [10:43:46<3:47:02, 12.38s/it]

 71%|███████▏  | 2745/3844 [10:44:06<4:27:01, 14.58s/it]

 71%|███████▏  | 2746/3844 [10:44:19<4:18:50, 14.14s/it]

 71%|███████▏  | 2747/3844 [10:44:36<4:32:20, 14.90s/it]

 71%|███████▏  | 2748/3844 [10:44:50<4:26:16, 14.58s/it]

 72%|███████▏  | 2749/3844 [10:45:00<4:03:08, 13.32s/it]

 72%|███████▏  | 2750/3844 [10:45:10<3:46:11, 12.41s/it]

 72%|███████▏  | 2751/3844 [10:45:24<3:52:10, 12.74s/it]

 72%|███████▏  | 2752/3844 [10:45:36<3:49:03, 12.59s/it]

 72%|███████▏  | 2753/3844 [10:45:53<4:11:06, 13.81s/it]

 72%|███████▏  | 2754/3844 [10:46:07<4:10:21, 13.78s/it]

 72%|███████▏  | 2755/3844 [10:46:20<4:10:14, 13.79s/it]

 72%|███████▏  | 2756/3844 [10:46:34<4:07:10, 13.63s/it]

 72%|███████▏  | 2757/3844 [10:46:44<3:52:09, 12.81s/it]
{'loss': 1.0134, 'grad_norm': 0.18334575611424941, 'learning_rate': 3.910157415577758e-05, 'epoch': 0.72}


 72%|███████▏  | 2759/3844 [10:47:12<3:59:17, 13.23s/it]

 72%|███████▏  | 2760/3844 [10:47:25<4:01:28, 13.37s/it]

 72%|███████▏  | 2761/3844 [10:47:37<3:54:24, 12.99s/it]

 72%|███████▏  | 2762/3844 [10:47:53<4:10:18, 13.88s/it]

 72%|███████▏  | 2763/3844 [10:48:04<3:52:43, 12.92s/it]

 72%|███████▏  | 2764/3844 [10:48:15<3:43:51, 12.44s/it]

 72%|███████▏  | 2765/3844 [10:48:28<3:43:02, 12.40s/it]

 72%|███████▏  | 2766/3844 [10:48:41<3:49:24, 12.77s/it]

 72%|███████▏  | 2767/3844 [10:48:52<3:38:18, 12.16s/it]

 72%|███████▏  | 2768/3844 [10:49:07<3:53:28, 13.02s/it]

 72%|███████▏  | 2769/3844 [10:49:19<3:47:02, 12.67s/it]

 72%|███████▏  | 2770/3844 [10:49:33<3:54:26, 13.10s/it]

 72%|███████▏  | 2771/3844 [10:49:46<3:51:35, 12.95s/it]

 72%|███████▏  | 2772/3844 [10:49:56<3:38:42, 12.24s/it]

 72%|███████▏  | 2773/3844 [10:50:10<3:46:52, 12.71s/it]

 72%|███████▏  | 2774/3844 [10:50:23<3:50:22, 12.92s/it]

 72%|███████▏  | 2775/3844 [10:50:36<3:48:01, 12.80s/it]

 72%|███████▏  | 2776/3844 [10:50:50<3:55:01, 13.20s/it]

 72%|███████▏  | 2777/3844 [10:51:02<3:50:46, 12.98s/it]

 72%|███████▏  | 2778/3844 [10:51:18<4:05:26, 13.81s/it]

 72%|███████▏  | 2779/3844 [10:51:31<4:01:33, 13.61s/it]

 72%|███████▏  | 2780/3844 [10:51:43<3:51:28, 13.05s/it]

 72%|███████▏  | 2781/3844 [10:51:56<3:51:53, 13.09s/it]

 72%|███████▏  | 2782/3844 [10:52:10<3:57:23, 13.41s/it]

 72%|███████▏  | 2783/3844 [10:52:23<3:54:22, 13.25s/it]

 72%|███████▏  | 2784/3844 [10:52:38<3:59:10, 13.54s/it]

 72%|███████▏  | 2785/3844 [10:52:52<4:01:41, 13.69s/it]

 72%|███████▏  | 2786/3844 [10:53:04<3:56:11, 13.39s/it]
{'loss': 1.0302, 'grad_norm': 0.1715899411060418, 'learning_rate': 3.718154440156847e-05, 'epoch': 0.72}


 73%|███████▎  | 2788/3844 [10:53:28<3:39:59, 12.50s/it]

 73%|███████▎  | 2789/3844 [10:53:38<3:23:59, 11.60s/it]

 73%|███████▎  | 2790/3844 [10:53:48<3:14:33, 11.08s/it]
{'loss': 1.0063, 'grad_norm': 0.1865064268757993, 'learning_rate': 3.691963125369422e-05, 'epoch': 0.73}


 73%|███████▎  | 2792/3844 [10:54:08<3:06:59, 10.66s/it]

 73%|███████▎  | 2793/3844 [10:54:18<3:04:20, 10.52s/it]

 73%|███████▎  | 2794/3844 [10:54:35<3:34:52, 12.28s/it]

 73%|███████▎  | 2795/3844 [10:54:48<3:39:29, 12.55s/it]

 73%|███████▎  | 2796/3844 [10:55:04<3:59:29, 13.71s/it]

 73%|███████▎  | 2797/3844 [10:55:15<3:45:48, 12.94s/it]

 73%|███████▎  | 2798/3844 [10:55:26<3:30:43, 12.09s/it]

 73%|███████▎  | 2799/3844 [10:55:37<3:27:17, 11.90s/it]

 73%|███████▎  | 2800/3844 [10:55:49<3:26:55, 11.89s/it]

 73%|███████▎  | 2801/3844 [10:56:00<3:22:20, 11.64s/it]

 73%|███████▎  | 2802/3844 [10:56:13<3:31:16, 12.17s/it]

 73%|███████▎  | 2803/3844 [10:56:23<3:19:14, 11.48s/it]

 73%|███████▎  | 2804/3844 [10:56:34<3:15:00, 11.25s/it]

 73%|███████▎  | 2805/3844 [10:56:45<3:12:21, 11.11s/it]

 73%|███████▎  | 2806/3844 [10:56:55<3:07:17, 10.83s/it]

 73%|███████▎  | 2807/3844 [10:57:06<3:09:09, 10.94s/it]

 73%|███████▎  | 2808/3844 [10:57:23<3:41:01, 12.80s/it]

 73%|███████▎  | 2809/3844 [10:57:37<3:46:41, 13.14s/it]
{'loss': 1.1728, 'grad_norm': 0.17175835922434685, 'learning_rate': 3.568538234913041e-05, 'epoch': 0.73}


 73%|███████▎  | 2811/3844 [10:57:58<3:22:53, 11.78s/it]

 73%|███████▎  | 2812/3844 [10:58:09<3:14:52, 11.33s/it]

 73%|███████▎  | 2813/3844 [10:58:20<3:13:48, 11.28s/it]

 73%|███████▎  | 2814/3844 [10:58:34<3:27:18, 12.08s/it]

 73%|███████▎  | 2815/3844 [10:58:47<3:34:04, 12.48s/it]
{'loss': 1.072, 'grad_norm': 0.18652631231768607, 'learning_rate': 3.529903004673195e-05, 'epoch': 0.73}


 73%|███████▎  | 2817/3844 [10:59:14<3:46:22, 13.23s/it]

 73%|███████▎  | 2818/3844 [10:59:24<3:27:15, 12.12s/it]

 73%|███████▎  | 2819/3844 [10:59:36<3:26:44, 12.10s/it]

 73%|███████▎  | 2820/3844 [10:59:47<3:24:10, 11.96s/it]

 73%|███████▎  | 2821/3844 [11:00:01<3:31:24, 12.40s/it]

 73%|███████▎  | 2822/3844 [11:00:16<3:46:28, 13.30s/it]

 73%|███████▎  | 2823/3844 [11:00:29<3:46:00, 13.28s/it]

 73%|███████▎  | 2824/3844 [11:00:41<3:39:09, 12.89s/it]

 73%|███████▎  | 2825/3844 [11:00:56<3:47:11, 13.38s/it]

 74%|███████▎  | 2826/3844 [11:01:07<3:35:30, 12.70s/it]

 74%|███████▎  | 2827/3844 [11:01:21<3:43:13, 13.17s/it]

 74%|███████▎  | 2828/3844 [11:01:34<3:42:41, 13.15s/it]

 74%|███████▎  | 2829/3844 [11:01:49<3:47:38, 13.46s/it]

 74%|███████▎  | 2830/3844 [11:02:01<3:42:29, 13.17s/it]

 74%|███████▎  | 2831/3844 [11:02:15<3:47:45, 13.49s/it]

 74%|███████▎  | 2832/3844 [11:02:33<4:09:45, 14.81s/it]

 74%|███████▎  | 2833/3844 [11:02:48<4:09:56, 14.83s/it]
{'loss': 1.1479, 'grad_norm': 0.18112736383047975, 'learning_rate': 3.4149937003283775e-05, 'epoch': 0.74}


 74%|███████▍  | 2835/3844 [11:03:14<3:52:10, 13.81s/it]

 74%|███████▍  | 2836/3844 [11:03:32<4:13:16, 15.08s/it]

 74%|███████▍  | 2837/3844 [11:03:46<4:07:36, 14.75s/it]
{'loss': 1.0851, 'grad_norm': 0.15998208125333627, 'learning_rate': 3.389663129377506e-05, 'epoch': 0.74}

 74%|███████▍  | 2838/3844 [11:03:59<3:59:17, 14.27s/it]

 74%|███████▍  | 2839/3844 [11:04:09<3:37:10, 12.97s/it]


 74%|███████▍  | 2841/3844 [11:04:34<3:28:38, 12.48s/it]

 74%|███████▍  | 2842/3844 [11:04:45<3:21:00, 12.04s/it]

 74%|███████▍  | 2843/3844 [11:04:54<3:09:16, 11.35s/it]

 74%|███████▍  | 2844/3844 [11:05:04<3:00:06, 10.81s/it]

 74%|███████▍  | 2845/3844 [11:05:14<2:58:24, 10.71s/it]

 74%|███████▍  | 2846/3844 [11:05:25<3:00:05, 10.83s/it]

 74%|███████▍  | 2847/3844 [11:05:36<2:58:56, 10.77s/it]

 74%|███████▍  | 2848/3844 [11:05:46<2:55:58, 10.60s/it]

 74%|███████▍  | 2849/3844 [11:05:58<3:02:42, 11.02s/it]

 74%|███████▍  | 2850/3844 [11:06:14<3:26:08, 12.44s/it]

 74%|███████▍  | 2851/3844 [11:06:29<3:37:48, 13.16s/it]

 74%|███████▍  | 2852/3844 [11:06:40<3:25:24, 12.42s/it]
{'loss': 1.0152, 'grad_norm': 0.18864310441913112, 'learning_rate': 3.29534476619609e-05, 'epoch': 0.74}


 74%|███████▍  | 2854/3844 [11:07:05<3:30:33, 12.76s/it]

 74%|███████▍  | 2855/3844 [11:07:18<3:32:49, 12.91s/it]

 74%|███████▍  | 2856/3844 [11:07:28<3:17:15, 11.98s/it]
{'loss': 1.0967, 'grad_norm': 0.17917035324278466, 'learning_rate': 3.270373511014419e-05, 'epoch': 0.74}


 74%|███████▍  | 2858/3844 [11:07:48<3:00:41, 11.00s/it]
{'loss': 1.2011, 'grad_norm': 0.18785149936231743, 'learning_rate': 3.2579165398204336e-05, 'epoch': 0.74}


 74%|███████▍  | 2860/3844 [11:08:12<3:06:00, 11.34s/it]

 74%|███████▍  | 2861/3844 [11:08:22<2:59:09, 10.94s/it]

 74%|███████▍  | 2862/3844 [11:08:33<3:01:20, 11.08s/it]

 74%|███████▍  | 2863/3844 [11:08:43<2:54:06, 10.65s/it]

 75%|███████▍  | 2864/3844 [11:08:54<2:58:22, 10.92s/it]

 75%|███████▍  | 2865/3844 [11:09:07<3:06:04, 11.40s/it]

 75%|███████▍  | 2866/3844 [11:09:18<3:04:57, 11.35s/it]

 75%|███████▍  | 2867/3844 [11:09:29<3:03:56, 11.30s/it]

 75%|███████▍  | 2868/3844 [11:09:40<3:01:12, 11.14s/it]

 75%|███████▍  | 2869/3844 [11:09:52<3:08:02, 11.57s/it]

 75%|███████▍  | 2870/3844 [11:10:08<3:26:03, 12.69s/it]

 75%|███████▍  | 2871/3844 [11:10:19<3:18:06, 12.22s/it]

 75%|███████▍  | 2872/3844 [11:10:30<3:14:02, 11.98s/it]
{'loss': 0.8206, 'grad_norm': 0.17175736392122354, 'learning_rate': 3.171255957118264e-05, 'epoch': 0.75}


 75%|███████▍  | 2874/3844 [11:10:58<3:29:07, 12.94s/it]
{'loss': 0.9888, 'grad_norm': 0.16957554985033255, 'learning_rate': 3.1589531838266927e-05, 'epoch': 0.75}


 75%|███████▍  | 2876/3844 [11:11:21<3:13:35, 12.00s/it]

 75%|███████▍  | 2877/3844 [11:11:32<3:09:33, 11.76s/it]

 75%|███████▍  | 2878/3844 [11:11:49<3:36:19, 13.44s/it]
{'loss': 1.0621, 'grad_norm': 0.19239749045159898, 'learning_rate': 3.134405969865335e-05, 'epoch': 0.75}


 75%|███████▍  | 2880/3844 [11:12:15<3:30:57, 13.13s/it]

 75%|███████▍  | 2881/3844 [11:12:28<3:33:16, 13.29s/it]

 75%|███████▍  | 2882/3844 [11:12:40<3:26:40, 12.89s/it]

 75%|███████▌  | 2883/3844 [11:12:52<3:22:10, 12.62s/it]

 75%|███████▌  | 2884/3844 [11:13:05<3:21:34, 12.60s/it]

 75%|███████▌  | 2885/3844 [11:13:17<3:20:12, 12.53s/it]
{'loss': 1.1497, 'grad_norm': 0.18652121130305202, 'learning_rate': 3.0916362222703e-05, 'epoch': 0.75}


 75%|███████▌  | 2887/3844 [11:13:39<3:05:55, 11.66s/it]

 75%|███████▌  | 2888/3844 [11:13:50<3:01:55, 11.42s/it]

 75%|███████▌  | 2889/3844 [11:14:01<2:57:05, 11.13s/it]

 75%|███████▌  | 2890/3844 [11:14:11<2:52:47, 10.87s/it]

 75%|███████▌  | 2891/3844 [11:14:23<2:59:34, 11.31s/it]

 75%|███████▌  | 2892/3844 [11:14:38<3:17:32, 12.45s/it]

 75%|███████▌  | 2893/3844 [11:14:48<3:06:00, 11.74s/it]
{'loss': 1.1198, 'grad_norm': 0.19458852591640544, 'learning_rate': 3.043050953288552e-05, 'epoch': 0.75}


 75%|███████▌  | 2895/3844 [11:15:10<2:54:35, 11.04s/it]
{'loss': 1.2, 'grad_norm': 0.18165486406926115, 'learning_rate': 3.0309539544433617e-05, 'epoch': 0.75}


 75%|███████▌  | 2897/3844 [11:15:41<3:36:23, 13.71s/it]
[2024-05-27 12:26:18,955] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 75%|███████▌  | 2898/3844 [11:15:52<3:25:47, 13.05s/it]

 75%|███████▌  | 2899/3844 [11:16:02<3:11:13, 12.14s/it]
{'loss': 1.1717, 'grad_norm': 0.17219008646022582, 'learning_rate': 3.0068193795673716e-05, 'epoch': 0.75}


 75%|███████▌  | 2901/3844 [11:16:25<3:03:31, 11.68s/it]

 75%|███████▌  | 2902/3844 [11:16:35<2:54:38, 11.12s/it]

 76%|███████▌  | 2903/3844 [11:16:45<2:51:26, 10.93s/it]

 76%|███████▌  | 2904/3844 [11:16:57<2:54:22, 11.13s/it]

 76%|███████▌  | 2905/3844 [11:17:07<2:47:33, 10.71s/it]

 76%|███████▌  | 2906/3844 [11:17:19<2:57:45, 11.37s/it]

 76%|███████▌  | 2907/3844 [11:17:30<2:51:54, 11.01s/it]

 76%|███████▌  | 2908/3844 [11:17:42<2:56:22, 11.31s/it]
{'loss': 1.0737, 'grad_norm': 0.1651255177720254, 'learning_rate': 2.952807523806176e-05, 'epoch': 0.76}


 76%|███████▌  | 2910/3844 [11:18:04<2:55:44, 11.29s/it]

 76%|███████▌  | 2911/3844 [11:18:14<2:49:08, 10.88s/it]

 76%|███████▌  | 2912/3844 [11:18:27<2:59:01, 11.52s/it]

 76%|███████▌  | 2913/3844 [11:18:40<3:02:28, 11.76s/it]

 76%|███████▌  | 2914/3844 [11:18:54<3:16:03, 12.65s/it]

 76%|███████▌  | 2915/3844 [11:19:09<3:25:42, 13.29s/it]

 76%|███████▌  | 2916/3844 [11:19:24<3:30:21, 13.60s/it]

 76%|███████▌  | 2917/3844 [11:19:39<3:39:41, 14.22s/it]

 76%|███████▌  | 2918/3844 [11:19:55<3:45:31, 14.61s/it]

 76%|███████▌  | 2919/3844 [11:20:05<3:26:48, 13.41s/it]

 76%|███████▌  | 2920/3844 [11:20:15<3:07:20, 12.17s/it]

 76%|███████▌  | 2921/3844 [11:20:29<3:17:43, 12.85s/it]

 76%|███████▌  | 2922/3844 [11:20:39<3:03:23, 11.93s/it]

 76%|███████▌  | 2923/3844 [11:20:54<3:16:27, 12.80s/it]

 76%|███████▌  | 2924/3844 [11:21:03<3:01:34, 11.84s/it]

 76%|███████▌  | 2925/3844 [11:21:13<2:50:27, 11.13s/it]

 76%|███████▌  | 2926/3844 [11:21:23<2:45:37, 10.83s/it]
{'loss': 1.0734, 'grad_norm': 0.16560819854157768, 'learning_rate': 2.846002992943181e-05, 'epoch': 0.76}


 76%|███████▌  | 2928/3844 [11:21:45<2:47:22, 10.96s/it]

 76%|███████▌  | 2929/3844 [11:21:57<2:55:45, 11.53s/it]

 76%|███████▌  | 2930/3844 [11:22:08<2:50:01, 11.16s/it]

 76%|███████▌  | 2931/3844 [11:22:23<3:09:09, 12.43s/it]

 76%|███████▋  | 2932/3844 [11:22:34<3:01:15, 11.92s/it]

 76%|███████▋  | 2933/3844 [11:22:45<2:56:17, 11.61s/it]

 76%|███████▋  | 2934/3844 [11:22:56<2:53:06, 11.41s/it]
{'loss': 1.203, 'grad_norm': 0.187296626784929, 'learning_rate': 2.7990612155181263e-05, 'epoch': 0.76}


 76%|███████▋  | 2936/3844 [11:23:17<2:48:35, 11.14s/it]

 76%|███████▋  | 2937/3844 [11:23:33<3:10:08, 12.58s/it]

 76%|███████▋  | 2938/3844 [11:23:44<3:01:03, 11.99s/it]
{'loss': 1.2041, 'grad_norm': 0.18291174061519536, 'learning_rate': 2.775712922890763e-05, 'epoch': 0.76}


 76%|███████▋  | 2940/3844 [11:24:08<3:03:28, 12.18s/it]

 77%|███████▋  | 2941/3844 [11:24:19<2:56:23, 11.72s/it]

 77%|███████▋  | 2942/3844 [11:24:31<2:59:06, 11.91s/it]

 77%|███████▋  | 2943/3844 [11:24:47<3:18:26, 13.21s/it]

 77%|███████▋  | 2944/3844 [11:24:59<3:10:16, 12.68s/it]
{'loss': 1.2071, 'grad_norm': 0.18409851190936793, 'learning_rate': 2.7408444755134044e-05, 'epoch': 0.77}


 77%|███████▋  | 2946/3844 [11:25:19<2:52:23, 11.52s/it]

 77%|███████▋  | 2947/3844 [11:25:31<2:51:58, 11.50s/it]

 77%|███████▋  | 2948/3844 [11:25:42<2:51:10, 11.46s/it]

 77%|███████▋  | 2949/3844 [11:26:02<3:27:32, 13.91s/it]

 77%|███████▋  | 2950/3844 [11:26:18<3:35:38, 14.47s/it]

 77%|███████▋  | 2951/3844 [11:26:35<3:48:05, 15.33s/it]

 77%|███████▋  | 2952/3844 [11:26:47<3:33:14, 14.34s/it]

 77%|███████▋  | 2953/3844 [11:27:01<3:32:19, 14.30s/it]

 77%|███████▋  | 2954/3844 [11:27:17<3:38:06, 14.70s/it]

 77%|███████▋  | 2955/3844 [11:27:31<3:36:33, 14.62s/it]

 77%|███████▋  | 2956/3844 [11:27:48<3:46:46, 15.32s/it]

 77%|███████▋  | 2957/3844 [11:28:00<3:31:58, 14.34s/it]

 77%|███████▋  | 2958/3844 [11:28:17<3:43:14, 15.12s/it]
{'loss': 1.1026, 'grad_norm': 0.17433482152535787, 'learning_rate': 2.66020800419021e-05, 'epoch': 0.77}


 77%|███████▋  | 2960/3844 [11:28:42<3:23:27, 13.81s/it]
{'loss': 0.9915, 'grad_norm': 0.16472029947439865, 'learning_rate': 2.6487716445542133e-05, 'epoch': 0.77}


 77%|███████▋  | 2962/3844 [11:29:06<3:06:25, 12.68s/it]

 77%|███████▋  | 2963/3844 [11:29:16<2:54:02, 11.85s/it]

 77%|███████▋  | 2964/3844 [11:29:27<2:51:03, 11.66s/it]
{'loss': 1.1183, 'grad_norm': 0.1805110452624406, 'learning_rate': 2.625961603081213e-05, 'epoch': 0.77}


 77%|███████▋  | 2966/3844 [11:29:52<2:55:55, 12.02s/it]
{'loss': 1.0064, 'grad_norm': 0.1827583820322723, 'learning_rate': 2.6145879860380773e-05, 'epoch': 0.77}

 77%|███████▋  | 2967/3844 [11:30:09<3:16:00, 13.41s/it]

 77%|███████▋  | 2968/3844 [11:30:19<3:00:21, 12.35s/it]


 77%|███████▋  | 2970/3844 [11:30:44<3:01:16, 12.44s/it]

 77%|███████▋  | 2971/3844 [11:30:54<2:52:38, 11.87s/it]

 77%|███████▋  | 2972/3844 [11:31:04<2:41:52, 11.14s/it]

 77%|███████▋  | 2973/3844 [11:31:15<2:43:29, 11.26s/it]

 77%|███████▋  | 2974/3844 [11:31:26<2:41:09, 11.11s/it]

 77%|███████▋  | 2975/3844 [11:31:41<2:56:21, 12.18s/it]

 77%|███████▋  | 2976/3844 [11:31:51<2:49:55, 11.75s/it]

 77%|███████▋  | 2977/3844 [11:32:06<3:02:43, 12.64s/it]

 77%|███████▋  | 2978/3844 [11:32:19<3:05:04, 12.82s/it]

 77%|███████▋  | 2979/3844 [11:32:32<3:04:57, 12.83s/it]
{'loss': 1.0537, 'grad_norm': 0.1796683628016991, 'learning_rate': 2.5411722738443465e-05, 'epoch': 0.77}


 78%|███████▊  | 2981/3844 [11:32:56<2:59:20, 12.47s/it]

 78%|███████▊  | 2982/3844 [11:33:11<3:08:40, 13.13s/it]

 78%|███████▊  | 2983/3844 [11:33:22<2:58:22, 12.43s/it]

 78%|███████▊  | 2984/3844 [11:33:32<2:51:16, 11.95s/it]

 78%|███████▊  | 2985/3844 [11:33:46<2:56:09, 12.30s/it]
{'loss': 1.0508, 'grad_norm': 0.17251692877634334, 'learning_rate': 2.5075894876052142e-05, 'epoch': 0.78}


 78%|███████▊  | 2987/3844 [11:34:10<2:54:31, 12.22s/it]

 78%|███████▊  | 2988/3844 [11:34:22<2:53:04, 12.13s/it]

 78%|███████▊  | 2989/3844 [11:34:38<3:06:46, 13.11s/it]

 78%|███████▊  | 2990/3844 [11:34:50<3:02:26, 12.82s/it]

 78%|███████▊  | 2991/3844 [11:35:02<3:00:35, 12.70s/it]

 78%|███████▊  | 2992/3844 [11:35:13<2:50:24, 12.00s/it]

 78%|███████▊  | 2993/3844 [11:35:24<2:48:31, 11.88s/it]

 78%|███████▊  | 2994/3844 [11:35:39<2:59:56, 12.70s/it]
{'loss': 1.1083, 'grad_norm': 0.1678322630244798, 'learning_rate': 2.4575747222939527e-05, 'epoch': 0.78}


 78%|███████▊  | 2996/3844 [11:36:02<2:51:42, 12.15s/it]

 78%|███████▊  | 2997/3844 [11:36:18<3:05:53, 13.17s/it]

 78%|███████▊  | 2998/3844 [11:36:28<2:51:26, 12.16s/it]

 78%|███████▊  | 2999/3844 [11:36:40<2:50:41, 12.12s/it]

 78%|███████▊  | 3000/3844 [11:36:51<2:46:12, 11.82s/it]
 78%|███████▊  | 3000/3844 [11:36:51<2:46:12, 11.82s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 78%|███████▊  | 3001/3844 [11:37:36<5:08:37, 21.97s/it]

 78%|███████▊  | 3002/3844 [11:37:48<4:23:57, 18.81s/it]

 78%|███████▊  | 3003/3844 [11:38:03<4:06:01, 17.55s/it]

 78%|███████▊  | 3004/3844 [11:38:20<4:06:44, 17.62s/it]

 78%|███████▊  | 3005/3844 [11:38:33<3:44:13, 16.04s/it]

 78%|███████▊  | 3006/3844 [11:38:46<3:32:21, 15.20s/it]

 78%|███████▊  | 3007/3844 [11:39:01<3:31:51, 15.19s/it]

 78%|███████▊  | 3008/3844 [11:39:19<3:41:59, 15.93s/it]
{'loss': 1.0578, 'grad_norm': 0.1826040883879333, 'learning_rate': 2.380637375419208e-05, 'epoch': 0.78}


 78%|███████▊  | 3010/3844 [11:39:47<3:25:30, 14.78s/it]

 78%|███████▊  | 3011/3844 [11:40:02<3:26:24, 14.87s/it]
{'loss': 1.0191, 'grad_norm': 0.17983438545037786, 'learning_rate': 2.3642884143916556e-05, 'epoch': 0.78}


 78%|███████▊  | 3013/3844 [11:40:31<3:23:25, 14.69s/it]

 78%|███████▊  | 3014/3844 [11:40:47<3:26:16, 14.91s/it]
{'loss': 1.0605, 'grad_norm': 0.18386078715128176, 'learning_rate': 2.3479882556013754e-05, 'epoch': 0.78}


 78%|███████▊  | 3016/3844 [11:41:11<3:06:14, 13.50s/it]
{'loss': 1.0771, 'grad_norm': 0.1853280260965939, 'learning_rate': 2.337148646888061e-05, 'epoch': 0.78}


 79%|███████▊  | 3018/3844 [11:41:33<2:47:58, 12.20s/it]

 79%|███████▊  | 3019/3844 [11:41:45<2:50:34, 12.40s/it]

 79%|███████▊  | 3020/3844 [11:41:57<2:46:17, 12.11s/it]

 79%|███████▊  | 3021/3844 [11:42:14<3:08:13, 13.72s/it]

 79%|███████▊  | 3022/3844 [11:42:26<3:00:34, 13.18s/it]

 79%|███████▊  | 3023/3844 [11:42:39<2:56:57, 12.93s/it]
{'loss': 1.1733, 'grad_norm': 0.17447966643666424, 'learning_rate': 2.299381632885116e-05, 'epoch': 0.79}


 79%|███████▊  | 3025/3844 [11:43:11<3:19:56, 14.65s/it]

 79%|███████▊  | 3026/3844 [11:43:30<3:39:09, 16.08s/it]

 79%|███████▊  | 3027/3844 [11:43:46<3:35:43, 15.84s/it]

 79%|███████▉  | 3028/3844 [11:43:57<3:16:17, 14.43s/it]

 79%|███████▉  | 3029/3844 [11:44:07<2:59:16, 13.20s/it]

 79%|███████▉  | 3030/3844 [11:44:19<2:52:52, 12.74s/it]

 79%|███████▉  | 3031/3844 [11:44:31<2:51:19, 12.64s/it]

 79%|███████▉  | 3032/3844 [11:44:45<2:57:34, 13.12s/it]

 79%|███████▉  | 3033/3844 [11:44:59<2:58:06, 13.18s/it]

 79%|███████▉  | 3034/3844 [11:45:11<2:56:00, 13.04s/it]

 79%|███████▉  | 3035/3844 [11:45:25<2:59:05, 13.28s/it]

 79%|███████▉  | 3036/3844 [11:45:41<3:07:01, 13.89s/it]
{'loss': 1.0243, 'grad_norm': 0.16065471507183596, 'learning_rate': 2.229954793603041e-05, 'epoch': 0.79}


 79%|███████▉  | 3038/3844 [11:46:09<3:08:30, 14.03s/it]

 79%|███████▉  | 3039/3844 [11:46:23<3:08:18, 14.04s/it]

 79%|███████▉  | 3040/3844 [11:46:36<3:04:37, 13.78s/it]

 79%|███████▉  | 3041/3844 [11:46:51<3:09:15, 14.14s/it]

 79%|███████▉  | 3042/3844 [11:47:04<3:06:40, 13.97s/it]

 79%|███████▉  | 3043/3844 [11:47:18<3:03:55, 13.78s/it]

 79%|███████▉  | 3044/3844 [11:47:32<3:03:59, 13.80s/it]

 79%|███████▉  | 3045/3844 [11:47:47<3:11:39, 14.39s/it]

 79%|███████▉  | 3046/3844 [11:48:03<3:16:37, 14.78s/it]

 79%|███████▉  | 3047/3844 [11:48:13<2:59:01, 13.48s/it]

 79%|███████▉  | 3048/3844 [11:48:29<3:06:01, 14.02s/it]

 79%|███████▉  | 3049/3844 [11:48:44<3:09:45, 14.32s/it]

 79%|███████▉  | 3050/3844 [11:48:53<2:50:24, 12.88s/it]

 79%|███████▉  | 3051/3844 [11:49:04<2:40:25, 12.14s/it]

 79%|███████▉  | 3052/3844 [11:49:15<2:38:09, 11.98s/it]
{'loss': 1.2099, 'grad_norm': 0.18930484055854607, 'learning_rate': 2.1457873794506123e-05, 'epoch': 0.79}


 79%|███████▉  | 3054/3844 [11:49:37<2:30:47, 11.45s/it]

 79%|███████▉  | 3055/3844 [11:49:53<2:46:49, 12.69s/it]

 80%|███████▉  | 3056/3844 [11:50:09<3:00:45, 13.76s/it]
{'loss': 0.8524, 'grad_norm': 0.16411485409821197, 'learning_rate': 2.1249680361695103e-05, 'epoch': 0.79}


 80%|███████▉  | 3058/3844 [11:50:32<2:45:42, 12.65s/it]

 80%|███████▉  | 3059/3844 [11:50:49<3:03:01, 13.99s/it]

 80%|███████▉  | 3060/3844 [11:51:02<2:56:38, 13.52s/it]

 80%|███████▉  | 3061/3844 [11:51:12<2:44:45, 12.63s/it]

 80%|███████▉  | 3062/3844 [11:51:22<2:32:02, 11.67s/it]

 80%|███████▉  | 3063/3844 [11:51:31<2:24:02, 11.07s/it]

 80%|███████▉  | 3064/3844 [11:51:42<2:21:54, 10.92s/it]

 80%|███████▉  | 3065/3844 [11:51:59<2:45:29, 12.75s/it]

 80%|███████▉  | 3066/3844 [11:52:13<2:52:17, 13.29s/it]

 80%|███████▉  | 3067/3844 [11:52:23<2:37:33, 12.17s/it]

 80%|███████▉  | 3068/3844 [11:52:42<3:04:04, 14.23s/it]

 80%|███████▉  | 3069/3844 [11:52:55<2:59:11, 13.87s/it]

 80%|███████▉  | 3070/3844 [11:53:06<2:45:50, 12.86s/it]
{'loss': 1.1488, 'grad_norm': 0.17224710927928133, 'learning_rate': 2.0528065229417148e-05, 'epoch': 0.8}

 80%|███████▉  | 3071/3844 [11:53:16<2:38:12, 12.28s/it]

 80%|███████▉  | 3072/3844 [11:53:31<2:44:52, 12.81s/it]


 80%|███████▉  | 3074/3844 [11:53:54<2:35:50, 12.14s/it]

 80%|███████▉  | 3075/3844 [11:54:06<2:35:32, 12.14s/it]
{'loss': 1.1337, 'grad_norm': 0.18825579886824645, 'learning_rate': 2.0273021083172982e-05, 'epoch': 0.8}

 80%|████████  | 3076/3844 [11:54:17<2:30:47, 11.78s/it]


 80%|████████  | 3078/3844 [11:54:41<2:34:18, 12.09s/it]
{'loss': 1.173, 'grad_norm': 0.17998318857455123, 'learning_rate': 2.012067371967643e-05, 'epoch': 0.8}


 80%|████████  | 3080/3844 [11:55:06<2:32:58, 12.01s/it]
{'loss': 1.2085, 'grad_norm': 0.18031506365395192, 'learning_rate': 2.0019392380668412e-05, 'epoch': 0.8}

 80%|████████  | 3081/3844 [11:55:19<2:36:23, 12.30s/it]


 80%|████████  | 3083/3844 [11:55:41<2:29:47, 11.81s/it]

 80%|████████  | 3084/3844 [11:55:58<2:48:44, 13.32s/it]

 80%|████████  | 3085/3844 [11:56:08<2:35:09, 12.27s/it]

 80%|████████  | 3086/3844 [11:56:20<2:34:51, 12.26s/it]

 80%|████████  | 3087/3844 [11:56:37<2:53:47, 13.77s/it]

 80%|████████  | 3088/3844 [11:56:50<2:49:16, 13.43s/it]

 80%|████████  | 3089/3844 [11:57:01<2:39:25, 12.67s/it]

 80%|████████  | 3090/3844 [11:57:11<2:28:40, 11.83s/it]

 80%|████████  | 3091/3844 [11:57:27<2:44:42, 13.12s/it]

 80%|████████  | 3092/3844 [11:57:42<2:52:05, 13.73s/it]

 80%|████████  | 3093/3844 [11:57:56<2:52:52, 13.81s/it]

 80%|████████  | 3094/3844 [11:58:10<2:52:46, 13.82s/it]

 81%|████████  | 3095/3844 [11:58:26<3:02:43, 14.64s/it]
{'loss': 1.0027, 'grad_norm': 0.16197890161076992, 'learning_rate': 1.926704383778273e-05, 'epoch': 0.81}

 81%|████████  | 3096/3844 [11:58:39<2:53:50, 13.94s/it]

 81%|████████  | 3097/3844 [11:58:51<2:47:24, 13.45s/it]

 81%|████████  | 3098/3844 [11:59:03<2:42:43, 13.09s/it]


 81%|████████  | 3100/3844 [11:59:30<2:40:22, 12.93s/it]
{'loss': 1.1394, 'grad_norm': 0.18612374529477357, 'learning_rate': 1.9019121686063392e-05, 'epoch': 0.81}

 81%|████████  | 3101/3844 [11:59:41<2:35:26, 12.55s/it]

 81%|████████  | 3102/3844 [11:59:55<2:38:17, 12.80s/it]

 81%|████████  | 3103/3844 [12:00:09<2:42:10, 13.13s/it]


 81%|████████  | 3105/3844 [12:00:40<3:03:05, 14.87s/it]

 81%|████████  | 3106/3844 [12:00:56<3:06:48, 15.19s/it]

 81%|████████  | 3107/3844 [12:01:09<2:59:17, 14.60s/it]

 81%|████████  | 3108/3844 [12:01:24<2:58:01, 14.51s/it]
{'loss': 1.0208, 'grad_norm': 0.17810249960041363, 'learning_rate': 1.8625438491216975e-05, 'epoch': 0.81}

 81%|████████  | 3109/3844 [12:01:41<3:08:09, 15.36s/it]


 81%|████████  | 3111/3844 [12:02:12<3:08:19, 15.42s/it]

 81%|████████  | 3112/3844 [12:02:26<3:05:56, 15.24s/it]

 81%|████████  | 3113/3844 [12:02:44<3:14:00, 15.92s/it]

 81%|████████  | 3114/3844 [12:02:58<3:07:34, 15.42s/it]

 81%|████████  | 3115/3844 [12:03:17<3:18:13, 16.32s/it]

 81%|████████  | 3116/3844 [12:03:31<3:09:57, 15.66s/it]
{'loss': 1.285, 'grad_norm': 0.18511931352221578, 'learning_rate': 1.8235453705295848e-05, 'epoch': 0.81}


 81%|████████  | 3118/3844 [12:03:58<2:59:16, 14.82s/it]
{'loss': 1.2175, 'grad_norm': 0.18187824571012506, 'learning_rate': 1.8138537466004636e-05, 'epoch': 0.81}

 81%|████████  | 3119/3844 [12:04:12<2:53:27, 14.36s/it]


 81%|████████  | 3121/3844 [12:04:44<3:04:47, 15.34s/it]

 81%|████████  | 3122/3844 [12:04:56<2:53:07, 14.39s/it]

 81%|████████  | 3123/3844 [12:05:10<2:51:51, 14.30s/it]

 81%|████████▏ | 3124/3844 [12:05:26<2:58:30, 14.88s/it]
{'loss': 1.1125, 'grad_norm': 0.19304533799543822, 'learning_rate': 1.7849185052797523e-05, 'epoch': 0.81}

 81%|████████▏ | 3125/3844 [12:05:47<3:20:31, 16.73s/it]

 81%|████████▏ | 3126/3844 [12:06:01<3:09:06, 15.80s/it]

 81%|████████▏ | 3127/3844 [12:06:18<3:12:11, 16.08s/it]


 81%|████████▏ | 3129/3844 [12:06:45<2:57:00, 14.85s/it]

 81%|████████▏ | 3130/3844 [12:07:02<3:04:49, 15.53s/it]
{'loss': 1.1101, 'grad_norm': 0.17949211763817996, 'learning_rate': 1.7561932843147068e-05, 'epoch': 0.81}

 81%|████████▏ | 3131/3844 [12:07:18<3:04:54, 15.56s/it]

 81%|████████▏ | 3132/3844 [12:07:33<3:04:13, 15.52s/it]

 82%|████████▏ | 3133/3844 [12:07:52<3:14:38, 16.43s/it]


 82%|████████▏ | 3135/3844 [12:08:26<3:20:34, 16.97s/it]
{'loss': 1.173, 'grad_norm': 0.18114894539662507, 'learning_rate': 1.7324165623643386e-05, 'epoch': 0.82}

 82%|████████▏ | 3136/3844 [12:08:39<3:06:33, 15.81s/it]


 82%|████████▏ | 3138/3844 [12:09:05<2:48:56, 14.36s/it]
{'loss': 1.0414, 'grad_norm': 0.18280552922079035, 'learning_rate': 1.7182209565255146e-05, 'epoch': 0.82}

 82%|████████▏ | 3139/3844 [12:09:22<2:57:41, 15.12s/it]

 82%|████████▏ | 3140/3844 [12:09:36<2:54:00, 14.83s/it]


 82%|████████▏ | 3142/3844 [12:10:07<2:56:47, 15.11s/it]
{'loss': 1.1432, 'grad_norm': 0.18163071558239663, 'learning_rate': 1.6993758355298373e-05, 'epoch': 0.82}


 82%|████████▏ | 3144/3844 [12:10:41<3:08:38, 16.17s/it]

 82%|████████▏ | 3145/3844 [12:10:57<3:05:51, 15.95s/it]

 82%|████████▏ | 3146/3844 [12:11:09<2:52:07, 14.80s/it]
{'loss': 1.077, 'grad_norm': 0.1653297237977871, 'learning_rate': 1.6806250289892254e-05, 'epoch': 0.82}


 82%|████████▏ | 3148/3844 [12:11:33<2:37:41, 13.59s/it]
{'loss': 1.2143, 'grad_norm': 0.18728601605987388, 'learning_rate': 1.671285060260528e-05, 'epoch': 0.82}


 82%|████████▏ | 3150/3844 [12:12:03<2:44:54, 14.26s/it]

 82%|████████▏ | 3150/3844 [12:12:04<2:44:54, 14.26s/it]

 82%|████████▏ | 3151/3844 [12:12:18<2:44:43, 14.26s/it]

 82%|████████▏ | 3152/3844 [12:12:32<2:43:29, 14.18s/it]


 82%|████████▏ | 3154/3844 [12:13:01<2:48:08, 14.62s/it]

 82%|████████▏ | 3155/3844 [12:13:13<2:39:55, 13.93s/it]

 82%|████████▏ | 3156/3844 [12:13:27<2:39:50, 13.94s/it]
{'loss': 1.304, 'grad_norm': 0.19166778206730076, 'learning_rate': 1.6341620338945185e-05, 'epoch': 0.82}


 82%|████████▏ | 3158/3844 [12:13:57<2:46:29, 14.56s/it]

 82%|████████▏ | 3159/3844 [12:14:11<2:44:52, 14.44s/it]

 82%|████████▏ | 3160/3844 [12:14:27<2:49:17, 14.85s/it]

 82%|████████▏ | 3161/3844 [12:14:41<2:47:38, 14.73s/it]
{'loss': 0.9809, 'grad_norm': 0.17760335055830734, 'learning_rate': 1.611153116842218e-05, 'epoch': 0.82}

 82%|████████▏ | 3162/3844 [12:14:57<2:49:29, 14.91s/it]


 82%|████████▏ | 3164/3844 [12:15:27<2:50:20, 15.03s/it]
{'loss': 0.9972, 'grad_norm': 0.20620535239897558, 'learning_rate': 1.5974192281924093e-05, 'epoch': 0.82}


 82%|████████▏ | 3166/3844 [12:15:59<2:54:53, 15.48s/it]

 82%|████████▏ | 3167/3844 [12:16:21<3:18:42, 17.61s/it]
[2024-05-27 13:26:59,419] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9701, 'grad_norm': 0.1728686941080174, 'learning_rate': 1.583739043082335e-05, 'epoch': 0.82}

 82%|████████▏ | 3168/3844 [12:16:34<3:02:12, 16.17s/it]

 82%|████████▏ | 3169/3844 [12:16:50<3:00:57, 16.08s/it]


 82%|████████▏ | 3171/3844 [12:17:19<2:52:02, 15.34s/it]

 83%|████████▎ | 3172/3844 [12:17:33<2:47:18, 14.94s/it]

 83%|████████▎ | 3173/3844 [12:17:47<2:44:24, 14.70s/it]
{'loss': 1.0158, 'grad_norm': 0.17704855809982284, 'learning_rate': 1.5565401328750784e-05, 'epoch': 0.83}

 83%|████████▎ | 3174/3844 [12:18:05<2:52:08, 15.42s/it]


 83%|████████▎ | 3176/3844 [12:18:33<2:46:43, 14.97s/it]
{'loss': 1.0112, 'grad_norm': 0.1803387313614347, 'learning_rate': 1.5430215816146952e-05, 'epoch': 0.83}


 83%|████████▎ | 3178/3844 [12:19:05<2:53:09, 15.60s/it]
{'loss': 0.9767, 'grad_norm': 0.16527089780199808, 'learning_rate': 1.534039237239805e-05, 'epoch': 0.83}

 83%|████████▎ | 3179/3844 [12:19:20<2:51:06, 15.44s/it]


 83%|████████▎ | 3181/3844 [12:19:49<2:44:52, 14.92s/it]
{'loss': 0.9766, 'grad_norm': 0.17875652777901888, 'learning_rate': 1.5206108191632873e-05, 'epoch': 0.83}


 83%|████████▎ | 3183/3844 [12:20:17<2:39:24, 14.47s/it]

 83%|████████▎ | 3184/3844 [12:20:32<2:40:35, 14.60s/it]

 83%|████████▎ | 3185/3844 [12:20:46<2:37:58, 14.38s/it]

 83%|████████▎ | 3186/3844 [12:20:59<2:35:03, 14.14s/it]
{'loss': 0.9048, 'grad_norm': 0.1766259987365991, 'learning_rate': 1.4983505966984058e-05, 'epoch': 0.83}

 83%|████████▎ | 3187/3844 [12:21:15<2:38:37, 14.49s/it]


 83%|████████▎ | 3189/3844 [12:21:44<2:39:54, 14.65s/it]
{'loss': 0.9912, 'grad_norm': 0.16567050252904633, 'learning_rate': 1.4850668869275496e-05, 'epoch': 0.83}


 83%|████████▎ | 3191/3844 [12:22:14<2:42:31, 14.93s/it]

 83%|████████▎ | 3192/3844 [12:22:29<2:42:12, 14.93s/it]

 83%|████████▎ | 3193/3844 [12:22:46<2:48:33, 15.54s/it]
{'loss': 1.1349, 'grad_norm': 0.18217080849225697, 'learning_rate': 1.4674399443754571e-05, 'epoch': 0.83}


 83%|████████▎ | 3195/3844 [12:23:16<2:41:43, 14.95s/it]

 83%|████████▎ | 3196/3844 [12:23:32<2:44:41, 15.25s/it]

 83%|████████▎ | 3197/3844 [12:23:46<2:43:13, 15.14s/it]

 83%|████████▎ | 3198/3844 [12:24:03<2:49:01, 15.70s/it]
{'loss': 0.993, 'grad_norm': 0.1757145681789998, 'learning_rate': 1.4455426251903692e-05, 'epoch': 0.83}


 83%|████████▎ | 3200/3844 [12:24:34<2:46:45, 15.54s/it]
{'loss': 1.2452, 'grad_norm': 0.18553371227577634, 'learning_rate': 1.4368262001980314e-05, 'epoch': 0.83}

 83%|████████▎ | 3201/3844 [12:24:49<2:42:58, 15.21s/it]


 83%|████████▎ | 3203/3844 [12:25:19<2:44:42, 15.42s/it]
{'loss': 1.1417, 'grad_norm': 0.1739055286874762, 'learning_rate': 1.4237971787251736e-05, 'epoch': 0.83}


 83%|████████▎ | 3205/3844 [12:25:50<2:44:38, 15.46s/it]

 83%|████████▎ | 3206/3844 [12:26:06<2:45:39, 15.58s/it]

 83%|████████▎ | 3207/3844 [12:26:21<2:42:32, 15.31s/it]
{'loss': 1.1233, 'grad_norm': 0.17960516735165669, 'learning_rate': 1.4065104294349251e-05, 'epoch': 0.83}


 83%|████████▎ | 3209/3844 [12:26:48<2:33:06, 14.47s/it]

 84%|████████▎ | 3210/3844 [12:27:02<2:31:31, 14.34s/it]
{'loss': 1.1159, 'grad_norm': 0.18394109298981035, 'learning_rate': 1.3936094343884376e-05, 'epoch': 0.83}


 84%|████████▎ | 3212/3844 [12:27:30<2:28:26, 14.09s/it]
{'loss': 1.1482, 'grad_norm': 0.1759861501607671, 'learning_rate': 1.3850393249223047e-05, 'epoch': 0.84}

 84%|████████▎ | 3213/3844 [12:27:47<2:37:10, 14.95s/it]

 84%|████████▎ | 3214/3844 [12:28:03<2:41:06, 15.34s/it]


 84%|████████▎ | 3216/3844 [12:28:32<2:33:54, 14.70s/it]
{'loss': 1.0254, 'grad_norm': 0.17970822717317234, 'learning_rate': 1.3679725448551451e-05, 'epoch': 0.84}

 84%|████████▎ | 3217/3844 [12:28:48<2:37:34, 15.08s/it]

 84%|████████▎ | 3218/3844 [12:29:04<2:40:49, 15.41s/it]

 84%|████████▎ | 3219/3844 [12:29:16<2:28:23, 14.25s/it]


 84%|████████▍ | 3221/3844 [12:29:49<2:39:48, 15.39s/it]
{'loss': 1.1079, 'grad_norm': 0.1691093869048593, 'learning_rate': 1.3467770173471505e-05, 'epoch': 0.84}


 84%|████████▍ | 3223/3844 [12:30:19<2:35:23, 15.01s/it]
{'loss': 1.1532, 'grad_norm': 0.175798143388449, 'learning_rate': 1.3383418006900373e-05, 'epoch': 0.84}

 84%|████████▍ | 3224/3844 [12:30:31<2:27:58, 14.32s/it]

 84%|████████▍ | 3225/3844 [12:30:48<2:34:53, 15.01s/it]


 84%|████████▍ | 3227/3844 [12:31:19<2:36:29, 15.22s/it]

 84%|████████▍ | 3228/3844 [12:31:37<2:44:20, 16.01s/it]
{'loss': 1.1744, 'grad_norm': 0.18085774828507764, 'learning_rate': 1.3173614545705937e-05, 'epoch': 0.84}


 84%|████████▍ | 3230/3844 [12:32:07<2:38:53, 15.53s/it]

 84%|████████▍ | 3231/3844 [12:32:23<2:40:34, 15.72s/it]

 84%|████████▍ | 3232/3844 [12:32:41<2:46:40, 16.34s/it]

 84%|████████▍ | 3233/3844 [12:32:57<2:45:27, 16.25s/it]
{'loss': 1.1566, 'grad_norm': 0.17470433678704972, 'learning_rate': 1.2965352568528521e-05, 'epoch': 0.84}

 84%|████████▍ | 3234/3844 [12:33:10<2:35:47, 15.32s/it]

 84%|████████▍ | 3235/3844 [12:33:24<2:31:41, 14.95s/it]

 84%|████████▍ | 3236/3844 [12:33:38<2:26:43, 14.48s/it]

 84%|████████▍ | 3237/3844 [12:33:56<2:37:35, 15.58s/it]


 84%|████████▍ | 3239/3844 [12:34:25<2:33:12, 15.19s/it]
{'loss': 0.9843, 'grad_norm': 0.1744854496004454, 'learning_rate': 1.2717478158837026e-05, 'epoch': 0.84}

 84%|████████▍ | 3240/3844 [12:34:39<2:28:17, 14.73s/it]

 84%|████████▍ | 3241/3844 [12:34:54<2:30:44, 15.00s/it]

 84%|████████▍ | 3242/3844 [12:35:10<2:33:04, 15.26s/it]


 84%|████████▍ | 3244/3844 [12:35:39<2:27:10, 14.72s/it]
{'loss': 1.1014, 'grad_norm': 0.1876914096878898, 'learning_rate': 1.2512620422740973e-05, 'epoch': 0.84}


 84%|████████▍ | 3246/3844 [12:36:11<2:32:29, 15.30s/it]
{'loss': 1.1359, 'grad_norm': 0.18775946849994704, 'learning_rate': 1.2431112026896542e-05, 'epoch': 0.84}

 84%|████████▍ | 3247/3844 [12:36:28<2:37:51, 15.87s/it]

 84%|████████▍ | 3248/3844 [12:36:48<2:48:04, 16.92s/it]


 85%|████████▍ | 3250/3844 [12:37:19<2:40:31, 16.21s/it]

 85%|████████▍ | 3251/3844 [12:37:33<2:34:54, 15.67s/it]

 85%|████████▍ | 3252/3844 [12:37:49<2:35:27, 15.76s/it]

 85%|████████▍ | 3253/3844 [12:38:05<2:34:48, 15.72s/it]
{'loss': 1.1691, 'grad_norm': 0.1820480058908442, 'learning_rate': 1.2147793036255273e-05, 'epoch': 0.85}

 85%|████████▍ | 3254/3844 [12:38:21<2:34:06, 15.67s/it]


 85%|████████▍ | 3256/3844 [12:38:47<2:21:59, 14.49s/it]

 85%|████████▍ | 3257/3844 [12:39:03<2:25:57, 14.92s/it]
{'loss': 1.0844, 'grad_norm': 0.17866061571097855, 'learning_rate': 1.1987268372821547e-05, 'epoch': 0.85}

 85%|████████▍ | 3258/3844 [12:39:17<2:22:09, 14.56s/it]

 85%|████████▍ | 3259/3844 [12:39:30<2:18:06, 14.16s/it]


 85%|████████▍ | 3261/3844 [12:39:59<2:18:27, 14.25s/it]
{'loss': 1.1502, 'grad_norm': 0.1818312841286526, 'learning_rate': 1.1827743739344322e-05, 'epoch': 0.85}


 85%|████████▍ | 3263/3844 [12:40:34<2:30:16, 15.52s/it]
{'loss': 1.1062, 'grad_norm': 0.17800466791254116, 'learning_rate': 1.1748357000712573e-05, 'epoch': 0.85}

 85%|████████▍ | 3264/3844 [12:40:51<2:35:26, 16.08s/it]

 85%|████████▍ | 3265/3844 [12:41:06<2:32:07, 15.76s/it]

 85%|████████▍ | 3266/3844 [12:41:21<2:29:40, 15.54s/it]

 85%|████████▍ | 3267/3844 [12:41:34<2:22:30, 14.82s/it]


 85%|████████▌ | 3269/3844 [12:42:05<2:27:52, 15.43s/it]

 85%|████████▌ | 3270/3844 [12:42:20<2:24:52, 15.14s/it]
{'loss': 1.2422, 'grad_norm': 0.20044847692231718, 'learning_rate': 1.1472479043678275e-05, 'epoch': 0.85}

 85%|████████▌ | 3271/3844 [12:42:34<2:23:25, 15.02s/it]

 85%|████████▌ | 3272/3844 [12:42:55<2:38:51, 16.66s/it]

 85%|████████▌ | 3273/3844 [12:43:07<2:25:33, 15.29s/it]

 85%|████████▌ | 3274/3844 [12:43:26<2:35:55, 16.41s/it]


 85%|████████▌ | 3276/3844 [12:43:54<2:23:13, 15.13s/it]
{'loss': 1.0552, 'grad_norm': 0.16041123555263576, 'learning_rate': 1.1238463688098844e-05, 'epoch': 0.85}

 85%|████████▌ | 3277/3844 [12:44:11<2:27:28, 15.61s/it]

 85%|████████▌ | 3278/3844 [12:44:29<2:34:43, 16.40s/it]

 85%|████████▌ | 3279/3844 [12:44:43<2:29:03, 15.83s/it]

 85%|████████▌ | 3280/3844 [12:44:57<2:21:11, 15.02s/it]


 85%|████████▌ | 3282/3844 [12:45:30<2:28:55, 15.90s/it]
{'loss': 1.1422, 'grad_norm': 0.19295431649802616, 'learning_rate': 1.1006717540613987e-05, 'epoch': 0.85}


 85%|████████▌ | 3284/3844 [12:46:02<2:31:30, 16.23s/it]
{'loss': 1.1631, 'grad_norm': 0.17526226303077208, 'learning_rate': 1.0929974118937259e-05, 'epoch': 0.85}

 85%|████████▌ | 3285/3844 [12:46:17<2:28:32, 15.94s/it]

 85%|████████▌ | 3286/3844 [12:46:33<2:28:32, 15.97s/it]

 86%|████████▌ | 3287/3844 [12:46:47<2:22:35, 15.36s/it]

 86%|████████▌ | 3288/3844 [12:47:03<2:22:32, 15.38s/it]

 86%|████████▌ | 3289/3844 [12:47:20<2:26:31, 15.84s/it]

 86%|████████▌ | 3290/3844 [12:47:35<2:25:52, 15.80s/it]

 86%|████████▌ | 3291/3844 [12:47:51<2:25:21, 15.77s/it]

 86%|████████▌ | 3292/3844 [12:48:07<2:24:56, 15.75s/it]

 86%|████████▌ | 3293/3844 [12:48:25<2:32:40, 16.63s/it]


 86%|████████▌ | 3295/3844 [12:48:58<2:28:45, 16.26s/it]
{'loss': 1.1308, 'grad_norm': 0.17531913982843958, 'learning_rate': 1.0512413680230959e-05, 'epoch': 0.86}


 86%|████████▌ | 3297/3844 [12:49:22<2:10:37, 14.33s/it]
{'loss': 1.1255, 'grad_norm': 0.18789338878832623, 'learning_rate': 1.0437318694596287e-05, 'epoch': 0.86}

 86%|████████▌ | 3298/3844 [12:49:37<2:10:16, 14.32s/it]

 86%|████████▌ | 3299/3844 [12:49:51<2:09:37, 14.27s/it]

 86%|████████▌ | 3300/3844 [12:50:07<2:14:57, 14.89s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.8137, 'grad_norm': 0.16590822372842326, 'learning_rate': 1.0287892167210545e-05, 'epoch': 0.86}
 86%|████████▌ | 3301/3844 [12:51:01<3:59:56, 26.51s/it]

 86%|████████▌ | 3302/3844 [12:51:14<3:22:28, 22.41s/it]

 86%|████████▌ | 3303/3844 [12:51:29<3:03:27, 20.35s/it]


 86%|████████▌ | 3305/3844 [12:52:02<2:44:07, 18.27s/it]

 86%|████████▌ | 3306/3844 [12:52:18<2:38:25, 17.67s/it]
{'loss': 1.0734, 'grad_norm': 0.17949862028986086, 'learning_rate': 1.0102542651077006e-05, 'epoch': 0.86}

 86%|████████▌ | 3307/3844 [12:52:31<2:25:37, 16.27s/it]

 86%|████████▌ | 3308/3844 [12:52:48<2:26:13, 16.37s/it]


 86%|████████▌ | 3310/3844 [12:53:18<2:21:06, 15.86s/it]
{'loss': 1.0802, 'grad_norm': 0.15947998570960167, 'learning_rate': 9.955412006001885e-06, 'epoch': 0.86}

 86%|████████▌ | 3311/3844 [12:53:33<2:18:25, 15.58s/it]


 86%|████████▌ | 3313/3844 [12:54:06<2:25:46, 16.47s/it]

 86%|████████▌ | 3314/3844 [12:54:20<2:18:54, 15.72s/it]

 86%|████████▌ | 3315/3844 [12:54:34<2:13:48, 15.18s/it]
{'loss': 0.9918, 'grad_norm': 0.18306005110373624, 'learning_rate': 9.772937652156855e-06, 'epoch': 0.86}


 86%|████████▋ | 3317/3844 [12:54:57<1:56:55, 13.31s/it]

 86%|████████▋ | 3318/3844 [12:55:09<1:53:13, 12.91s/it]
{'loss': 1.1334, 'grad_norm': 0.1873108758697338, 'learning_rate': 9.66422172572884e-06, 'epoch': 0.86}


 86%|████████▋ | 3320/3844 [12:55:37<1:55:21, 13.21s/it]
{'loss': 1.0596, 'grad_norm': 0.17583962673659104, 'learning_rate': 9.592065156707531e-06, 'epoch': 0.86}

 86%|████████▋ | 3321/3844 [12:55:53<2:03:37, 14.18s/it]

 86%|████████▋ | 3322/3844 [12:56:10<2:09:22, 14.87s/it]


 86%|████████▋ | 3324/3844 [12:56:39<2:05:18, 14.46s/it]
{'loss': 1.1164, 'grad_norm': 0.18442911203417495, 'learning_rate': 9.448522657239045e-06, 'epoch': 0.86}

 86%|████████▋ | 3325/3844 [12:56:53<2:05:56, 14.56s/it]


 87%|████████▋ | 3327/3844 [12:57:23<2:06:44, 14.71s/it]
{'loss': 1.2046, 'grad_norm': 0.18476880650929084, 'learning_rate': 9.341540893777944e-06, 'epoch': 0.87}

 87%|████████▋ | 3328/3844 [12:57:36<2:01:51, 14.17s/it]


 87%|████████▋ | 3330/3844 [12:58:05<2:01:01, 14.13s/it]
{'loss': 0.957, 'grad_norm': 0.17262491580562503, 'learning_rate': 9.23513855707786e-06, 'epoch': 0.87}

 87%|████████▋ | 3331/3844 [12:58:18<2:00:03, 14.04s/it]

 87%|████████▋ | 3332/3844 [12:58:34<2:03:17, 14.45s/it]

 87%|████████▋ | 3333/3844 [12:58:48<2:01:36, 14.28s/it]


 87%|████████▋ | 3335/3844 [12:59:23<2:17:40, 16.23s/it]
{'loss': 1.1892, 'grad_norm': 0.1797071196197391, 'learning_rate': 9.059090789642332e-06, 'epoch': 0.87}

 87%|████████▋ | 3336/3844 [12:59:37<2:11:36, 15.54s/it]

 87%|████████▋ | 3337/3844 [12:59:52<2:11:32, 15.57s/it]


 87%|████████▋ | 3339/3844 [13:00:21<2:06:25, 15.02s/it]

 87%|████████▋ | 3340/3844 [13:00:37<2:08:08, 15.25s/it]
{'loss': 1.1316, 'grad_norm': 0.16814528891840988, 'learning_rate': 8.884657553979692e-06, 'epoch': 0.87}

 87%|████████▋ | 3341/3844 [13:00:50<2:02:39, 14.63s/it]

 87%|████████▋ | 3342/3844 [13:01:05<2:02:31, 14.65s/it]

 87%|████████▋ | 3343/3844 [13:01:17<1:55:13, 13.80s/it]

 87%|████████▋ | 3344/3844 [13:01:30<1:54:43, 13.77s/it]


 87%|████████▋ | 3346/3844 [13:02:01<2:00:54, 14.57s/it]
{'loss': 1.0307, 'grad_norm': 0.17893027113021182, 'learning_rate': 8.677473211431908e-06, 'epoch': 0.87}

 87%|████████▋ | 3347/3844 [13:02:18<2:07:33, 15.40s/it]

 87%|████████▋ | 3348/3844 [13:02:34<2:07:59, 15.48s/it]

 87%|████████▋ | 3349/3844 [13:02:50<2:08:37, 15.59s/it]


 87%|████████▋ | 3351/3844 [13:03:17<1:59:45, 14.57s/it]

 87%|████████▋ | 3352/3844 [13:03:36<2:08:24, 15.66s/it]

 87%|████████▋ | 3353/3844 [13:03:49<2:03:31, 15.09s/it]

 87%|████████▋ | 3354/3844 [13:04:05<2:05:36, 15.38s/it]
{'loss': 1.0546, 'grad_norm': 0.16842359160657022, 'learning_rate': 8.404860053285135e-06, 'epoch': 0.87}

 87%|████████▋ | 3355/3844 [13:04:23<2:09:49, 15.93s/it]

 87%|████████▋ | 3356/3844 [13:04:37<2:06:00, 15.49s/it]

 87%|████████▋ | 3357/3844 [13:04:56<2:14:13, 16.54s/it]


 87%|████████▋ | 3359/3844 [13:05:26<2:05:42, 15.55s/it]
{'loss': 1.0154, 'grad_norm': 0.16815104505330336, 'learning_rate': 8.236590036732772e-06, 'epoch': 0.87}

 87%|████████▋ | 3360/3844 [13:05:38<1:58:32, 14.69s/it]

 87%|████████▋ | 3361/3844 [13:05:55<2:03:16, 15.31s/it]


 87%|████████▋ | 3363/3844 [13:06:24<2:00:36, 15.04s/it]
{'loss': 1.0644, 'grad_norm': 0.191091621538012, 'learning_rate': 8.103146857656019e-06, 'epoch': 0.87}


 88%|████████▊ | 3365/3844 [13:06:52<1:56:57, 14.65s/it]
{'loss': 1.1096, 'grad_norm': 0.19075030242445962, 'learning_rate': 8.036816734806085e-06, 'epoch': 0.88}

 88%|████████▊ | 3366/3844 [13:07:05<1:52:09, 14.08s/it]


 88%|████████▊ | 3368/3844 [13:07:35<1:56:52, 14.73s/it]
{'loss': 1.0519, 'grad_norm': 0.18265331684772454, 'learning_rate': 7.937811414073338e-06, 'epoch': 0.88}

 88%|████████▊ | 3369/3844 [13:07:51<1:57:27, 14.84s/it]

 88%|████████▊ | 3370/3844 [13:08:05<1:56:32, 14.75s/it]


 88%|████████▊ | 3372/3844 [13:08:32<1:50:03, 13.99s/it]

 88%|████████▊ | 3373/3844 [13:08:44<1:44:22, 13.30s/it]
{'loss': 1.0678, 'grad_norm': 0.19265142266008528, 'learning_rate': 7.774110409049118e-06, 'epoch': 0.88}


 88%|████████▊ | 3375/3844 [13:09:14<1:50:13, 14.10s/it]

 88%|████████▊ | 3376/3844 [13:09:28<1:49:04, 13.98s/it]

 88%|████████▊ | 3377/3844 [13:09:42<1:49:16, 14.04s/it]
{'loss': 1.1454, 'grad_norm': 0.17964730002582607, 'learning_rate': 7.64432835479364e-06, 'epoch': 0.88}

 88%|████████▊ | 3378/3844 [13:09:57<1:52:22, 14.47s/it]

 88%|████████▊ | 3379/3844 [13:10:15<1:59:40, 15.44s/it]

 88%|████████▊ | 3380/3844 [13:10:33<2:04:06, 16.05s/it]

 88%|████████▊ | 3381/3844 [13:10:47<1:59:26, 15.48s/it]

 88%|████████▊ | 3382/3844 [13:11:02<1:57:52, 15.31s/it]


 88%|████████▊ | 3384/3844 [13:11:34<2:00:35, 15.73s/it]

 88%|████████▊ | 3385/3844 [13:11:48<1:56:32, 15.23s/it]

 88%|████████▊ | 3386/3844 [13:12:04<1:57:16, 15.36s/it]

 88%|████████▊ | 3387/3844 [13:12:20<1:58:32, 15.56s/it]
{'loss': 1.1833, 'grad_norm': 0.18153268426533709, 'learning_rate': 7.324467435059145e-06, 'epoch': 0.88}

 88%|████████▊ | 3388/3844 [13:12:35<1:58:06, 15.54s/it]


 88%|████████▊ | 3390/3844 [13:13:04<1:51:47, 14.77s/it]
{'loss': 1.1244, 'grad_norm': 0.176663602429176, 'learning_rate': 7.229791487700566e-06, 'epoch': 0.88}


 88%|████████▊ | 3392/3844 [13:13:36<1:56:30, 15.47s/it]
{'loss': 1.1157, 'grad_norm': 0.1863489080886864, 'learning_rate': 7.167003554274454e-06, 'epoch': 0.88}


 88%|████████▊ | 3394/3844 [13:14:14<2:10:31, 17.40s/it]
{'loss': 1.0512, 'grad_norm': 0.18576962230266514, 'learning_rate': 7.104479320888147e-06, 'epoch': 0.88}

 88%|████████▊ | 3395/3844 [13:14:29<2:05:06, 16.72s/it]
[2024-05-27 14:25:28,893] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 88%|████████▊ | 3396/3844 [13:14:51<2:15:33, 18.16s/it]


 88%|████████▊ | 3398/3844 [13:15:24<2:09:30, 17.42s/it]
{'loss': 1.1805, 'grad_norm': 0.18634830741571184, 'learning_rate': 6.980222663906932e-06, 'epoch': 0.88}

 88%|████████▊ | 3399/3844 [13:15:40<2:05:08, 16.87s/it]


 88%|████████▊ | 3401/3844 [13:16:15<2:03:20, 16.71s/it]

 89%|████████▊ | 3402/3844 [13:16:30<2:00:41, 16.38s/it]
{'loss': 1.0154, 'grad_norm': 0.16530110192408667, 'learning_rate': 6.857022928602419e-06, 'epoch': 0.88}

 89%|████████▊ | 3403/3844 [13:16:42<1:49:27, 14.89s/it]

 89%|████████▊ | 3404/3844 [13:16:56<1:47:41, 14.68s/it]


 89%|████████▊ | 3406/3844 [13:17:28<1:53:37, 15.57s/it]
{'loss': 1.0893, 'grad_norm': 0.1810933538847291, 'learning_rate': 6.734881514811031e-06, 'epoch': 0.89}

 89%|████████▊ | 3407/3844 [13:17:47<2:01:10, 16.64s/it]

 89%|████████▊ | 3408/3844 [13:18:02<1:55:46, 15.93s/it]

 89%|████████▊ | 3409/3844 [13:18:15<1:50:10, 15.20s/it]

 89%|████████▊ | 3410/3844 [13:18:37<2:04:56, 17.27s/it]

 89%|████████▊ | 3411/3844 [13:18:52<1:59:09, 16.51s/it]


 89%|████████▉ | 3413/3844 [13:19:31<2:09:40, 18.05s/it]
{'loss': 0.9373, 'grad_norm': 0.1688488562167337, 'learning_rate': 6.5236847943033306e-06, 'epoch': 0.89}

 89%|████████▉ | 3414/3844 [13:19:50<2:11:41, 18.38s/it]

 89%|████████▉ | 3415/3844 [13:20:09<2:14:03, 18.75s/it]

 89%|████████▉ | 3416/3844 [13:20:25<2:07:32, 17.88s/it]

 89%|████████▉ | 3417/3844 [13:20:38<1:56:13, 16.33s/it]

 89%|████████▉ | 3418/3844 [13:20:53<1:54:13, 16.09s/it]

 89%|████████▉ | 3419/3844 [13:21:09<1:53:38, 16.04s/it]


 89%|████████▉ | 3421/3844 [13:21:43<1:55:19, 16.36s/it]
{'loss': 0.9583, 'grad_norm': 0.16918636274899915, 'learning_rate': 6.286300438071035e-06, 'epoch': 0.89}

 89%|████████▉ | 3422/3844 [13:22:01<1:59:38, 17.01s/it]

 89%|████████▉ | 3423/3844 [13:22:19<1:59:45, 17.07s/it]


 89%|████████▉ | 3425/3844 [13:22:47<1:48:25, 15.53s/it]
{'loss': 1.0894, 'grad_norm': 0.1855930432511408, 'learning_rate': 6.16920479804377e-06, 'epoch': 0.89}

 89%|████████▉ | 3426/3844 [13:23:01<1:45:13, 15.10s/it]

 89%|████████▉ | 3427/3844 [13:23:20<1:53:17, 16.30s/it]


 89%|████████▉ | 3429/3844 [13:23:53<1:52:30, 16.27s/it]
{'loss': 1.0974, 'grad_norm': 0.17417334684248117, 'learning_rate': 6.053175294748192e-06, 'epoch': 0.89}


 89%|████████▉ | 3431/3844 [13:24:19<1:42:05, 14.83s/it]
{'loss': 1.15, 'grad_norm': 0.18856560292552899, 'learning_rate': 5.995560756837715e-06, 'epoch': 0.89}


 89%|████████▉ | 3433/3844 [13:24:47<1:38:29, 14.38s/it]

 89%|████████▉ | 3434/3844 [13:25:05<1:45:57, 15.51s/it]
{'loss': 0.9223, 'grad_norm': 0.17131323135366472, 'learning_rate': 5.909639677700973e-06, 'epoch': 0.89}

 89%|████████▉ | 3435/3844 [13:25:20<1:45:02, 15.41s/it]

 89%|████████▉ | 3436/3844 [13:25:36<1:45:37, 15.53s/it]

 89%|████████▉ | 3437/3844 [13:25:53<1:48:56, 16.06s/it]

 89%|████████▉ | 3438/3844 [13:26:07<1:43:15, 15.26s/it]

 89%|████████▉ | 3439/3844 [13:26:19<1:37:54, 14.50s/it]


 90%|████████▉ | 3441/3844 [13:26:49<1:37:17, 14.49s/it]
{'loss': 1.1062, 'grad_norm': 0.18298793656063572, 'learning_rate': 5.71149672825122e-06, 'epoch': 0.9}

 90%|████████▉ | 3442/3844 [13:27:04<1:38:29, 14.70s/it]

 90%|████████▉ | 3443/3844 [13:27:22<1:43:23, 15.47s/it]

 90%|████████▉ | 3444/3844 [13:27:39<1:46:42, 16.01s/it]

 90%|████████▉ | 3445/3844 [13:27:54<1:44:47, 15.76s/it]

 90%|████████▉ | 3446/3844 [13:28:13<1:50:25, 16.65s/it]


 90%|████████▉ | 3448/3844 [13:28:35<1:31:58, 13.94s/it]
{'loss': 1.1156, 'grad_norm': 0.18294377514313223, 'learning_rate': 5.516634743068694e-06, 'epoch': 0.9}

 90%|████████▉ | 3449/3844 [13:28:50<1:33:34, 14.21s/it]

 90%|████████▉ | 3450/3844 [13:29:06<1:35:46, 14.58s/it]

 90%|████████▉ | 3451/3844 [13:29:24<1:43:56, 15.87s/it]

 90%|████████▉ | 3452/3844 [13:29:39<1:41:37, 15.56s/it]

 90%|████████▉ | 3453/3844 [13:29:50<1:32:40, 14.22s/it]

 90%|████████▉ | 3454/3844 [13:30:03<1:29:29, 13.77s/it]

 90%|████████▉ | 3455/3844 [13:30:17<1:29:03, 13.74s/it]

 90%|████████▉ | 3456/3844 [13:30:31<1:29:15, 13.80s/it]

 90%|████████▉ | 3457/3844 [13:30:47<1:33:58, 14.57s/it]

 90%|████████▉ | 3458/3844 [13:31:03<1:36:00, 14.92s/it]

 90%|████████▉ | 3459/3844 [13:31:17<1:33:42, 14.60s/it]

 90%|█████████ | 3460/3844 [13:31:30<1:30:32, 14.15s/it]

 90%|█████████ | 3461/3844 [13:31:48<1:37:47, 15.32s/it]

 90%|█████████ | 3462/3844 [13:32:04<1:39:53, 15.69s/it]

 90%|█████████ | 3463/3844 [13:32:17<1:33:05, 14.66s/it]

 90%|█████████ | 3464/3844 [13:32:30<1:31:25, 14.44s/it]

 90%|█████████ | 3465/3844 [13:32:45<1:32:13, 14.60s/it]

 90%|█████████ | 3466/3844 [13:33:03<1:37:34, 15.49s/it]

 90%|█████████ | 3467/3844 [13:33:18<1:36:37, 15.38s/it]

 90%|█████████ | 3468/3844 [13:33:37<1:43:09, 16.46s/it]

 90%|█████████ | 3469/3844 [13:33:51<1:37:10, 15.55s/it]

 90%|█████████ | 3470/3844 [13:34:03<1:31:19, 14.65s/it]

 90%|█████████ | 3471/3844 [13:34:20<1:34:32, 15.21s/it]

 90%|█████████ | 3472/3844 [13:34:36<1:35:48, 15.45s/it]

 90%|█████████ | 3473/3844 [13:34:51<1:35:04, 15.38s/it]

 90%|█████████ | 3474/3844 [13:35:06<1:35:23, 15.47s/it]

 90%|█████████ | 3475/3844 [13:35:19<1:29:35, 14.57s/it]

 90%|█████████ | 3476/3844 [13:35:31<1:25:00, 13.86s/it]

 90%|█████████ | 3477/3844 [13:35:45<1:24:48, 13.86s/it]

 90%|█████████ | 3478/3844 [13:36:01<1:27:49, 14.40s/it]

 91%|█████████ | 3479/3844 [13:36:16<1:29:37, 14.73s/it]

 91%|█████████ | 3480/3844 [13:36:34<1:34:38, 15.60s/it]

 91%|█████████ | 3481/3844 [13:36:48<1:31:42, 15.16s/it]
{'loss': 1.0179, 'grad_norm': 0.1833671436628208, 'learning_rate': 4.642393451283766e-06, 'epoch': 0.91}

 91%|█████████ | 3482/3844 [13:37:05<1:34:26, 15.65s/it]


 91%|█████████ | 3484/3844 [13:37:34<1:30:58, 15.16s/it]
{'loss': 0.9537, 'grad_norm': 0.17024574165993053, 'learning_rate': 4.56656378731759e-06, 'epoch': 0.91}

 91%|█████████ | 3485/3844 [13:37:50<1:31:38, 15.31s/it]


 91%|█████████ | 3487/3844 [13:38:16<1:25:11, 14.32s/it]
{'loss': 1.0274, 'grad_norm': 0.17915943690170627, 'learning_rate': 4.491344068494774e-06, 'epoch': 0.91}

 91%|█████████ | 3488/3844 [13:38:27<1:18:46, 13.28s/it]

 91%|█████████ | 3489/3844 [13:38:41<1:20:05, 13.54s/it]

 91%|█████████ | 3490/3844 [13:38:53<1:16:37, 12.99s/it]

 91%|█████████ | 3491/3844 [13:39:13<1:29:52, 15.27s/it]

 91%|█████████ | 3492/3844 [13:39:29<1:30:12, 15.38s/it]


 91%|█████████ | 3494/3844 [13:40:00<1:30:48, 15.57s/it]
{'loss': 0.9998, 'grad_norm': 0.17338407883690712, 'learning_rate': 4.318206093352584e-06, 'epoch': 0.91}

 91%|█████████ | 3495/3844 [13:40:15<1:28:48, 15.27s/it]

 91%|█████████ | 3496/3844 [13:40:32<1:31:12, 15.73s/it]

 91%|█████████ | 3497/3844 [13:40:48<1:32:02, 15.91s/it]

 91%|█████████ | 3498/3844 [13:41:05<1:33:01, 16.13s/it]

 91%|█████████ | 3499/3844 [13:41:16<1:25:14, 14.82s/it]

 91%|█████████ | 3500/3844 [13:41:34<1:29:44, 15.65s/it]

 91%|█████████ | 3501/3844 [13:41:49<1:28:11, 15.43s/it]


 91%|█████████ | 3503/3844 [13:42:19<1:25:16, 15.00s/it]

 91%|█████████ | 3504/3844 [13:42:35<1:26:29, 15.26s/it]
{'loss': 1.1356, 'grad_norm': 0.17278617984412736, 'learning_rate': 4.076643168080296e-06, 'epoch': 0.91}

 91%|█████████ | 3505/3844 [13:42:50<1:26:35, 15.32s/it]

 91%|█████████ | 3506/3844 [13:43:03<1:22:23, 14.62s/it]

 91%|█████████ | 3507/3844 [13:43:23<1:31:19, 16.26s/it]


 91%|█████████▏| 3509/3844 [13:43:55<1:30:23, 16.19s/it]
{'loss': 1.1081, 'grad_norm': 0.19784001889136424, 'learning_rate': 3.958415123337544e-06, 'epoch': 0.91}

 91%|█████████▏| 3510/3844 [13:44:09<1:27:11, 15.66s/it]

 91%|█████████▏| 3511/3844 [13:44:29<1:34:14, 16.98s/it]

 91%|█████████▏| 3512/3844 [13:44:44<1:31:05, 16.46s/it]

 91%|█████████▏| 3513/3844 [13:45:00<1:29:08, 16.16s/it]

 91%|█████████▏| 3514/3844 [13:45:18<1:31:53, 16.71s/it]


 91%|█████████▏| 3516/3844 [13:45:51<1:31:05, 16.66s/it]

 91%|█████████▏| 3517/3844 [13:46:07<1:29:43, 16.46s/it]
{'loss': 1.0286, 'grad_norm': 0.17369724663342045, 'learning_rate': 3.7727976951971722e-06, 'epoch': 0.91}

 92%|█████████▏| 3518/3844 [13:46:22<1:26:51, 15.99s/it]

 92%|█████████▏| 3519/3844 [13:46:36<1:24:21, 15.57s/it]

 92%|█████████▏| 3520/3844 [13:46:52<1:24:11, 15.59s/it]

 92%|█████████▏| 3521/3844 [13:47:07<1:23:24, 15.49s/it]

 92%|█████████▏| 3522/3844 [13:47:22<1:21:34, 15.20s/it]

 92%|█████████▏| 3523/3844 [13:47:38<1:23:25, 15.59s/it]


 92%|█████████▏| 3525/3844 [13:48:07<1:19:34, 14.97s/it]
{'loss': 0.9468, 'grad_norm': 0.17702246531183402, 'learning_rate': 3.591553716661422e-06, 'epoch': 0.92}

 92%|█████████▏| 3526/3844 [13:48:20<1:16:03, 14.35s/it]

 92%|█████████▏| 3527/3844 [13:48:32<1:12:27, 13.72s/it]

 92%|█████████▏| 3528/3844 [13:48:47<1:14:59, 14.24s/it]

 92%|█████████▏| 3529/3844 [13:49:02<1:14:43, 14.23s/it]

 92%|█████████▏| 3530/3844 [13:49:18<1:17:54, 14.89s/it]

 92%|█████████▏| 3531/3844 [13:49:30<1:13:14, 14.04s/it]

 92%|█████████▏| 3532/3844 [13:49:44<1:13:08, 14.07s/it]

 92%|█████████▏| 3533/3844 [13:49:56<1:09:47, 13.46s/it]

 92%|█████████▏| 3534/3844 [13:50:08<1:06:15, 12.83s/it]

 92%|█████████▏| 3535/3844 [13:50:20<1:05:50, 12.79s/it]

 92%|█████████▏| 3536/3844 [13:50:34<1:06:28, 12.95s/it]


 92%|█████████▏| 3538/3844 [13:51:03<1:11:20, 13.99s/it]
{'loss': 1.0818, 'grad_norm': 0.17931465675626299, 'learning_rate': 3.306381148333393e-06, 'epoch': 0.92}

 92%|█████████▏| 3539/3844 [13:51:18<1:12:16, 14.22s/it]

 92%|█████████▏| 3540/3844 [13:51:32<1:11:55, 14.20s/it]

 92%|█████████▏| 3541/3844 [13:51:45<1:08:43, 13.61s/it]

 92%|█████████▏| 3542/3844 [13:52:00<1:10:55, 14.09s/it]

 92%|█████████▏| 3543/3844 [13:52:13<1:09:27, 13.85s/it]

 92%|█████████▏| 3544/3844 [13:52:27<1:09:26, 13.89s/it]

 92%|█████████▏| 3545/3844 [13:52:38<1:05:32, 13.15s/it]

 92%|█████████▏| 3546/3844 [13:52:55<1:10:34, 14.21s/it]

 92%|█████████▏| 3547/3844 [13:53:08<1:08:26, 13.83s/it]

 92%|█████████▏| 3548/3844 [13:53:22<1:08:18, 13.85s/it]

 92%|█████████▏| 3549/3844 [13:53:35<1:06:54, 13.61s/it]

 92%|█████████▏| 3550/3844 [13:53:49<1:07:14, 13.72s/it]

 92%|█████████▏| 3551/3844 [13:54:02<1:06:36, 13.64s/it]


 92%|█████████▏| 3553/3844 [13:54:31<1:07:43, 13.97s/it]

 92%|█████████▏| 3554/3844 [13:54:46<1:07:58, 14.06s/it]
{'loss': 1.0885, 'grad_norm': 0.17245643229796526, 'learning_rate': 2.971333520628694e-06, 'epoch': 0.92}

 92%|█████████▏| 3555/3844 [13:55:00<1:08:16, 14.17s/it]


 93%|█████████▎| 3557/3844 [13:55:25<1:04:12, 13.42s/it]

 93%|█████████▎| 3558/3844 [13:55:40<1:05:16, 13.69s/it]
{'loss': 1.1449, 'grad_norm': 0.17293178731997463, 'learning_rate': 2.890325445665987e-06, 'epoch': 0.93}


 93%|█████████▎| 3560/3844 [13:56:18<1:16:34, 16.18s/it]
{'loss': 1.1207, 'grad_norm': 0.17966782880658358, 'learning_rate': 2.8502351233156255e-06, 'epoch': 0.93}


 93%|█████████▎| 3562/3844 [13:56:52<1:18:20, 16.67s/it]
{'loss': 0.9746, 'grad_norm': 0.1713671609417109, 'learning_rate': 2.8104207631537427e-06, 'epoch': 0.93}

 93%|█████████▎| 3563/3844 [13:57:09<1:18:15, 16.71s/it]

 93%|█████████▎| 3564/3844 [13:57:28<1:21:35, 17.48s/it]


 93%|█████████▎| 3566/3844 [13:57:58<1:14:33, 16.09s/it]
{'loss': 1.0966, 'grad_norm': 0.1616359758991585, 'learning_rate': 2.7316203809955145e-06, 'epoch': 0.93}

 93%|█████████▎| 3567/3844 [13:58:14<1:14:20, 16.10s/it]

 93%|█████████▎| 3568/3844 [13:58:29<1:12:41, 15.80s/it]


 93%|█████████▎| 3570/3844 [13:59:08<1:20:23, 17.60s/it]
{'loss': 0.9754, 'grad_norm': 0.16308331790766065, 'learning_rate': 2.653925194547513e-06, 'epoch': 0.93}


 93%|█████████▎| 3572/3844 [13:59:46<1:22:40, 18.24s/it]

 93%|█████████▎| 3573/3844 [13:59:58<1:14:13, 16.43s/it]
{'loss': 1.0946, 'grad_norm': 0.18155494726304416, 'learning_rate': 2.5963796209272694e-06, 'epoch': 0.93}

 93%|█████████▎| 3574/3844 [14:00:13<1:11:21, 15.86s/it]

 93%|█████████▎| 3575/3844 [14:00:28<1:09:45, 15.56s/it]


 93%|█████████▎| 3577/3844 [14:00:58<1:08:54, 15.48s/it]
{'loss': 1.1083, 'grad_norm': 0.18847120323888727, 'learning_rate': 2.520620643646354e-06, 'epoch': 0.93}

 93%|█████████▎| 3578/3844 [14:01:13<1:07:17, 15.18s/it]

 93%|█████████▎| 3579/3844 [14:01:27<1:05:55, 14.93s/it]

 93%|█████████▎| 3580/3844 [14:01:40<1:02:27, 14.19s/it]

 93%|█████████▎| 3581/3844 [14:01:54<1:03:11, 14.42s/it]

 93%|█████████▎| 3582/3844 [14:02:09<1:03:01, 14.43s/it]

 93%|█████████▎| 3583/3844 [14:02:20<59:00, 13.56s/it]


 93%|█████████▎| 3585/3844 [14:02:54<1:06:04, 15.31s/it]
{'loss': 1.1304, 'grad_norm': 0.18983458129765737, 'learning_rate': 2.3724263167768212e-06, 'epoch': 0.93}

 93%|█████████▎| 3586/3844 [14:03:07<1:02:22, 14.50s/it]

 93%|█████████▎| 3587/3844 [14:03:19<59:02, 13.78s/it]

 93%|█████████▎| 3588/3844 [14:03:33<59:53, 14.04s/it]

 93%|█████████▎| 3589/3844 [14:03:46<58:22, 13.73s/it]

 93%|█████████▎| 3590/3844 [14:04:01<59:25, 14.04s/it]

 93%|█████████▎| 3591/3844 [14:04:14<57:28, 13.63s/it]

 93%|█████████▎| 3592/3844 [14:04:28<57:55, 13.79s/it]

 93%|█████████▎| 3593/3844 [14:04:42<57:44, 13.80s/it]

 93%|█████████▎| 3594/3844 [14:04:57<59:03, 14.18s/it]

 94%|█████████▎| 3595/3844 [14:05:11<58:31, 14.10s/it]

 94%|█████████▎| 3596/3844 [14:05:25<58:20, 14.11s/it]

 94%|█████████▎| 3597/3844 [14:05:37<55:59, 13.60s/it]

 94%|█████████▎| 3598/3844 [14:05:52<56:33, 13.79s/it]

 94%|█████████▎| 3599/3844 [14:06:03<53:41, 13.15s/it]

 94%|█████████▎| 3600/3844 [14:06:18<55:31, 13.66s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.087, 'grad_norm': 0.18396765389540792, 'learning_rate': 2.0893554827903117e-06, 'epoch': 0.94}
 94%|█████████▎| 3601/3844 [14:07:06<1:36:35, 23.85s/it]


 94%|█████████▎| 3603/3844 [14:07:37<1:17:35, 19.32s/it]
{'loss': 1.0888, 'grad_norm': 0.1730161270734872, 'learning_rate': 2.0552221456403565e-06, 'epoch': 0.94}

 94%|█████████▍| 3604/3844 [14:07:48<1:07:45, 16.94s/it]


 94%|█████████▍| 3606/3844 [14:08:17<1:02:19, 15.71s/it]
{'loss': 1.0619, 'grad_norm': 0.17328057947857067, 'learning_rate': 2.004543833418826e-06, 'epoch': 0.94}


 94%|█████████▍| 3608/3844 [14:08:48<1:01:07, 15.54s/it]
{'loss': 0.9641, 'grad_norm': 0.1739787731126058, 'learning_rate': 1.9711062275640014e-06, 'epoch': 0.94}

 94%|█████████▍| 3609/3844 [14:09:04<1:00:59, 15.57s/it]

 94%|█████████▍| 3610/3844 [14:09:23<1:04:24, 16.52s/it]

 94%|█████████▍| 3611/3844 [14:09:36<1:00:16, 15.52s/it]

 94%|█████████▍| 3612/3844 [14:09:47<54:42, 14.15s/it]

 94%|█████████▍| 3613/3844 [14:10:00<52:48, 13.71s/it]

 94%|█████████▍| 3614/3844 [14:10:15<54:41, 14.27s/it]

 94%|█████████▍| 3615/3844 [14:10:28<53:17, 13.96s/it]

 94%|█████████▍| 3616/3844 [14:10:43<54:12, 14.27s/it]

 94%|█████████▍| 3617/3844 [14:11:00<56:16, 14.87s/it]

 94%|█████████▍| 3618/3844 [14:11:14<55:16, 14.67s/it]

 94%|█████████▍| 3619/3844 [14:11:27<52:44, 14.07s/it]

 94%|█████████▍| 3620/3844 [14:11:38<49:51, 13.36s/it]

 94%|█████████▍| 3621/3844 [14:11:54<51:57, 13.98s/it]

 94%|█████████▍| 3622/3844 [14:12:05<48:51, 13.20s/it]

 94%|█████████▍| 3623/3844 [14:12:17<46:46, 12.70s/it]

 94%|█████████▍| 3624/3844 [14:12:32<48:57, 13.35s/it]

 94%|█████████▍| 3625/3844 [14:12:47<50:36, 13.86s/it]

 94%|█████████▍| 3626/3844 [14:13:03<53:27, 14.71s/it]

 94%|█████████▍| 3627/3844 [14:13:20<54:55, 15.19s/it]

 94%|█████████▍| 3628/3844 [14:13:34<53:31, 14.87s/it]

 94%|█████████▍| 3629/3844 [14:13:45<49:59, 13.95s/it]

 94%|█████████▍| 3630/3844 [14:13:59<49:08, 13.78s/it]

 94%|█████████▍| 3631/3844 [14:14:14<50:08, 14.12s/it]

 94%|█████████▍| 3632/3844 [14:14:26<48:20, 13.68s/it]

 95%|█████████▍| 3633/3844 [14:14:40<47:30, 13.51s/it]

 95%|█████████▍| 3634/3844 [14:14:52<46:16, 13.22s/it]

 95%|█████████▍| 3635/3844 [14:15:07<48:16, 13.86s/it]

 95%|█████████▍| 3636/3844 [14:15:21<47:44, 13.77s/it]

 95%|█████████▍| 3637/3844 [14:15:37<49:19, 14.30s/it]

 95%|█████████▍| 3638/3844 [14:15:52<50:36, 14.74s/it]

 95%|█████████▍| 3639/3844 [14:16:06<49:08, 14.38s/it]

 95%|█████████▍| 3640/3844 [14:16:20<48:32, 14.28s/it]

 95%|█████████▍| 3641/3844 [14:16:38<52:08, 15.41s/it]

 95%|█████████▍| 3642/3844 [14:16:51<49:35, 14.73s/it]

 95%|█████████▍| 3643/3844 [14:17:02<46:00, 13.73s/it]

 95%|█████████▍| 3644/3844 [14:17:16<45:32, 13.66s/it]

 95%|█████████▍| 3645/3844 [14:17:34<49:37, 14.96s/it]

 95%|█████████▍| 3646/3844 [14:17:46<46:24, 14.07s/it]

 95%|█████████▍| 3647/3844 [14:18:01<46:50, 14.27s/it]

 95%|█████████▍| 3648/3844 [14:18:15<46:11, 14.14s/it]


 95%|█████████▍| 3650/3844 [14:18:43<46:25, 14.36s/it]
{'loss': 0.9872, 'grad_norm': 0.1755802095988701, 'learning_rate': 1.3333798925996844e-06, 'epoch': 0.95}

 95%|█████████▍| 3651/3844 [14:18:59<47:04, 14.63s/it]

 95%|█████████▌| 3652/3844 [14:19:15<48:36, 15.19s/it]


 95%|█████████▌| 3654/3844 [14:19:41<45:06, 14.25s/it]
{'loss': 1.1224, 'grad_norm': 0.18577865500435958, 'learning_rate': 1.279078319824667e-06, 'epoch': 0.95}


 95%|█████████▌| 3656/3844 [14:20:10<44:17, 14.14s/it]

 95%|█████████▌| 3657/3844 [14:20:27<47:10, 15.13s/it]

 95%|█████████▌| 3658/3844 [14:20:41<45:23, 14.64s/it]

 95%|█████████▌| 3659/3844 [14:20:57<46:16, 15.01s/it]

 95%|█████████▌| 3660/3844 [14:21:08<42:56, 14.00s/it]

 95%|█████████▌| 3661/3844 [14:21:23<43:28, 14.25s/it]

 95%|█████████▌| 3662/3844 [14:21:37<42:35, 14.04s/it]

 95%|█████████▌| 3663/3844 [14:21:50<41:54, 13.89s/it]

 95%|█████████▌| 3664/3844 [14:22:04<41:42, 13.90s/it]

 95%|█████████▌| 3665/3844 [14:22:20<43:06, 14.45s/it]

 95%|█████████▌| 3666/3844 [14:22:36<44:34, 15.03s/it]

 95%|█████████▌| 3667/3844 [14:22:54<46:20, 15.71s/it]

 95%|█████████▌| 3668/3844 [14:23:07<44:20, 15.11s/it]

 95%|█████████▌| 3669/3844 [14:23:21<42:46, 14.67s/it]

 95%|█████████▌| 3670/3844 [14:23:32<39:46, 13.71s/it]

 95%|█████████▌| 3671/3844 [14:23:51<43:49, 15.20s/it]

 96%|█████████▌| 3672/3844 [14:24:06<43:19, 15.12s/it]

 96%|█████████▌| 3673/3844 [14:24:20<42:24, 14.88s/it]

 96%|█████████▌| 3674/3844 [14:24:39<45:46, 16.16s/it]

 96%|█████████▌| 3675/3844 [14:24:57<46:30, 16.51s/it]

 96%|█████████▌| 3676/3844 [14:25:12<45:28, 16.24s/it]

 96%|█████████▌| 3677/3844 [14:25:26<43:03, 15.47s/it]

 96%|█████████▌| 3678/3844 [14:25:41<42:14, 15.27s/it]

 96%|█████████▌| 3679/3844 [14:25:58<43:38, 15.87s/it]

 96%|█████████▌| 3680/3844 [14:26:15<44:09, 16.16s/it]

 96%|█████████▌| 3681/3844 [14:26:30<43:00, 15.83s/it]

 96%|█████████▌| 3682/3844 [14:26:45<42:17, 15.66s/it]

 96%|█████████▌| 3683/3844 [14:27:02<42:30, 15.84s/it]

 96%|█████████▌| 3684/3844 [14:27:17<42:07, 15.80s/it]

 96%|█████████▌| 3685/3844 [14:27:31<40:31, 15.29s/it]

 96%|█████████▌| 3686/3844 [14:27:46<39:54, 15.16s/it]

 96%|█████████▌| 3687/3844 [14:28:03<40:55, 15.64s/it]

 96%|█████████▌| 3688/3844 [14:28:18<40:33, 15.60s/it]

 96%|█████████▌| 3689/3844 [14:28:31<37:53, 14.66s/it]

 96%|█████████▌| 3690/3844 [14:28:52<42:15, 16.46s/it]

 96%|█████████▌| 3691/3844 [14:29:07<41:07, 16.13s/it]

 96%|█████████▌| 3692/3844 [14:29:24<41:13, 16.27s/it]

 96%|█████████▌| 3693/3844 [14:29:37<39:06, 15.54s/it]

 96%|█████████▌| 3694/3844 [14:29:53<39:00, 15.60s/it]

 96%|█████████▌| 3695/3844 [14:30:07<37:40, 15.17s/it]

 96%|█████████▌| 3696/3844 [14:30:20<35:43, 14.48s/it]

 96%|█████████▌| 3697/3844 [14:30:38<37:40, 15.38s/it]

 96%|█████████▌| 3698/3844 [14:30:52<36:32, 15.02s/it]

 96%|█████████▌| 3699/3844 [14:31:06<35:30, 14.69s/it]

 96%|█████████▋| 3700/3844 [14:31:21<35:19, 14.72s/it]

 96%|█████████▋| 3701/3844 [14:31:38<37:14, 15.63s/it]

 96%|█████████▋| 3702/3844 [14:31:53<36:19, 15.35s/it]

 96%|█████████▋| 3703/3844 [14:32:06<34:46, 14.80s/it]

 96%|█████████▋| 3704/3844 [14:32:24<36:12, 15.52s/it]
{'loss': 0.9961, 'grad_norm': 0.16751343184659181, 'learning_rate': 6.951366946906346e-07, 'epoch': 0.96}


 96%|█████████▋| 3706/3844 [14:32:50<32:29, 14.13s/it]

 96%|█████████▋| 3707/3844 [14:33:10<36:26, 15.96s/it]

 96%|█████████▋| 3708/3844 [14:33:25<35:17, 15.57s/it]

 96%|█████████▋| 3709/3844 [14:33:40<34:35, 15.37s/it]

 97%|█████████▋| 3710/3844 [14:33:54<33:19, 14.92s/it]

 97%|█████████▋| 3711/3844 [14:34:10<34:00, 15.34s/it]

 97%|█████████▋| 3712/3844 [14:34:24<33:03, 15.02s/it]

 97%|█████████▋| 3713/3844 [14:34:38<32:07, 14.72s/it]

 97%|█████████▋| 3714/3844 [14:34:59<35:50, 16.54s/it]

 97%|█████████▋| 3715/3844 [14:35:14<34:12, 15.91s/it]

 97%|█████████▋| 3716/3844 [14:35:27<32:15, 15.12s/it]

 97%|█████████▋| 3717/3844 [14:35:46<34:39, 16.37s/it]

 97%|█████████▋| 3718/3844 [14:36:02<34:09, 16.27s/it]

 97%|█████████▋| 3719/3844 [14:36:17<32:53, 15.79s/it]

 97%|█████████▋| 3720/3844 [14:36:33<32:35, 15.77s/it]

 97%|█████████▋| 3721/3844 [14:36:48<32:20, 15.78s/it]

 97%|█████████▋| 3722/3844 [14:37:03<31:15, 15.37s/it]

 97%|█████████▋| 3723/3844 [14:37:17<30:16, 15.01s/it]

 97%|█████████▋| 3724/3844 [14:37:34<31:05, 15.55s/it]

 97%|█████████▋| 3725/3844 [14:37:51<32:07, 16.20s/it]

 97%|█████████▋| 3726/3844 [14:38:07<31:15, 15.90s/it]

 97%|█████████▋| 3727/3844 [14:38:19<29:01, 14.89s/it]

 97%|█████████▋| 3728/3844 [14:38:33<28:03, 14.51s/it]

 97%|█████████▋| 3729/3844 [14:38:51<30:00, 15.66s/it]

 97%|█████████▋| 3730/3844 [14:39:06<29:27, 15.50s/it]

 97%|█████████▋| 3731/3844 [14:39:21<28:50, 15.31s/it]

 97%|█████████▋| 3732/3844 [14:39:35<27:34, 14.77s/it]

 97%|█████████▋| 3733/3844 [14:39:46<25:11, 13.62s/it]

 97%|█████████▋| 3734/3844 [14:40:00<25:11, 13.74s/it]

 97%|█████████▋| 3735/3844 [14:40:12<24:26, 13.46s/it]

 97%|█████████▋| 3736/3844 [14:40:31<26:45, 14.86s/it]

 97%|█████████▋| 3737/3844 [14:40:43<25:16, 14.18s/it]

 97%|█████████▋| 3738/3844 [14:41:00<26:19, 14.90s/it]

 97%|█████████▋| 3739/3844 [14:41:13<25:14, 14.43s/it]

 97%|█████████▋| 3740/3844 [14:41:26<24:08, 13.93s/it]

 97%|█████████▋| 3741/3844 [14:41:39<23:27, 13.67s/it]

 97%|█████████▋| 3742/3844 [14:41:58<26:04, 15.34s/it]

 97%|█████████▋| 3743/3844 [14:42:11<24:43, 14.69s/it]

 97%|█████████▋| 3744/3844 [14:42:22<22:22, 13.42s/it]

 97%|█████████▋| 3745/3844 [14:42:34<21:20, 12.94s/it]

 97%|█████████▋| 3746/3844 [14:42:49<22:32, 13.80s/it]

 97%|█████████▋| 3747/3844 [14:43:06<23:35, 14.60s/it]

 98%|█████████▊| 3748/3844 [14:43:23<24:38, 15.40s/it]

 98%|█████████▊| 3749/3844 [14:43:34<22:19, 14.10s/it]

 98%|█████████▊| 3750/3844 [14:43:51<23:23, 14.93s/it]

 98%|█████████▊| 3751/3844 [14:44:08<23:54, 15.42s/it]

 98%|█████████▊| 3752/3844 [14:44:20<22:28, 14.66s/it]

 98%|█████████▊| 3753/3844 [14:44:36<22:32, 14.86s/it]

 98%|█████████▊| 3754/3844 [14:44:52<22:42, 15.14s/it]

 98%|█████████▊| 3755/3844 [14:45:06<22:11, 14.96s/it]

 98%|█████████▊| 3756/3844 [14:45:23<22:57, 15.65s/it]

 98%|█████████▊| 3757/3844 [14:45:38<22:18, 15.38s/it]

 98%|█████████▊| 3758/3844 [14:45:56<23:16, 16.23s/it]

 98%|█████████▊| 3759/3844 [14:46:13<23:06, 16.31s/it]

 98%|█████████▊| 3760/3844 [14:46:30<23:18, 16.65s/it]

 98%|█████████▊| 3761/3844 [14:46:42<21:08, 15.29s/it]

 98%|█████████▊| 3762/3844 [14:46:58<21:02, 15.40s/it]

 98%|█████████▊| 3763/3844 [14:47:14<20:52, 15.46s/it]

 98%|█████████▊| 3764/3844 [14:47:32<21:53, 16.42s/it]

 98%|█████████▊| 3765/3844 [14:47:46<20:20, 15.45s/it]

 98%|█████████▊| 3766/3844 [14:48:01<20:12, 15.55s/it]

 98%|█████████▊| 3767/3844 [14:48:14<18:43, 14.59s/it]

 98%|█████████▊| 3768/3844 [14:48:27<18:02, 14.25s/it]

 98%|█████████▊| 3769/3844 [14:48:44<18:52, 15.09s/it]

 98%|█████████▊| 3770/3844 [14:48:58<18:06, 14.68s/it]

 98%|█████████▊| 3771/3844 [14:49:14<18:20, 15.08s/it]

 98%|█████████▊| 3772/3844 [14:49:26<17:10, 14.32s/it]

 98%|█████████▊| 3773/3844 [14:49:47<19:00, 16.07s/it]

 98%|█████████▊| 3774/3844 [14:50:00<17:44, 15.21s/it]

 98%|█████████▊| 3775/3844 [14:50:19<18:48, 16.36s/it]

 98%|█████████▊| 3776/3844 [14:50:30<16:55, 14.94s/it]

 98%|█████████▊| 3777/3844 [14:50:50<18:06, 16.21s/it]

 98%|█████████▊| 3778/3844 [14:51:03<16:44, 15.21s/it]
{'loss': 1.1328, 'grad_norm': 0.18119359946923277, 'learning_rate': 1.5463003591225101e-07, 'epoch': 0.98}


 98%|█████████▊| 3780/3844 [14:51:37<17:22, 16.28s/it]

 98%|█████████▊| 3781/3844 [14:51:53<17:00, 16.19s/it]
{'loss': 1.18, 'grad_norm': 0.17792919662163728, 'learning_rate': 1.40895470407143e-07, 'epoch': 0.98}


 98%|█████████▊| 3783/3844 [14:52:20<14:53, 14.65s/it]

 98%|█████████▊| 3784/3844 [14:52:33<14:15, 14.26s/it]
{'loss': 0.9842, 'grad_norm': 0.19276354677093543, 'learning_rate': 1.2779913588529812e-07, 'epoch': 0.98}


 98%|█████████▊| 3786/3844 [14:53:06<14:49, 15.33s/it]

 99%|█████████▊| 3787/3844 [14:53:24<15:13, 16.02s/it]

 99%|█████████▊| 3788/3844 [14:53:37<14:11, 15.20s/it]

 99%|█████████▊| 3789/3844 [14:53:49<13:09, 14.35s/it]

 99%|█████████▊| 3790/3844 [14:54:04<12:55, 14.37s/it]

 99%|█████████▊| 3791/3844 [14:54:19<13:00, 14.72s/it]

 99%|█████████▊| 3792/3844 [14:54:36<13:11, 15.23s/it]
{'loss': 1.0688, 'grad_norm': 0.18761969843670068, 'learning_rate': 9.599644115004803e-08, 'epoch': 0.99}


 99%|█████████▊| 3794/3844 [14:55:07<12:55, 15.51s/it]

 99%|█████████▊| 3795/3844 [14:55:18<11:40, 14.29s/it]

 99%|█████████▉| 3796/3844 [14:55:36<12:06, 15.14s/it]

 99%|█████████▉| 3797/3844 [14:55:53<12:24, 15.84s/it]

 99%|█████████▉| 3798/3844 [14:56:10<12:29, 16.30s/it]

 99%|█████████▉| 3799/3844 [14:56:26<11:59, 15.98s/it]

 99%|█████████▉| 3800/3844 [14:56:44<12:12, 16.65s/it]

 99%|█████████▉| 3801/3844 [14:56:59<11:30, 16.07s/it]

 99%|█████████▉| 3802/3844 [14:57:13<10:59, 15.71s/it]

 99%|█████████▉| 3803/3844 [14:57:30<10:58, 16.07s/it]

 99%|█████████▉| 3804/3844 [14:57:46<10:32, 15.81s/it]

 99%|█████████▉| 3805/3844 [14:58:10<11:53, 18.29s/it]

 99%|█████████▉| 3806/3844 [14:58:34<12:42, 20.07s/it]

 99%|█████████▉| 3807/3844 [14:58:50<11:40, 18.94s/it]

 99%|█████████▉| 3808/3844 [14:59:04<10:26, 17.40s/it]
{'loss': 1.0123, 'grad_norm': 0.1827229142863277, 'learning_rate': 4.6013962590252254e-08, 'epoch': 0.99}


 99%|█████████▉| 3810/3844 [14:59:41<10:05, 17.80s/it]

 99%|█████████▉| 3811/3844 [14:59:59<09:50, 17.89s/it]

 99%|█████████▉| 3812/3844 [15:00:16<09:22, 17.58s/it]

 99%|█████████▉| 3813/3844 [15:00:36<09:30, 18.40s/it]

 99%|█████████▉| 3814/3844 [15:00:49<08:20, 16.70s/it]

 99%|█████████▉| 3815/3844 [15:01:01<07:24, 15.33s/it]
{'loss': 1.115, 'grad_norm': 0.1677527927797733, 'learning_rate': 2.986017326852553e-08, 'epoch': 0.99}


 99%|█████████▉| 3817/3844 [15:01:28<06:32, 14.55s/it]

 99%|█████████▉| 3818/3844 [15:01:42<06:17, 14.50s/it]

 99%|█████████▉| 3819/3844 [15:01:59<06:18, 15.14s/it]

 99%|█████████▉| 3820/3844 [15:02:12<05:51, 14.66s/it]

 99%|█████████▉| 3821/3844 [15:02:26<05:29, 14.30s/it]

 99%|█████████▉| 3822/3844 [15:02:39<05:05, 13.89s/it]
{'loss': 1.0567, 'grad_norm': 0.17271843877016335, 'learning_rate': 1.718505255621228e-08, 'epoch': 0.99}


 99%|█████████▉| 3824/3844 [15:03:15<05:19, 15.97s/it]

100%|█████████▉| 3825/3844 [15:03:30<04:56, 15.59s/it]

100%|█████████▉| 3826/3844 [15:03:46<04:46, 15.92s/it]

100%|█████████▉| 3827/3844 [15:04:02<04:30, 15.90s/it]

100%|█████████▉| 3828/3844 [15:04:16<04:05, 15.32s/it]

100%|█████████▉| 3829/3844 [15:04:31<03:48, 15.25s/it]

100%|█████████▉| 3830/3844 [15:04:45<03:26, 14.74s/it]

100%|█████████▉| 3831/3844 [15:04:58<03:05, 14.26s/it]

100%|█████████▉| 3832/3844 [15:05:11<02:45, 13.83s/it]

100%|█████████▉| 3833/3844 [15:05:25<02:33, 13.93s/it]

100%|█████████▉| 3834/3844 [15:05:40<02:24, 14.41s/it]

100%|█████████▉| 3835/3844 [15:05:57<02:15, 15.09s/it]

100%|█████████▉| 3836/3844 [15:06:18<02:13, 16.72s/it]
{'loss': 1.0777, 'grad_norm': 0.16431893686360538, 'learning_rate': 2.272460125563036e-09, 'epoch': 1.0}


100%|█████████▉| 3838/3844 [15:06:45<01:29, 14.99s/it]

100%|█████████▉| 3839/3844 [15:06:55<01:08, 13.67s/it]

100%|█████████▉| 3840/3844 [15:07:14<01:01, 15.27s/it]

100%|█████████▉| 3841/3844 [15:07:28<00:44, 14.90s/it]

100%|█████████▉| 3842/3844 [15:07:46<00:31, 15.84s/it]

100%|█████████▉| 3843/3844 [15:08:00<00:15, 15.29s/it]

100%|██████████| 3844/3844 [15:08:17<00:00, 15.53s/it]
{'loss': 1.0956, 'grad_norm': 0.18078881382495954, 'learning_rate': 0.0, 'epoch': 1.0}

100%|██████████| 3844/3844 [15:08:21<00:00, 14.18s/it]
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(