/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
  0%|          | 0/3107 [00:00<?, ?it/s]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/3107 [00:51<44:04:28, 51.08s/it]
{'loss': 1.4853, 'grad_norm': 0.5682410225096285, 'learning_rate': 2.1276595744680853e-06, 'epoch': 0.0}

  0%|          | 2/3107 [00:57<21:34:09, 25.01s/it]

  0%|          | 3/3107 [01:03<14:05:08, 16.34s/it]

  0%|          | 4/3107 [01:11<10:59:49, 12.76s/it]

  0%|          | 5/3107 [01:20<9:55:43, 11.52s/it]

  0%|          | 6/3107 [01:26<8:24:48,  9.77s/it]

  0%|          | 7/3107 [01:33<7:31:01,  8.73s/it]

  0%|          | 8/3107 [01:42<7:32:04,  8.75s/it]

  0%|          | 9/3107 [01:50<7:30:06,  8.72s/it]

  0%|          | 10/3107 [02:03<8:35:27,  9.99s/it]

  0%|          | 11/3107 [02:11<7:58:17,  9.27s/it]

  0%|          | 12/3107 [02:17<7:08:03,  8.30s/it]

  0%|          | 13/3107 [02:23<6:39:19,  7.74s/it]

  0%|          | 14/3107 [02:30<6:15:16,  7.28s/it]

  0%|          | 15/3107 [02:35<5:45:47,  6.71s/it]

  1%|          | 16/3107 [02:44<6:15:14,  7.28s/it]

  1%|          | 17/3107 [02:50<6:03:34,  7.06s/it]

  1%|          | 18/3107 [02:57<6:05:37,  7.10s/it]

  1%|          | 19/3107 [03:03<5:39:26,  6.60s/it]

  1%|          | 20/3107 [03:09<5:33:15,  6.48s/it]

  1%|          | 21/3107 [03:16<5:40:53,  6.63s/it]

  1%|          | 22/3107 [03:23<5:46:23,  6.74s/it]

  1%|          | 23/3107 [03:31<6:03:18,  7.07s/it]

  1%|          | 24/3107 [03:41<6:58:12,  8.14s/it]

  1%|          | 25/3107 [03:49<6:48:53,  7.96s/it]

  1%|          | 26/3107 [03:57<6:46:07,  7.91s/it]

  1%|          | 27/3107 [04:06<7:02:24,  8.23s/it]

  1%|          | 28/3107 [04:14<6:59:19,  8.17s/it]

  1%|          | 29/3107 [04:24<7:37:38,  8.92s/it]

  1%|          | 30/3107 [04:33<7:29:38,  8.77s/it]

  1%|          | 31/3107 [04:41<7:18:36,  8.56s/it]

  1%|          | 32/3107 [04:49<7:08:41,  8.36s/it]

  1%|          | 33/3107 [04:56<6:50:49,  8.02s/it]

  1%|          | 34/3107 [05:04<6:57:41,  8.16s/it]

  1%|          | 35/3107 [05:11<6:38:12,  7.78s/it]

  1%|          | 36/3107 [05:18<6:21:14,  7.45s/it]

  1%|          | 37/3107 [05:24<5:53:15,  6.90s/it]

  1%|          | 38/3107 [05:34<6:38:32,  7.79s/it]

  1%|▏         | 39/3107 [05:41<6:34:04,  7.71s/it]

  1%|▏         | 40/3107 [05:51<7:07:07,  8.36s/it]

  1%|▏         | 41/3107 [05:59<7:06:13,  8.34s/it]

  1%|▏         | 42/3107 [06:07<6:50:10,  8.03s/it]

  1%|▏         | 43/3107 [06:12<6:16:38,  7.38s/it]

  1%|▏         | 44/3107 [06:18<5:45:51,  6.77s/it]

  1%|▏         | 45/3107 [06:26<6:11:13,  7.27s/it]

  1%|▏         | 46/3107 [06:34<6:14:47,  7.35s/it]

  2%|▏         | 47/3107 [06:42<6:29:18,  7.63s/it]

  2%|▏         | 48/3107 [06:49<6:26:31,  7.58s/it]

  2%|▏         | 49/3107 [06:55<6:02:11,  7.11s/it]

  2%|▏         | 50/3107 [07:06<6:58:30,  8.21s/it]

  2%|▏         | 51/3107 [07:12<6:18:20,  7.43s/it]

  2%|▏         | 52/3107 [07:21<6:42:19,  7.90s/it]

  2%|▏         | 53/3107 [07:27<6:18:04,  7.43s/it]

  2%|▏         | 54/3107 [07:35<6:26:19,  7.59s/it]

  2%|▏         | 55/3107 [07:41<5:53:46,  6.95s/it]

  2%|▏         | 56/3107 [07:47<5:46:10,  6.81s/it]

  2%|▏         | 57/3107 [07:57<6:27:41,  7.63s/it]

  2%|▏         | 58/3107 [08:05<6:30:59,  7.69s/it]

  2%|▏         | 59/3107 [08:12<6:28:53,  7.66s/it]

  2%|▏         | 60/3107 [08:17<5:52:41,  6.95s/it]

  2%|▏         | 61/3107 [08:23<5:39:11,  6.68s/it]

  2%|▏         | 62/3107 [08:30<5:30:19,  6.51s/it]

  2%|▏         | 63/3107 [08:36<5:33:12,  6.57s/it]

  2%|▏         | 64/3107 [08:47<6:41:30,  7.92s/it]

  2%|▏         | 65/3107 [08:53<6:01:18,  7.13s/it]

  2%|▏         | 66/3107 [08:58<5:37:39,  6.66s/it]

  2%|▏         | 67/3107 [09:08<6:24:39,  7.59s/it]

  2%|▏         | 68/3107 [09:17<6:47:25,  8.04s/it]

  2%|▏         | 69/3107 [09:24<6:31:52,  7.74s/it]

  2%|▏         | 70/3107 [09:31<6:21:03,  7.53s/it]

  2%|▏         | 71/3107 [09:38<6:06:23,  7.24s/it]

  2%|▏         | 72/3107 [09:49<7:09:08,  8.48s/it]

  2%|▏         | 73/3107 [10:01<7:54:25,  9.38s/it]

  2%|▏         | 74/3107 [10:16<9:30:03, 11.28s/it]

  2%|▏         | 75/3107 [10:25<8:57:36, 10.64s/it]

  2%|▏         | 76/3107 [10:33<8:09:13,  9.68s/it]

  2%|▏         | 77/3107 [10:39<7:12:05,  8.56s/it]

  3%|▎         | 78/3107 [10:44<6:27:01,  7.67s/it]

  3%|▎         | 79/3107 [10:50<5:59:52,  7.13s/it]

  3%|▎         | 80/3107 [10:57<5:58:33,  7.11s/it]

  3%|▎         | 81/3107 [11:06<6:18:45,  7.51s/it]

  3%|▎         | 82/3107 [11:12<5:56:54,  7.08s/it]

  3%|▎         | 83/3107 [11:18<5:42:46,  6.80s/it]

  3%|▎         | 84/3107 [11:24<5:27:31,  6.50s/it]

  3%|▎         | 85/3107 [11:30<5:27:09,  6.50s/it]

  3%|▎         | 86/3107 [11:40<6:13:53,  7.43s/it]

  3%|▎         | 87/3107 [11:46<5:51:48,  6.99s/it]

  3%|▎         | 88/3107 [11:53<5:56:40,  7.09s/it]

  3%|▎         | 89/3107 [11:59<5:43:35,  6.83s/it]

  3%|▎         | 90/3107 [12:08<6:13:30,  7.43s/it]

  3%|▎         | 91/3107 [12:14<5:46:47,  6.90s/it]

  3%|▎         | 92/3107 [12:24<6:33:02,  7.82s/it]

  3%|▎         | 93/3107 [12:29<5:57:20,  7.11s/it]

  3%|▎         | 94/3107 [12:39<6:42:37,  8.02s/it]

  3%|▎         | 95/3107 [12:47<6:38:09,  7.93s/it]

  3%|▎         | 96/3107 [12:53<6:05:41,  7.29s/it]

  3%|▎         | 97/3107 [12:59<5:43:47,  6.85s/it]

  3%|▎         | 98/3107 [13:07<6:05:24,  7.29s/it]

  3%|▎         | 99/3107 [13:19<7:18:06,  8.74s/it]

  3%|▎         | 100/3107 [13:27<7:09:35,  8.57s/it]

  3%|▎         | 101/3107 [13:33<6:25:34,  7.70s/it]

  3%|▎         | 102/3107 [13:39<6:03:43,  7.26s/it]

  3%|▎         | 103/3107 [13:46<5:52:21,  7.04s/it]

  3%|▎         | 104/3107 [13:52<5:41:15,  6.82s/it]

  3%|▎         | 105/3107 [13:59<5:43:33,  6.87s/it]

  3%|▎         | 106/3107 [14:06<5:39:47,  6.79s/it]

  3%|▎         | 107/3107 [14:13<5:46:00,  6.92s/it]

  3%|▎         | 108/3107 [14:21<6:06:11,  7.33s/it]

  4%|▎         | 109/3107 [14:33<7:09:05,  8.59s/it]

  4%|▎         | 110/3107 [14:39<6:33:30,  7.88s/it]

  4%|▎         | 111/3107 [14:46<6:24:09,  7.69s/it]

  4%|▎         | 112/3107 [14:54<6:20:54,  7.63s/it]

  4%|▎         | 113/3107 [15:01<6:19:43,  7.61s/it]

  4%|▎         | 114/3107 [15:07<5:50:47,  7.03s/it]

  4%|▎         | 115/3107 [15:15<6:06:55,  7.36s/it]

  4%|▎         | 116/3107 [15:22<5:59:05,  7.20s/it]

  4%|▍         | 117/3107 [15:32<6:47:34,  8.18s/it]

  4%|▍         | 118/3107 [15:41<6:51:22,  8.26s/it]

  4%|▍         | 119/3107 [15:48<6:30:02,  7.83s/it]

  4%|▍         | 120/3107 [15:53<5:52:01,  7.07s/it]

  4%|▍         | 121/3107 [16:01<6:13:33,  7.51s/it]

  4%|▍         | 122/3107 [16:07<5:40:53,  6.85s/it]

  4%|▍         | 123/3107 [16:14<5:49:48,  7.03s/it]

  4%|▍         | 124/3107 [16:24<6:23:38,  7.72s/it]

  4%|▍         | 125/3107 [16:29<5:51:58,  7.08s/it]

  4%|▍         | 126/3107 [16:37<5:57:49,  7.20s/it]

  4%|▍         | 127/3107 [16:46<6:30:38,  7.87s/it]

  4%|▍         | 128/3107 [16:56<7:00:17,  8.47s/it]

  4%|▍         | 129/3107 [17:02<6:27:12,  7.80s/it]

  4%|▍         | 130/3107 [17:08<5:55:54,  7.17s/it]

  4%|▍         | 131/3107 [17:15<5:50:14,  7.06s/it]

  4%|▍         | 132/3107 [17:20<5:28:58,  6.63s/it]

  4%|▍         | 133/3107 [17:27<5:33:03,  6.72s/it]

  4%|▍         | 134/3107 [17:34<5:39:43,  6.86s/it]

  4%|▍         | 135/3107 [17:41<5:39:39,  6.86s/it]

  4%|▍         | 136/3107 [17:51<6:26:45,  7.81s/it]

  4%|▍         | 137/3107 [17:59<6:20:31,  7.69s/it]

  4%|▍         | 138/3107 [18:07<6:28:35,  7.85s/it]

  4%|▍         | 139/3107 [18:13<5:58:47,  7.25s/it]

  5%|▍         | 140/3107 [18:19<5:42:17,  6.92s/it]

  5%|▍         | 141/3107 [18:29<6:32:39,  7.94s/it]

  5%|▍         | 142/3107 [18:36<6:07:47,  7.44s/it]

  5%|▍         | 143/3107 [18:42<5:54:20,  7.17s/it]

  5%|▍         | 144/3107 [18:49<5:44:25,  6.97s/it]

  5%|▍         | 145/3107 [18:56<5:45:51,  7.01s/it]

  5%|▍         | 146/3107 [19:05<6:13:54,  7.58s/it]

  5%|▍         | 147/3107 [19:11<5:56:57,  7.24s/it]

  5%|▍         | 148/3107 [19:21<6:41:10,  8.13s/it]

  5%|▍         | 149/3107 [19:28<6:27:58,  7.87s/it]

  5%|▍         | 150/3107 [19:36<6:28:46,  7.89s/it]

  5%|▍         | 151/3107 [19:43<6:11:52,  7.55s/it]

  5%|▍         | 152/3107 [19:50<5:58:56,  7.29s/it]

  5%|▍         | 153/3107 [19:56<5:38:50,  6.88s/it]

  5%|▍         | 154/3107 [20:03<5:40:01,  6.91s/it]

  5%|▍         | 155/3107 [20:10<5:46:58,  7.05s/it]

  5%|▌         | 156/3107 [20:18<5:56:30,  7.25s/it]

  5%|▌         | 157/3107 [20:24<5:33:04,  6.77s/it]

  5%|▌         | 158/3107 [20:32<5:50:53,  7.14s/it]

  5%|▌         | 159/3107 [20:38<5:36:44,  6.85s/it]

  5%|▌         | 160/3107 [20:45<5:39:37,  6.91s/it]

  5%|▌         | 161/3107 [20:52<5:36:53,  6.86s/it]

  5%|▌         | 162/3107 [20:58<5:38:19,  6.89s/it]

  5%|▌         | 163/3107 [21:06<5:42:03,  6.97s/it]

  5%|▌         | 164/3107 [21:11<5:24:31,  6.62s/it]

  5%|▌         | 165/3107 [21:18<5:22:09,  6.57s/it]

  5%|▌         | 166/3107 [21:27<6:01:35,  7.38s/it]

  5%|▌         | 167/3107 [21:39<7:13:15,  8.84s/it]

  5%|▌         | 168/3107 [21:48<7:16:40,  8.91s/it]

  5%|▌         | 169/3107 [21:56<7:03:05,  8.64s/it]

  5%|▌         | 170/3107 [22:06<7:09:51,  8.78s/it]

  6%|▌         | 171/3107 [22:13<6:47:44,  8.33s/it]

  6%|▌         | 172/3107 [22:19<6:10:39,  7.58s/it]

  6%|▌         | 173/3107 [22:28<6:31:10,  8.00s/it]

  6%|▌         | 174/3107 [22:36<6:42:40,  8.24s/it]

  6%|▌         | 175/3107 [22:45<6:46:38,  8.32s/it]

  6%|▌         | 176/3107 [22:55<7:14:12,  8.89s/it]

  6%|▌         | 177/3107 [23:01<6:28:16,  7.95s/it]

  6%|▌         | 178/3107 [23:07<5:59:57,  7.37s/it]

  6%|▌         | 179/3107 [23:13<5:37:51,  6.92s/it]

  6%|▌         | 180/3107 [23:22<6:04:26,  7.47s/it]

  6%|▌         | 181/3107 [23:29<6:04:41,  7.48s/it]

  6%|▌         | 182/3107 [23:35<5:35:11,  6.88s/it]

  6%|▌         | 183/3107 [23:42<5:37:45,  6.93s/it]

  6%|▌         | 184/3107 [23:49<5:48:34,  7.16s/it]

  6%|▌         | 185/3107 [23:58<6:10:18,  7.60s/it]

  6%|▌         | 186/3107 [24:04<5:47:39,  7.14s/it]

  6%|▌         | 187/3107 [24:10<5:24:18,  6.66s/it]

  6%|▌         | 188/3107 [24:17<5:36:19,  6.91s/it]

  6%|▌         | 189/3107 [24:24<5:33:15,  6.85s/it]

  6%|▌         | 190/3107 [24:30<5:17:01,  6.52s/it]

  6%|▌         | 191/3107 [24:39<6:06:10,  7.53s/it]

  6%|▌         | 192/3107 [24:46<5:46:37,  7.13s/it]

  6%|▌         | 193/3107 [24:52<5:32:30,  6.85s/it]

  6%|▌         | 194/3107 [24:59<5:41:51,  7.04s/it]

  6%|▋         | 195/3107 [25:10<6:33:05,  8.10s/it]

  6%|▋         | 196/3107 [25:18<6:37:06,  8.19s/it]

  6%|▋         | 197/3107 [25:25<6:12:48,  7.69s/it]

  6%|▋         | 198/3107 [25:33<6:27:28,  7.99s/it]

  6%|▋         | 199/3107 [25:41<6:20:36,  7.85s/it]

  6%|▋         | 200/3107 [25:48<6:05:42,  7.55s/it]

  6%|▋         | 201/3107 [25:54<5:52:30,  7.28s/it]

  7%|▋         | 202/3107 [26:00<5:33:56,  6.90s/it]

  7%|▋         | 203/3107 [26:10<6:11:23,  7.67s/it]

  7%|▋         | 204/3107 [26:16<5:49:52,  7.23s/it]

  7%|▋         | 205/3107 [26:25<6:17:17,  7.80s/it]

  7%|▋         | 206/3107 [26:33<6:18:15,  7.82s/it]

  7%|▋         | 207/3107 [26:41<6:24:24,  7.95s/it]

  7%|▋         | 208/3107 [26:48<5:59:18,  7.44s/it]

  7%|▋         | 209/3107 [26:55<6:01:17,  7.48s/it]

  7%|▋         | 210/3107 [27:02<5:57:05,  7.40s/it]

  7%|▋         | 211/3107 [27:10<6:05:02,  7.56s/it]

  7%|▋         | 212/3107 [27:17<5:47:35,  7.20s/it]

  7%|▋         | 213/3107 [27:24<5:40:55,  7.07s/it]

  7%|▋         | 214/3107 [27:31<5:45:58,  7.18s/it]

  7%|▋         | 215/3107 [27:39<6:00:26,  7.48s/it]

  7%|▋         | 216/3107 [27:48<6:19:45,  7.88s/it]

  7%|▋         | 217/3107 [27:54<5:46:52,  7.20s/it]

  7%|▋         | 218/3107 [28:04<6:35:35,  8.22s/it]

  7%|▋         | 219/3107 [28:12<6:36:53,  8.25s/it]

  7%|▋         | 220/3107 [28:19<6:08:14,  7.65s/it]

  7%|▋         | 221/3107 [28:25<5:41:28,  7.10s/it]

  7%|▋         | 222/3107 [28:30<5:17:29,  6.60s/it]

  7%|▋         | 223/3107 [28:36<5:04:20,  6.33s/it]

  7%|▋         | 224/3107 [28:42<5:04:29,  6.34s/it]

  7%|▋         | 225/3107 [28:49<5:10:15,  6.46s/it]

  7%|▋         | 226/3107 [28:57<5:29:15,  6.86s/it]

  7%|▋         | 227/3107 [29:05<5:46:19,  7.22s/it]

  7%|▋         | 228/3107 [29:13<6:00:18,  7.51s/it]

  7%|▋         | 229/3107 [29:22<6:24:31,  8.02s/it]

  7%|▋         | 230/3107 [29:28<5:55:37,  7.42s/it]

  7%|▋         | 231/3107 [29:37<6:22:32,  7.98s/it]

  7%|▋         | 232/3107 [29:45<6:24:33,  8.03s/it]

  7%|▋         | 233/3107 [29:51<5:50:37,  7.32s/it]

  8%|▊         | 234/3107 [29:57<5:33:13,  6.96s/it]

  8%|▊         | 235/3107 [30:05<5:37:59,  7.06s/it]

  8%|▊         | 236/3107 [30:11<5:26:07,  6.82s/it]

  8%|▊         | 237/3107 [30:17<5:10:52,  6.50s/it]

  8%|▊         | 238/3107 [30:26<5:55:09,  7.43s/it]

  8%|▊         | 239/3107 [30:33<5:43:48,  7.19s/it]

  8%|▊         | 240/3107 [30:41<6:02:21,  7.58s/it]

  8%|▊         | 241/3107 [30:50<6:20:35,  7.97s/it]

  8%|▊         | 242/3107 [30:56<5:50:38,  7.34s/it]

  8%|▊         | 243/3107 [31:05<6:19:23,  7.95s/it]

  8%|▊         | 244/3107 [31:16<6:51:27,  8.62s/it]

  8%|▊         | 245/3107 [31:24<6:54:22,  8.69s/it]

  8%|▊         | 246/3107 [31:34<7:03:36,  8.88s/it]

  8%|▊         | 247/3107 [31:42<6:55:44,  8.72s/it]

  8%|▊         | 248/3107 [31:51<6:57:15,  8.76s/it]

  8%|▊         | 249/3107 [31:58<6:35:55,  8.31s/it]

  8%|▊         | 250/3107 [32:07<6:43:43,  8.48s/it]

  8%|▊         | 251/3107 [32:13<6:03:00,  7.63s/it]

  8%|▊         | 252/3107 [32:22<6:29:39,  8.19s/it]

  8%|▊         | 253/3107 [32:29<6:15:56,  7.90s/it]

  8%|▊         | 254/3107 [32:37<6:15:58,  7.91s/it]

  8%|▊         | 255/3107 [32:45<6:09:20,  7.77s/it]

  8%|▊         | 256/3107 [32:56<6:59:38,  8.83s/it]

  8%|▊         | 257/3107 [33:04<6:50:40,  8.65s/it]

  8%|▊         | 258/3107 [33:11<6:19:59,  8.00s/it]

  8%|▊         | 259/3107 [33:21<6:49:39,  8.63s/it]

  8%|▊         | 260/3107 [33:27<6:07:08,  7.74s/it]

  8%|▊         | 261/3107 [33:32<5:35:39,  7.08s/it]

  8%|▊         | 262/3107 [33:38<5:17:14,  6.69s/it]

  8%|▊         | 263/3107 [33:49<6:20:15,  8.02s/it]

  8%|▊         | 264/3107 [33:55<5:52:35,  7.44s/it]

  9%|▊         | 265/3107 [34:02<5:38:04,  7.14s/it]

  9%|▊         | 266/3107 [34:11<6:06:42,  7.74s/it]

  9%|▊         | 267/3107 [34:20<6:23:44,  8.11s/it]

  9%|▊         | 268/3107 [34:27<6:12:32,  7.87s/it]

  9%|▊         | 269/3107 [34:33<5:51:29,  7.43s/it]

  9%|▊         | 270/3107 [34:40<5:45:11,  7.30s/it]

  9%|▊         | 271/3107 [34:47<5:34:26,  7.08s/it]

  9%|▉         | 272/3107 [34:54<5:29:32,  6.97s/it]

  9%|▉         | 273/3107 [35:04<6:14:27,  7.93s/it]

  9%|▉         | 274/3107 [35:18<7:36:46,  9.67s/it]

  9%|▉         | 275/3107 [35:26<7:16:25,  9.25s/it]

  9%|▉         | 276/3107 [35:35<7:21:48,  9.36s/it]

  9%|▉         | 277/3107 [35:43<6:59:22,  8.89s/it]

  9%|▉         | 278/3107 [35:49<6:14:29,  7.94s/it]

  9%|▉         | 279/3107 [35:57<6:16:02,  7.98s/it]

  9%|▉         | 280/3107 [36:04<6:04:58,  7.75s/it]

  9%|▉         | 281/3107 [36:13<6:12:36,  7.91s/it]

  9%|▉         | 282/3107 [36:21<6:23:22,  8.14s/it]

  9%|▉         | 283/3107 [36:28<6:02:49,  7.71s/it]

  9%|▉         | 284/3107 [36:34<5:43:09,  7.29s/it]

  9%|▉         | 285/3107 [36:43<5:59:42,  7.65s/it]

  9%|▉         | 286/3107 [36:48<5:30:50,  7.04s/it]

  9%|▉         | 287/3107 [36:55<5:29:46,  7.02s/it]

  9%|▉         | 288/3107 [37:06<6:21:46,  8.13s/it]

  9%|▉         | 289/3107 [37:13<6:05:04,  7.77s/it]

  9%|▉         | 290/3107 [37:21<6:06:35,  7.81s/it]

  9%|▉         | 291/3107 [37:33<7:05:22,  9.06s/it]

  9%|▉         | 292/3107 [37:46<8:07:32, 10.39s/it]

  9%|▉         | 293/3107 [37:53<7:19:15,  9.37s/it]

  9%|▉         | 294/3107 [37:59<6:30:43,  8.33s/it]

  9%|▉         | 295/3107 [38:07<6:25:34,  8.23s/it]

 10%|▉         | 296/3107 [38:13<5:52:16,  7.52s/it]

 10%|▉         | 297/3107 [38:19<5:33:20,  7.12s/it]

 10%|▉         | 298/3107 [38:28<5:49:15,  7.46s/it]

 10%|▉         | 299/3107 [38:35<5:43:11,  7.33s/it]

 10%|▉         | 300/3107 [38:41<5:27:30,  7.00s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1352, 'grad_norm': 0.15620783043828312, 'learning_rate': 0.00019767979921075866, 'epoch': 0.1}
 10%|▉         | 301/3107 [39:25<14:15:45, 18.30s/it]

 10%|▉         | 302/3107 [39:35<12:09:01, 15.59s/it]

 10%|▉         | 303/3107 [39:42<10:15:26, 13.17s/it]

 10%|▉         | 304/3107 [39:53<9:35:25, 12.32s/it]

 10%|▉         | 305/3107 [40:00<8:24:10, 10.80s/it]

 10%|▉         | 306/3107 [40:06<7:16:46,  9.36s/it]

 10%|▉         | 307/3107 [40:14<7:00:16,  9.01s/it]

 10%|▉         | 308/3107 [40:22<6:40:19,  8.58s/it]

 10%|▉         | 309/3107 [40:29<6:16:32,  8.07s/it]

 10%|▉         | 310/3107 [40:38<6:34:33,  8.46s/it]

 10%|█         | 311/3107 [40:45<6:21:38,  8.19s/it]

 10%|█         | 312/3107 [40:51<5:44:12,  7.39s/it]

 10%|█         | 313/3107 [40:58<5:43:44,  7.38s/it]

 10%|█         | 314/3107 [41:04<5:19:49,  6.87s/it]

 10%|█         | 315/3107 [41:12<5:32:10,  7.14s/it]

 10%|█         | 316/3107 [41:19<5:36:31,  7.23s/it]

 10%|█         | 317/3107 [41:26<5:31:53,  7.14s/it]

 10%|█         | 318/3107 [41:32<5:17:37,  6.83s/it]

 10%|█         | 319/3107 [41:39<5:12:34,  6.73s/it]

 10%|█         | 320/3107 [41:46<5:20:01,  6.89s/it]

 10%|█         | 321/3107 [41:53<5:22:20,  6.94s/it]

 10%|█         | 322/3107 [42:02<5:44:01,  7.41s/it]

 10%|█         | 323/3107 [42:09<5:41:45,  7.37s/it]

 10%|█         | 324/3107 [42:15<5:22:23,  6.95s/it]

 10%|█         | 325/3107 [42:22<5:25:36,  7.02s/it]

 10%|█         | 326/3107 [42:34<6:35:15,  8.53s/it]

 11%|█         | 327/3107 [42:41<6:07:10,  7.92s/it]

 11%|█         | 328/3107 [42:47<5:40:16,  7.35s/it]

 11%|█         | 329/3107 [42:52<5:16:20,  6.83s/it]

 11%|█         | 330/3107 [43:00<5:28:17,  7.09s/it]

 11%|█         | 331/3107 [43:08<5:41:08,  7.37s/it]

 11%|█         | 332/3107 [43:16<5:47:19,  7.51s/it]

 11%|█         | 333/3107 [43:23<5:38:04,  7.31s/it]

 11%|█         | 334/3107 [43:29<5:18:43,  6.90s/it]

 11%|█         | 335/3107 [43:36<5:21:48,  6.97s/it]

 11%|█         | 336/3107 [43:43<5:33:32,  7.22s/it]

 11%|█         | 337/3107 [43:51<5:38:18,  7.33s/it]

 11%|█         | 338/3107 [43:57<5:21:59,  6.98s/it]

 11%|█         | 339/3107 [44:06<5:40:36,  7.38s/it]

 11%|█         | 340/3107 [44:14<5:48:36,  7.56s/it]

 11%|█         | 341/3107 [44:19<5:23:07,  7.01s/it]

 11%|█         | 342/3107 [44:29<5:54:53,  7.70s/it]

 11%|█         | 343/3107 [44:38<6:25:04,  8.36s/it]

 11%|█         | 344/3107 [44:45<5:53:37,  7.68s/it]

 11%|█         | 345/3107 [44:53<6:07:25,  7.98s/it]

 11%|█         | 346/3107 [45:00<5:47:53,  7.56s/it]

 11%|█         | 347/3107 [45:06<5:28:20,  7.14s/it]

 11%|█         | 348/3107 [45:13<5:31:54,  7.22s/it]

 11%|█         | 349/3107 [45:24<6:12:19,  8.10s/it]

 11%|█▏        | 350/3107 [45:32<6:22:14,  8.32s/it]

 11%|█▏        | 351/3107 [45:42<6:39:38,  8.70s/it]


 11%|█▏        | 353/3107 [45:56<5:57:58,  7.80s/it]

 11%|█▏        | 354/3107 [46:03<5:48:29,  7.60s/it]

 11%|█▏        | 355/3107 [46:09<5:27:47,  7.15s/it]

 11%|█▏        | 356/3107 [46:15<5:15:47,  6.89s/it]

 11%|█▏        | 357/3107 [46:25<5:55:36,  7.76s/it]

 12%|█▏        | 358/3107 [46:32<5:39:45,  7.42s/it]

 12%|█▏        | 359/3107 [46:37<5:14:45,  6.87s/it]

 12%|█▏        | 360/3107 [46:43<4:59:58,  6.55s/it]

 12%|█▏        | 361/3107 [46:53<5:46:11,  7.56s/it]

 12%|█▏        | 362/3107 [47:06<6:59:09,  9.16s/it]

 12%|█▏        | 363/3107 [47:16<7:12:41,  9.46s/it]

 12%|█▏        | 364/3107 [47:24<6:48:43,  8.94s/it]

 12%|█▏        | 365/3107 [47:29<6:00:48,  7.90s/it]

 12%|█▏        | 366/3107 [47:39<6:21:39,  8.35s/it]

 12%|█▏        | 367/3107 [47:44<5:43:58,  7.53s/it]

 12%|█▏        | 368/3107 [47:51<5:28:08,  7.19s/it]

 12%|█▏        | 369/3107 [47:57<5:17:54,  6.97s/it]

 12%|█▏        | 370/3107 [48:05<5:26:13,  7.15s/it]

 12%|█▏        | 371/3107 [48:15<6:05:42,  8.02s/it]

 12%|█▏        | 372/3107 [48:24<6:27:44,  8.51s/it]
{'loss': 0.9447, 'grad_norm': 0.168917770170014, 'learning_rate': 0.0001958282516557996, 'epoch': 0.12}

 12%|█▏        | 373/3107 [48:32<6:11:57,  8.16s/it]

 12%|█▏        | 374/3107 [48:40<6:08:57,  8.10s/it]

 12%|█▏        | 375/3107 [48:45<5:36:17,  7.39s/it]

 12%|█▏        | 376/3107 [48:51<5:10:53,  6.83s/it]

 12%|█▏        | 377/3107 [49:01<5:59:48,  7.91s/it]

 12%|█▏        | 378/3107 [49:08<5:48:12,  7.66s/it]

 12%|█▏        | 379/3107 [49:20<6:35:33,  8.70s/it]


 12%|█▏        | 381/3107 [49:33<5:55:41,  7.83s/it]

 12%|█▏        | 382/3107 [49:43<6:14:03,  8.24s/it]

 12%|█▏        | 383/3107 [49:49<5:50:06,  7.71s/it]

 12%|█▏        | 384/3107 [49:58<6:14:15,  8.25s/it]

 12%|█▏        | 385/3107 [50:06<6:07:51,  8.11s/it]

 12%|█▏        | 386/3107 [50:12<5:36:01,  7.41s/it]

 12%|█▏        | 387/3107 [50:20<5:39:58,  7.50s/it]

 12%|█▏        | 388/3107 [50:26<5:16:08,  6.98s/it]

 13%|█▎        | 389/3107 [50:32<5:14:57,  6.95s/it]

 13%|█▎        | 390/3107 [50:38<4:57:23,  6.57s/it]

 13%|█▎        | 391/3107 [50:45<5:07:39,  6.80s/it]

 13%|█▎        | 392/3107 [50:56<5:55:26,  7.85s/it]

 13%|█▎        | 393/3107 [51:03<5:45:51,  7.65s/it]
{'loss': 1.0496, 'grad_norm': 0.16439795612584773, 'learning_rate': 0.000195179485365184, 'epoch': 0.13}


 13%|█▎        | 395/3107 [51:19<5:54:15,  7.84s/it]

 13%|█▎        | 396/3107 [51:25<5:31:03,  7.33s/it]

 13%|█▎        | 397/3107 [51:34<5:47:36,  7.70s/it]

 13%|█▎        | 398/3107 [51:41<5:40:05,  7.53s/it]

 13%|█▎        | 399/3107 [51:49<5:44:54,  7.64s/it]

 13%|█▎        | 400/3107 [51:55<5:18:32,  7.06s/it]

 13%|█▎        | 401/3107 [52:03<5:29:51,  7.31s/it]

 13%|█▎        | 402/3107 [52:10<5:27:00,  7.25s/it]

 13%|█▎        | 403/3107 [52:15<5:00:42,  6.67s/it]

 13%|█▎        | 404/3107 [52:25<5:42:02,  7.59s/it]

 13%|█▎        | 405/3107 [52:31<5:25:36,  7.23s/it]

 13%|█▎        | 406/3107 [52:38<5:16:47,  7.04s/it]

 13%|█▎        | 407/3107 [52:45<5:14:52,  7.00s/it]

 13%|█▎        | 408/3107 [52:53<5:37:57,  7.51s/it]

 13%|█▎        | 409/3107 [53:01<5:34:25,  7.44s/it]

 13%|█▎        | 410/3107 [53:06<5:04:53,  6.78s/it]

 13%|█▎        | 411/3107 [53:13<5:08:33,  6.87s/it]

 13%|█▎        | 412/3107 [53:21<5:21:55,  7.17s/it]

 13%|█▎        | 413/3107 [53:27<5:08:05,  6.86s/it]

 13%|█▎        | 414/3107 [53:33<4:59:38,  6.68s/it]

 13%|█▎        | 415/3107 [53:39<4:49:48,  6.46s/it]

 13%|█▎        | 416/3107 [53:48<5:20:30,  7.15s/it]

 13%|█▎        | 417/3107 [53:55<5:15:06,  7.03s/it]

 13%|█▎        | 418/3107 [54:02<5:18:41,  7.11s/it]

 13%|█▎        | 419/3107 [54:10<5:26:09,  7.28s/it]

 14%|█▎        | 420/3107 [54:19<5:54:49,  7.92s/it]

 14%|█▎        | 421/3107 [54:26<5:40:34,  7.61s/it]

 14%|█▎        | 422/3107 [54:32<5:20:25,  7.16s/it]

 14%|█▎        | 423/3107 [54:40<5:28:26,  7.34s/it]

 14%|█▎        | 424/3107 [54:45<5:03:14,  6.78s/it]

 14%|█▎        | 425/3107 [54:54<5:29:08,  7.36s/it]

 14%|█▎        | 426/3107 [55:01<5:30:27,  7.40s/it]

 14%|█▎        | 427/3107 [55:08<5:19:23,  7.15s/it]

 14%|█▍        | 428/3107 [55:18<6:00:23,  8.07s/it]

 14%|█▍        | 429/3107 [55:28<6:19:27,  8.50s/it]

 14%|█▍        | 430/3107 [55:35<6:05:35,  8.19s/it]

 14%|█▍        | 431/3107 [55:44<6:17:05,  8.46s/it]

 14%|█▍        | 432/3107 [55:50<5:41:31,  7.66s/it]

 14%|█▍        | 433/3107 [55:58<5:42:05,  7.68s/it]

 14%|█▍        | 434/3107 [56:06<5:46:29,  7.78s/it]

 14%|█▍        | 435/3107 [56:14<5:53:44,  7.94s/it]

 14%|█▍        | 436/3107 [56:20<5:31:18,  7.44s/it]

 14%|█▍        | 437/3107 [56:31<6:11:49,  8.36s/it]

 14%|█▍        | 438/3107 [56:38<5:55:17,  7.99s/it]

 14%|█▍        | 439/3107 [56:47<6:10:00,  8.32s/it]

 14%|█▍        | 440/3107 [56:53<5:40:02,  7.65s/it]

 14%|█▍        | 441/3107 [56:59<5:13:36,  7.06s/it]

 14%|█▍        | 442/3107 [57:06<5:09:28,  6.97s/it]

 14%|█▍        | 443/3107 [57:13<5:19:08,  7.19s/it]

 14%|█▍        | 444/3107 [57:21<5:23:45,  7.29s/it]

 14%|█▍        | 445/3107 [57:27<5:09:35,  6.98s/it]

 14%|█▍        | 446/3107 [57:34<5:08:57,  6.97s/it]

 14%|█▍        | 447/3107 [57:42<5:16:17,  7.13s/it]

 14%|█▍        | 448/3107 [57:48<5:06:59,  6.93s/it]

 14%|█▍        | 449/3107 [58:00<6:08:47,  8.32s/it]

 14%|█▍        | 450/3107 [58:08<6:03:49,  8.22s/it]

 15%|█▍        | 451/3107 [58:14<5:39:30,  7.67s/it]

 15%|█▍        | 452/3107 [58:20<5:14:49,  7.11s/it]

 15%|█▍        | 453/3107 [58:29<5:38:43,  7.66s/it]

 15%|█▍        | 454/3107 [58:39<6:07:49,  8.32s/it]

 15%|█▍        | 455/3107 [58:45<5:41:37,  7.73s/it]

 15%|█▍        | 456/3107 [58:51<5:19:17,  7.23s/it]

 15%|█▍        | 457/3107 [58:59<5:22:58,  7.31s/it]

 15%|█▍        | 458/3107 [59:04<5:04:44,  6.90s/it]

 15%|█▍        | 459/3107 [59:11<4:53:01,  6.64s/it]

 15%|█▍        | 460/3107 [59:17<4:46:13,  6.49s/it]

 15%|█▍        | 461/3107 [59:23<4:38:12,  6.31s/it]

 15%|█▍        | 462/3107 [59:29<4:34:58,  6.24s/it]

 15%|█▍        | 463/3107 [59:35<4:32:08,  6.18s/it]

 15%|█▍        | 464/3107 [59:44<5:18:33,  7.23s/it]

 15%|█▍        | 465/3107 [59:51<5:10:09,  7.04s/it]

 15%|█▍        | 466/3107 [59:57<4:53:08,  6.66s/it]

 15%|█▌        | 467/3107 [1:00:08<5:53:12,  8.03s/it]

 15%|█▌        | 468/3107 [1:00:17<6:07:14,  8.35s/it]

 15%|█▌        | 469/3107 [1:00:24<5:47:13,  7.90s/it]

 15%|█▌        | 470/3107 [1:00:31<5:41:11,  7.76s/it]

 15%|█▌        | 471/3107 [1:00:39<5:46:14,  7.88s/it]

 15%|█▌        | 472/3107 [1:00:48<5:53:36,  8.05s/it]

 15%|█▌        | 473/3107 [1:00:56<5:53:52,  8.06s/it]

 15%|█▌        | 474/3107 [1:01:03<5:38:52,  7.72s/it]

 15%|█▌        | 475/3107 [1:01:12<5:57:36,  8.15s/it]

 15%|█▌        | 476/3107 [1:01:20<5:54:19,  8.08s/it]

 15%|█▌        | 477/3107 [1:01:26<5:28:46,  7.50s/it]

 15%|█▌        | 478/3107 [1:01:33<5:19:14,  7.29s/it]

 15%|█▌        | 479/3107 [1:01:45<6:27:19,  8.84s/it]

 15%|█▌        | 480/3107 [1:01:53<6:08:31,  8.42s/it]

 15%|█▌        | 481/3107 [1:01:59<5:38:05,  7.73s/it]

 16%|█▌        | 482/3107 [1:02:05<5:20:33,  7.33s/it]

 16%|█▌        | 483/3107 [1:02:11<5:04:34,  6.96s/it]

 16%|█▌        | 484/3107 [1:02:18<4:58:41,  6.83s/it]

 16%|█▌        | 485/3107 [1:02:29<5:50:56,  8.03s/it]

 16%|█▌        | 486/3107 [1:02:36<5:41:56,  7.83s/it]

 16%|█▌        | 487/3107 [1:02:47<6:23:13,  8.78s/it]

 16%|█▌        | 488/3107 [1:02:54<5:56:53,  8.18s/it]

 16%|█▌        | 489/3107 [1:03:02<5:54:16,  8.12s/it]

 16%|█▌        | 490/3107 [1:03:09<5:37:29,  7.74s/it]

 16%|█▌        | 491/3107 [1:03:17<5:45:12,  7.92s/it]

 16%|█▌        | 492/3107 [1:03:24<5:30:00,  7.57s/it]

 16%|█▌        | 493/3107 [1:03:31<5:17:27,  7.29s/it]

 16%|█▌        | 494/3107 [1:03:39<5:33:24,  7.66s/it]

 16%|█▌        | 495/3107 [1:03:51<6:33:09,  9.03s/it]

 16%|█▌        | 496/3107 [1:04:02<6:52:40,  9.48s/it]

 16%|█▌        | 497/3107 [1:04:09<6:20:32,  8.75s/it]

 16%|█▌        | 498/3107 [1:04:16<5:54:56,  8.16s/it]

 16%|█▌        | 499/3107 [1:04:22<5:25:51,  7.50s/it]

 16%|█▌        | 500/3107 [1:04:29<5:29:53,  7.59s/it]

 16%|█▌        | 501/3107 [1:04:35<5:08:10,  7.10s/it]

 16%|█▌        | 502/3107 [1:04:42<5:08:00,  7.09s/it]

 16%|█▌        | 503/3107 [1:04:49<5:05:40,  7.04s/it]

 16%|█▌        | 504/3107 [1:04:56<4:54:14,  6.78s/it]

 16%|█▋        | 505/3107 [1:05:01<4:43:09,  6.53s/it]

 16%|█▋        | 506/3107 [1:05:08<4:48:29,  6.65s/it]

 16%|█▋        | 507/3107 [1:05:16<5:03:19,  7.00s/it]

 16%|█▋        | 508/3107 [1:05:23<5:05:39,  7.06s/it]

 16%|█▋        | 509/3107 [1:05:35<6:02:45,  8.38s/it]

 16%|█▋        | 510/3107 [1:05:42<5:51:38,  8.12s/it]

 16%|█▋        | 511/3107 [1:05:50<5:39:42,  7.85s/it]

 16%|█▋        | 512/3107 [1:05:55<5:11:42,  7.21s/it]

 17%|█▋        | 513/3107 [1:06:02<5:08:48,  7.14s/it]

 17%|█▋        | 514/3107 [1:06:09<5:06:53,  7.10s/it]

 17%|█▋        | 515/3107 [1:06:19<5:46:24,  8.02s/it]

 17%|█▋        | 516/3107 [1:06:30<6:25:00,  8.92s/it]

 17%|█▋        | 517/3107 [1:06:43<7:07:11,  9.90s/it]

 17%|█▋        | 518/3107 [1:06:51<6:42:46,  9.33s/it]

 17%|█▋        | 519/3107 [1:06:58<6:14:23,  8.68s/it]

 17%|█▋        | 520/3107 [1:07:09<6:44:30,  9.38s/it]

 17%|█▋        | 521/3107 [1:07:20<7:00:58,  9.77s/it]

 17%|█▋        | 522/3107 [1:07:27<6:34:21,  9.15s/it]

 17%|█▋        | 523/3107 [1:07:34<6:05:59,  8.50s/it]

 17%|█▋        | 524/3107 [1:07:43<6:11:37,  8.63s/it]

 17%|█▋        | 525/3107 [1:07:49<5:38:09,  7.86s/it]

 17%|█▋        | 526/3107 [1:07:56<5:29:14,  7.65s/it]

 17%|█▋        | 527/3107 [1:08:04<5:25:05,  7.56s/it]

 17%|█▋        | 528/3107 [1:08:12<5:35:42,  7.81s/it]

 17%|█▋        | 529/3107 [1:08:21<5:48:24,  8.11s/it]

 17%|█▋        | 530/3107 [1:08:31<6:15:13,  8.74s/it]

 17%|█▋        | 531/3107 [1:08:40<6:15:15,  8.74s/it]

 17%|█▋        | 532/3107 [1:08:50<6:34:52,  9.20s/it]

 17%|█▋        | 533/3107 [1:08:57<5:59:49,  8.39s/it]

 17%|█▋        | 534/3107 [1:09:04<5:44:00,  8.02s/it]

 17%|█▋        | 535/3107 [1:09:11<5:32:39,  7.76s/it]

 17%|█▋        | 536/3107 [1:09:19<5:33:42,  7.79s/it]

 17%|█▋        | 537/3107 [1:09:25<5:11:02,  7.26s/it]

 17%|█▋        | 538/3107 [1:09:32<5:14:29,  7.35s/it]

 17%|█▋        | 539/3107 [1:09:39<5:08:37,  7.21s/it]

 17%|█▋        | 540/3107 [1:09:51<6:00:09,  8.42s/it]

 17%|█▋        | 541/3107 [1:09:58<5:42:06,  8.00s/it]

 17%|█▋        | 542/3107 [1:10:08<6:19:22,  8.87s/it]

 17%|█▋        | 543/3107 [1:10:15<5:44:12,  8.05s/it]

 18%|█▊        | 544/3107 [1:10:21<5:21:25,  7.52s/it]

 18%|█▊        | 545/3107 [1:10:28<5:20:01,  7.49s/it]

 18%|█▊        | 546/3107 [1:10:40<6:15:55,  8.81s/it]

 18%|█▊        | 547/3107 [1:10:50<6:35:11,  9.26s/it]

 18%|█▊        | 548/3107 [1:10:56<5:50:47,  8.22s/it]

 18%|█▊        | 549/3107 [1:11:03<5:25:09,  7.63s/it]

 18%|█▊        | 550/3107 [1:11:09<5:08:56,  7.25s/it]

 18%|█▊        | 551/3107 [1:11:18<5:37:17,  7.92s/it]

 18%|█▊        | 552/3107 [1:11:27<5:45:48,  8.12s/it]

 18%|█▊        | 553/3107 [1:11:41<6:59:39,  9.86s/it]

 18%|█▊        | 554/3107 [1:11:48<6:23:26,  9.01s/it]

 18%|█▊        | 555/3107 [1:11:54<5:51:50,  8.27s/it]

 18%|█▊        | 556/3107 [1:12:02<5:39:32,  7.99s/it]

 18%|█▊        | 557/3107 [1:12:10<5:43:33,  8.08s/it]

 18%|█▊        | 558/3107 [1:12:18<5:43:46,  8.09s/it]

 18%|█▊        | 559/3107 [1:12:24<5:15:10,  7.42s/it]

 18%|█▊        | 560/3107 [1:12:32<5:26:01,  7.68s/it]

 18%|█▊        | 561/3107 [1:12:40<5:22:43,  7.61s/it]

 18%|█▊        | 562/3107 [1:12:46<5:00:50,  7.09s/it]

 18%|█▊        | 563/3107 [1:12:54<5:17:00,  7.48s/it]

 18%|█▊        | 564/3107 [1:13:04<5:51:35,  8.30s/it]

 18%|█▊        | 565/3107 [1:13:11<5:33:11,  7.86s/it]

 18%|█▊        | 566/3107 [1:13:17<5:12:25,  7.38s/it]

 18%|█▊        | 567/3107 [1:13:27<5:37:40,  7.98s/it]

 18%|█▊        | 568/3107 [1:13:36<5:51:23,  8.30s/it]

 18%|█▊        | 569/3107 [1:13:41<5:17:40,  7.51s/it]

 18%|█▊        | 570/3107 [1:13:48<5:10:49,  7.35s/it]

 18%|█▊        | 571/3107 [1:13:56<5:12:02,  7.38s/it]

 18%|█▊        | 572/3107 [1:14:02<4:51:19,  6.90s/it]

 18%|█▊        | 573/3107 [1:14:08<4:41:29,  6.67s/it]

 18%|█▊        | 574/3107 [1:14:16<5:00:07,  7.11s/it]

 19%|█▊        | 575/3107 [1:14:24<5:08:05,  7.30s/it]

 19%|█▊        | 576/3107 [1:14:31<5:04:52,  7.23s/it]

 19%|█▊        | 577/3107 [1:14:37<4:47:58,  6.83s/it]

 19%|█▊        | 578/3107 [1:14:45<5:11:26,  7.39s/it]

 19%|█▊        | 579/3107 [1:14:52<5:03:47,  7.21s/it]

 19%|█▊        | 580/3107 [1:14:59<5:05:43,  7.26s/it]

 19%|█▊        | 581/3107 [1:15:06<5:00:13,  7.13s/it]

 19%|█▊        | 582/3107 [1:15:15<5:21:48,  7.65s/it]

 19%|█▉        | 583/3107 [1:15:21<5:00:00,  7.13s/it]

 19%|█▉        | 584/3107 [1:15:30<5:18:05,  7.56s/it]

 19%|█▉        | 585/3107 [1:15:35<4:55:26,  7.03s/it]

 19%|█▉        | 586/3107 [1:15:43<4:55:59,  7.04s/it]

 19%|█▉        | 587/3107 [1:15:51<5:15:08,  7.50s/it]

 19%|█▉        | 588/3107 [1:15:59<5:15:57,  7.53s/it]

 19%|█▉        | 589/3107 [1:16:06<5:15:26,  7.52s/it]

 19%|█▉        | 590/3107 [1:16:13<5:02:48,  7.22s/it]

 19%|█▉        | 591/3107 [1:16:20<5:07:51,  7.34s/it]

 19%|█▉        | 592/3107 [1:16:27<5:03:46,  7.25s/it]

 19%|█▉        | 593/3107 [1:16:36<5:17:48,  7.59s/it]

 19%|█▉        | 594/3107 [1:16:45<5:44:14,  8.22s/it]

 19%|█▉        | 595/3107 [1:16:51<5:16:47,  7.57s/it]

 19%|█▉        | 596/3107 [1:16:57<4:51:18,  6.96s/it]

 19%|█▉        | 597/3107 [1:17:03<4:40:12,  6.70s/it]

 19%|█▉        | 598/3107 [1:17:09<4:35:30,  6.59s/it]

 19%|█▉        | 599/3107 [1:17:16<4:30:23,  6.47s/it]

 19%|█▉        | 600/3107 [1:17:23<4:39:59,  6.70s/it]
 19%|█▉        | 600/3107 [1:17:23<4:39:59,  6.70s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 19%|█▉        | 601/3107 [1:18:13<13:39:55, 19.63s/it]

 19%|█▉        | 602/3107 [1:18:19<10:50:47, 15.59s/it]

 19%|█▉        | 603/3107 [1:18:26<9:10:54, 13.20s/it]

 19%|█▉        | 604/3107 [1:18:37<8:42:21, 12.52s/it]

 19%|█▉        | 605/3107 [1:18:45<7:36:16, 10.94s/it]

 20%|█▉        | 606/3107 [1:18:51<6:34:46,  9.47s/it]

 20%|█▉        | 607/3107 [1:18:59<6:21:56,  9.17s/it]

 20%|█▉        | 608/3107 [1:19:09<6:30:52,  9.38s/it]

 20%|█▉        | 609/3107 [1:19:16<5:58:11,  8.60s/it]

 20%|█▉        | 610/3107 [1:19:24<5:50:20,  8.42s/it]

 20%|█▉        | 611/3107 [1:19:33<5:59:24,  8.64s/it]

 20%|█▉        | 612/3107 [1:19:40<5:43:20,  8.26s/it]

 20%|█▉        | 613/3107 [1:19:46<5:14:48,  7.57s/it]

 20%|█▉        | 614/3107 [1:19:55<5:34:11,  8.04s/it]

 20%|█▉        | 615/3107 [1:20:01<5:07:20,  7.40s/it]

 20%|█▉        | 616/3107 [1:20:08<5:01:11,  7.25s/it]

 20%|█▉        | 617/3107 [1:20:16<5:03:14,  7.31s/it]

 20%|█▉        | 618/3107 [1:20:23<5:05:30,  7.36s/it]

 20%|█▉        | 619/3107 [1:20:30<4:55:13,  7.12s/it]

 20%|█▉        | 620/3107 [1:20:35<4:37:15,  6.69s/it]

 20%|█▉        | 621/3107 [1:20:42<4:40:43,  6.78s/it]

 20%|██        | 622/3107 [1:20:51<5:02:15,  7.30s/it]

 20%|██        | 623/3107 [1:20:58<5:03:21,  7.33s/it]

 20%|██        | 624/3107 [1:21:07<5:19:45,  7.73s/it]

 20%|██        | 625/3107 [1:21:14<5:13:18,  7.57s/it]

 20%|██        | 626/3107 [1:21:21<5:07:22,  7.43s/it]

 20%|██        | 627/3107 [1:21:30<5:21:29,  7.78s/it]

 20%|██        | 628/3107 [1:21:42<6:16:05,  9.10s/it]

 20%|██        | 629/3107 [1:21:52<6:26:22,  9.36s/it]

 20%|██        | 630/3107 [1:22:00<6:15:17,  9.09s/it]

 20%|██        | 631/3107 [1:22:08<5:58:02,  8.68s/it]

 20%|██        | 632/3107 [1:22:14<5:26:46,  7.92s/it]

 20%|██        | 633/3107 [1:22:22<5:28:20,  7.96s/it]

 20%|██        | 634/3107 [1:22:31<5:29:51,  8.00s/it]

 20%|██        | 635/3107 [1:22:38<5:29:13,  7.99s/it]

 20%|██        | 636/3107 [1:22:45<5:06:10,  7.43s/it]

 21%|██        | 637/3107 [1:22:52<5:08:35,  7.50s/it]

 21%|██        | 638/3107 [1:22:59<4:59:00,  7.27s/it]

 21%|██        | 639/3107 [1:23:05<4:39:14,  6.79s/it]

 21%|██        | 640/3107 [1:23:13<4:57:56,  7.25s/it]

 21%|██        | 641/3107 [1:23:19<4:47:34,  7.00s/it]

 21%|██        | 642/3107 [1:23:25<4:35:25,  6.70s/it]

 21%|██        | 643/3107 [1:23:32<4:34:48,  6.69s/it]

 21%|██        | 644/3107 [1:23:37<4:19:06,  6.31s/it]

 21%|██        | 645/3107 [1:23:43<4:11:33,  6.13s/it]

 21%|██        | 646/3107 [1:23:50<4:18:19,  6.30s/it]

 21%|██        | 647/3107 [1:23:56<4:20:47,  6.36s/it]

 21%|██        | 648/3107 [1:24:04<4:33:05,  6.66s/it]

 21%|██        | 649/3107 [1:24:12<4:52:31,  7.14s/it]

 21%|██        | 650/3107 [1:24:26<6:11:40,  9.08s/it]

 21%|██        | 651/3107 [1:24:37<6:42:19,  9.83s/it]

 21%|██        | 652/3107 [1:24:44<6:01:55,  8.85s/it]

 21%|██        | 653/3107 [1:24:50<5:24:21,  7.93s/it]

 21%|██        | 654/3107 [1:25:00<5:55:39,  8.70s/it]

 21%|██        | 655/3107 [1:25:07<5:36:12,  8.23s/it]

 21%|██        | 656/3107 [1:25:16<5:39:49,  8.32s/it]

 21%|██        | 657/3107 [1:25:26<5:59:42,  8.81s/it]

 21%|██        | 658/3107 [1:25:32<5:34:11,  8.19s/it]

 21%|██        | 659/3107 [1:25:41<5:36:26,  8.25s/it]

 21%|██        | 660/3107 [1:25:48<5:29:27,  8.08s/it]

 21%|██▏       | 661/3107 [1:25:54<4:57:35,  7.30s/it]

 21%|██▏       | 662/3107 [1:26:05<5:45:11,  8.47s/it]

 21%|██▏       | 663/3107 [1:26:12<5:20:22,  7.87s/it]

 21%|██▏       | 664/3107 [1:26:20<5:32:05,  8.16s/it]

 21%|██▏       | 665/3107 [1:26:29<5:34:14,  8.21s/it]

 21%|██▏       | 666/3107 [1:26:37<5:32:42,  8.18s/it]

 21%|██▏       | 667/3107 [1:26:43<5:06:48,  7.54s/it]

 21%|██▏       | 668/3107 [1:26:50<4:55:30,  7.27s/it]

 22%|██▏       | 669/3107 [1:27:00<5:38:43,  8.34s/it]

 22%|██▏       | 670/3107 [1:27:07<5:23:30,  7.96s/it]

 22%|██▏       | 671/3107 [1:27:18<5:48:48,  8.59s/it]

 22%|██▏       | 672/3107 [1:27:26<5:42:08,  8.43s/it]

 22%|██▏       | 673/3107 [1:27:34<5:44:01,  8.48s/it]

 22%|██▏       | 674/3107 [1:27:44<5:54:43,  8.75s/it]

 22%|██▏       | 675/3107 [1:27:49<5:14:04,  7.75s/it]

 22%|██▏       | 676/3107 [1:27:59<5:37:38,  8.33s/it]

 22%|██▏       | 677/3107 [1:28:05<5:12:46,  7.72s/it]

 22%|██▏       | 678/3107 [1:28:11<4:46:04,  7.07s/it]

 22%|██▏       | 679/3107 [1:28:18<4:54:57,  7.29s/it]

 22%|██▏       | 680/3107 [1:28:27<5:11:40,  7.71s/it]

 22%|██▏       | 681/3107 [1:28:35<5:10:59,  7.69s/it]

 22%|██▏       | 682/3107 [1:28:41<4:51:45,  7.22s/it]

 22%|██▏       | 683/3107 [1:28:47<4:42:12,  6.99s/it]

 22%|██▏       | 684/3107 [1:28:54<4:41:07,  6.96s/it]

 22%|██▏       | 685/3107 [1:29:01<4:44:08,  7.04s/it]

 22%|██▏       | 686/3107 [1:29:08<4:36:35,  6.85s/it]

 22%|██▏       | 687/3107 [1:29:15<4:37:19,  6.88s/it]

 22%|██▏       | 688/3107 [1:29:22<4:45:47,  7.09s/it]

 22%|██▏       | 689/3107 [1:29:31<5:09:32,  7.68s/it]

 22%|██▏       | 690/3107 [1:29:42<5:43:47,  8.53s/it]

 22%|██▏       | 691/3107 [1:29:53<6:10:40,  9.21s/it]

 22%|██▏       | 692/3107 [1:30:00<5:48:56,  8.67s/it]

 22%|██▏       | 693/3107 [1:30:06<5:10:04,  7.71s/it]

 22%|██▏       | 694/3107 [1:30:12<5:00:58,  7.48s/it]

 22%|██▏       | 695/3107 [1:30:18<4:38:19,  6.92s/it]

 22%|██▏       | 696/3107 [1:30:24<4:28:06,  6.67s/it]

 22%|██▏       | 697/3107 [1:30:32<4:41:39,  7.01s/it]

 22%|██▏       | 698/3107 [1:30:38<4:27:38,  6.67s/it]

 22%|██▏       | 699/3107 [1:30:43<4:14:14,  6.33s/it]

 23%|██▎       | 700/3107 [1:30:49<4:03:13,  6.06s/it]

 23%|██▎       | 701/3107 [1:30:55<4:01:37,  6.03s/it]

 23%|██▎       | 702/3107 [1:31:03<4:31:32,  6.77s/it]

 23%|██▎       | 703/3107 [1:31:09<4:19:39,  6.48s/it]

 23%|██▎       | 704/3107 [1:31:21<5:21:13,  8.02s/it]

 23%|██▎       | 705/3107 [1:31:30<5:39:02,  8.47s/it]

 23%|██▎       | 706/3107 [1:31:38<5:25:51,  8.14s/it]

 23%|██▎       | 707/3107 [1:31:44<5:07:10,  7.68s/it]

 23%|██▎       | 708/3107 [1:31:52<5:04:41,  7.62s/it]

 23%|██▎       | 709/3107 [1:32:01<5:21:33,  8.05s/it]

 23%|██▎       | 710/3107 [1:32:10<5:33:50,  8.36s/it]

 23%|██▎       | 711/3107 [1:32:17<5:22:18,  8.07s/it]

 23%|██▎       | 712/3107 [1:32:26<5:29:09,  8.25s/it]

 23%|██▎       | 713/3107 [1:32:33<5:10:00,  7.77s/it]

 23%|██▎       | 714/3107 [1:32:41<5:12:54,  7.85s/it]

 23%|██▎       | 715/3107 [1:32:47<4:59:46,  7.52s/it]

 23%|██▎       | 716/3107 [1:32:53<4:43:09,  7.11s/it]

 23%|██▎       | 717/3107 [1:33:03<5:16:58,  7.96s/it]

 23%|██▎       | 718/3107 [1:33:12<5:20:38,  8.05s/it]

 23%|██▎       | 719/3107 [1:33:20<5:24:50,  8.16s/it]

 23%|██▎       | 720/3107 [1:33:31<6:03:08,  9.13s/it]

 23%|██▎       | 721/3107 [1:33:42<6:15:41,  9.45s/it]

 23%|██▎       | 722/3107 [1:33:52<6:29:51,  9.81s/it]

 23%|██▎       | 723/3107 [1:33:59<5:57:12,  8.99s/it]

 23%|██▎       | 724/3107 [1:34:06<5:31:02,  8.33s/it]
{'loss': 0.8867, 'grad_norm': 0.1515946745094749, 'learning_rate': 0.000179189645761499, 'epoch': 0.23}


 23%|██▎       | 726/3107 [1:34:22<5:24:36,  8.18s/it]

 23%|██▎       | 727/3107 [1:34:34<6:16:35,  9.49s/it]

 23%|██▎       | 728/3107 [1:34:41<5:35:56,  8.47s/it]

 23%|██▎       | 729/3107 [1:34:49<5:31:23,  8.36s/it]

 23%|██▎       | 730/3107 [1:34:57<5:35:48,  8.48s/it]

 24%|██▎       | 731/3107 [1:35:07<5:54:56,  8.96s/it]

 24%|██▎       | 732/3107 [1:35:14<5:32:05,  8.39s/it]

 24%|██▎       | 733/3107 [1:35:20<5:00:47,  7.60s/it]

 24%|██▎       | 734/3107 [1:35:26<4:43:15,  7.16s/it]

 24%|██▎       | 735/3107 [1:35:34<4:53:22,  7.42s/it]

 24%|██▎       | 736/3107 [1:35:43<5:12:44,  7.91s/it]

 24%|██▎       | 737/3107 [1:35:52<5:17:35,  8.04s/it]

 24%|██▍       | 738/3107 [1:36:00<5:23:19,  8.19s/it]
{'loss': 0.9773, 'grad_norm': 0.15243164910748452, 'learning_rate': 0.00017828983561456941, 'epoch': 0.24}

 24%|██▍       | 739/3107 [1:36:09<5:28:46,  8.33s/it]


 24%|██▍       | 741/3107 [1:36:22<4:51:57,  7.40s/it]

 24%|██▍       | 742/3107 [1:36:32<5:28:04,  8.32s/it]

 24%|██▍       | 743/3107 [1:36:39<5:01:42,  7.66s/it]
{'loss': 1.0166, 'grad_norm': 0.18593995807310842, 'learning_rate': 0.00017796442188376137, 'epoch': 0.24}


 24%|██▍       | 745/3107 [1:36:54<5:07:21,  7.81s/it]

 24%|██▍       | 746/3107 [1:37:00<4:51:02,  7.40s/it]

 24%|██▍       | 747/3107 [1:37:06<4:29:11,  6.84s/it]

 24%|██▍       | 748/3107 [1:37:12<4:23:05,  6.69s/it]

 24%|██▍       | 749/3107 [1:37:20<4:33:05,  6.95s/it]

 24%|██▍       | 750/3107 [1:37:28<4:43:31,  7.22s/it]

 24%|██▍       | 751/3107 [1:37:34<4:31:17,  6.91s/it]

 24%|██▍       | 752/3107 [1:37:40<4:24:56,  6.75s/it]

 24%|██▍       | 753/3107 [1:37:48<4:34:33,  7.00s/it]

 24%|██▍       | 754/3107 [1:37:58<5:10:25,  7.92s/it]
{'loss': 0.9142, 'grad_norm': 0.1691831157117377, 'learning_rate': 0.00017724106523098486, 'epoch': 0.24}


 24%|██▍       | 756/3107 [1:38:10<4:36:17,  7.05s/it]

 24%|██▍       | 757/3107 [1:38:16<4:24:40,  6.76s/it]

 24%|██▍       | 758/3107 [1:38:27<5:10:25,  7.93s/it]

 24%|██▍       | 759/3107 [1:38:34<4:58:17,  7.62s/it]
{'loss': 0.9127, 'grad_norm': 0.16148007058639038, 'learning_rate': 0.00017690890202261676, 'epoch': 0.24}

 24%|██▍       | 760/3107 [1:38:41<4:55:46,  7.56s/it]

 24%|██▍       | 761/3107 [1:38:51<5:26:01,  8.34s/it]


 25%|██▍       | 763/3107 [1:39:09<5:33:15,  8.53s/it]

 25%|██▍       | 764/3107 [1:39:16<5:15:59,  8.09s/it]

 25%|██▍       | 765/3107 [1:39:22<4:52:27,  7.49s/it]

 25%|██▍       | 766/3107 [1:39:29<4:48:12,  7.39s/it]

 25%|██▍       | 767/3107 [1:39:36<4:42:43,  7.25s/it]

 25%|██▍       | 768/3107 [1:39:45<5:01:46,  7.74s/it]
{'loss': 0.9135, 'grad_norm': 0.16528255578008438, 'learning_rate': 0.00017630574669158318, 'epoch': 0.25}


 25%|██▍       | 770/3107 [1:40:04<5:33:57,  8.57s/it]

 25%|██▍       | 771/3107 [1:40:14<5:46:31,  8.90s/it]

 25%|██▍       | 772/3107 [1:40:20<5:17:14,  8.15s/it]

 25%|██▍       | 773/3107 [1:40:27<4:57:10,  7.64s/it]
{'loss': 0.8655, 'grad_norm': 0.16415277370843218, 'learning_rate': 0.00017596775346047147, 'epoch': 0.25}


 25%|██▍       | 775/3107 [1:40:41<4:44:09,  7.31s/it]

 25%|██▍       | 776/3107 [1:40:47<4:28:59,  6.92s/it]

 25%|██▌       | 777/3107 [1:40:56<4:51:34,  7.51s/it]

 25%|██▌       | 778/3107 [1:41:02<4:37:25,  7.15s/it]
{'loss': 0.9458, 'grad_norm': 0.16932812031100905, 'learning_rate': 0.00017562769546834988, 'epoch': 0.25}


 25%|██▌       | 780/3107 [1:41:15<4:18:57,  6.68s/it]

 25%|██▌       | 781/3107 [1:41:20<4:05:39,  6.34s/it]

 25%|██▌       | 782/3107 [1:41:27<4:12:44,  6.52s/it]

 25%|██▌       | 783/3107 [1:41:37<4:46:16,  7.39s/it]

 25%|██▌       | 784/3107 [1:41:42<4:26:00,  6.87s/it]

 25%|██▌       | 785/3107 [1:41:51<4:44:06,  7.34s/it]

 25%|██▌       | 786/3107 [1:41:57<4:30:34,  6.99s/it]

 25%|██▌       | 787/3107 [1:42:06<4:59:53,  7.76s/it]

 25%|██▌       | 788/3107 [1:42:15<5:05:24,  7.90s/it]

 25%|██▌       | 789/3107 [1:42:25<5:36:38,  8.71s/it]

 25%|██▌       | 790/3107 [1:42:35<5:45:21,  8.94s/it]

 25%|██▌       | 791/3107 [1:42:41<5:08:11,  7.98s/it]

 25%|██▌       | 792/3107 [1:42:50<5:26:15,  8.46s/it]
{'loss': 0.9604, 'grad_norm': 0.16909768877877612, 'learning_rate': 0.0001746646274485689, 'epoch': 0.25}


 26%|██▌       | 794/3107 [1:43:06<5:15:51,  8.19s/it]

 26%|██▌       | 795/3107 [1:43:13<4:53:21,  7.61s/it]

 26%|██▌       | 796/3107 [1:43:21<4:56:57,  7.71s/it]

 26%|██▌       | 797/3107 [1:43:27<4:39:47,  7.27s/it]

 26%|██▌       | 798/3107 [1:43:37<5:07:04,  7.98s/it]
{'loss': 0.8597, 'grad_norm': 0.15276390747795343, 'learning_rate': 0.00017424700157798138, 'epoch': 0.26}


 26%|██▌       | 800/3107 [1:43:50<4:45:34,  7.43s/it]

 26%|██▌       | 801/3107 [1:43:57<4:34:47,  7.15s/it]
{'loss': 1.0247, 'grad_norm': 0.1768131009510938, 'learning_rate': 0.00017403709790210305, 'epoch': 0.26}


 26%|██▌       | 803/3107 [1:44:11<4:32:28,  7.10s/it]

 26%|██▌       | 804/3107 [1:44:18<4:35:02,  7.17s/it]

 26%|██▌       | 805/3107 [1:44:28<5:05:55,  7.97s/it]

 26%|██▌       | 806/3107 [1:44:35<4:57:22,  7.75s/it]

 26%|██▌       | 807/3107 [1:44:41<4:38:08,  7.26s/it]
{'loss': 0.9663, 'grad_norm': 0.1621316755020728, 'learning_rate': 0.00017361511933828801, 'epoch': 0.26}


 26%|██▌       | 809/3107 [1:44:57<4:50:42,  7.59s/it]
{'loss': 0.9046, 'grad_norm': 0.1593281858391637, 'learning_rate': 0.00017347381873714316, 'epoch': 0.26}


 26%|██▌       | 811/3107 [1:45:11<4:41:49,  7.36s/it]

 26%|██▌       | 812/3107 [1:45:20<5:05:13,  7.98s/it]

 26%|██▌       | 813/3107 [1:45:30<5:18:05,  8.32s/it]

 26%|██▌       | 814/3107 [1:45:37<5:02:40,  7.92s/it]

 26%|██▌       | 815/3107 [1:45:47<5:36:54,  8.82s/it]
{'loss': 0.9357, 'grad_norm': 0.15404928106256996, 'learning_rate': 0.0001730480022967424, 'epoch': 0.26}


 26%|██▋       | 817/3107 [1:46:09<6:10:52,  9.72s/it]

 26%|██▋       | 818/3107 [1:46:15<5:37:02,  8.83s/it]

 26%|██▋       | 819/3107 [1:46:25<5:51:55,  9.23s/it]

 26%|██▋       | 820/3107 [1:46:33<5:28:18,  8.61s/it]

 26%|██▋       | 821/3107 [1:46:43<5:42:39,  8.99s/it]

 26%|██▋       | 822/3107 [1:46:51<5:37:26,  8.86s/it]

 26%|██▋       | 823/3107 [1:46:58<5:09:45,  8.14s/it]
{'loss': 0.8986, 'grad_norm': 0.18447493781265648, 'learning_rate': 0.00017247580263940736, 'epoch': 0.26}


 27%|██▋       | 825/3107 [1:47:12<4:44:41,  7.49s/it]

 27%|██▋       | 826/3107 [1:47:19<4:45:52,  7.52s/it]
{'loss': 0.9416, 'grad_norm': 0.16411526671372928, 'learning_rate': 0.00017225992552073093, 'epoch': 0.27}

 27%|██▋       | 827/3107 [1:47:28<5:01:02,  7.92s/it]


 27%|██▋       | 829/3107 [1:47:43<4:45:38,  7.52s/it]

 27%|██▋       | 830/3107 [1:47:52<5:11:39,  8.21s/it]
{'loss': 1.0541, 'grad_norm': 0.1706346025663369, 'learning_rate': 0.00017197098989576222, 'epoch': 0.27}


 27%|██▋       | 832/3107 [1:48:06<4:43:27,  7.48s/it]

 27%|██▋       | 833/3107 [1:48:15<5:01:54,  7.97s/it]

 27%|██▋       | 834/3107 [1:48:23<5:00:48,  7.94s/it]
{'loss': 0.9679, 'grad_norm': 0.15051856526592228, 'learning_rate': 0.0001716808023457959, 'epoch': 0.27}


 27%|██▋       | 836/3107 [1:48:39<5:03:37,  8.02s/it]

 27%|██▋       | 837/3107 [1:48:45<4:43:29,  7.49s/it]
{'loss': 0.9698, 'grad_norm': 0.17409330006478482, 'learning_rate': 0.00017146234314327475, 'epoch': 0.27}


 27%|██▋       | 839/3107 [1:48:58<4:24:39,  7.00s/it]

 27%|██▋       | 840/3107 [1:49:05<4:17:04,  6.80s/it]
{'loss': 0.9939, 'grad_norm': 0.15455234582346317, 'learning_rate': 0.0001712431847094073, 'epoch': 0.27}

 27%|██▋       | 841/3107 [1:49:14<4:44:14,  7.53s/it]


 27%|██▋       | 843/3107 [1:49:32<5:19:05,  8.46s/it]

 27%|██▋       | 844/3107 [1:49:40<5:16:10,  8.38s/it]

 27%|██▋       | 845/3107 [1:49:48<5:04:18,  8.07s/it]

 27%|██▋       | 846/3107 [1:49:56<5:09:27,  8.21s/it]

 27%|██▋       | 847/3107 [1:50:11<6:17:35, 10.02s/it]
{'loss': 0.9525, 'grad_norm': 0.17194942794459428, 'learning_rate': 0.00017072910785573202, 'epoch': 0.27}


 27%|██▋       | 849/3107 [1:50:33<6:47:01, 10.82s/it]
[2024-05-28 00:14:42,802] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 27%|██▋       | 850/3107 [1:50:38<5:51:31,  9.34s/it]

 27%|██▋       | 851/3107 [1:50:47<5:40:19,  9.05s/it]

 27%|██▋       | 852/3107 [1:50:53<5:05:29,  8.13s/it]

 27%|██▋       | 853/3107 [1:51:03<5:23:29,  8.61s/it]
{'loss': 0.9808, 'grad_norm': 0.16868606113038, 'learning_rate': 0.000170285470606732, 'epoch': 0.27}

 27%|██▋       | 854/3107 [1:51:16<6:20:37, 10.14s/it]


 28%|██▊       | 856/3107 [1:51:32<5:33:51,  8.90s/it]

 28%|██▊       | 857/3107 [1:51:39<5:13:35,  8.36s/it]
{'loss': 1.0498, 'grad_norm': 0.16365699252244256, 'learning_rate': 0.000169988183110218, 'epoch': 0.28}


 28%|██▊       | 859/3107 [1:51:56<5:20:58,  8.57s/it]

 28%|██▊       | 860/3107 [1:52:06<5:32:50,  8.89s/it]
{'loss': 0.9856, 'grad_norm': 0.17309165477218796, 'learning_rate': 0.0001697644182629332, 'epoch': 0.28}


 28%|██▊       | 862/3107 [1:52:23<5:34:04,  8.93s/it]

 28%|██▊       | 863/3107 [1:52:30<5:07:09,  8.21s/it]
{'loss': 0.9553, 'grad_norm': 0.15689113623899745, 'learning_rate': 0.00016953997079783935, 'epoch': 0.28}

 28%|██▊       | 864/3107 [1:52:38<5:09:22,  8.28s/it]


 28%|██▊       | 866/3107 [1:52:50<4:20:51,  6.98s/it]
{'loss': 0.9116, 'grad_norm': 0.16962302993522196, 'learning_rate': 0.00016931484291106793, 'epoch': 0.28}

 28%|██▊       | 867/3107 [1:52:56<4:12:59,  6.78s/it]


 28%|██▊       | 869/3107 [1:53:09<4:04:35,  6.56s/it]

 28%|██▊       | 870/3107 [1:53:19<4:50:07,  7.78s/it]

 28%|██▊       | 871/3107 [1:53:32<5:40:55,  9.15s/it]

 28%|██▊       | 872/3107 [1:53:41<5:36:47,  9.04s/it]

 28%|██▊       | 873/3107 [1:53:48<5:15:39,  8.48s/it]

 28%|██▊       | 874/3107 [1:54:02<6:20:17, 10.22s/it]
{'loss': 0.9582, 'grad_norm': 0.17105069545798812, 'learning_rate': 0.00016871119214679304, 'epoch': 0.28}


 28%|██▊       | 876/3107 [1:54:16<5:18:09,  8.56s/it]

 28%|██▊       | 877/3107 [1:54:23<4:59:03,  8.05s/it]

 28%|██▊       | 878/3107 [1:54:29<4:35:46,  7.42s/it]
{'loss': 1.0364, 'grad_norm': 0.17296487626963467, 'learning_rate': 0.00016840757130240223, 'epoch': 0.28}

 28%|██▊       | 879/3107 [1:54:38<5:01:24,  8.12s/it]


 28%|██▊       | 881/3107 [1:54:52<4:40:44,  7.57s/it]
{'loss': 1.0252, 'grad_norm': 0.16276099487073958, 'learning_rate': 0.00016817907448147819, 'epoch': 0.28}

 28%|██▊       | 882/3107 [1:54:59<4:27:52,  7.22s/it]

 28%|██▊       | 883/3107 [1:55:05<4:14:31,  6.87s/it]


 28%|██▊       | 885/3107 [1:55:23<4:57:31,  8.03s/it]

 29%|██▊       | 886/3107 [1:55:31<4:59:12,  8.08s/it]

 29%|██▊       | 887/3107 [1:55:42<5:27:53,  8.86s/it]

 29%|██▊       | 888/3107 [1:55:52<5:38:29,  9.15s/it]

 29%|██▊       | 889/3107 [1:55:59<5:15:48,  8.54s/it]

 29%|██▊       | 890/3107 [1:56:04<4:39:37,  7.57s/it]

 29%|██▊       | 891/3107 [1:56:11<4:31:29,  7.35s/it]

 29%|██▊       | 892/3107 [1:56:17<4:13:51,  6.88s/it]

 29%|██▊       | 893/3107 [1:56:24<4:18:13,  7.00s/it]
{'loss': 0.9498, 'grad_norm': 0.15863117107843094, 'learning_rate': 0.00016725843859474745, 'epoch': 0.29}


 29%|██▉       | 895/3107 [1:56:42<4:51:39,  7.91s/it]

 29%|██▉       | 896/3107 [1:56:48<4:37:39,  7.53s/it]

 29%|██▉       | 897/3107 [1:56:57<4:50:32,  7.89s/it]

 29%|██▉       | 898/3107 [1:57:04<4:42:00,  7.66s/it]

 29%|██▉       | 899/3107 [1:57:11<4:38:14,  7.56s/it]

 29%|██▉       | 900/3107 [1:57:21<5:04:04,  8.27s/it]
 29%|██▉       | 900/3107 [1:57:21<5:04:04,  8.27s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 29%|██▉       | 901/3107 [1:58:01<10:51:51, 17.73s/it]

 29%|██▉       | 902/3107 [1:58:07<8:46:06, 14.32s/it]

 29%|██▉       | 903/3107 [1:58:16<7:45:12, 12.66s/it]

 29%|██▉       | 904/3107 [1:58:24<6:51:44, 11.21s/it]

 29%|██▉       | 905/3107 [1:58:30<5:53:47,  9.64s/it]
{'loss': 1.1235, 'grad_norm': 0.18355769999613575, 'learning_rate': 0.00016632727327250182, 'epoch': 0.29}

 29%|██▉       | 906/3107 [1:58:37<5:21:51,  8.77s/it]


 29%|██▉       | 908/3107 [1:58:52<4:56:04,  8.08s/it]

 29%|██▉       | 909/3107 [1:58:58<4:32:08,  7.43s/it]

 29%|██▉       | 910/3107 [1:59:04<4:25:12,  7.24s/it]

 29%|██▉       | 911/3107 [1:59:13<4:40:11,  7.66s/it]
{'loss': 0.8351, 'grad_norm': 0.16229973662288188, 'learning_rate': 0.00016585778756419514, 'epoch': 0.29}


 29%|██▉       | 913/3107 [1:59:24<4:02:03,  6.62s/it]
{'loss': 1.0097, 'grad_norm': 0.15639155326607787, 'learning_rate': 0.00016570071862545346, 'epoch': 0.29}

 29%|██▉       | 914/3107 [1:59:31<4:00:59,  6.59s/it]


 29%|██▉       | 916/3107 [1:59:49<4:43:13,  7.76s/it]

 30%|██▉       | 917/3107 [1:59:57<4:48:45,  7.91s/it]

 30%|██▉       | 918/3107 [2:00:08<5:15:43,  8.65s/it]

 30%|██▉       | 919/3107 [2:00:15<5:06:40,  8.41s/it]

 30%|██▉       | 920/3107 [2:00:21<4:36:18,  7.58s/it]

 30%|██▉       | 921/3107 [2:00:29<4:43:31,  7.78s/it]

 30%|██▉       | 922/3107 [2:00:36<4:30:18,  7.42s/it]

 30%|██▉       | 923/3107 [2:00:42<4:16:46,  7.05s/it]

 30%|██▉       | 924/3107 [2:00:49<4:17:59,  7.09s/it]

 30%|██▉       | 925/3107 [2:00:56<4:18:20,  7.10s/it]
{'loss': 1.0069, 'grad_norm': 0.1642690958576406, 'learning_rate': 0.00016475232899369454, 'epoch': 0.3}


 30%|██▉       | 927/3107 [2:01:09<4:06:31,  6.79s/it]

 30%|██▉       | 928/3107 [2:01:15<3:56:45,  6.52s/it]
{'loss': 0.8771, 'grad_norm': 0.18576500495745527, 'learning_rate': 0.0001645136418292402, 'epoch': 0.3}


 30%|██▉       | 930/3107 [2:01:29<4:09:41,  6.88s/it]

 30%|██▉       | 931/3107 [2:01:36<4:07:27,  6.82s/it]

 30%|██▉       | 932/3107 [2:01:41<3:52:25,  6.41s/it]

 30%|███       | 933/3107 [2:01:48<3:51:01,  6.38s/it]

 30%|███       | 934/3107 [2:01:54<3:48:44,  6.32s/it]

 30%|███       | 935/3107 [2:02:00<3:44:37,  6.20s/it]

 30%|███       | 936/3107 [2:02:08<4:03:46,  6.74s/it]

 30%|███       | 937/3107 [2:02:15<4:11:16,  6.95s/it]

 30%|███       | 938/3107 [2:02:24<4:25:35,  7.35s/it]
{'loss': 0.9163, 'grad_norm': 0.17405534116084473, 'learning_rate': 0.00016371347215014432, 'epoch': 0.3}


 30%|███       | 940/3107 [2:02:38<4:22:17,  7.26s/it]

 30%|███       | 941/3107 [2:02:46<4:25:54,  7.37s/it]

 30%|███       | 942/3107 [2:02:51<4:05:59,  6.82s/it]

 30%|███       | 943/3107 [2:02:57<4:00:54,  6.68s/it]

 30%|███       | 944/3107 [2:03:06<4:20:10,  7.22s/it]

 30%|███       | 945/3107 [2:03:13<4:22:00,  7.27s/it]
{'loss': 0.9587, 'grad_norm': 0.1690164411191468, 'learning_rate': 0.0001631492267587301, 'epoch': 0.3}


 30%|███       | 947/3107 [2:03:31<4:50:03,  8.06s/it]

 31%|███       | 948/3107 [2:03:38<4:31:47,  7.55s/it]

 31%|███       | 949/3107 [2:03:47<4:47:06,  7.98s/it]

 31%|███       | 950/3107 [2:03:53<4:26:39,  7.42s/it]

 31%|███       | 951/3107 [2:04:02<4:49:05,  8.05s/it]

 31%|███       | 952/3107 [2:04:09<4:38:33,  7.76s/it]

 31%|███       | 953/3107 [2:04:16<4:24:55,  7.38s/it]

 31%|███       | 954/3107 [2:04:24<4:38:31,  7.76s/it]
{'loss': 0.9537, 'grad_norm': 0.17084067378461043, 'learning_rate': 0.0001624188295175019, 'epoch': 0.31}


 31%|███       | 956/3107 [2:04:40<4:39:22,  7.79s/it]

 31%|███       | 957/3107 [2:04:46<4:18:40,  7.22s/it]

 31%|███       | 958/3107 [2:04:53<4:15:53,  7.14s/it]

 31%|███       | 959/3107 [2:05:02<4:35:39,  7.70s/it]

 31%|███       | 960/3107 [2:05:11<4:49:31,  8.09s/it]
{'loss': 0.7526, 'grad_norm': 0.16127575997327637, 'learning_rate': 0.00016192884033260744, 'epoch': 0.31}


 31%|███       | 962/3107 [2:05:28<5:01:55,  8.45s/it]
{'loss': 0.9119, 'grad_norm': 0.18205886350895528, 'learning_rate': 0.00016176497103388818, 'epoch': 0.31}


 31%|███       | 964/3107 [2:05:43<4:42:27,  7.91s/it]

 31%|███       | 965/3107 [2:05:52<4:51:48,  8.17s/it]

 31%|███       | 966/3107 [2:05:59<4:40:49,  7.87s/it]
{'loss': 0.8737, 'grad_norm': 0.17264987430054068, 'learning_rate': 0.0001614364273547854, 'epoch': 0.31}

 31%|███       | 967/3107 [2:06:05<4:27:35,  7.50s/it]


 31%|███       | 969/3107 [2:06:20<4:30:45,  7.60s/it]

 31%|███       | 970/3107 [2:06:30<4:49:57,  8.14s/it]

 31%|███▏      | 971/3107 [2:06:38<4:51:02,  8.18s/it]

 31%|███▏      | 972/3107 [2:06:45<4:44:42,  8.00s/it]

 31%|███▏      | 973/3107 [2:06:52<4:27:40,  7.53s/it]

 31%|███▏      | 974/3107 [2:06:57<4:07:03,  6.95s/it]

 31%|███▏      | 975/3107 [2:07:06<4:24:27,  7.44s/it]

 31%|███▏      | 976/3107 [2:07:12<4:04:17,  6.88s/it]

 31%|███▏      | 977/3107 [2:07:20<4:16:20,  7.22s/it]

 31%|███▏      | 978/3107 [2:07:29<4:33:59,  7.72s/it]

 32%|███▏      | 979/3107 [2:07:37<4:38:23,  7.85s/it]

 32%|███▏      | 980/3107 [2:07:45<4:43:05,  7.99s/it]

 32%|███▏      | 981/3107 [2:07:52<4:37:21,  7.83s/it]

 32%|███▏      | 982/3107 [2:07:59<4:19:25,  7.32s/it]

 32%|███▏      | 983/3107 [2:08:05<4:06:56,  6.98s/it]
{'loss': 0.9828, 'grad_norm': 0.171322712032754, 'learning_rate': 0.00016002826370285975, 'epoch': 0.32}


 32%|███▏      | 985/3107 [2:08:20<4:15:44,  7.23s/it]

 32%|███▏      | 986/3107 [2:08:30<4:46:46,  8.11s/it]

 32%|███▏      | 987/3107 [2:08:37<4:32:52,  7.72s/it]

 32%|███▏      | 988/3107 [2:08:42<4:09:07,  7.05s/it]

 32%|███▏      | 989/3107 [2:08:48<3:52:17,  6.58s/it]

 32%|███▏      | 990/3107 [2:08:55<3:54:53,  6.66s/it]

 32%|███▏      | 991/3107 [2:09:04<4:24:56,  7.51s/it]

 32%|███▏      | 992/3107 [2:09:10<4:08:31,  7.05s/it]
{'loss': 0.9639, 'grad_norm': 0.16834544543299199, 'learning_rate': 0.00015927510156369095, 'epoch': 0.32}


 32%|███▏      | 994/3107 [2:09:28<4:36:29,  7.85s/it]

 32%|███▏      | 995/3107 [2:09:35<4:24:09,  7.50s/it]
{'loss': 0.8661, 'grad_norm': 0.15344835702039133, 'learning_rate': 0.0001590228842684864, 'epoch': 0.32}


 32%|███▏      | 997/3107 [2:09:50<4:17:45,  7.33s/it]

 32%|███▏      | 998/3107 [2:09:59<4:34:20,  7.81s/it]
{'loss': 0.9865, 'grad_norm': 0.16158331133842138, 'learning_rate': 0.00015877008945722215, 'epoch': 0.32}


 32%|███▏      | 1000/3107 [2:10:14<4:32:10,  7.75s/it]

 32%|███▏      | 1001/3107 [2:10:20<4:09:37,  7.11s/it]

 32%|███▏      | 1002/3107 [2:10:26<4:01:47,  6.89s/it]

 32%|███▏      | 1003/3107 [2:10:34<4:07:17,  7.05s/it]

 32%|███▏      | 1004/3107 [2:10:42<4:23:51,  7.53s/it]

 32%|███▏      | 1005/3107 [2:10:49<4:16:51,  7.33s/it]
{'loss': 0.9106, 'grad_norm': 0.17559196650252687, 'learning_rate': 0.0001581780029066981, 'epoch': 0.32}


 32%|███▏      | 1007/3107 [2:11:05<4:31:58,  7.77s/it]

 32%|███▏      | 1008/3107 [2:11:11<4:13:08,  7.24s/it]

 32%|███▏      | 1009/3107 [2:11:17<3:59:20,  6.85s/it]

 33%|███▎      | 1010/3107 [2:11:23<3:46:04,  6.47s/it]

 33%|███▎      | 1011/3107 [2:11:29<3:45:11,  6.45s/it]
{'loss': 0.9423, 'grad_norm': 0.15869273378927512, 'learning_rate': 0.00015766803221148673, 'epoch': 0.33}

 33%|███▎      | 1012/3107 [2:11:36<3:47:43,  6.52s/it]


 33%|███▎      | 1014/3107 [2:11:53<4:25:15,  7.60s/it]

 33%|███▎      | 1015/3107 [2:12:02<4:43:19,  8.13s/it]

 33%|███▎      | 1016/3107 [2:12:14<5:25:03,  9.33s/it]

 33%|███▎      | 1017/3107 [2:12:25<5:37:50,  9.70s/it]

 33%|███▎      | 1018/3107 [2:12:30<4:55:02,  8.47s/it]

 33%|███▎      | 1019/3107 [2:12:39<4:53:02,  8.42s/it]

 33%|███▎      | 1020/3107 [2:12:51<5:28:57,  9.46s/it]

 33%|███▎      | 1021/3107 [2:12:57<5:00:24,  8.64s/it]

 33%|███▎      | 1022/3107 [2:13:04<4:42:46,  8.14s/it]

 33%|███▎      | 1023/3107 [2:13:10<4:19:45,  7.48s/it]

 33%|███▎      | 1024/3107 [2:13:16<4:03:13,  7.01s/it]
{'loss': 1.1229, 'grad_norm': 0.1798565242559463, 'learning_rate': 0.00015655537958252324, 'epoch': 0.33}


 33%|███▎      | 1026/3107 [2:13:29<3:57:11,  6.84s/it]

 33%|███▎      | 1027/3107 [2:13:38<4:18:57,  7.47s/it]
{'loss': 0.9642, 'grad_norm': 0.17078082462252728, 'learning_rate': 0.00015629713046971214, 'epoch': 0.33}


 33%|███▎      | 1029/3107 [2:13:52<4:09:42,  7.21s/it]

 33%|███▎      | 1030/3107 [2:14:00<4:20:01,  7.51s/it]
{'loss': 0.8788, 'grad_norm': 0.14985812866440779, 'learning_rate': 0.00015603833051128647, 'epoch': 0.33}


 33%|███▎      | 1032/3107 [2:14:14<4:06:11,  7.12s/it]

 33%|███▎      | 1033/3107 [2:14:20<3:53:35,  6.76s/it]

 33%|███▎      | 1034/3107 [2:14:27<3:54:07,  6.78s/it]

 33%|███▎      | 1035/3107 [2:14:34<4:03:10,  7.04s/it]

 33%|███▎      | 1036/3107 [2:14:40<3:47:27,  6.59s/it]

 33%|███▎      | 1037/3107 [2:14:48<3:57:19,  6.88s/it]

 33%|███▎      | 1038/3107 [2:14:55<4:06:25,  7.15s/it]

 33%|███▎      | 1039/3107 [2:15:02<4:03:50,  7.07s/it]

 33%|███▎      | 1040/3107 [2:15:09<4:02:33,  7.04s/it]
{'loss': 0.9728, 'grad_norm': 0.17395876429669102, 'learning_rate': 0.0001551717182068287, 'epoch': 0.33}

 34%|███▎      | 1041/3107 [2:15:16<3:55:35,  6.84s/it]


 34%|███▎      | 1043/3107 [2:15:30<4:05:03,  7.12s/it]
{'loss': 1.0055, 'grad_norm': 0.1692663920184105, 'learning_rate': 0.00015491056058107843, 'epoch': 0.34}


 34%|███▎      | 1045/3107 [2:15:44<4:02:45,  7.06s/it]

 34%|███▎      | 1046/3107 [2:15:51<3:56:11,  6.88s/it]

 34%|███▎      | 1047/3107 [2:16:02<4:37:41,  8.09s/it]
{'loss': 0.8654, 'grad_norm': 0.1695322202023976, 'learning_rate': 0.00015456151508917316, 'epoch': 0.34}


 34%|███▍      | 1049/3107 [2:16:14<4:07:29,  7.22s/it]

 34%|███▍      | 1050/3107 [2:16:20<3:47:16,  6.63s/it]

 34%|███▍      | 1051/3107 [2:16:28<4:09:03,  7.27s/it]

 34%|███▍      | 1052/3107 [2:16:37<4:26:47,  7.79s/it]

 34%|███▍      | 1053/3107 [2:16:44<4:16:03,  7.48s/it]

 34%|███▍      | 1054/3107 [2:16:53<4:27:56,  7.83s/it]
{'loss': 1.0119, 'grad_norm': 0.16024718982688463, 'learning_rate': 0.00015394840539302527, 'epoch': 0.34}


 34%|███▍      | 1056/3107 [2:17:09<4:32:53,  7.98s/it]

 34%|███▍      | 1057/3107 [2:17:18<4:44:00,  8.31s/it]

 34%|███▍      | 1058/3107 [2:17:24<4:20:00,  7.61s/it]

 34%|███▍      | 1059/3107 [2:17:31<4:12:16,  7.39s/it]

 34%|███▍      | 1060/3107 [2:17:39<4:17:53,  7.56s/it]

 34%|███▍      | 1061/3107 [2:17:46<4:06:34,  7.23s/it]

 34%|███▍      | 1062/3107 [2:17:51<3:51:04,  6.78s/it]

 34%|███▍      | 1063/3107 [2:17:59<3:55:26,  6.91s/it]

 34%|███▍      | 1064/3107 [2:18:09<4:32:17,  8.00s/it]
{'loss': 0.7659, 'grad_norm': 0.15897268122295036, 'learning_rate': 0.00015306755715849293, 'epoch': 0.34}


 34%|███▍      | 1066/3107 [2:18:25<4:31:17,  7.98s/it]

 34%|███▍      | 1067/3107 [2:18:32<4:20:11,  7.65s/it]

 34%|███▍      | 1068/3107 [2:18:37<4:00:44,  7.08s/it]

 34%|███▍      | 1069/3107 [2:18:44<3:51:11,  6.81s/it]

 34%|███▍      | 1070/3107 [2:18:51<3:58:38,  7.03s/it]

 34%|███▍      | 1071/3107 [2:19:01<4:28:03,  7.90s/it]

 35%|███▍      | 1072/3107 [2:19:07<4:04:22,  7.21s/it]

 35%|███▍      | 1073/3107 [2:19:13<3:51:46,  6.84s/it]

 35%|███▍      | 1074/3107 [2:19:19<3:43:00,  6.58s/it]

 35%|███▍      | 1075/3107 [2:19:25<3:43:36,  6.60s/it]

 35%|███▍      | 1076/3107 [2:19:32<3:42:38,  6.58s/it]

 35%|███▍      | 1077/3107 [2:19:39<3:47:15,  6.72s/it]

 35%|███▍      | 1078/3107 [2:19:45<3:45:44,  6.68s/it]

 35%|███▍      | 1079/3107 [2:19:57<4:37:01,  8.20s/it]

 35%|███▍      | 1080/3107 [2:20:05<4:31:37,  8.04s/it]

 35%|███▍      | 1081/3107 [2:20:11<4:16:42,  7.60s/it]

 35%|███▍      | 1082/3107 [2:20:17<4:01:08,  7.15s/it]

 35%|███▍      | 1083/3107 [2:20:23<3:44:32,  6.66s/it]

 35%|███▍      | 1084/3107 [2:20:29<3:40:03,  6.53s/it]

 35%|███▍      | 1085/3107 [2:20:41<4:33:00,  8.10s/it]

 35%|███▍      | 1086/3107 [2:20:54<5:20:25,  9.51s/it]

 35%|███▍      | 1087/3107 [2:21:01<4:53:42,  8.72s/it]
{'loss': 0.9873, 'grad_norm': 0.16717800602958527, 'learning_rate': 0.00015101987013835236, 'epoch': 0.35}


 35%|███▌      | 1089/3107 [2:21:17<4:43:03,  8.42s/it]
{'loss': 0.9712, 'grad_norm': 0.16268520239280623, 'learning_rate': 0.00015084040670299516, 'epoch': 0.35}


 35%|███▌      | 1091/3107 [2:21:34<4:48:46,  8.59s/it]

 35%|███▌      | 1092/3107 [2:21:43<4:49:39,  8.62s/it]

 35%|███▌      | 1093/3107 [2:21:49<4:22:50,  7.83s/it]

 35%|███▌      | 1094/3107 [2:21:57<4:33:28,  8.15s/it]

 35%|███▌      | 1095/3107 [2:22:04<4:13:21,  7.56s/it]

 35%|███▌      | 1096/3107 [2:22:12<4:16:53,  7.66s/it]
{'loss': 0.9618, 'grad_norm': 0.17294408780231674, 'learning_rate': 0.0001502105487208319, 'epoch': 0.35}

 35%|███▌      | 1097/3107 [2:22:18<4:06:06,  7.35s/it]

 35%|███▌      | 1098/3107 [2:22:24<3:53:47,  6.98s/it]


 35%|███▌      | 1100/3107 [2:22:35<3:29:34,  6.27s/it]

 35%|███▌      | 1101/3107 [2:22:49<4:39:15,  8.35s/it]

 35%|███▌      | 1102/3107 [2:22:55<4:13:52,  7.60s/it]

 36%|███▌      | 1103/3107 [2:23:01<4:04:00,  7.31s/it]

 36%|███▌      | 1104/3107 [2:23:13<4:51:11,  8.72s/it]

 36%|███▌      | 1105/3107 [2:23:22<4:56:36,  8.89s/it]
{'loss': 0.8285, 'grad_norm': 0.1656077751175221, 'learning_rate': 0.00014939680571522502, 'epoch': 0.36}


 36%|███▌      | 1107/3107 [2:23:35<4:09:07,  7.47s/it]

 36%|███▌      | 1108/3107 [2:23:48<5:03:24,  9.11s/it]

 36%|███▌      | 1109/3107 [2:23:55<4:51:07,  8.74s/it]

 36%|███▌      | 1110/3107 [2:24:05<5:00:58,  9.04s/it]
{'loss': 0.9053, 'grad_norm': 0.16359103739351616, 'learning_rate': 0.00014894284206570219, 'epoch': 0.36}


 36%|███▌      | 1112/3107 [2:24:21<4:37:28,  8.35s/it]

 36%|███▌      | 1113/3107 [2:24:27<4:14:41,  7.66s/it]

 36%|███▌      | 1114/3107 [2:24:36<4:28:29,  8.08s/it]

 36%|███▌      | 1115/3107 [2:24:44<4:23:45,  7.94s/it]

 36%|███▌      | 1116/3107 [2:24:53<4:40:20,  8.45s/it]

 36%|███▌      | 1117/3107 [2:25:01<4:29:31,  8.13s/it]

 36%|███▌      | 1118/3107 [2:25:07<4:08:42,  7.50s/it]

 36%|███▌      | 1119/3107 [2:25:13<3:52:37,  7.02s/it]
{'loss': 0.9498, 'grad_norm': 0.17271879295151965, 'learning_rate': 0.00014812236360870834, 'epoch': 0.36}

 36%|███▌      | 1120/3107 [2:25:22<4:18:26,  7.80s/it]

 36%|███▌      | 1121/3107 [2:25:30<4:21:28,  7.90s/it]


 36%|███▌      | 1123/3107 [2:25:45<4:10:40,  7.58s/it]
{'loss': 0.9467, 'grad_norm': 0.166747672515212, 'learning_rate': 0.00014775634195870481, 'epoch': 0.36}


 36%|███▌      | 1125/3107 [2:25:59<3:56:17,  7.15s/it]

 36%|███▌      | 1126/3107 [2:26:06<3:55:26,  7.13s/it]
{'loss': 1.0193, 'grad_norm': 0.1602151473418672, 'learning_rate': 0.00014748128021595543, 'epoch': 0.36}


 36%|███▋      | 1128/3107 [2:26:25<4:35:05,  8.34s/it]

 36%|███▋      | 1129/3107 [2:26:32<4:17:49,  7.82s/it]

 36%|███▋      | 1130/3107 [2:26:38<4:01:54,  7.34s/it]

 36%|███▋      | 1131/3107 [2:26:44<3:46:52,  6.89s/it]
{'loss': 0.8588, 'grad_norm': 0.1653193296564565, 'learning_rate': 0.00014702181289598292, 'epoch': 0.36}


 36%|███▋      | 1133/3107 [2:26:59<4:00:21,  7.31s/it]

 36%|███▋      | 1134/3107 [2:27:08<4:20:15,  7.91s/it]

 37%|███▋      | 1135/3107 [2:27:16<4:20:32,  7.93s/it]

 37%|███▋      | 1136/3107 [2:27:23<4:07:23,  7.53s/it]

 37%|███▋      | 1137/3107 [2:27:29<3:52:05,  7.07s/it]

 37%|███▋      | 1138/3107 [2:27:36<3:48:15,  6.96s/it]

 37%|███▋      | 1139/3107 [2:27:44<4:02:02,  7.38s/it]
{'loss': 0.9389, 'grad_norm': 0.1705408025253129, 'learning_rate': 0.0001462840120968527, 'epoch': 0.37}


 37%|███▋      | 1141/3107 [2:27:57<3:46:29,  6.91s/it]

 37%|███▋      | 1142/3107 [2:28:03<3:42:13,  6.79s/it]

 37%|███▋      | 1143/3107 [2:28:09<3:28:42,  6.38s/it]

 37%|███▋      | 1144/3107 [2:28:17<3:50:16,  7.04s/it]

 37%|███▋      | 1145/3107 [2:28:26<4:06:23,  7.53s/it]
{'loss': 0.9941, 'grad_norm': 0.16879841725363204, 'learning_rate': 0.0001457285452935592, 'epoch': 0.37}


 37%|███▋      | 1147/3107 [2:28:39<3:49:57,  7.04s/it]

 37%|███▋      | 1148/3107 [2:28:48<4:07:51,  7.59s/it]

 37%|███▋      | 1149/3107 [2:28:56<4:10:44,  7.68s/it]

 37%|███▋      | 1150/3107 [2:29:06<4:33:11,  8.38s/it]

 37%|███▋      | 1151/3107 [2:29:13<4:21:26,  8.02s/it]
{'loss': 1.0048, 'grad_norm': 0.18407889548333148, 'learning_rate': 0.0001451712887502338, 'epoch': 0.37}


 37%|███▋      | 1153/3107 [2:29:33<4:56:12,  9.10s/it]

 37%|███▋      | 1154/3107 [2:29:41<4:43:35,  8.71s/it]

 37%|███▋      | 1155/3107 [2:29:49<4:38:03,  8.55s/it]

 37%|███▋      | 1156/3107 [2:29:56<4:22:29,  8.07s/it]

 37%|███▋      | 1157/3107 [2:30:04<4:15:52,  7.87s/it]

 37%|███▋      | 1158/3107 [2:30:12<4:21:44,  8.06s/it]

 37%|███▋      | 1159/3107 [2:30:20<4:22:46,  8.09s/it]

 37%|███▋      | 1160/3107 [2:30:26<4:04:46,  7.54s/it]

 37%|███▋      | 1161/3107 [2:30:34<4:04:24,  7.54s/it]

 37%|███▋      | 1162/3107 [2:30:42<4:07:18,  7.63s/it]

 37%|███▋      | 1163/3107 [2:30:52<4:35:25,  8.50s/it]

 37%|███▋      | 1164/3107 [2:30:58<4:07:18,  7.64s/it]

 37%|███▋      | 1165/3107 [2:31:04<3:55:23,  7.27s/it]
{'loss': 0.8699, 'grad_norm': 0.1618254921922406, 'learning_rate': 0.00014386418602535314, 'epoch': 0.37}


 38%|███▊      | 1167/3107 [2:31:26<4:53:29,  9.08s/it]

 38%|███▊      | 1168/3107 [2:31:32<4:22:38,  8.13s/it]
{'loss': 1.0422, 'grad_norm': 0.17357281333804422, 'learning_rate': 0.00014358286702662216, 'epoch': 0.38}


 38%|███▊      | 1170/3107 [2:31:49<4:31:55,  8.42s/it]

 38%|███▊      | 1171/3107 [2:31:55<4:07:01,  7.66s/it]

 38%|███▊      | 1172/3107 [2:32:02<4:03:02,  7.54s/it]
{'loss': 0.9628, 'grad_norm': 0.17435874540042684, 'learning_rate': 0.00014320711215127277, 'epoch': 0.38}
[2024-05-28 00:56:23,146] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 1173/3107 [2:32:13<4:31:17,  8.42s/it]

 38%|███▊      | 1174/3107 [2:32:23<4:45:21,  8.86s/it]


 38%|███▊      | 1176/3107 [2:32:38<4:18:54,  8.05s/it]

 38%|███▊      | 1177/3107 [2:32:46<4:19:09,  8.06s/it]

 38%|███▊      | 1178/3107 [2:32:52<3:59:55,  7.46s/it]

 38%|███▊      | 1179/3107 [2:33:00<4:09:29,  7.76s/it]

 38%|███▊      | 1180/3107 [2:33:09<4:21:38,  8.15s/it]

 38%|███▊      | 1181/3107 [2:33:18<4:28:31,  8.37s/it]

 38%|███▊      | 1182/3107 [2:33:29<4:48:24,  8.99s/it]
{'loss': 0.967, 'grad_norm': 0.15980597409022096, 'learning_rate': 0.00014226445112397042, 'epoch': 0.38}


 38%|███▊      | 1184/3107 [2:33:43<4:17:08,  8.02s/it]

 38%|███▊      | 1185/3107 [2:33:50<4:08:51,  7.77s/it]
{'loss': 0.916, 'grad_norm': 0.164643295392242, 'learning_rate': 0.00014198075214089519, 'epoch': 0.38}


 38%|███▊      | 1187/3107 [2:34:04<3:57:06,  7.41s/it]

 38%|███▊      | 1188/3107 [2:34:10<3:43:16,  6.98s/it]
{'loss': 0.8357, 'grad_norm': 0.15862906179683098, 'learning_rate': 0.00014169664239242175, 'epoch': 0.38}


 38%|███▊      | 1190/3107 [2:34:26<3:52:37,  7.28s/it]
{'loss': 0.9369, 'grad_norm': 0.18698769977993365, 'learning_rate': 0.0001415070090630679, 'epoch': 0.38}


 38%|███▊      | 1192/3107 [2:34:48<4:43:32,  8.88s/it]
{'loss': 1.0091, 'grad_norm': 0.1845769639213027, 'learning_rate': 0.0001413171952314075, 'epoch': 0.38}


 38%|███▊      | 1194/3107 [2:35:06<4:44:06,  8.91s/it]

 38%|███▊      | 1195/3107 [2:35:11<4:13:50,  7.97s/it]

 38%|███▊      | 1196/3107 [2:35:18<4:04:04,  7.66s/it]
{'loss': 0.8743, 'grad_norm': 0.17837846096414356, 'learning_rate': 0.0001409370293637364, 'epoch': 0.38}

 39%|███▊      | 1197/3107 [2:35:27<4:14:35,  8.00s/it]


 39%|███▊      | 1199/3107 [2:35:46<4:40:16,  8.81s/it]

 39%|███▊      | 1200/3107 [2:35:52<4:14:04,  7.99s/it]
 39%|███▊      | 1200/3107 [2:35:52<4:14:04,  7.99s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 39%|███▊      | 1201/3107 [2:36:31<9:08:21, 17.26s/it]

 39%|███▊      | 1202/3107 [2:36:38<7:28:38, 14.13s/it]

 39%|███▊      | 1203/3107 [2:36:44<6:17:09, 11.89s/it]

 39%|███▉      | 1204/3107 [2:36:52<5:39:01, 10.69s/it]

 39%|███▉      | 1205/3107 [2:37:00<5:15:17,  9.95s/it]

 39%|███▉      | 1206/3107 [2:37:07<4:41:32,  8.89s/it]

 39%|███▉      | 1207/3107 [2:37:16<4:46:10,  9.04s/it]
{'loss': 0.7951, 'grad_norm': 0.14996823952589056, 'learning_rate': 0.00013988792142900015, 'epoch': 0.39}


 39%|███▉      | 1209/3107 [2:37:32<4:27:21,  8.45s/it]

 39%|███▉      | 1210/3107 [2:37:37<3:56:37,  7.48s/it]

 39%|███▉      | 1211/3107 [2:37:45<3:55:12,  7.44s/it]

 39%|███▉      | 1212/3107 [2:37:51<3:41:47,  7.02s/it]

 39%|███▉      | 1213/3107 [2:37:56<3:27:56,  6.59s/it]

 39%|███▉      | 1214/3107 [2:38:04<3:38:34,  6.93s/it]

 39%|███▉      | 1215/3107 [2:38:10<3:31:16,  6.70s/it]

 39%|███▉      | 1216/3107 [2:38:17<3:35:09,  6.83s/it]

 39%|███▉      | 1217/3107 [2:38:24<3:32:21,  6.74s/it]
{'loss': 0.883, 'grad_norm': 0.161632859413335, 'learning_rate': 0.00013892962998838753, 'epoch': 0.39}


 39%|███▉      | 1219/3107 [2:38:40<3:55:51,  7.50s/it]

 39%|███▉      | 1220/3107 [2:38:46<3:49:10,  7.29s/it]

 39%|███▉      | 1221/3107 [2:38:57<4:20:43,  8.29s/it]

 39%|███▉      | 1222/3107 [2:39:04<4:05:51,  7.83s/it]

 39%|███▉      | 1223/3107 [2:39:10<3:49:01,  7.29s/it]

 39%|███▉      | 1224/3107 [2:39:15<3:33:51,  6.81s/it]
{'loss': 1.0393, 'grad_norm': 0.1711576585806697, 'learning_rate': 0.00013825630153600058, 'epoch': 0.39}


 39%|███▉      | 1226/3107 [2:39:28<3:30:16,  6.71s/it]

 39%|███▉      | 1227/3107 [2:39:34<3:19:02,  6.35s/it]
{'loss': 0.9216, 'grad_norm': 0.16622669720015057, 'learning_rate': 0.00013796710623433696, 'epoch': 0.39}


 40%|███▉      | 1229/3107 [2:39:52<3:59:07,  7.64s/it]

 40%|███▉      | 1230/3107 [2:40:01<4:13:08,  8.09s/it]

 40%|███▉      | 1231/3107 [2:40:06<3:47:50,  7.29s/it]

 40%|███▉      | 1232/3107 [2:40:12<3:30:43,  6.74s/it]

 40%|███▉      | 1233/3107 [2:40:22<4:04:38,  7.83s/it]

 40%|███▉      | 1234/3107 [2:40:30<4:00:20,  7.70s/it]

 40%|███▉      | 1235/3107 [2:40:36<3:47:24,  7.29s/it]

 40%|███▉      | 1236/3107 [2:40:42<3:34:57,  6.89s/it]

 40%|███▉      | 1237/3107 [2:40:48<3:28:25,  6.69s/it]

 40%|███▉      | 1238/3107 [2:40:55<3:24:56,  6.58s/it]

 40%|███▉      | 1239/3107 [2:41:02<3:34:20,  6.88s/it]

 40%|███▉      | 1240/3107 [2:41:09<3:34:17,  6.89s/it]
{'loss': 1.0525, 'grad_norm': 0.16541154801509023, 'learning_rate': 0.00013670967018597255, 'epoch': 0.4}


 40%|███▉      | 1242/3107 [2:41:22<3:28:35,  6.71s/it]

 40%|████      | 1243/3107 [2:41:30<3:39:30,  7.07s/it]

 40%|████      | 1244/3107 [2:41:37<3:35:30,  6.94s/it]

 40%|████      | 1245/3107 [2:41:43<3:31:45,  6.82s/it]
{'loss': 0.8892, 'grad_norm': 0.16118585669333368, 'learning_rate': 0.00013622423235350428, 'epoch': 0.4}

 40%|████      | 1246/3107 [2:41:52<3:46:09,  7.29s/it]


 40%|████      | 1248/3107 [2:42:05<3:40:44,  7.12s/it]

 40%|████      | 1249/3107 [2:42:13<3:48:17,  7.37s/it]

 40%|████      | 1250/3107 [2:42:20<3:43:11,  7.21s/it]

 40%|████      | 1251/3107 [2:42:27<3:36:56,  7.01s/it]

 40%|████      | 1252/3107 [2:42:33<3:33:44,  6.91s/it]

 40%|████      | 1253/3107 [2:42:41<3:38:33,  7.07s/it]

 40%|████      | 1254/3107 [2:42:47<3:30:29,  6.82s/it]
{'loss': 1.0413, 'grad_norm': 0.1815375758452136, 'learning_rate': 0.000135347972061497, 'epoch': 0.4}

 40%|████      | 1255/3107 [2:42:56<3:48:09,  7.39s/it]


 40%|████      | 1257/3107 [2:43:11<3:54:38,  7.61s/it]

 40%|████      | 1258/3107 [2:43:17<3:40:16,  7.15s/it]

 41%|████      | 1259/3107 [2:43:25<3:40:43,  7.17s/it]

 41%|████      | 1260/3107 [2:43:31<3:31:08,  6.86s/it]

 41%|████      | 1261/3107 [2:43:36<3:19:50,  6.50s/it]

 41%|████      | 1262/3107 [2:43:42<3:11:19,  6.22s/it]

 41%|████      | 1263/3107 [2:43:50<3:28:22,  6.78s/it]

 41%|████      | 1264/3107 [2:44:01<4:09:12,  8.11s/it]

 41%|████      | 1265/3107 [2:44:10<4:13:31,  8.26s/it]

 41%|████      | 1266/3107 [2:44:17<3:59:17,  7.80s/it]

 41%|████      | 1267/3107 [2:44:23<3:46:54,  7.40s/it]

 41%|████      | 1268/3107 [2:44:34<4:20:41,  8.51s/it]

 41%|████      | 1269/3107 [2:44:40<4:00:01,  7.84s/it]

 41%|████      | 1270/3107 [2:44:47<3:47:52,  7.44s/it]

 41%|████      | 1271/3107 [2:44:55<3:49:31,  7.50s/it]

 41%|████      | 1272/3107 [2:45:02<3:47:48,  7.45s/it]
{'loss': 0.9772, 'grad_norm': 0.16502393180463926, 'learning_rate': 0.00013358619058902762, 'epoch': 0.41}


 41%|████      | 1274/3107 [2:45:15<3:38:17,  7.15s/it]

 41%|████      | 1275/3107 [2:45:22<3:35:36,  7.06s/it]
{'loss': 0.8175, 'grad_norm': 0.169893963412605, 'learning_rate': 0.00013329139335775114, 'epoch': 0.41}


 41%|████      | 1277/3107 [2:45:39<4:01:51,  7.93s/it]

 41%|████      | 1278/3107 [2:45:47<3:55:57,  7.74s/it]

 41%|████      | 1279/3107 [2:45:54<3:55:31,  7.73s/it]

 41%|████      | 1280/3107 [2:46:04<4:12:33,  8.29s/it]

 41%|████      | 1281/3107 [2:46:15<4:37:51,  9.13s/it]

 41%|████▏     | 1282/3107 [2:46:21<4:10:04,  8.22s/it]

 41%|████▏     | 1283/3107 [2:46:27<3:51:55,  7.63s/it]

 41%|████▏     | 1284/3107 [2:46:37<4:05:55,  8.09s/it]

 41%|████▏     | 1285/3107 [2:46:42<3:42:39,  7.33s/it]

 41%|████▏     | 1286/3107 [2:46:55<4:34:12,  9.04s/it]

 41%|████▏     | 1287/3107 [2:47:01<4:08:17,  8.19s/it]

 41%|████▏     | 1288/3107 [2:47:10<4:13:12,  8.35s/it]

 41%|████▏     | 1289/3107 [2:47:16<3:46:14,  7.47s/it]
{'loss': 0.9689, 'grad_norm': 0.1709685990686498, 'learning_rate': 0.0001319114125936675, 'epoch': 0.41}


 42%|████▏     | 1291/3107 [2:47:29<3:39:42,  7.26s/it]
{'loss': 0.9028, 'grad_norm': 0.16847188313857667, 'learning_rate': 0.00013171371052241032, 'epoch': 0.42}


 42%|████▏     | 1293/3107 [2:47:49<4:08:35,  8.22s/it]

 42%|████▏     | 1294/3107 [2:47:56<4:03:00,  8.04s/it]

 42%|████▏     | 1295/3107 [2:48:03<3:48:28,  7.57s/it]

 42%|████▏     | 1296/3107 [2:48:09<3:34:35,  7.11s/it]

 42%|████▏     | 1297/3107 [2:48:18<3:49:11,  7.60s/it]

 42%|████▏     | 1298/3107 [2:48:24<3:41:35,  7.35s/it]
{'loss': 1.0392, 'grad_norm': 0.1586245325653806, 'learning_rate': 0.00013102067284772836, 'epoch': 0.42}


 42%|████▏     | 1300/3107 [2:48:39<3:44:01,  7.44s/it]

 42%|████▏     | 1301/3107 [2:48:47<3:47:39,  7.56s/it]

 42%|████▏     | 1302/3107 [2:48:55<3:56:12,  7.85s/it]

 42%|████▏     | 1303/3107 [2:49:02<3:45:07,  7.49s/it]

 42%|████▏     | 1304/3107 [2:49:10<3:47:19,  7.57s/it]

 42%|████▏     | 1305/3107 [2:49:18<3:53:34,  7.78s/it]

 42%|████▏     | 1306/3107 [2:49:27<4:02:54,  8.09s/it]

 42%|████▏     | 1307/3107 [2:49:37<4:24:17,  8.81s/it]

 42%|████▏     | 1308/3107 [2:49:47<4:31:13,  9.05s/it]
{'loss': 0.9362, 'grad_norm': 0.16845756821385466, 'learning_rate': 0.00013002776157743762, 'epoch': 0.42}


 42%|████▏     | 1310/3107 [2:50:01<3:59:19,  7.99s/it]

 42%|████▏     | 1311/3107 [2:50:10<4:13:18,  8.46s/it]

 42%|████▏     | 1312/3107 [2:50:18<4:10:09,  8.36s/it]

 42%|████▏     | 1313/3107 [2:50:26<3:58:20,  7.97s/it]
{'loss': 1.0515, 'grad_norm': 0.17902758281880882, 'learning_rate': 0.00012953007498333808, 'epoch': 0.42}


 42%|████▏     | 1315/3107 [2:50:38<3:33:34,  7.15s/it]

 42%|████▏     | 1316/3107 [2:50:45<3:29:30,  7.02s/it]

 42%|████▏     | 1317/3107 [2:50:53<3:40:03,  7.38s/it]

 42%|████▏     | 1318/3107 [2:51:01<3:42:11,  7.45s/it]

 42%|████▏     | 1319/3107 [2:51:07<3:30:06,  7.05s/it]

 42%|████▏     | 1320/3107 [2:51:12<3:14:48,  6.54s/it]

 43%|████▎     | 1321/3107 [2:51:22<3:37:59,  7.32s/it]

 43%|████▎     | 1322/3107 [2:51:28<3:28:14,  7.00s/it]

 43%|████▎     | 1323/3107 [2:51:35<3:27:13,  6.97s/it]

 43%|████▎     | 1324/3107 [2:51:44<3:43:58,  7.54s/it]

 43%|████▎     | 1325/3107 [2:51:49<3:28:21,  7.02s/it]

 43%|████▎     | 1326/3107 [2:51:57<3:29:47,  7.07s/it]
{'loss': 0.9855, 'grad_norm': 0.16786672415547715, 'learning_rate': 0.00012823236744512805, 'epoch': 0.43}


 43%|████▎     | 1328/3107 [2:52:09<3:16:43,  6.63s/it]

 43%|████▎     | 1329/3107 [2:52:15<3:17:22,  6.66s/it]

 43%|████▎     | 1330/3107 [2:52:24<3:34:01,  7.23s/it]

 43%|████▎     | 1331/3107 [2:52:30<3:19:03,  6.72s/it]
{'loss': 1.0273, 'grad_norm': 0.1767343274967927, 'learning_rate': 0.00012773185491287532, 'epoch': 0.43}


 43%|████▎     | 1333/3107 [2:52:47<3:45:12,  7.62s/it]
{'loss': 0.9549, 'grad_norm': 0.16544468677433272, 'learning_rate': 0.0001275314380913159, 'epoch': 0.43}


 43%|████▎     | 1335/3107 [2:53:06<4:12:50,  8.56s/it]

 43%|████▎     | 1336/3107 [2:53:12<3:53:08,  7.90s/it]

 43%|████▎     | 1337/3107 [2:53:17<3:32:01,  7.19s/it]

 43%|████▎     | 1338/3107 [2:53:25<3:31:08,  7.16s/it]

 43%|████▎     | 1339/3107 [2:53:32<3:33:08,  7.23s/it]

 43%|████▎     | 1340/3107 [2:53:40<3:39:15,  7.45s/it]

 43%|████▎     | 1341/3107 [2:53:48<3:49:22,  7.79s/it]

 43%|████▎     | 1342/3107 [2:53:57<3:57:23,  8.07s/it]

 43%|████▎     | 1343/3107 [2:54:06<4:01:47,  8.22s/it]

 43%|████▎     | 1344/3107 [2:54:15<4:07:52,  8.44s/it]

 43%|████▎     | 1345/3107 [2:54:21<3:51:31,  7.88s/it]

 43%|████▎     | 1346/3107 [2:54:27<3:29:37,  7.14s/it]

 43%|████▎     | 1347/3107 [2:54:35<3:42:42,  7.59s/it]
{'loss': 0.8588, 'grad_norm': 0.1740489232275231, 'learning_rate': 0.00012612521687125085, 'epoch': 0.43}


 43%|████▎     | 1349/3107 [2:54:51<3:43:55,  7.64s/it]

 43%|████▎     | 1350/3107 [2:54:57<3:34:26,  7.32s/it]

 43%|████▎     | 1351/3107 [2:55:04<3:30:10,  7.18s/it]

 44%|████▎     | 1352/3107 [2:55:14<3:53:38,  7.99s/it]
{'loss': 0.9525, 'grad_norm': 0.175529332046386, 'learning_rate': 0.00012562163029935462, 'epoch': 0.44}


 44%|████▎     | 1354/3107 [2:55:27<3:34:32,  7.34s/it]

 44%|████▎     | 1355/3107 [2:55:41<4:30:00,  9.25s/it]

 44%|████▎     | 1356/3107 [2:55:51<4:38:45,  9.55s/it]

 44%|████▎     | 1357/3107 [2:56:01<4:40:28,  9.62s/it]

 44%|████▎     | 1358/3107 [2:56:08<4:17:18,  8.83s/it]

 44%|████▎     | 1359/3107 [2:56:14<3:48:36,  7.85s/it]
{'loss': 0.944, 'grad_norm': 0.17705237501892807, 'learning_rate': 0.00012491544224721136, 'epoch': 0.44}


 44%|████▍     | 1361/3107 [2:56:29<3:45:45,  7.76s/it]
{'loss': 0.9961, 'grad_norm': 0.18288470571944657, 'learning_rate': 0.00012471342879828245, 'epoch': 0.44}

 44%|████▍     | 1362/3107 [2:56:38<3:58:35,  8.20s/it]


 44%|████▍     | 1364/3107 [2:56:52<3:35:31,  7.42s/it]

 44%|████▍     | 1365/3107 [2:56:58<3:18:18,  6.83s/it]

 44%|████▍     | 1366/3107 [2:57:04<3:16:27,  6.77s/it]

 44%|████▍     | 1367/3107 [2:57:16<3:58:16,  8.22s/it]
{'loss': 0.9883, 'grad_norm': 0.1649434185636593, 'learning_rate': 0.00012410674713732764, 'epoch': 0.44}


 44%|████▍     | 1369/3107 [2:57:34<4:02:37,  8.38s/it]

 44%|████▍     | 1370/3107 [2:57:43<4:08:37,  8.59s/it]

 44%|████▍     | 1371/3107 [2:57:49<3:50:10,  7.96s/it]
{'loss': 0.8895, 'grad_norm': 0.15818390940060506, 'learning_rate': 0.00012370176706365919, 'epoch': 0.44}


 44%|████▍     | 1373/3107 [2:58:04<3:44:35,  7.77s/it]

 44%|████▍     | 1374/3107 [2:58:15<4:11:55,  8.72s/it]
{'loss': 0.8676, 'grad_norm': 0.1651540023051912, 'learning_rate': 0.00012339776105834744, 'epoch': 0.44}


 44%|████▍     | 1376/3107 [2:58:34<4:12:48,  8.76s/it]
{'loss': 0.8965, 'grad_norm': 0.17148638613004633, 'learning_rate': 0.00012319496301663722, 'epoch': 0.44}

 44%|████▍     | 1377/3107 [2:58:41<3:56:38,  8.21s/it]


 44%|████▍     | 1379/3107 [2:58:53<3:29:35,  7.28s/it]

 44%|████▍     | 1380/3107 [2:59:00<3:24:09,  7.09s/it]

 44%|████▍     | 1381/3107 [2:59:10<3:47:30,  7.91s/it]

 44%|████▍     | 1382/3107 [2:59:16<3:29:19,  7.28s/it]

 45%|████▍     | 1383/3107 [2:59:22<3:20:27,  6.98s/it]

 45%|████▍     | 1384/3107 [2:59:30<3:28:19,  7.25s/it]

 45%|████▍     | 1385/3107 [2:59:36<3:23:27,  7.09s/it]

 45%|████▍     | 1386/3107 [2:59:44<3:28:56,  7.28s/it]

 45%|████▍     | 1387/3107 [2:59:50<3:17:23,  6.89s/it]

 45%|████▍     | 1388/3107 [3:00:00<3:45:57,  7.89s/it]

 45%|████▍     | 1389/3107 [3:00:08<3:41:08,  7.72s/it]
{'loss': 0.9096, 'grad_norm': 0.16736114526277884, 'learning_rate': 0.00012187435653076889, 'epoch': 0.45}


 45%|████▍     | 1391/3107 [3:00:20<3:19:17,  6.97s/it]

 45%|████▍     | 1392/3107 [3:00:29<3:29:13,  7.32s/it]

 45%|████▍     | 1393/3107 [3:00:36<3:33:34,  7.48s/it]
{'loss': 1.0092, 'grad_norm': 0.17999572347516135, 'learning_rate': 0.0001214671962345431, 'epoch': 0.45}


 45%|████▍     | 1395/3107 [3:00:48<3:10:43,  6.68s/it]

 45%|████▍     | 1396/3107 [3:00:58<3:33:17,  7.48s/it]

 45%|████▍     | 1397/3107 [3:01:05<3:33:49,  7.50s/it]

 45%|████▍     | 1398/3107 [3:01:11<3:22:10,  7.10s/it]

 45%|████▌     | 1399/3107 [3:01:22<3:55:10,  8.26s/it]
{'loss': 0.9052, 'grad_norm': 0.16146229274137838, 'learning_rate': 0.00012085575784504191, 'epoch': 0.45}


 45%|████▌     | 1401/3107 [3:01:36<3:33:34,  7.51s/it]

 45%|████▌     | 1402/3107 [3:01:42<3:20:16,  7.05s/it]

 45%|████▌     | 1403/3107 [3:01:49<3:20:53,  7.07s/it]

 45%|████▌     | 1404/3107 [3:01:58<3:35:59,  7.61s/it]

 45%|████▌     | 1405/3107 [3:02:07<3:51:39,  8.17s/it]

 45%|████▌     | 1406/3107 [3:02:14<3:40:45,  7.79s/it]

 45%|████▌     | 1407/3107 [3:02:20<3:23:33,  7.18s/it]

 45%|████▌     | 1408/3107 [3:02:26<3:09:41,  6.70s/it]

 45%|████▌     | 1409/3107 [3:02:34<3:24:22,  7.22s/it]

 45%|████▌     | 1410/3107 [3:02:40<3:11:23,  6.77s/it]

 45%|████▌     | 1411/3107 [3:02:46<3:05:29,  6.56s/it]

 45%|████▌     | 1412/3107 [3:02:56<3:35:57,  7.64s/it]
{'loss': 0.953, 'grad_norm': 0.15378008559814096, 'learning_rate': 0.00011952820641274518, 'epoch': 0.45}


 46%|████▌     | 1414/3107 [3:03:12<3:46:02,  8.01s/it]
{'loss': 1.0775, 'grad_norm': 0.15840181646195525, 'learning_rate': 0.00011932364316034514, 'epoch': 0.46}


 46%|████▌     | 1416/3107 [3:03:24<3:15:55,  6.95s/it]

 46%|████▌     | 1417/3107 [3:03:36<3:58:03,  8.45s/it]

 46%|████▌     | 1418/3107 [3:03:42<3:32:24,  7.55s/it]
{'loss': 1.0082, 'grad_norm': 0.1854764152991618, 'learning_rate': 0.0001189142654462335, 'epoch': 0.46}

 46%|████▌     | 1419/3107 [3:03:49<3:29:14,  7.44s/it]


 46%|████▌     | 1421/3107 [3:04:01<3:10:59,  6.80s/it]

 46%|████▌     | 1422/3107 [3:04:08<3:07:47,  6.69s/it]

 46%|████▌     | 1423/3107 [3:04:14<3:02:30,  6.50s/it]

 46%|████▌     | 1424/3107 [3:04:20<2:59:53,  6.41s/it]

 46%|████▌     | 1425/3107 [3:04:27<3:07:05,  6.67s/it]
{'loss': 0.9028, 'grad_norm': 0.19490543815474456, 'learning_rate': 0.00011819706705100529, 'epoch': 0.46}

 46%|████▌     | 1426/3107 [3:04:35<3:15:14,  6.97s/it]

 46%|████▌     | 1427/3107 [3:04:41<3:07:03,  6.68s/it]


 46%|████▌     | 1429/3107 [3:04:54<3:03:49,  6.57s/it]

 46%|████▌     | 1430/3107 [3:05:07<3:55:18,  8.42s/it]

 46%|████▌     | 1431/3107 [3:05:13<3:35:07,  7.70s/it]

 46%|████▌     | 1432/3107 [3:05:20<3:33:48,  7.66s/it]
{'loss': 0.8436, 'grad_norm': 0.15174466646882098, 'learning_rate': 0.00011747889926913838, 'epoch': 0.46}

 46%|████▌     | 1433/3107 [3:05:29<3:44:57,  8.06s/it]


 46%|████▌     | 1435/3107 [3:05:43<3:23:19,  7.30s/it]

 46%|████▌     | 1436/3107 [3:05:51<3:29:55,  7.54s/it]

 46%|████▋     | 1437/3107 [3:05:58<3:29:04,  7.51s/it]

 46%|████▋     | 1438/3107 [3:06:08<3:48:11,  8.20s/it]

 46%|████▋     | 1439/3107 [3:06:14<3:31:04,  7.59s/it]

 46%|████▋     | 1440/3107 [3:06:21<3:20:03,  7.20s/it]

 46%|████▋     | 1441/3107 [3:06:29<3:27:16,  7.46s/it]

 46%|████▋     | 1442/3107 [3:06:35<3:17:12,  7.11s/it]

 46%|████▋     | 1443/3107 [3:06:41<3:07:32,  6.76s/it]

 46%|████▋     | 1444/3107 [3:06:49<3:15:58,  7.07s/it]

 47%|████▋     | 1445/3107 [3:06:56<3:16:19,  7.09s/it]

 47%|████▋     | 1446/3107 [3:07:05<3:31:58,  7.66s/it]

 47%|████▋     | 1447/3107 [3:07:14<3:42:31,  8.04s/it]

 47%|████▋     | 1448/3107 [3:07:25<4:08:26,  8.99s/it]

 47%|████▋     | 1449/3107 [3:07:32<3:54:00,  8.47s/it]

 47%|████▋     | 1450/3107 [3:07:42<4:05:40,  8.90s/it]

 47%|████▋     | 1451/3107 [3:07:52<4:15:42,  9.26s/it]

 47%|████▋     | 1452/3107 [3:07:59<3:52:58,  8.45s/it]

 47%|████▋     | 1453/3107 [3:08:06<3:45:21,  8.17s/it]

 47%|████▋     | 1454/3107 [3:08:12<3:27:36,  7.54s/it]

 47%|████▋     | 1455/3107 [3:08:20<3:28:44,  7.58s/it]

 47%|████▋     | 1456/3107 [3:08:28<3:29:48,  7.62s/it]

 47%|████▋     | 1457/3107 [3:08:34<3:17:03,  7.17s/it]

 47%|████▋     | 1458/3107 [3:08:40<3:08:45,  6.87s/it]

 47%|████▋     | 1459/3107 [3:08:47<3:06:52,  6.80s/it]

 47%|████▋     | 1460/3107 [3:08:57<3:36:43,  7.90s/it]

 47%|████▋     | 1461/3107 [3:09:03<3:18:53,  7.25s/it]

 47%|████▋     | 1462/3107 [3:09:12<3:37:12,  7.92s/it]

 47%|████▋     | 1463/3107 [3:09:19<3:28:09,  7.60s/it]

 47%|████▋     | 1464/3107 [3:09:27<3:31:18,  7.72s/it]

 47%|████▋     | 1465/3107 [3:09:34<3:26:45,  7.56s/it]
{'loss': 1.0225, 'grad_norm': 0.18583355807396904, 'learning_rate': 0.0001140813487826651, 'epoch': 0.47}


 47%|████▋     | 1467/3107 [3:09:51<3:34:53,  7.86s/it]
{'loss': 0.9697, 'grad_norm': 0.1735444486356153, 'learning_rate': 0.0001138748602812547, 'epoch': 0.47}


 47%|████▋     | 1469/3107 [3:10:03<3:08:36,  6.91s/it]

 47%|████▋     | 1470/3107 [3:10:09<3:01:55,  6.67s/it]

 47%|████▋     | 1471/3107 [3:10:17<3:12:34,  7.06s/it]
{'loss': 0.7882, 'grad_norm': 0.16625400227075648, 'learning_rate': 0.00011346170316306355, 'epoch': 0.47}


 47%|████▋     | 1473/3107 [3:10:30<3:06:23,  6.84s/it]

 47%|████▋     | 1474/3107 [3:10:37<3:01:36,  6.67s/it]

 47%|████▋     | 1475/3107 [3:10:42<2:53:24,  6.38s/it]

 48%|████▊     | 1476/3107 [3:10:48<2:48:01,  6.18s/it]

 48%|████▊     | 1477/3107 [3:10:59<3:25:25,  7.56s/it]

 48%|████▊     | 1478/3107 [3:11:06<3:20:53,  7.40s/it]

 48%|████▊     | 1479/3107 [3:11:12<3:11:31,  7.06s/it]

 48%|████▊     | 1480/3107 [3:11:18<3:02:34,  6.73s/it]

 48%|████▊     | 1481/3107 [3:11:25<3:03:33,  6.77s/it]

 48%|████▊     | 1482/3107 [3:11:32<3:08:29,  6.96s/it]

 48%|████▊     | 1483/3107 [3:11:40<3:15:04,  7.21s/it]

 48%|████▊     | 1484/3107 [3:11:48<3:23:35,  7.53s/it]
{'loss': 1.0122, 'grad_norm': 0.16673879041820913, 'learning_rate': 0.00011211736258404864, 'epoch': 0.48}

 48%|████▊     | 1485/3107 [3:11:58<3:38:22,  8.08s/it]


 48%|████▊     | 1487/3107 [3:12:13<3:28:58,  7.74s/it]

 48%|████▊     | 1488/3107 [3:12:19<3:17:08,  7.31s/it]

 48%|████▊     | 1489/3107 [3:12:24<3:01:47,  6.74s/it]

 48%|████▊     | 1490/3107 [3:12:34<3:26:19,  7.66s/it]

 48%|████▊     | 1491/3107 [3:12:42<3:31:26,  7.85s/it]

 48%|████▊     | 1492/3107 [3:12:50<3:30:48,  7.83s/it]
{'loss': 0.9312, 'grad_norm': 0.18106662810566793, 'learning_rate': 0.0001112889537384103, 'epoch': 0.48}


 48%|████▊     | 1494/3107 [3:13:05<3:27:42,  7.73s/it]
{'loss': 0.9049, 'grad_norm': 0.17670515467699294, 'learning_rate': 0.00011108172654366467, 'epoch': 0.48}


 48%|████▊     | 1496/3107 [3:13:18<3:07:01,  6.97s/it]
{'loss': 0.8979, 'grad_norm': 0.18550639222731458, 'learning_rate': 0.00011087445115760758, 'epoch': 0.48}


 48%|████▊     | 1498/3107 [3:13:37<3:44:10,  8.36s/it]
{'loss': 0.8474, 'grad_norm': 0.15405031447472564, 'learning_rate': 0.00011066712848162135, 'epoch': 0.48}


 48%|████▊     | 1500/3107 [3:13:50<3:21:41,  7.53s/it]
 48%|████▊     | 1500/3107 [3:13:50<3:21:41,  7.53s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 48%|████▊     | 1501/3107 [3:14:33<8:06:53, 18.19s/it]

 48%|████▊     | 1502/3107 [3:14:39<6:28:52, 14.54s/it]
{'loss': 0.9623, 'grad_norm': 0.16382308366988077, 'learning_rate': 0.00011025234486641533, 'epoch': 0.48}


 48%|████▊     | 1504/3107 [3:14:54<4:56:12, 11.09s/it]

 48%|████▊     | 1505/3107 [3:15:02<4:24:48,  9.92s/it]
{'loss': 0.9726, 'grad_norm': 0.1772668470566115, 'learning_rate': 0.00010994113972596429, 'epoch': 0.48}


 49%|████▊     | 1507/3107 [3:15:16<3:46:51,  8.51s/it]
{'loss': 0.9157, 'grad_norm': 0.17040172478217297, 'learning_rate': 0.00010973361540532567, 'epoch': 0.49}

 49%|████▊     | 1508/3107 [3:15:22<3:29:00,  7.84s/it]

 49%|████▊     | 1509/3107 [3:15:28<3:12:29,  7.23s/it]


 49%|████▊     | 1511/3107 [3:15:42<3:10:03,  7.15s/it]
{'loss': 0.899, 'grad_norm': 0.17199328600389874, 'learning_rate': 0.00010931844068043138, 'epoch': 0.49}


 49%|████▊     | 1513/3107 [3:15:55<3:04:34,  6.95s/it]

 49%|████▊     | 1514/3107 [3:16:07<3:40:17,  8.30s/it]

 49%|████▉     | 1515/3107 [3:16:14<3:31:46,  7.98s/it]
{'loss': 1.1063, 'grad_norm': 0.17273516802445177, 'learning_rate': 0.00010890310386260429, 'epoch': 0.49}


 49%|████▉     | 1517/3107 [3:16:27<3:11:24,  7.22s/it]

 49%|████▉     | 1518/3107 [3:16:33<3:03:19,  6.92s/it]

 49%|████▉     | 1519/3107 [3:16:40<3:05:13,  7.00s/it]

 49%|████▉     | 1520/3107 [3:16:49<3:19:12,  7.53s/it]
{'loss': 0.9877, 'grad_norm': 0.17663697364525419, 'learning_rate': 0.00010838371590380765, 'epoch': 0.49}


 49%|████▉     | 1522/3107 [3:17:02<3:06:39,  7.07s/it]
{'loss': 1.0847, 'grad_norm': 0.1920733191094721, 'learning_rate': 0.0001081758961274257, 'epoch': 0.49}


 49%|████▉     | 1524/3107 [3:17:20<3:35:27,  8.17s/it]
{'loss': 0.935, 'grad_norm': 0.17790548964635375, 'learning_rate': 0.00010796804079637137, 'epoch': 0.49}

 49%|████▉     | 1525/3107 [3:17:30<3:46:12,  8.58s/it]


 49%|████▉     | 1527/3107 [3:17:44<3:26:34,  7.84s/it]

 49%|████▉     | 1528/3107 [3:17:51<3:13:18,  7.35s/it]

 49%|████▉     | 1529/3107 [3:18:01<3:39:55,  8.36s/it]

 49%|████▉     | 1530/3107 [3:18:07<3:19:42,  7.60s/it]

 49%|████▉     | 1531/3107 [3:18:15<3:20:30,  7.63s/it]

 49%|████▉     | 1532/3107 [3:18:21<3:11:06,  7.28s/it]

 49%|████▉     | 1533/3107 [3:18:29<3:18:03,  7.55s/it]
{'loss': 0.9802, 'grad_norm': 0.17470951333911822, 'learning_rate': 0.000107032276056981, 'epoch': 0.49}


 49%|████▉     | 1535/3107 [3:18:42<2:58:49,  6.83s/it]
{'loss': 0.938, 'grad_norm': 0.17751190863112148, 'learning_rate': 0.0001068242413364671, 'epoch': 0.49}


 49%|████▉     | 1537/3107 [3:19:00<3:23:36,  7.78s/it]

 50%|████▉     | 1538/3107 [3:19:07<3:19:44,  7.64s/it]

 50%|████▉     | 1539/3107 [3:19:12<3:02:49,  7.00s/it]

 50%|████▉     | 1540/3107 [3:19:22<3:21:25,  7.71s/it]

 50%|████▉     | 1541/3107 [3:19:33<3:45:18,  8.63s/it]

 50%|████▉     | 1542/3107 [3:19:39<3:25:13,  7.87s/it]

 50%|████▉     | 1543/3107 [3:19:44<3:07:46,  7.20s/it]

 50%|████▉     | 1544/3107 [3:19:56<3:39:21,  8.42s/it]

 50%|████▉     | 1545/3107 [3:20:04<3:37:56,  8.37s/it]
{'loss': 1.0335, 'grad_norm': 0.17123714099848997, 'learning_rate': 0.0001057836406814328, 'epoch': 0.5}


 50%|████▉     | 1547/3107 [3:20:20<3:31:43,  8.14s/it]

 50%|████▉     | 1548/3107 [3:20:29<3:36:08,  8.32s/it]

 50%|████▉     | 1549/3107 [3:20:41<4:04:10,  9.40s/it]

 50%|████▉     | 1550/3107 [3:20:46<3:37:04,  8.36s/it]
{'loss': 0.9456, 'grad_norm': 0.167274100016317, 'learning_rate': 0.00010526309748784184, 'epoch': 0.5}


 50%|████▉     | 1552/3107 [3:21:01<3:17:51,  7.63s/it]

 50%|████▉     | 1553/3107 [3:21:11<3:42:07,  8.58s/it]

 50%|█████     | 1554/3107 [3:21:19<3:36:25,  8.36s/it]

 50%|█████     | 1555/3107 [3:21:25<3:13:51,  7.49s/it]

 50%|█████     | 1556/3107 [3:21:32<3:15:40,  7.57s/it]
{'loss': 0.813, 'grad_norm': 0.17921731619493034, 'learning_rate': 0.00010463825807742398, 'epoch': 0.5}

 50%|█████     | 1557/3107 [3:21:38<3:02:14,  7.05s/it]

 50%|█████     | 1558/3107 [3:21:46<3:07:54,  7.28s/it]


 50%|█████     | 1560/3107 [3:22:00<3:04:21,  7.15s/it]

 50%|█████     | 1561/3107 [3:22:07<3:05:46,  7.21s/it]

 50%|█████     | 1562/3107 [3:22:15<3:11:59,  7.46s/it]
{'loss': 0.9466, 'grad_norm': 0.18069840223756584, 'learning_rate': 0.00010401323713321569, 'epoch': 0.5}


 50%|█████     | 1564/3107 [3:22:33<3:32:23,  8.26s/it]

 50%|█████     | 1565/3107 [3:22:41<3:24:49,  7.97s/it]

 50%|█████     | 1566/3107 [3:22:47<3:16:23,  7.65s/it]

 50%|█████     | 1567/3107 [3:22:55<3:15:39,  7.62s/it]

 50%|█████     | 1568/3107 [3:23:02<3:07:19,  7.30s/it]

 50%|█████     | 1569/3107 [3:23:09<3:05:07,  7.22s/it]

 51%|█████     | 1570/3107 [3:23:18<3:18:03,  7.73s/it]
{'loss': 1.0272, 'grad_norm': 0.16490596101428207, 'learning_rate': 0.00010317963576978267, 'epoch': 0.51}


 51%|█████     | 1572/3107 [3:23:31<3:07:30,  7.33s/it]

 51%|█████     | 1573/3107 [3:23:41<3:21:31,  7.88s/it]
{'loss': 0.8484, 'grad_norm': 0.1619217436711576, 'learning_rate': 0.00010286697510518723, 'epoch': 0.51}


 51%|█████     | 1575/3107 [3:23:54<3:08:39,  7.39s/it]

 51%|█████     | 1576/3107 [3:24:00<2:56:51,  6.93s/it]

 51%|█████     | 1577/3107 [3:24:06<2:49:01,  6.63s/it]

 51%|█████     | 1578/3107 [3:24:16<3:13:30,  7.59s/it]

 51%|█████     | 1579/3107 [3:24:23<3:12:22,  7.55s/it]

 51%|█████     | 1580/3107 [3:24:29<3:02:27,  7.17s/it]

 51%|█████     | 1581/3107 [3:24:37<3:02:31,  7.18s/it]
{'loss': 0.8404, 'grad_norm': 0.1652077573907829, 'learning_rate': 0.00010203308449861193, 'epoch': 0.51}


 51%|█████     | 1583/3107 [3:24:52<3:14:03,  7.64s/it]
{'loss': 0.887, 'grad_norm': 0.16202282400639656, 'learning_rate': 0.00010182458747709949, 'epoch': 0.51}

 51%|█████     | 1584/3107 [3:24:58<3:02:46,  7.20s/it]


 51%|█████     | 1586/3107 [3:25:10<2:43:21,  6.44s/it]

 51%|█████     | 1587/3107 [3:25:16<2:42:05,  6.40s/it]

 51%|█████     | 1588/3107 [3:25:25<2:58:34,  7.05s/it]

 51%|█████     | 1589/3107 [3:25:32<2:57:20,  7.01s/it]
{'loss': 0.8535, 'grad_norm': 0.16559807272004068, 'learning_rate': 0.00010119905243180432, 'epoch': 0.51}


 51%|█████     | 1591/3107 [3:25:48<3:11:18,  7.57s/it]

 51%|█████     | 1592/3107 [3:25:56<3:12:28,  7.62s/it]

 51%|█████▏    | 1593/3107 [3:26:02<3:05:09,  7.34s/it]

 51%|█████▏    | 1594/3107 [3:26:10<3:06:33,  7.40s/it]
{'loss': 0.8961, 'grad_norm': 0.1733601563338603, 'learning_rate': 0.00010067773633984294, 'epoch': 0.51}

 51%|█████▏    | 1595/3107 [3:26:17<3:00:00,  7.14s/it]


 51%|█████▏    | 1597/3107 [3:26:31<3:01:29,  7.21s/it]

 51%|█████▏    | 1598/3107 [3:26:37<2:53:39,  6.91s/it]

 51%|█████▏    | 1599/3107 [3:26:43<2:46:26,  6.62s/it]
{'loss': 0.9646, 'grad_norm': 0.17365620257948114, 'learning_rate': 0.00010015640182738733, 'epoch': 0.51}


 52%|█████▏    | 1601/3107 [3:27:00<3:07:21,  7.46s/it]

 52%|█████▏    | 1602/3107 [3:27:10<3:23:18,  8.11s/it]

 52%|█████▏    | 1603/3107 [3:27:16<3:04:45,  7.37s/it]

 52%|█████▏    | 1604/3107 [3:27:21<2:53:15,  6.92s/it]

 52%|█████▏    | 1605/3107 [3:27:27<2:47:04,  6.67s/it]

 52%|█████▏    | 1606/3107 [3:27:33<2:39:35,  6.38s/it]

 52%|█████▏    | 1607/3107 [3:27:41<2:48:53,  6.76s/it]
{'loss': 0.912, 'grad_norm': 0.1624998773685776, 'learning_rate': 9.932226366015708e-05, 'epoch': 0.52}

 52%|█████▏    | 1608/3107 [3:27:46<2:40:34,  6.43s/it]


 52%|█████▏    | 1610/3107 [3:27:58<2:30:36,  6.04s/it]

 52%|█████▏    | 1611/3107 [3:28:06<2:46:51,  6.69s/it]
{'loss': 0.8259, 'grad_norm': 0.17035352675428855, 'learning_rate': 9.890520863282228e-05, 'epoch': 0.52}


 52%|█████▏    | 1613/3107 [3:28:22<3:00:49,  7.26s/it]

 52%|█████▏    | 1614/3107 [3:28:31<3:17:40,  7.94s/it]
{'loss': 0.8265, 'grad_norm': 0.1712201090030888, 'learning_rate': 9.859242946304903e-05, 'epoch': 0.52}


 52%|█████▏    | 1616/3107 [3:28:44<2:57:11,  7.13s/it]

 52%|█████▏    | 1617/3107 [3:28:56<3:30:15,  8.47s/it]

 52%|█████▏    | 1618/3107 [3:29:02<3:12:15,  7.75s/it]

 52%|█████▏    | 1619/3107 [3:29:12<3:33:26,  8.61s/it]
{'loss': 0.881, 'grad_norm': 0.17513650218178584, 'learning_rate': 9.807116296364783e-05, 'epoch': 0.52}


 52%|█████▏    | 1621/3107 [3:29:32<3:54:42,  9.48s/it]

 52%|█████▏    | 1622/3107 [3:29:40<3:40:29,  8.91s/it]

 52%|█████▏    | 1623/3107 [3:29:48<3:33:17,  8.62s/it]

 52%|█████▏    | 1624/3107 [3:29:58<3:41:37,  8.97s/it]
{'loss': 0.9151, 'grad_norm': 0.17124007842056516, 'learning_rate': 9.754994888895744e-05, 'epoch': 0.52}

 52%|█████▏    | 1625/3107 [3:30:05<3:26:56,  8.38s/it]


 52%|█████▏    | 1627/3107 [3:30:20<3:19:18,  8.08s/it]

 52%|█████▏    | 1628/3107 [3:30:26<3:05:14,  7.51s/it]
{'loss': 0.997, 'grad_norm': 0.1937300358695413, 'learning_rate': 9.71330248948128e-05, 'epoch': 0.52}


 52%|█████▏    | 1630/3107 [3:30:39<2:55:03,  7.11s/it]
{'loss': 0.9799, 'grad_norm': 0.17844218054130906, 'learning_rate': 9.692458114598413e-05, 'epoch': 0.52}


 53%|█████▎    | 1632/3107 [3:30:52<2:44:55,  6.71s/it]
{'loss': 0.8783, 'grad_norm': 0.17844083706564878, 'learning_rate': 9.671615077128692e-05, 'epoch': 0.53}

 53%|█████▎    | 1633/3107 [3:31:05<3:29:29,  8.53s/it]


 53%|█████▎    | 1635/3107 [3:31:18<3:03:32,  7.48s/it]

 53%|█████▎    | 1636/3107 [3:31:24<2:48:25,  6.87s/it]
{'loss': 0.9491, 'grad_norm': 0.18222366184145855, 'learning_rate': 9.629933376984518e-05, 'epoch': 0.53}

 53%|█████▎    | 1637/3107 [3:31:33<3:03:53,  7.51s/it]


 53%|█████▎    | 1639/3107 [3:31:50<3:21:19,  8.23s/it]
{'loss': 1.0035, 'grad_norm': 0.17304987606082822, 'learning_rate': 9.598676286678434e-05, 'epoch': 0.53}
[2024-05-28 01:56:11,282] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 53%|█████▎    | 1641/3107 [3:32:10<3:37:47,  8.91s/it]
{'loss': 1.0338, 'grad_norm': 0.17144419306617795, 'learning_rate': 9.577840389150935e-05, 'epoch': 0.53}


 53%|█████▎    | 1643/3107 [3:32:28<3:45:27,  9.24s/it]
{'loss': 0.9311, 'grad_norm': 0.1643025572660052, 'learning_rate': 9.557006327476837e-05, 'epoch': 0.53}


 53%|█████▎    | 1645/3107 [3:32:48<3:56:03,  9.69s/it]
{'loss': 0.9412, 'grad_norm': 0.17720362018796276, 'learning_rate': 9.536174192257603e-05, 'epoch': 0.53}


 53%|█████▎    | 1647/3107 [3:33:02<3:22:17,  8.31s/it]
{'loss': 0.9362, 'grad_norm': 0.17317744070925312, 'learning_rate': 9.515344074086332e-05, 'epoch': 0.53}


 53%|█████▎    | 1649/3107 [3:33:18<3:17:33,  8.13s/it]

 53%|█████▎    | 1650/3107 [3:33:30<3:48:13,  9.40s/it]
{'loss': 0.857, 'grad_norm': 0.1764253506709463, 'learning_rate': 9.484102876945075e-05, 'epoch': 0.53}


 53%|█████▎    | 1652/3107 [3:33:44<3:18:53,  8.20s/it]

 53%|█████▎    | 1653/3107 [3:33:52<3:15:15,  8.06s/it]
{'loss': 0.9618, 'grad_norm': 0.18366657786145527, 'learning_rate': 9.452866727657331e-05, 'epoch': 0.53}


 53%|█████▎    | 1655/3107 [3:34:08<3:14:44,  8.05s/it]

 53%|█████▎    | 1656/3107 [3:34:14<3:00:49,  7.48s/it]
{'loss': 0.9743, 'grad_norm': 0.17133155940688918, 'learning_rate': 9.421635931856723e-05, 'epoch': 0.53}

 53%|█████▎    | 1657/3107 [3:34:21<2:54:46,  7.23s/it]


 53%|█████▎    | 1659/3107 [3:34:34<2:47:38,  6.95s/it]

 53%|█████▎    | 1660/3107 [3:34:44<3:07:46,  7.79s/it]

 53%|█████▎    | 1661/3107 [3:34:50<2:53:32,  7.20s/it]

 53%|█████▎    | 1662/3107 [3:34:57<2:50:40,  7.09s/it]
{'loss': 0.8425, 'grad_norm': 0.16777225641559004, 'learning_rate': 9.359191622986489e-05, 'epoch': 0.53}


 54%|█████▎    | 1664/3107 [3:35:12<2:55:33,  7.30s/it]

 54%|█████▎    | 1665/3107 [3:35:18<2:45:19,  6.88s/it]

 54%|█████▎    | 1666/3107 [3:35:28<3:10:39,  7.94s/it]

 54%|█████▎    | 1667/3107 [3:35:38<3:24:36,  8.53s/it]
{'loss': 0.9829, 'grad_norm': 0.17569149918255808, 'learning_rate': 9.307173753714186e-05, 'epoch': 0.54}

 54%|█████▎    | 1668/3107 [3:35:45<3:13:12,  8.06s/it]


 54%|█████▎    | 1670/3107 [3:35:59<2:54:01,  7.27s/it]
{'loss': 0.87, 'grad_norm': 0.17326016665666374, 'learning_rate': 9.275971980389552e-05, 'epoch': 0.54}


 54%|█████▍    | 1672/3107 [3:36:15<2:59:58,  7.53s/it]
{'loss': 0.9654, 'grad_norm': 0.17113727215609878, 'learning_rate': 9.255174715071395e-05, 'epoch': 0.54}

 54%|█████▍    | 1673/3107 [3:36:23<3:08:18,  7.88s/it]

 54%|█████▍    | 1674/3107 [3:36:29<2:53:37,  7.27s/it]


 54%|█████▍    | 1676/3107 [3:36:43<2:46:38,  6.99s/it]

 54%|█████▍    | 1677/3107 [3:36:51<2:56:17,  7.40s/it]

 54%|█████▍    | 1678/3107 [3:36:59<2:58:17,  7.49s/it]
{'loss': 0.9105, 'grad_norm': 0.1659538133106632, 'learning_rate': 9.192802715025788e-05, 'epoch': 0.54}

 54%|█████▍    | 1679/3107 [3:37:08<3:10:32,  8.01s/it]

 54%|█████▍    | 1680/3107 [3:37:14<2:54:41,  7.35s/it]
[2024-05-28 02:01:37,709] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 54%|█████▍    | 1682/3107 [3:37:35<3:25:30,  8.65s/it]

 54%|█████▍    | 1683/3107 [3:37:41<3:09:18,  7.98s/it]

 54%|█████▍    | 1684/3107 [3:37:46<2:51:12,  7.22s/it]

 54%|█████▍    | 1685/3107 [3:37:52<2:41:49,  6.83s/it]
{'loss': 0.853, 'grad_norm': 0.1756895492089561, 'learning_rate': 9.120075482228604e-05, 'epoch': 0.54}


 54%|█████▍    | 1687/3107 [3:38:04<2:31:00,  6.38s/it]

 54%|█████▍    | 1688/3107 [3:38:11<2:34:36,  6.54s/it]
{'loss': 0.7336, 'grad_norm': 0.15769967390051448, 'learning_rate': 9.088920791834625e-05, 'epoch': 0.54}


 54%|█████▍    | 1690/3107 [3:38:23<2:26:30,  6.20s/it]
{'loss': 1.0318, 'grad_norm': 0.17032496261779898, 'learning_rate': 9.068155931956864e-05, 'epoch': 0.54}


 54%|█████▍    | 1692/3107 [3:38:43<3:08:27,  7.99s/it]

 54%|█████▍    | 1693/3107 [3:38:53<3:24:43,  8.69s/it]
[2024-05-28 02:03:03,065] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 55%|█████▍    | 1694/3107 [3:39:00<3:16:28,  8.34s/it]
{'loss': 0.8954, 'grad_norm': 0.172497982493067, 'learning_rate': 9.026638459467435e-05, 'epoch': 0.55}


 55%|█████▍    | 1696/3107 [3:39:15<3:03:04,  7.78s/it]

 55%|█████▍    | 1697/3107 [3:39:21<2:53:22,  7.38s/it]
{'loss': 0.9259, 'grad_norm': 0.18362915597155816, 'learning_rate': 8.995511426902723e-05, 'epoch': 0.55}

 55%|█████▍    | 1698/3107 [3:39:29<2:58:57,  7.62s/it]

 55%|█████▍    | 1699/3107 [3:39:36<2:49:32,  7.22s/it]


 55%|█████▍    | 1701/3107 [3:39:50<2:50:25,  7.27s/it]

 55%|█████▍    | 1702/3107 [3:39:58<2:53:56,  7.43s/it]

 55%|█████▍    | 1703/3107 [3:40:04<2:42:12,  6.93s/it]
{'loss': 0.9009, 'grad_norm': 0.17891808151129135, 'learning_rate': 8.933287151837868e-05, 'epoch': 0.55}


 55%|█████▍    | 1705/3107 [3:40:19<2:50:14,  7.29s/it]

 55%|█████▍    | 1706/3107 [3:40:25<2:42:00,  6.94s/it]
{'loss': 0.9638, 'grad_norm': 0.17402877504355865, 'learning_rate': 8.90219051817815e-05, 'epoch': 0.55}


 55%|█████▍    | 1708/3107 [3:40:41<2:56:24,  7.57s/it]

 55%|█████▌    | 1709/3107 [3:40:47<2:44:47,  7.07s/it]

 55%|█████▌    | 1710/3107 [3:40:53<2:36:51,  6.74s/it]

 55%|█████▌    | 1711/3107 [3:40:59<2:32:59,  6.58s/it]

 55%|█████▌    | 1712/3107 [3:41:05<2:30:23,  6.47s/it]
{'loss': 0.7738, 'grad_norm': 0.16940754714773226, 'learning_rate': 8.84002977994374e-05, 'epoch': 0.55}


 55%|█████▌    | 1714/3107 [3:41:19<2:35:27,  6.70s/it]

 55%|█████▌    | 1715/3107 [3:41:25<2:32:00,  6.55s/it]
{'loss': 0.996, 'grad_norm': 0.16246653807058298, 'learning_rate': 8.808966283587794e-05, 'epoch': 0.55}


 55%|█████▌    | 1717/3107 [3:41:43<3:02:45,  7.89s/it]

 55%|█████▌    | 1718/3107 [3:41:53<3:15:33,  8.45s/it]

 55%|█████▌    | 1719/3107 [3:42:03<3:27:32,  8.97s/it]
{'loss': 0.942, 'grad_norm': 0.16680211286113697, 'learning_rate': 8.767566469102613e-05, 'epoch': 0.55}

 55%|█████▌    | 1720/3107 [3:42:10<3:09:58,  8.22s/it]

 55%|█████▌    | 1721/3107 [3:42:16<2:57:52,  7.70s/it]

 55%|█████▌    | 1722/3107 [3:42:24<2:56:04,  7.63s/it]


 55%|█████▌    | 1724/3107 [3:42:39<3:00:40,  7.84s/it]

 56%|█████▌    | 1725/3107 [3:42:53<3:42:00,  9.64s/it]

 56%|█████▌    | 1726/3107 [3:42:59<3:19:34,  8.67s/it]

 56%|█████▌    | 1727/3107 [3:43:06<3:08:21,  8.19s/it]
{'loss': 0.9011, 'grad_norm': 0.17109165211288682, 'learning_rate': 8.684831873914145e-05, 'epoch': 0.56}


 56%|█████▌    | 1729/3107 [3:43:28<3:44:48,  9.79s/it]

 56%|█████▌    | 1730/3107 [3:43:35<3:19:43,  8.70s/it]

 56%|█████▌    | 1731/3107 [3:43:42<3:12:32,  8.40s/it]

 56%|█████▌    | 1732/3107 [3:43:49<3:01:29,  7.92s/it]
{'loss': 0.9891, 'grad_norm': 0.18281485232840194, 'learning_rate': 8.633168855802011e-05, 'epoch': 0.56}


 56%|█████▌    | 1734/3107 [3:44:03<2:49:14,  7.40s/it]

 56%|█████▌    | 1735/3107 [3:44:09<2:41:35,  7.07s/it]

 56%|█████▌    | 1736/3107 [3:44:16<2:43:04,  7.14s/it]

 56%|█████▌    | 1737/3107 [3:44:23<2:37:41,  6.91s/it]
{'loss': 0.9787, 'grad_norm': 0.1833700959757117, 'learning_rate': 8.581542987395181e-05, 'epoch': 0.56}


 56%|█████▌    | 1739/3107 [3:44:41<3:08:26,  8.26s/it]

 56%|█████▌    | 1740/3107 [3:44:49<3:01:50,  7.98s/it]

 56%|█████▌    | 1741/3107 [3:44:55<2:54:07,  7.65s/it]
{'loss': 0.9959, 'grad_norm': 0.179212808481001, 'learning_rate': 8.540269983417437e-05, 'epoch': 0.56}


 56%|█████▌    | 1743/3107 [3:45:09<2:41:04,  7.09s/it]
{'loss': 0.9208, 'grad_norm': 0.16965229774763163, 'learning_rate': 8.51964295849703e-05, 'epoch': 0.56}


 56%|█████▌    | 1745/3107 [3:45:21<2:29:45,  6.60s/it]
{'loss': 1.0669, 'grad_norm': 0.1823180443197918, 'learning_rate': 8.499022371232975e-05, 'epoch': 0.56}


 56%|█████▌    | 1747/3107 [3:45:37<2:52:34,  7.61s/it]

 56%|█████▋    | 1748/3107 [3:45:43<2:40:23,  7.08s/it]

 56%|█████▋    | 1749/3107 [3:45:53<2:58:02,  7.87s/it]

 56%|█████▋    | 1750/3107 [3:45:59<2:47:55,  7.42s/it]
{'loss': 0.8809, 'grad_norm': 0.18994568062866252, 'learning_rate': 8.447499656229344e-05, 'epoch': 0.56}


 56%|█████▋    | 1752/3107 [3:46:15<2:48:52,  7.48s/it]
{'loss': 0.9003, 'grad_norm': 0.18777472226514152, 'learning_rate': 8.4269023067512e-05, 'epoch': 0.56}

 56%|█████▋    | 1753/3107 [3:46:24<2:58:32,  7.91s/it]


 56%|█████▋    | 1755/3107 [3:46:41<3:04:39,  8.19s/it]
{'loss': 0.8928, 'grad_norm': 0.18450798234895413, 'learning_rate': 8.396019137315921e-05, 'epoch': 0.56}


 57%|█████▋    | 1757/3107 [3:46:55<2:58:01,  7.91s/it]

 57%|█████▋    | 1758/3107 [3:47:05<3:07:45,  8.35s/it]

 57%|█████▋    | 1759/3107 [3:47:11<2:53:41,  7.73s/it]
{'loss': 0.974, 'grad_norm': 0.16997295352443287, 'learning_rate': 8.354866043679887e-05, 'epoch': 0.57}

 57%|█████▋    | 1760/3107 [3:47:18<2:47:56,  7.48s/it]


 57%|█████▋    | 1762/3107 [3:47:33<2:44:21,  7.33s/it]

 57%|█████▋    | 1763/3107 [3:47:40<2:42:01,  7.23s/it]

 57%|█████▋    | 1764/3107 [3:47:47<2:40:46,  7.18s/it]

 57%|█████▋    | 1765/3107 [3:47:55<2:48:43,  7.54s/it]

 57%|█████▋    | 1766/3107 [3:48:02<2:42:16,  7.26s/it]

 57%|█████▋    | 1767/3107 [3:48:07<2:32:57,  6.85s/it]

 57%|█████▋    | 1768/3107 [3:48:14<2:28:34,  6.66s/it]

 57%|█████▋    | 1769/3107 [3:48:19<2:21:38,  6.35s/it]

 57%|█████▋    | 1770/3107 [3:48:25<2:19:59,  6.28s/it]

 57%|█████▋    | 1771/3107 [3:48:33<2:29:31,  6.71s/it]

 57%|█████▋    | 1772/3107 [3:48:39<2:22:46,  6.42s/it]

 57%|█████▋    | 1773/3107 [3:48:45<2:21:50,  6.38s/it]
{'loss': 0.8333, 'grad_norm': 0.17014877378734286, 'learning_rate': 8.211060267044191e-05, 'epoch': 0.57}

 57%|█████▋    | 1774/3107 [3:48:52<2:24:19,  6.50s/it]

 57%|█████▋    | 1775/3107 [3:48:58<2:22:55,  6.44s/it]


 57%|█████▋    | 1777/3107 [3:49:13<2:30:45,  6.80s/it]

 57%|█████▋    | 1778/3107 [3:49:21<2:37:45,  7.12s/it]
{'loss': 0.8648, 'grad_norm': 0.1762441021458184, 'learning_rate': 8.159791853296811e-05, 'epoch': 0.57}

 57%|█████▋    | 1779/3107 [3:49:32<3:06:37,  8.43s/it]

 57%|█████▋    | 1780/3107 [3:49:38<2:52:08,  7.78s/it]


 57%|█████▋    | 1782/3107 [3:49:55<2:57:30,  8.04s/it]

 57%|█████▋    | 1783/3107 [3:50:04<3:01:51,  8.24s/it]
{'loss': 0.9469, 'grad_norm': 0.17601499553507557, 'learning_rate': 8.108573455376654e-05, 'epoch': 0.57}


 57%|█████▋    | 1785/3107 [3:50:20<2:58:37,  8.11s/it]

 57%|█████▋    | 1786/3107 [3:50:27<2:54:32,  7.93s/it]

 58%|█████▊    | 1787/3107 [3:50:39<3:20:39,  9.12s/it]

 58%|█████▊    | 1788/3107 [3:50:47<3:11:55,  8.73s/it]

 58%|█████▊    | 1789/3107 [3:50:54<2:58:31,  8.13s/it]
{'loss': 0.9355, 'grad_norm': 0.16958121639497126, 'learning_rate': 8.047179358725487e-05, 'epoch': 0.58}

 58%|█████▊    | 1790/3107 [3:51:03<3:03:05,  8.34s/it]

 58%|█████▊    | 1791/3107 [3:51:11<3:00:15,  8.22s/it]


 58%|█████▊    | 1793/3107 [3:51:29<3:12:17,  8.78s/it]

 58%|█████▊    | 1794/3107 [3:51:36<2:56:36,  8.07s/it]

 58%|█████▊    | 1795/3107 [3:51:43<2:51:39,  7.85s/it]

 58%|█████▊    | 1796/3107 [3:51:51<2:52:13,  7.88s/it]

 58%|█████▊    | 1797/3107 [3:51:58<2:44:49,  7.55s/it]

 58%|█████▊    | 1798/3107 [3:52:03<2:32:11,  6.98s/it]

 58%|█████▊    | 1799/3107 [3:52:10<2:28:08,  6.80s/it]

 58%|█████▊    | 1800/3107 [3:52:17<2:32:07,  6.98s/it]
 58%|█████▊    | 1800/3107 [3:52:17<2:32:07,  6.98s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 58%|█████▊    | 1801/3107 [3:53:12<7:42:40, 21.26s/it]

 58%|█████▊    | 1802/3107 [3:53:18<6:04:40, 16.77s/it]

 58%|█████▊    | 1803/3107 [3:53:31<5:39:54, 15.64s/it]
{'loss': 0.8027, 'grad_norm': 0.15372894339037513, 'learning_rate': 7.904227842530525e-05, 'epoch': 0.58}


 58%|█████▊    | 1805/3107 [3:53:48<4:15:40, 11.78s/it]

 58%|█████▊    | 1806/3107 [3:53:53<3:34:19,  9.88s/it]

 58%|█████▊    | 1807/3107 [3:53:59<3:10:42,  8.80s/it]
{'loss': 1.0047, 'grad_norm': 0.17495888740005427, 'learning_rate': 7.863465246300212e-05, 'epoch': 0.58}

 58%|█████▊    | 1808/3107 [3:54:06<2:58:05,  8.23s/it]

 58%|█████▊    | 1809/3107 [3:54:12<2:43:22,  7.55s/it]

 58%|█████▊    | 1810/3107 [3:54:19<2:36:17,  7.23s/it]


 58%|█████▊    | 1812/3107 [3:54:34<2:44:34,  7.63s/it]

 58%|█████▊    | 1813/3107 [3:54:44<2:55:49,  8.15s/it]

 58%|█████▊    | 1814/3107 [3:54:49<2:40:44,  7.46s/it]
{'loss': 1.021, 'grad_norm': 0.17889766883489117, 'learning_rate': 7.792220556669929e-05, 'epoch': 0.58}


 58%|█████▊    | 1816/3107 [3:55:04<2:38:49,  7.38s/it]
{'loss': 0.8729, 'grad_norm': 0.17841044117456784, 'learning_rate': 7.771886367428495e-05, 'epoch': 0.58}


 59%|█████▊    | 1818/3107 [3:55:18<2:35:10,  7.22s/it]

 59%|█████▊    | 1819/3107 [3:55:26<2:38:13,  7.37s/it]
{'loss': 0.8745, 'grad_norm': 0.1665919687452095, 'learning_rate': 7.741403278887397e-05, 'epoch': 0.59}

 59%|█████▊    | 1820/3107 [3:55:34<2:47:31,  7.81s/it]

 59%|█████▊    | 1821/3107 [3:55:41<2:38:09,  7.38s/it]

 59%|█████▊    | 1822/3107 [3:55:49<2:40:36,  7.50s/it]


 59%|█████▊    | 1824/3107 [3:56:01<2:26:20,  6.84s/it]
{'loss': 0.9176, 'grad_norm': 0.17977673558295787, 'learning_rate': 7.690647388499305e-05, 'epoch': 0.59}

 59%|█████▊    | 1825/3107 [3:56:07<2:18:45,  6.49s/it]

 59%|█████▉    | 1826/3107 [3:56:12<2:12:25,  6.20s/it]


 59%|█████▉    | 1828/3107 [3:56:26<2:18:09,  6.48s/it]

 59%|█████▉    | 1829/3107 [3:56:32<2:11:11,  6.16s/it]

 59%|█████▉    | 1830/3107 [3:56:38<2:11:38,  6.18s/it]
{'loss': 0.9143, 'grad_norm': 0.16960048646831163, 'learning_rate': 7.629823293634084e-05, 'epoch': 0.59}

 59%|█████▉    | 1831/3107 [3:56:45<2:15:40,  6.38s/it]


 59%|█████▉    | 1833/3107 [3:56:58<2:20:04,  6.60s/it]

 59%|█████▉    | 1834/3107 [3:57:08<2:40:05,  7.55s/it]

 59%|█████▉    | 1835/3107 [3:57:14<2:32:32,  7.20s/it]

 59%|█████▉    | 1836/3107 [3:57:20<2:23:47,  6.79s/it]

 59%|█████▉    | 1837/3107 [3:57:26<2:18:58,  6.57s/it]

 59%|█████▉    | 1838/3107 [3:57:33<2:23:26,  6.78s/it]
{'loss': 0.9223, 'grad_norm': 0.17427014101615662, 'learning_rate': 7.548869212239642e-05, 'epoch': 0.59}

 59%|█████▉    | 1839/3107 [3:57:39<2:16:25,  6.46s/it]


 59%|█████▉    | 1841/3107 [3:57:56<2:32:31,  7.23s/it]

 59%|█████▉    | 1842/3107 [3:58:06<2:51:33,  8.14s/it]
{'loss': 0.886, 'grad_norm': 0.17311319594552435, 'learning_rate': 7.508455775278867e-05, 'epoch': 0.59}


 59%|█████▉    | 1844/3107 [3:58:20<2:38:17,  7.52s/it]
{'loss': 0.8841, 'grad_norm': 0.18310763229819613, 'learning_rate': 7.48826526541094e-05, 'epoch': 0.59}

 59%|█████▉    | 1845/3107 [3:58:27<2:33:59,  7.32s/it]


 59%|█████▉    | 1847/3107 [3:58:39<2:23:32,  6.84s/it]

 59%|█████▉    | 1848/3107 [3:58:46<2:25:03,  6.91s/it]

 60%|█████▉    | 1849/3107 [3:58:56<2:43:12,  7.78s/it]

 60%|█████▉    | 1850/3107 [3:59:05<2:51:15,  8.17s/it]

 60%|█████▉    | 1851/3107 [3:59:14<2:53:18,  8.28s/it]
{'loss': 0.7638, 'grad_norm': 0.16741509248269298, 'learning_rate': 7.417685073918757e-05, 'epoch': 0.6}

 60%|█████▉    | 1852/3107 [3:59:23<2:59:37,  8.59s/it]


 60%|█████▉    | 1854/3107 [3:59:38<2:44:52,  7.90s/it]

 60%|█████▉    | 1855/3107 [3:59:43<2:29:47,  7.18s/it]

 60%|█████▉    | 1856/3107 [3:59:52<2:41:12,  7.73s/it]
{'loss': 1.0039, 'grad_norm': 0.15953367556783732, 'learning_rate': 7.367354655340716e-05, 'epoch': 0.6}


 60%|█████▉    | 1858/3107 [4:00:10<2:47:45,  8.06s/it]

 60%|█████▉    | 1859/3107 [4:00:16<2:34:32,  7.43s/it]
{'loss': 0.8972, 'grad_norm': 0.18037753415619082, 'learning_rate': 7.337190662562174e-05, 'epoch': 0.6}


 60%|█████▉    | 1861/3107 [4:00:32<2:41:51,  7.79s/it]

 60%|█████▉    | 1862/3107 [4:00:41<2:44:27,  7.93s/it]

 60%|█████▉    | 1863/3107 [4:00:48<2:38:53,  7.66s/it]
{'loss': 0.8941, 'grad_norm': 0.16896751035984997, 'learning_rate': 7.297012585812136e-05, 'epoch': 0.6}


 60%|██████    | 1865/3107 [4:01:00<2:21:06,  6.82s/it]
{'loss': 1.0813, 'grad_norm': 0.17270454309283137, 'learning_rate': 7.276941135566884e-05, 'epoch': 0.6}


 60%|██████    | 1867/3107 [4:01:12<2:12:47,  6.43s/it]
{'loss': 0.8659, 'grad_norm': 0.16457399744537002, 'learning_rate': 7.256881527138637e-05, 'epoch': 0.6}


 60%|██████    | 1869/3107 [4:01:22<2:02:35,  5.94s/it]

 60%|██████    | 1870/3107 [4:01:30<2:14:47,  6.54s/it]

 60%|██████    | 1871/3107 [4:01:36<2:08:40,  6.25s/it]

 60%|██████    | 1872/3107 [4:01:42<2:09:52,  6.31s/it]

 60%|██████    | 1873/3107 [4:01:48<2:04:41,  6.06s/it]

 60%|██████    | 1874/3107 [4:01:54<2:06:21,  6.15s/it]

 60%|██████    | 1875/3107 [4:02:00<2:00:53,  5.89s/it]
{'loss': 0.9943, 'grad_norm': 0.19255936888164474, 'learning_rate': 7.176763255487196e-05, 'epoch': 0.6}


 60%|██████    | 1877/3107 [4:02:16<2:26:09,  7.13s/it]
{'loss': 0.8656, 'grad_norm': 0.17785226977531382, 'learning_rate': 7.156764163604692e-05, 'epoch': 0.6}

 60%|██████    | 1878/3107 [4:02:25<2:39:28,  7.79s/it]


 61%|██████    | 1880/3107 [4:02:42<2:51:04,  8.37s/it]

 61%|██████    | 1881/3107 [4:02:48<2:37:12,  7.69s/it]
{'loss': 0.9279, 'grad_norm': 0.16713016410593867, 'learning_rate': 7.116803160054897e-05, 'epoch': 0.61}


 61%|██████    | 1883/3107 [4:03:08<2:55:10,  8.59s/it]

 61%|██████    | 1884/3107 [4:03:18<3:08:47,  9.26s/it]
{'loss': 0.8388, 'grad_norm': 0.17497918283770184, 'learning_rate': 7.086865282181841e-05, 'epoch': 0.61}


 61%|██████    | 1886/3107 [4:03:33<2:47:06,  8.21s/it]

 61%|██████    | 1887/3107 [4:03:38<2:31:33,  7.45s/it]

 61%|██████    | 1888/3107 [4:03:48<2:45:34,  8.15s/it]
{'loss': 0.9849, 'grad_norm': 0.16441896604219217, 'learning_rate': 7.046992501666195e-05, 'epoch': 0.61}


 61%|██████    | 1890/3107 [4:04:06<2:59:19,  8.84s/it]

 61%|██████    | 1891/3107 [4:04:13<2:43:46,  8.08s/it]
{'loss': 1.1063, 'grad_norm': 0.1867850579020537, 'learning_rate': 7.017121588068257e-05, 'epoch': 0.61}


 61%|██████    | 1893/3107 [4:04:31<2:49:42,  8.39s/it]

 61%|██████    | 1894/3107 [4:04:38<2:41:59,  8.01s/it]
{'loss': 0.9995, 'grad_norm': 0.168342032410736, 'learning_rate': 6.987279860780148e-05, 'epoch': 0.61}

 61%|██████    | 1895/3107 [4:04:43<2:27:55,  7.32s/it]


 61%|██████    | 1897/3107 [4:04:57<2:19:02,  6.89s/it]

 61%|██████    | 1898/3107 [4:05:04<2:21:13,  7.01s/it]
{'loss': 1.078, 'grad_norm': 0.16851698037598517, 'learning_rate': 6.947536796621199e-05, 'epoch': 0.61}

 61%|██████    | 1899/3107 [4:05:11<2:22:44,  7.09s/it]


 61%|██████    | 1901/3107 [4:05:29<2:44:09,  8.17s/it]

 61%|██████    | 1902/3107 [4:05:37<2:43:40,  8.15s/it]

 61%|██████    | 1903/3107 [4:05:44<2:40:33,  8.00s/it]
{'loss': 1.0281, 'grad_norm': 0.18178971317120257, 'learning_rate': 6.897932715227164e-05, 'epoch': 0.61}


 61%|██████▏   | 1905/3107 [4:05:58<2:28:56,  7.43s/it]

 61%|██████▏   | 1906/3107 [4:06:04<2:20:11,  7.00s/it]
{'loss': 0.9897, 'grad_norm': 0.17565789702284965, 'learning_rate': 6.868210650177167e-05, 'epoch': 0.61}

 61%|██████▏   | 1907/3107 [4:06:13<2:31:15,  7.56s/it]


 61%|██████▏   | 1909/3107 [4:06:28<2:29:17,  7.48s/it]

 61%|██████▏   | 1910/3107 [4:06:36<2:30:21,  7.54s/it]

 62%|██████▏   | 1911/3107 [4:06:44<2:35:31,  7.80s/it]
{'loss': 0.8856, 'grad_norm': 0.1659934264647333, 'learning_rate': 6.818742114896184e-05, 'epoch': 0.62}


 62%|██████▏   | 1913/3107 [4:06:58<2:28:28,  7.46s/it]

 62%|██████▏   | 1914/3107 [4:07:04<2:22:04,  7.15s/it]
{'loss': 1.0296, 'grad_norm': 0.17105060357156976, 'learning_rate': 6.789102410883201e-05, 'epoch': 0.62}

 62%|██████▏   | 1915/3107 [4:07:12<2:22:50,  7.19s/it]

 62%|██████▏   | 1916/3107 [4:07:20<2:27:43,  7.44s/it]


 62%|██████▏   | 1918/3107 [4:07:32<2:14:49,  6.80s/it]
{'loss': 0.7402, 'grad_norm': 0.17297990696608118, 'learning_rate': 6.749631727108278e-05, 'epoch': 0.62}

 62%|██████▏   | 1919/3107 [4:07:38<2:07:41,  6.45s/it]

 62%|██████▏   | 1920/3107 [4:07:44<2:05:51,  6.36s/it]


 62%|██████▏   | 1922/3107 [4:07:58<2:16:26,  6.91s/it]
{'loss': 0.9746, 'grad_norm': 0.17856484662842204, 'learning_rate': 6.710217583021059e-05, 'epoch': 0.62}

 62%|██████▏   | 1923/3107 [4:08:04<2:07:59,  6.49s/it]


 62%|██████▏   | 1925/3107 [4:08:20<2:26:40,  7.45s/it]

 62%|██████▏   | 1926/3107 [4:08:31<2:46:36,  8.46s/it]

 62%|██████▏   | 1927/3107 [4:08:39<2:41:55,  8.23s/it]

 62%|██████▏   | 1928/3107 [4:08:46<2:37:38,  8.02s/it]
{'loss': 0.9528, 'grad_norm': 0.1776336563713588, 'learning_rate': 6.651203878290139e-05, 'epoch': 0.62}


 62%|██████▏   | 1930/3107 [4:09:00<2:25:50,  7.43s/it]

 62%|██████▏   | 1931/3107 [4:09:11<2:46:42,  8.51s/it]

 62%|██████▏   | 1932/3107 [4:09:19<2:42:00,  8.27s/it]

 62%|██████▏   | 1933/3107 [4:09:27<2:39:31,  8.15s/it]
{'loss': 0.7492, 'grad_norm': 0.165647050705829, 'learning_rate': 6.602125813292726e-05, 'epoch': 0.62}

 62%|██████▏   | 1934/3107 [4:09:38<2:57:33,  9.08s/it]


 62%|██████▏   | 1936/3107 [4:09:52<2:39:41,  8.18s/it]

 62%|██████▏   | 1937/3107 [4:09:59<2:30:50,  7.74s/it]

 62%|██████▏   | 1938/3107 [4:10:07<2:32:48,  7.84s/it]

 62%|██████▏   | 1939/3107 [4:10:12<2:18:43,  7.13s/it]
{'loss': 0.9317, 'grad_norm': 0.1880019859202391, 'learning_rate': 6.54335415756396e-05, 'epoch': 0.62}

 62%|██████▏   | 1940/3107 [4:10:20<2:19:36,  7.18s/it]


 63%|██████▎   | 1942/3107 [4:10:35<2:22:59,  7.36s/it]
{'loss': 0.8609, 'grad_norm': 0.1757386640812712, 'learning_rate': 6.514018918928054e-05, 'epoch': 0.63}


 63%|██████▎   | 1944/3107 [4:10:49<2:17:04,  7.07s/it]

 63%|██████▎   | 1945/3107 [4:10:55<2:14:44,  6.96s/it]

 63%|██████▎   | 1946/3107 [4:11:01<2:08:48,  6.66s/it]

 63%|██████▎   | 1947/3107 [4:11:09<2:14:45,  6.97s/it]

 63%|██████▎   | 1948/3107 [4:11:16<2:16:27,  7.06s/it]

 63%|██████▎   | 1949/3107 [4:11:22<2:10:22,  6.76s/it]
{'loss': 0.8885, 'grad_norm': 0.18233551450959645, 'learning_rate': 6.445703170272603e-05, 'epoch': 0.63}


 63%|██████▎   | 1951/3107 [4:11:37<2:16:12,  7.07s/it]

 63%|██████▎   | 1952/3107 [4:11:43<2:08:41,  6.69s/it]

 63%|██████▎   | 1953/3107 [4:11:53<2:29:24,  7.77s/it]

 63%|██████▎   | 1954/3107 [4:12:05<2:52:12,  8.96s/it]
{'loss': 0.8857, 'grad_norm': 0.15889007842145797, 'learning_rate': 6.39702191944657e-05, 'epoch': 0.63}


 63%|██████▎   | 1956/3107 [4:12:19<2:31:37,  7.90s/it]

 63%|██████▎   | 1957/3107 [4:12:25<2:23:08,  7.47s/it]
{'loss': 1.0046, 'grad_norm': 0.20037222240003605, 'learning_rate': 6.367860089306028e-05, 'epoch': 0.63}

 63%|██████▎   | 1958/3107 [4:12:32<2:18:09,  7.21s/it]


 63%|██████▎   | 1960/3107 [4:12:47<2:24:56,  7.58s/it]

 63%|██████▎   | 1961/3107 [4:12:55<2:28:31,  7.78s/it]
{'loss': 0.9377, 'grad_norm': 0.16458182699124826, 'learning_rate': 6.329032981402747e-05, 'epoch': 0.63}


 63%|██████▎   | 1963/3107 [4:13:08<2:16:18,  7.15s/it]
{'loss': 0.8692, 'grad_norm': 0.1767492502062851, 'learning_rate': 6.30964333126071e-05, 'epoch': 0.63}

 63%|██████▎   | 1964/3107 [4:13:16<2:16:59,  7.19s/it]


 63%|██████▎   | 1966/3107 [4:13:29<2:13:00,  6.99s/it]

 63%|██████▎   | 1967/3107 [4:13:35<2:07:31,  6.71s/it]
{'loss': 1.0227, 'grad_norm': 0.18273139357624837, 'learning_rate': 6.270912260196155e-05, 'epoch': 0.63}


 63%|██████▎   | 1969/3107 [4:13:49<2:10:19,  6.87s/it]

 63%|██████▎   | 1970/3107 [4:13:57<2:19:11,  7.35s/it]
{'loss': 0.9469, 'grad_norm': 0.16746738551241058, 'learning_rate': 6.241906489027807e-05, 'epoch': 0.63}

 63%|██████▎   | 1971/3107 [4:14:04<2:12:14,  6.98s/it]

 63%|██████▎   | 1972/3107 [4:14:10<2:07:01,  6.72s/it]

 64%|██████▎   | 1973/3107 [4:14:16<2:05:49,  6.66s/it]

 64%|██████▎   | 1974/3107 [4:14:24<2:13:42,  7.08s/it]

 64%|██████▎   | 1975/3107 [4:14:30<2:07:21,  6.75s/it]

 64%|██████▎   | 1976/3107 [4:14:38<2:13:37,  7.09s/it]

 64%|██████▎   | 1977/3107 [4:14:44<2:04:09,  6.59s/it]

 64%|██████▎   | 1978/3107 [4:14:50<2:01:22,  6.45s/it]


 64%|██████▎   | 1980/3107 [4:15:07<2:25:00,  7.72s/it]

 64%|██████▍   | 1981/3107 [4:15:15<2:24:15,  7.69s/it]

 64%|██████▍   | 1982/3107 [4:15:27<2:45:35,  8.83s/it]

 64%|██████▍   | 1983/3107 [4:15:33<2:31:32,  8.09s/it]

 64%|██████▍   | 1984/3107 [4:15:46<2:57:32,  9.49s/it]

 64%|██████▍   | 1985/3107 [4:15:53<2:46:24,  8.90s/it]
{'loss': 0.893, 'grad_norm': 0.16849085962834656, 'learning_rate': 6.097434869079015e-05, 'epoch': 0.64}


 64%|██████▍   | 1987/3107 [4:16:11<2:49:46,  9.09s/it]
{'loss': 0.8713, 'grad_norm': 0.17146450082411618, 'learning_rate': 6.078243343721115e-05, 'epoch': 0.64}


 64%|██████▍   | 1989/3107 [4:16:27<2:38:38,  8.51s/it]
{'loss': 0.9408, 'grad_norm': 0.1921849388177739, 'learning_rate': 6.0590688729797295e-05, 'epoch': 0.64}

 64%|██████▍   | 1990/3107 [4:16:32<2:21:12,  7.59s/it]


 64%|██████▍   | 1992/3107 [4:16:50<2:30:09,  8.08s/it]
{'loss': 1.0164, 'grad_norm': 0.18234066600122142, 'learning_rate': 6.030339326656566e-05, 'epoch': 0.64}


 64%|██████▍   | 1994/3107 [4:17:05<2:28:00,  7.98s/it]

 64%|██████▍   | 1995/3107 [4:17:13<2:29:08,  8.05s/it]

 64%|██████▍   | 1996/3107 [4:17:19<2:17:51,  7.45s/it]

 64%|██████▍   | 1997/3107 [4:17:25<2:07:09,  6.87s/it]
{'loss': 0.8746, 'grad_norm': 0.177611761142598, 'learning_rate': 5.982543202746775e-05, 'epoch': 0.64}


 64%|██████▍   | 1999/3107 [4:17:37<1:59:20,  6.46s/it]
{'loss': 0.9162, 'grad_norm': 0.1878387692151896, 'learning_rate': 5.963455254357631e-05, 'epoch': 0.64}

 64%|██████▍   | 2000/3107 [4:17:44<2:02:46,  6.65s/it]


 64%|██████▍   | 2002/3107 [4:18:03<2:29:00,  8.09s/it]

 64%|██████▍   | 2003/3107 [4:18:15<2:47:39,  9.11s/it]

 64%|██████▍   | 2004/3107 [4:18:23<2:43:14,  8.88s/it]
{'loss': 0.8858, 'grad_norm': 0.17776667707019628, 'learning_rate': 5.9158123626416794e-05, 'epoch': 0.64}

 65%|██████▍   | 2005/3107 [4:18:30<2:31:23,  8.24s/it]

 65%|██████▍   | 2006/3107 [4:18:36<2:20:38,  7.66s/it]


 65%|██████▍   | 2008/3107 [4:18:55<2:35:33,  8.49s/it]
{'loss': 0.8801, 'grad_norm': 0.17967642495945774, 'learning_rate': 5.877777911486603e-05, 'epoch': 0.65}


 65%|██████▍   | 2010/3107 [4:19:08<2:17:20,  7.51s/it]
{'loss': 0.9042, 'grad_norm': 0.17058712826724196, 'learning_rate': 5.858787534154607e-05, 'epoch': 0.65}


 65%|██████▍   | 2012/3107 [4:19:20<2:02:05,  6.69s/it]

 65%|██████▍   | 2013/3107 [4:19:26<1:59:59,  6.58s/it]
{'loss': 0.9497, 'grad_norm': 0.1703819493016802, 'learning_rate': 5.830335760757828e-05, 'epoch': 0.65}

 65%|██████▍   | 2014/3107 [4:19:32<1:57:53,  6.47s/it]


 65%|██████▍   | 2016/3107 [4:19:52<2:30:52,  8.30s/it]

 65%|██████▍   | 2017/3107 [4:19:59<2:26:06,  8.04s/it]

 65%|██████▍   | 2018/3107 [4:20:06<2:17:57,  7.60s/it]
{'loss': 0.8926, 'grad_norm': 0.17586551397530023, 'learning_rate': 5.783006939168765e-05, 'epoch': 0.65}

 65%|██████▍   | 2019/3107 [4:20:12<2:11:43,  7.26s/it]

 65%|██████▌   | 2020/3107 [4:20:18<2:06:20,  6.97s/it]


 65%|██████▌   | 2022/3107 [4:20:36<2:22:20,  7.87s/it]

 65%|██████▌   | 2023/3107 [4:20:44<2:24:02,  7.97s/it]

 65%|██████▌   | 2024/3107 [4:20:51<2:20:26,  7.78s/it]
{'loss': 0.9352, 'grad_norm': 0.18078840457255405, 'learning_rate': 5.7263637587175836e-05, 'epoch': 0.65}


 65%|██████▌   | 2026/3107 [4:21:05<2:14:08,  7.44s/it]
{'loss': 0.8809, 'grad_norm': 0.17949138815949653, 'learning_rate': 5.707519758853288e-05, 'epoch': 0.65}

 65%|██████▌   | 2027/3107 [4:21:12<2:10:40,  7.26s/it]


 65%|██████▌   | 2029/3107 [4:21:25<2:03:23,  6.87s/it]
{'loss': 0.7789, 'grad_norm': 0.1776838158109144, 'learning_rate': 5.679288784872727e-05, 'epoch': 0.65}


 65%|██████▌   | 2031/3107 [4:21:38<1:57:20,  6.54s/it]

 65%|██████▌   | 2032/3107 [4:21:43<1:50:56,  6.19s/it]
{'loss': 0.9317, 'grad_norm': 0.17382313833174126, 'learning_rate': 5.651100087377752e-05, 'epoch': 0.65}


 65%|██████▌   | 2034/3107 [4:21:58<2:02:04,  6.83s/it]

 65%|██████▌   | 2035/3107 [4:22:05<2:05:23,  7.02s/it]
{'loss': 0.9608, 'grad_norm': 0.1867835395533794, 'learning_rate': 5.622953942183854e-05, 'epoch': 0.65}


 66%|██████▌   | 2037/3107 [4:22:20<2:08:21,  7.20s/it]
{'loss': 0.8691, 'grad_norm': 0.16697497230784655, 'learning_rate': 5.6042136215719697e-05, 'epoch': 0.66}


 66%|██████▌   | 2039/3107 [4:22:34<2:07:16,  7.15s/it]

 66%|██████▌   | 2040/3107 [4:22:40<1:59:54,  6.74s/it]
{'loss': 1.0736, 'grad_norm': 0.17596807120689037, 'learning_rate': 5.576139008671094e-05, 'epoch': 0.66}


 66%|██████▌   | 2042/3107 [4:22:53<1:58:59,  6.70s/it]
{'loss': 1.1089, 'grad_norm': 0.1856605780090946, 'learning_rate': 5.55744663077905e-05, 'epoch': 0.66}


 66%|██████▌   | 2044/3107 [4:23:08<2:03:47,  6.99s/it]

 66%|██████▌   | 2045/3107 [4:23:17<2:17:18,  7.76s/it]

 66%|██████▌   | 2046/3107 [4:23:26<2:21:04,  7.98s/it]

 66%|██████▌   | 2047/3107 [4:23:32<2:09:52,  7.35s/it]
{'loss': 1.1229, 'grad_norm': 0.1956575476080524, 'learning_rate': 5.510800386099617e-05, 'epoch': 0.66}


 66%|██████▌   | 2049/3107 [4:23:51<2:26:35,  8.31s/it]
{'loss': 0.8435, 'grad_norm': 0.1746144852678646, 'learning_rate': 5.492175981242097e-05, 'epoch': 0.66}


 66%|██████▌   | 2051/3107 [4:24:07<2:24:31,  8.21s/it]
{'loss': 0.9821, 'grad_norm': 0.17443730982782327, 'learning_rate': 5.4735711796431824e-05, 'epoch': 0.66}

 66%|██████▌   | 2052/3107 [4:24:13<2:11:15,  7.47s/it]

 66%|██████▌   | 2053/3107 [4:24:20<2:11:11,  7.47s/it]


 66%|██████▌   | 2055/3107 [4:24:35<2:12:20,  7.55s/it]

 66%|██████▌   | 2056/3107 [4:24:44<2:16:44,  7.81s/it]
{'loss': 1.0329, 'grad_norm': 0.17797386015239108, 'learning_rate': 5.427145470644084e-05, 'epoch': 0.66}


 66%|██████▌   | 2058/3107 [4:25:00<2:17:43,  7.88s/it]
{'loss': 0.8369, 'grad_norm': 0.1723085518090425, 'learning_rate': 5.408609917030689e-05, 'epoch': 0.66}


 66%|██████▋   | 2060/3107 [4:25:17<2:28:24,  8.51s/it]

 66%|██████▋   | 2061/3107 [4:25:23<2:15:17,  7.76s/it]

 66%|██████▋   | 2062/3107 [4:25:32<2:19:47,  8.03s/it]
{'loss': 0.8292, 'grad_norm': 0.15876235421595947, 'learning_rate': 5.371598790314728e-05, 'epoch': 0.66}


 66%|██████▋   | 2064/3107 [4:25:50<2:27:38,  8.49s/it]

 66%|██████▋   | 2065/3107 [4:25:58<2:25:03,  8.35s/it]

 66%|██████▋   | 2066/3107 [4:26:06<2:23:27,  8.27s/it]
{'loss': 0.8474, 'grad_norm': 0.17244389011544362, 'learning_rate': 5.334668173970819e-05, 'epoch': 0.66}


 67%|██████▋   | 2068/3107 [4:26:22<2:19:43,  8.07s/it]

 67%|██████▋   | 2069/3107 [4:26:30<2:23:26,  8.29s/it]

 67%|██████▋   | 2070/3107 [4:26:36<2:10:44,  7.56s/it]

 67%|██████▋   | 2071/3107 [4:26:43<2:08:48,  7.46s/it]
{'loss': 0.8407, 'grad_norm': 0.18217332016514406, 'learning_rate': 5.288619099777818e-05, 'epoch': 0.67}


 67%|██████▋   | 2073/3107 [4:26:56<1:57:17,  6.81s/it]

 67%|██████▋   | 2074/3107 [4:27:08<2:25:32,  8.45s/it]
[2024-05-28 02:51:18,119] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 67%|██████▋   | 2075/3107 [4:27:15<2:20:32,  8.17s/it]

 67%|██████▋   | 2076/3107 [4:27:22<2:10:19,  7.58s/it]
{'loss': 1.0706, 'grad_norm': 0.19316978508244154, 'learning_rate': 5.242698078280096e-05, 'epoch': 0.67}


 67%|██████▋   | 2078/3107 [4:27:36<2:05:51,  7.34s/it]
{'loss': 0.9694, 'grad_norm': 0.18154022260323546, 'learning_rate': 5.224365804129523e-05, 'epoch': 0.67}


 67%|██████▋   | 2080/3107 [4:27:56<2:27:02,  8.59s/it]
{'loss': 1.0004, 'grad_norm': 0.17080267799033566, 'learning_rate': 5.206054297868682e-05, 'epoch': 0.67}


 67%|██████▋   | 2082/3107 [4:28:12<2:20:46,  8.24s/it]
{'loss': 0.9655, 'grad_norm': 0.1629820470759342, 'learning_rate': 5.187763639129165e-05, 'epoch': 0.67}


 67%|██████▋   | 2084/3107 [4:28:25<2:05:29,  7.36s/it]

 67%|██████▋   | 2085/3107 [4:28:32<2:02:25,  7.19s/it]

 67%|██████▋   | 2086/3107 [4:28:40<2:03:52,  7.28s/it]

 67%|██████▋   | 2087/3107 [4:28:45<1:56:51,  6.87s/it]
{'loss': 0.8732, 'grad_norm': 0.1713978716400687, 'learning_rate': 5.142128721949482e-05, 'epoch': 0.67}

 67%|██████▋   | 2088/3107 [4:28:51<1:51:16,  6.55s/it]


 67%|██████▋   | 2090/3107 [4:29:06<2:03:20,  7.28s/it]
{'loss': 0.8225, 'grad_norm': 0.1794428407512624, 'learning_rate': 5.114811068835783e-05, 'epoch': 0.67}


 67%|██████▋   | 2092/3107 [4:29:22<2:08:21,  7.59s/it]

 67%|██████▋   | 2093/3107 [4:29:28<1:59:14,  7.06s/it]

 67%|██████▋   | 2094/3107 [4:29:34<1:54:24,  6.78s/it]
{'loss': 0.9606, 'grad_norm': 0.16861748832955992, 'learning_rate': 5.078461932542204e-05, 'epoch': 0.67}


 67%|██████▋   | 2096/3107 [4:29:52<2:13:57,  7.95s/it]
{'loss': 0.9071, 'grad_norm': 0.17511491164236298, 'learning_rate': 5.060319428477498e-05, 'epoch': 0.67}

 67%|██████▋   | 2097/3107 [4:30:03<2:26:21,  8.69s/it]

 68%|██████▊   | 2098/3107 [4:30:11<2:25:43,  8.67s/it]

 68%|██████▊   | 2099/3107 [4:30:17<2:10:12,  7.75s/it]

 68%|██████▊   | 2100/3107 [4:30:23<2:02:43,  7.31s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.9333, 'grad_norm': 0.16425585957299596, 'learning_rate': 5.015057321277761e-05, 'epoch': 0.68}
 68%|██████▊   | 2101/3107 [4:30:55<4:06:23, 14.70s/it]

 68%|██████▊   | 2102/3107 [4:31:03<3:29:54, 12.53s/it]

 68%|██████▊   | 2103/3107 [4:31:11<3:08:44, 11.28s/it]

 68%|██████▊   | 2104/3107 [4:31:23<3:11:16, 11.44s/it]

 68%|██████▊   | 2105/3107 [4:31:29<2:44:37,  9.86s/it]


 68%|██████▊   | 2107/3107 [4:31:50<2:45:17,  9.92s/it]
{'loss': 0.8403, 'grad_norm': 0.1870113197768854, 'learning_rate': 4.960921744732378e-05, 'epoch': 0.68}

 68%|██████▊   | 2108/3107 [4:31:59<2:38:51,  9.54s/it]


 68%|██████▊   | 2110/3107 [4:32:16<2:29:11,  8.98s/it]

 68%|██████▊   | 2111/3107 [4:32:26<2:34:49,  9.33s/it]

 68%|██████▊   | 2112/3107 [4:32:37<2:39:04,  9.59s/it]

 68%|██████▊   | 2113/3107 [4:32:44<2:27:54,  8.93s/it]

 68%|██████▊   | 2114/3107 [4:32:51<2:15:33,  8.19s/it]
{'loss': 0.925, 'grad_norm': 0.17472458859296885, 'learning_rate': 4.898012986164764e-05, 'epoch': 0.68}


 68%|██████▊   | 2116/3107 [4:33:06<2:13:59,  8.11s/it]
{'loss': 0.9063, 'grad_norm': 0.16751273397976627, 'learning_rate': 4.8800888297353745e-05, 'epoch': 0.68}

 68%|██████▊   | 2117/3107 [4:33:13<2:07:48,  7.75s/it]

 68%|██████▊   | 2118/3107 [4:33:19<1:58:34,  7.19s/it]


 68%|██████▊   | 2120/3107 [4:33:34<2:04:29,  7.57s/it]
{'loss': 0.9426, 'grad_norm': 0.17204607203327027, 'learning_rate': 4.844307389887246e-05, 'epoch': 0.68}

 68%|██████▊   | 2121/3107 [4:33:41<2:01:20,  7.38s/it]


 68%|██████▊   | 2123/3107 [4:33:54<1:54:33,  6.99s/it]
{'loss': 1.0444, 'grad_norm': 0.1715969059155909, 'learning_rate': 4.817530130181785e-05, 'epoch': 0.68}


 68%|██████▊   | 2125/3107 [4:34:12<2:11:13,  8.02s/it]

 68%|██████▊   | 2126/3107 [4:34:21<2:14:28,  8.23s/it]

 68%|██████▊   | 2127/3107 [4:34:30<2:20:08,  8.58s/it]

 68%|██████▊   | 2128/3107 [4:34:38<2:19:56,  8.58s/it]

 69%|██████▊   | 2129/3107 [4:34:47<2:17:09,  8.41s/it]

 69%|██████▊   | 2130/3107 [4:34:55<2:16:26,  8.38s/it]

 69%|██████▊   | 2131/3107 [4:35:01<2:04:27,  7.65s/it]

 69%|██████▊   | 2132/3107 [4:35:06<1:53:43,  7.00s/it]

 69%|██████▊   | 2133/3107 [4:35:12<1:46:41,  6.57s/it]
{'loss': 0.8772, 'grad_norm': 0.19408587583373207, 'learning_rate': 4.7286402936343634e-05, 'epoch': 0.69}

 69%|██████▊   | 2134/3107 [4:35:21<1:59:02,  7.34s/it]


 69%|██████▊   | 2136/3107 [4:35:37<2:03:18,  7.62s/it]

 69%|██████▉   | 2137/3107 [4:35:42<1:53:38,  7.03s/it]
{'loss': 0.9539, 'grad_norm': 0.17496661378724146, 'learning_rate': 4.693244284150712e-05, 'epoch': 0.69}

 69%|██████▉   | 2138/3107 [4:35:51<2:02:45,  7.60s/it]


 69%|██████▉   | 2140/3107 [4:36:15<2:33:04,  9.50s/it]

 69%|██████▉   | 2141/3107 [4:36:24<2:32:04,  9.45s/it]
{'loss': 1.0384, 'grad_norm': 0.1862913070137291, 'learning_rate': 4.657940584917983e-05, 'epoch': 0.69}

 69%|██████▉   | 2142/3107 [4:36:30<2:12:38,  8.25s/it]

 69%|██████▉   | 2143/3107 [4:36:37<2:08:43,  8.01s/it]

 69%|██████▉   | 2144/3107 [4:36:45<2:08:54,  8.03s/it]

 69%|██████▉   | 2145/3107 [4:36:53<2:09:07,  8.05s/it]

 69%|██████▉   | 2146/3107 [4:37:00<2:00:17,  7.51s/it]

 69%|██████▉   | 2147/3107 [4:37:06<1:53:39,  7.10s/it]


 69%|██████▉   | 2149/3107 [4:37:18<1:46:48,  6.69s/it]

 69%|██████▉   | 2150/3107 [4:37:24<1:44:09,  6.53s/it]

 69%|██████▉   | 2151/3107 [4:37:33<1:53:32,  7.13s/it]
{'loss': 0.8346, 'grad_norm': 0.1561617462273947, 'learning_rate': 4.5700892202528444e-05, 'epoch': 0.69}

 69%|██████▉   | 2152/3107 [4:37:40<1:51:25,  7.00s/it]


 69%|██████▉   | 2154/3107 [4:37:53<1:50:15,  6.94s/it]

 69%|██████▉   | 2155/3107 [4:37:59<1:45:08,  6.63s/it]
{'loss': 1.016, 'grad_norm': 0.18431643289148222, 'learning_rate': 4.535113432323723e-05, 'epoch': 0.69}


 69%|██████▉   | 2157/3107 [4:38:14<1:52:37,  7.11s/it]
{'loss': 1.0464, 'grad_norm': 0.1869756866762683, 'learning_rate': 4.517661148241571e-05, 'epoch': 0.69}


 69%|██████▉   | 2159/3107 [4:38:29<1:52:29,  7.12s/it]

 70%|██████▉   | 2160/3107 [4:38:34<1:44:58,  6.65s/it]

 70%|██████▉   | 2161/3107 [4:38:46<2:10:15,  8.26s/it]

 70%|██████▉   | 2162/3107 [4:38:57<2:20:56,  8.95s/it]

 70%|██████▉   | 2163/3107 [4:39:05<2:17:29,  8.74s/it]
{'loss': 0.9238, 'grad_norm': 0.16133472462193324, 'learning_rate': 4.465447645953621e-05, 'epoch': 0.7}


 70%|██████▉   | 2165/3107 [4:39:24<2:26:22,  9.32s/it]

 70%|██████▉   | 2166/3107 [4:39:32<2:19:38,  8.90s/it]

 70%|██████▉   | 2167/3107 [4:39:38<2:05:46,  8.03s/it]

 70%|██████▉   | 2168/3107 [4:39:45<1:58:23,  7.57s/it]

 70%|██████▉   | 2169/3107 [4:39:50<1:48:13,  6.92s/it]
{'loss': 0.8879, 'grad_norm': 0.18231233941371142, 'learning_rate': 4.413450756939574e-05, 'epoch': 0.7}

 70%|██████▉   | 2170/3107 [4:39:56<1:41:47,  6.52s/it]


 70%|██████▉   | 2172/3107 [4:40:08<1:38:55,  6.35s/it]
{'loss': 0.9533, 'grad_norm': 0.16623363076557973, 'learning_rate': 4.3875341787038236e-05, 'epoch': 0.7}


 70%|██████▉   | 2174/3107 [4:40:22<1:44:03,  6.69s/it]
{'loss': 0.9951, 'grad_norm': 0.18476090674187245, 'learning_rate': 4.370286953028787e-05, 'epoch': 0.7}


 70%|███████   | 2176/3107 [4:40:36<1:49:29,  7.06s/it]

 70%|███████   | 2177/3107 [4:40:48<2:11:21,  8.47s/it]
{'loss': 0.9292, 'grad_norm': 0.18191066684009877, 'learning_rate': 4.3444620417476765e-05, 'epoch': 0.7}


 70%|███████   | 2179/3107 [4:41:04<2:08:31,  8.31s/it]

 70%|███████   | 2180/3107 [4:41:10<1:57:52,  7.63s/it]

 70%|███████   | 2181/3107 [4:41:19<2:02:12,  7.92s/it]

 70%|███████   | 2182/3107 [4:41:27<2:01:49,  7.90s/it]
{'loss': 1.0069, 'grad_norm': 0.16520690225252196, 'learning_rate': 4.301543619147089e-05, 'epoch': 0.7}


 70%|███████   | 2184/3107 [4:41:41<1:56:55,  7.60s/it]
{'loss': 0.855, 'grad_norm': 0.17723998346147488, 'learning_rate': 4.2844195515632166e-05, 'epoch': 0.7}

 70%|███████   | 2185/3107 [4:41:50<2:00:23,  7.83s/it]


 70%|███████   | 2187/3107 [4:42:02<1:47:45,  7.03s/it]
{'loss': 0.8442, 'grad_norm': 0.17934932574837661, 'learning_rate': 4.258780077400748e-05, 'epoch': 0.7}


 70%|███████   | 2189/3107 [4:42:18<1:56:33,  7.62s/it]

 70%|███████   | 2190/3107 [4:42:27<2:00:25,  7.88s/it]

 71%|███████   | 2191/3107 [4:42:38<2:17:05,  8.98s/it]
{'loss': 0.8678, 'grad_norm': 0.17652672937643238, 'learning_rate': 4.224681539419282e-05, 'epoch': 0.71}

 71%|███████   | 2192/3107 [4:42:46<2:09:48,  8.51s/it]

 71%|███████   | 2193/3107 [4:42:54<2:06:10,  8.28s/it]


 71%|███████   | 2195/3107 [4:43:09<2:02:41,  8.07s/it]

 71%|███████   | 2196/3107 [4:43:17<1:59:41,  7.88s/it]
{'loss': 0.7444, 'grad_norm': 0.16686135878102248, 'learning_rate': 4.1821997093301904e-05, 'epoch': 0.71}

 71%|███████   | 2197/3107 [4:43:24<1:55:03,  7.59s/it]


 71%|███████   | 2199/3107 [4:43:37<1:46:28,  7.04s/it]

 71%|███████   | 2200/3107 [4:43:43<1:41:44,  6.73s/it]

 71%|███████   | 2201/3107 [4:43:51<1:46:56,  7.08s/it]

 71%|███████   | 2202/3107 [4:43:57<1:39:24,  6.59s/it]

 71%|███████   | 2203/3107 [4:44:03<1:38:28,  6.54s/it]

 71%|███████   | 2204/3107 [4:44:08<1:33:32,  6.21s/it]

 71%|███████   | 2205/3107 [4:44:17<1:45:12,  7.00s/it]

 71%|███████   | 2206/3107 [4:44:25<1:47:58,  7.19s/it]

 71%|███████   | 2207/3107 [4:44:31<1:44:20,  6.96s/it]

 71%|███████   | 2208/3107 [4:44:39<1:46:02,  7.08s/it]
{'loss': 0.9635, 'grad_norm': 0.17942652466403158, 'learning_rate': 4.080890654713995e-05, 'epoch': 0.71}


 71%|███████   | 2210/3107 [4:44:51<1:40:22,  6.71s/it]

 71%|███████   | 2211/3107 [4:44:59<1:46:29,  7.13s/it]
{'loss': 0.959, 'grad_norm': 0.17911165458722422, 'learning_rate': 4.055707563401864e-05, 'epoch': 0.71}

 71%|███████   | 2212/3107 [4:45:06<1:43:33,  6.94s/it]


 71%|███████▏  | 2214/3107 [4:45:19<1:39:17,  6.67s/it]
{'loss': 0.9768, 'grad_norm': 0.17102507601402853, 'learning_rate': 4.030582634688669e-05, 'epoch': 0.71}

 71%|███████▏  | 2215/3107 [4:45:24<1:34:40,  6.37s/it]

 71%|███████▏  | 2216/3107 [4:45:32<1:41:13,  6.82s/it]


 71%|███████▏  | 2218/3107 [4:45:47<1:46:05,  7.16s/it]

 71%|███████▏  | 2219/3107 [4:45:53<1:39:49,  6.74s/it]

 71%|███████▏  | 2220/3107 [4:45:59<1:36:53,  6.55s/it]

 71%|███████▏  | 2221/3107 [4:46:05<1:35:13,  6.45s/it]
{'loss': 0.8658, 'grad_norm': 0.1815807382766541, 'learning_rate': 3.97218536877903e-05, 'epoch': 0.71}


 72%|███████▏  | 2223/3107 [4:46:19<1:38:00,  6.65s/it]

 72%|███████▏  | 2224/3107 [4:46:26<1:36:54,  6.58s/it]

 72%|███████▏  | 2225/3107 [4:46:33<1:40:14,  6.82s/it]

 72%|███████▏  | 2226/3107 [4:46:41<1:46:17,  7.24s/it]

 72%|███████▏  | 2227/3107 [4:46:49<1:50:42,  7.55s/it]

 72%|███████▏  | 2228/3107 [4:46:55<1:43:51,  7.09s/it]

 72%|███████▏  | 2229/3107 [4:47:02<1:39:27,  6.80s/it]
{'loss': 0.8956, 'grad_norm': 0.19601267809064726, 'learning_rate': 3.905839014373047e-05, 'epoch': 0.72}


 72%|███████▏  | 2231/3107 [4:47:19<1:55:16,  7.90s/it]
{'loss': 0.7477, 'grad_norm': 0.1747081965660252, 'learning_rate': 3.8893185002117706e-05, 'epoch': 0.72}

 72%|███████▏  | 2232/3107 [4:47:28<1:57:45,  8.07s/it]


 72%|███████▏  | 2234/3107 [4:47:44<1:53:43,  7.82s/it]

 72%|███████▏  | 2235/3107 [4:47:53<1:59:47,  8.24s/it]
{'loss': 1.0241, 'grad_norm': 0.17182799016159417, 'learning_rate': 3.856357264521464e-05, 'epoch': 0.72}


 72%|███████▏  | 2237/3107 [4:48:07<1:51:21,  7.68s/it]
{'loss': 0.9122, 'grad_norm': 0.17331719864222087, 'learning_rate': 3.839916686331573e-05, 'epoch': 0.72}

 72%|███████▏  | 2238/3107 [4:48:14<1:48:09,  7.47s/it]

 72%|███████▏  | 2239/3107 [4:48:20<1:42:11,  7.06s/it]


 72%|███████▏  | 2241/3107 [4:48:39<2:04:34,  8.63s/it]
{'loss': 0.8581, 'grad_norm': 0.18049438484542335, 'learning_rate': 3.807115966739258e-05, 'epoch': 0.72}

 72%|███████▏  | 2242/3107 [4:48:48<2:05:56,  8.74s/it]


 72%|███████▏  | 2244/3107 [4:49:07<2:08:10,  8.91s/it]

 72%|███████▏  | 2245/3107 [4:49:13<1:56:20,  8.10s/it]
{'loss': 1.0192, 'grad_norm': 0.19288396864474938, 'learning_rate': 3.7744229714722514e-05, 'epoch': 0.72}


 72%|███████▏  | 2247/3107 [4:49:26<1:40:11,  6.99s/it]

 72%|███████▏  | 2248/3107 [4:49:37<1:58:15,  8.26s/it]

 72%|███████▏  | 2249/3107 [4:49:44<1:52:01,  7.83s/it]
{'loss': 0.9489, 'grad_norm': 0.18465332919042612, 'learning_rate': 3.741838269220496e-05, 'epoch': 0.72}

 72%|███████▏  | 2250/3107 [4:49:50<1:45:32,  7.39s/it]


 72%|███████▏  | 2252/3107 [4:50:09<2:03:25,  8.66s/it]
[2024-05-28 03:14:19,550] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 73%|███████▎  | 2253/3107 [4:50:16<1:53:01,  7.94s/it]
{'loss': 0.8686, 'grad_norm': 0.19141177103276913, 'learning_rate': 3.709362426790186e-05, 'epoch': 0.73}

 73%|███████▎  | 2254/3107 [4:50:22<1:48:28,  7.63s/it]

 73%|███████▎  | 2255/3107 [4:50:32<1:57:25,  8.27s/it]

 73%|███████▎  | 2256/3107 [4:50:38<1:48:21,  7.64s/it]


 73%|███████▎  | 2258/3107 [4:50:51<1:40:47,  7.12s/it]

 73%|███████▎  | 2259/3107 [4:50:59<1:43:07,  7.30s/it]
{'loss': 0.8276, 'grad_norm': 0.16117047014990404, 'learning_rate': 3.660854010536055e-05, 'epoch': 0.73}

 73%|███████▎  | 2260/3107 [4:51:10<2:00:15,  8.52s/it]


 73%|███████▎  | 2262/3107 [4:51:23<1:45:03,  7.46s/it]

 73%|███████▎  | 2263/3107 [4:51:29<1:38:52,  7.03s/it]

 73%|███████▎  | 2264/3107 [4:51:36<1:35:46,  6.82s/it]

 73%|███████▎  | 2265/3107 [4:51:44<1:42:21,  7.29s/it]

 73%|███████▎  | 2266/3107 [4:51:53<1:49:09,  7.79s/it]

 73%|███████▎  | 2267/3107 [4:52:01<1:51:16,  7.95s/it]
{'loss': 1.0373, 'grad_norm': 0.1957844349111833, 'learning_rate': 3.59656238810172e-05, 'epoch': 0.73}

 73%|███████▎  | 2268/3107 [4:52:10<1:55:09,  8.24s/it]


 73%|███████▎  | 2270/3107 [4:52:23<1:43:25,  7.41s/it]
{'loss': 1.0294, 'grad_norm': 0.17349516762951314, 'learning_rate': 3.572567657620969e-05, 'epoch': 0.73}

 73%|███████▎  | 2271/3107 [4:52:33<1:51:03,  7.97s/it]

 73%|███████▎  | 2272/3107 [4:52:40<1:49:31,  7.87s/it]

 73%|███████▎  | 2273/3107 [4:52:47<1:42:58,  7.41s/it]

 73%|███████▎  | 2274/3107 [4:52:56<1:52:26,  8.10s/it]


 73%|███████▎  | 2276/3107 [4:53:12<1:48:46,  7.85s/it]

 73%|███████▎  | 2277/3107 [4:53:22<1:56:33,  8.43s/it]

 73%|███████▎  | 2278/3107 [4:53:29<1:52:43,  8.16s/it]

 73%|███████▎  | 2279/3107 [4:53:35<1:44:50,  7.60s/it]
{'loss': 1.0159, 'grad_norm': 0.18136354893316256, 'learning_rate': 3.500961741830821e-05, 'epoch': 0.73}

 73%|███████▎  | 2280/3107 [4:53:47<2:00:36,  8.75s/it]

 73%|███████▎  | 2281/3107 [4:53:57<2:05:25,  9.11s/it]

 73%|███████▎  | 2282/3107 [4:54:05<2:00:57,  8.80s/it]


 74%|███████▎  | 2284/3107 [4:54:21<1:56:06,  8.46s/it]
{'loss': 0.9305, 'grad_norm': 0.16179691759754947, 'learning_rate': 3.4614275709570033e-05, 'epoch': 0.74}

 74%|███████▎  | 2285/3107 [4:54:27<1:44:49,  7.65s/it]

 74%|███████▎  | 2286/3107 [4:54:35<1:46:18,  7.77s/it]

 74%|███████▎  | 2287/3107 [4:54:41<1:37:49,  7.16s/it]


 74%|███████▎  | 2289/3107 [4:54:53<1:32:22,  6.78s/it]
{'loss': 0.9379, 'grad_norm': 0.17765460154136414, 'learning_rate': 3.422071114821304e-05, 'epoch': 0.74}

 74%|███████▎  | 2290/3107 [4:55:01<1:34:47,  6.96s/it]

 74%|███████▎  | 2291/3107 [4:55:07<1:31:15,  6.71s/it]


 74%|███████▍  | 2293/3107 [4:55:21<1:34:16,  6.95s/it]
{'loss': 1.015, 'grad_norm': 0.16676328976055504, 'learning_rate': 3.390714623516522e-05, 'epoch': 0.74}


 74%|███████▍  | 2295/3107 [4:55:40<1:48:47,  8.04s/it]

 74%|███████▍  | 2296/3107 [4:55:48<1:49:09,  8.08s/it]

 74%|███████▍  | 2297/3107 [4:55:58<1:56:57,  8.66s/it]
[2024-05-28 03:20:08,053] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 74%|███████▍  | 2298/3107 [4:56:06<1:53:24,  8.41s/it]

 74%|███████▍  | 2299/3107 [4:56:14<1:52:12,  8.33s/it]

 74%|███████▍  | 2300/3107 [4:56:19<1:41:16,  7.53s/it]

 74%|███████▍  | 2301/3107 [4:56:26<1:35:15,  7.09s/it]
{'loss': 0.9737, 'grad_norm': 0.1843087814288082, 'learning_rate': 3.3283470870487634e-05, 'epoch': 0.74}

 74%|███████▍  | 2302/3107 [4:56:33<1:36:26,  7.19s/it]


 74%|███████▍  | 2304/3107 [4:56:52<1:51:25,  8.33s/it]

 74%|███████▍  | 2305/3107 [4:56:58<1:42:43,  7.68s/it]

 74%|███████▍  | 2306/3107 [4:57:08<1:51:42,  8.37s/it]
{'loss': 0.8981, 'grad_norm': 0.16576599265783298, 'learning_rate': 3.289602833138874e-05, 'epoch': 0.74}

 74%|███████▍  | 2307/3107 [4:57:17<1:53:11,  8.49s/it]


 74%|███████▍  | 2309/3107 [4:57:34<1:50:45,  8.33s/it]
{'loss': 1.1121, 'grad_norm': 0.19282727680453993, 'learning_rate': 3.26644375832619e-05, 'epoch': 0.74}


 74%|███████▍  | 2311/3107 [4:57:47<1:39:23,  7.49s/it]

 74%|███████▍  | 2312/3107 [4:57:54<1:34:33,  7.14s/it]
{'loss': 0.9488, 'grad_norm': 0.17923503508464086, 'learning_rate': 3.2433505687530505e-05, 'epoch': 0.74}


 74%|███████▍  | 2314/3107 [4:58:08<1:34:10,  7.13s/it]

 75%|███████▍  | 2315/3107 [4:58:13<1:27:46,  6.65s/it]
{'loss': 0.9529, 'grad_norm': 0.18176995214467162, 'learning_rate': 3.220323490377368e-05, 'epoch': 0.75}

 75%|███████▍  | 2316/3107 [4:58:21<1:31:06,  6.91s/it]

 75%|███████▍  | 2317/3107 [4:58:29<1:34:45,  7.20s/it]


 75%|███████▍  | 2319/3107 [4:58:42<1:31:06,  6.94s/it]

 75%|███████▍  | 2320/3107 [4:58:48<1:26:06,  6.56s/it]

 75%|███████▍  | 2321/3107 [4:58:54<1:24:15,  6.43s/it]

 75%|███████▍  | 2322/3107 [4:59:04<1:38:45,  7.55s/it]

 75%|███████▍  | 2323/3107 [4:59:10<1:34:57,  7.27s/it]
{'loss': 0.8329, 'grad_norm': 0.18162587997237695, 'learning_rate': 3.159242869759778e-05, 'epoch': 0.75}


 75%|███████▍  | 2325/3107 [4:59:26<1:38:39,  7.57s/it]

 75%|███████▍  | 2326/3107 [4:59:34<1:41:37,  7.81s/it]
{'loss': 0.8927, 'grad_norm': 0.1781750272659141, 'learning_rate': 3.136460121826087e-05, 'epoch': 0.75}


 75%|███████▍  | 2328/3107 [4:59:46<1:29:41,  6.91s/it]
{'loss': 1.0527, 'grad_norm': 0.1911926993889478, 'learning_rate': 3.121308918958503e-05, 'epoch': 0.75}

 75%|███████▍  | 2329/3107 [4:59:59<1:50:46,  8.54s/it]

 75%|███████▍  | 2330/3107 [5:00:05<1:41:13,  7.82s/it]

 75%|███████▌  | 2331/3107 [5:00:11<1:35:38,  7.40s/it]


 75%|███████▌  | 2333/3107 [5:00:32<1:51:04,  8.61s/it]
{'loss': 1.0152, 'grad_norm': 0.15990066829335275, 'learning_rate': 3.083561927129895e-05, 'epoch': 0.75}


 75%|███████▌  | 2335/3107 [5:00:43<1:30:35,  7.04s/it]

 75%|███████▌  | 2336/3107 [5:00:52<1:39:00,  7.70s/it]

 75%|███████▌  | 2337/3107 [5:01:02<1:48:20,  8.44s/it]

 75%|███████▌  | 2338/3107 [5:01:08<1:40:53,  7.87s/it]

 75%|███████▌  | 2339/3107 [5:01:14<1:32:04,  7.19s/it]

 75%|███████▌  | 2340/3107 [5:01:21<1:29:23,  6.99s/it]
{'loss': 1.0163, 'grad_norm': 0.18971933236904653, 'learning_rate': 3.031032182065525e-05, 'epoch': 0.75}


 75%|███████▌  | 2342/3107 [5:01:34<1:26:59,  6.82s/it]
{'loss': 0.9353, 'grad_norm': 0.17038626264780396, 'learning_rate': 3.0160917499956587e-05, 'epoch': 0.75}


 75%|███████▌  | 2344/3107 [5:01:48<1:26:38,  6.81s/it]
{'loss': 0.9883, 'grad_norm': 0.16561692128179228, 'learning_rate': 3.001181688978203e-05, 'epoch': 0.75}

 75%|███████▌  | 2345/3107 [5:01:55<1:29:17,  7.03s/it]


 76%|███████▌  | 2347/3107 [5:02:08<1:24:08,  6.64s/it]
{'loss': 0.9186, 'grad_norm': 0.1819426862935293, 'learning_rate': 2.978873684975858e-05, 'epoch': 0.76}


 76%|███████▌  | 2349/3107 [5:02:20<1:20:51,  6.40s/it]
{'loss': 1.0795, 'grad_norm': 0.17962465825719184, 'learning_rate': 2.9640398349733334e-05, 'epoch': 0.76}

 76%|███████▌  | 2350/3107 [5:02:29<1:30:44,  7.19s/it]

 76%|███████▌  | 2351/3107 [5:02:35<1:25:08,  6.76s/it]


 76%|███████▌  | 2353/3107 [5:02:50<1:28:37,  7.05s/it]
{'loss': 0.8564, 'grad_norm': 0.17825450434274287, 'learning_rate': 2.9344639915781093e-05, 'epoch': 0.76}


 76%|███████▌  | 2355/3107 [5:03:05<1:30:34,  7.23s/it]

 76%|███████▌  | 2356/3107 [5:03:10<1:24:53,  6.78s/it]

 76%|███████▌  | 2357/3107 [5:03:20<1:34:34,  7.57s/it]
{'loss': 0.8751, 'grad_norm': 0.18387840280459616, 'learning_rate': 2.9050110521635444e-05, 'epoch': 0.76}

 76%|███████▌  | 2358/3107 [5:03:31<1:49:42,  8.79s/it]


 76%|███████▌  | 2360/3107 [5:03:45<1:34:02,  7.55s/it]

 76%|███████▌  | 2361/3107 [5:03:54<1:42:41,  8.26s/it]
{'loss': 0.9698, 'grad_norm': 0.1869821110450722, 'learning_rate': 2.8756815290592765e-05, 'epoch': 0.76}

 76%|███████▌  | 2362/3107 [5:04:03<1:44:55,  8.45s/it]

 76%|███████▌  | 2363/3107 [5:04:11<1:41:53,  8.22s/it]

 76%|███████▌  | 2364/3107 [5:04:17<1:34:03,  7.60s/it]


 76%|███████▌  | 2366/3107 [5:04:29<1:22:49,  6.71s/it]

 76%|███████▌  | 2367/3107 [5:04:36<1:25:18,  6.92s/it]

 76%|███████▌  | 2368/3107 [5:04:43<1:23:19,  6.77s/it]
{'loss': 0.7861, 'grad_norm': 0.17491718901435513, 'learning_rate': 2.8246533674422617e-05, 'epoch': 0.76}

 76%|███████▌  | 2369/3107 [5:04:49<1:23:29,  6.79s/it]

 76%|███████▋  | 2370/3107 [5:04:58<1:28:34,  7.21s/it]


 76%|███████▋  | 2372/3107 [5:05:10<1:22:55,  6.77s/it]

 76%|███████▋  | 2373/3107 [5:05:17<1:22:11,  6.72s/it]

 76%|███████▋  | 2374/3107 [5:05:26<1:30:10,  7.38s/it]

 76%|███████▋  | 2375/3107 [5:05:34<1:34:07,  7.72s/it]

 76%|███████▋  | 2376/3107 [5:05:40<1:27:11,  7.16s/it]

 77%|███████▋  | 2377/3107 [5:05:47<1:25:26,  7.02s/it]

 77%|███████▋  | 2378/3107 [5:05:56<1:33:39,  7.71s/it]

 77%|███████▋  | 2379/3107 [5:06:02<1:26:34,  7.14s/it]

 77%|███████▋  | 2380/3107 [5:06:08<1:23:36,  6.90s/it]

 77%|███████▋  | 2381/3107 [5:06:15<1:21:56,  6.77s/it]

 77%|███████▋  | 2382/3107 [5:06:24<1:32:17,  7.64s/it]

 77%|███████▋  | 2383/3107 [5:06:30<1:26:23,  7.16s/it]

 77%|███████▋  | 2384/3107 [5:06:36<1:21:49,  6.79s/it]

 77%|███████▋  | 2385/3107 [5:06:43<1:19:55,  6.64s/it]

 77%|███████▋  | 2386/3107 [5:06:51<1:25:54,  7.15s/it]

 77%|███████▋  | 2387/3107 [5:07:00<1:34:09,  7.85s/it]

 77%|███████▋  | 2388/3107 [5:07:10<1:41:13,  8.45s/it]

 77%|███████▋  | 2389/3107 [5:07:17<1:33:18,  7.80s/it]

 77%|███████▋  | 2390/3107 [5:07:23<1:27:03,  7.29s/it]

 77%|███████▋  | 2391/3107 [5:07:30<1:27:00,  7.29s/it]
{'loss': 0.7904, 'grad_norm': 0.18910022520520683, 'learning_rate': 2.659695142075197e-05, 'epoch': 0.77}


 77%|███████▋  | 2393/3107 [5:07:46<1:33:16,  7.84s/it]

 77%|███████▋  | 2394/3107 [5:07:55<1:34:12,  7.93s/it]
{'loss': 1.0111, 'grad_norm': 0.18304170423722688, 'learning_rate': 2.638488066171201e-05, 'epoch': 0.77}


 77%|███████▋  | 2396/3107 [5:08:07<1:22:15,  6.94s/it]
{'loss': 0.938, 'grad_norm': 0.18092881614960046, 'learning_rate': 2.6243900192013304e-05, 'epoch': 0.77}


 77%|███████▋  | 2398/3107 [5:08:23<1:27:07,  7.37s/it]

 77%|███████▋  | 2399/3107 [5:08:28<1:20:02,  6.78s/it]

 77%|███████▋  | 2400/3107 [5:08:36<1:24:58,  7.21s/it]
 77%|███████▋  | 2400/3107 [5:08:36<1:24:58,  7.21s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 77%|███████▋  | 2401/3107 [5:09:11<3:02:06, 15.48s/it]

 77%|███████▋  | 2402/3107 [5:09:17<2:27:56, 12.59s/it]
{'loss': 0.9604, 'grad_norm': 0.18321665476466453, 'learning_rate': 2.5822885695461052e-05, 'epoch': 0.77}

 77%|███████▋  | 2403/3107 [5:09:24<2:08:09, 10.92s/it]


 77%|███████▋  | 2405/3107 [5:09:42<2:01:43, 10.40s/it]

 77%|███████▋  | 2406/3107 [5:09:49<1:46:56,  9.15s/it]
{'loss': 0.8815, 'grad_norm': 0.1828854066995881, 'learning_rate': 2.5543821224290765e-05, 'epoch': 0.77}


 78%|███████▊  | 2408/3107 [5:10:04<1:38:37,  8.47s/it]

 78%|███████▊  | 2409/3107 [5:10:12<1:37:45,  8.40s/it]

 78%|███████▊  | 2410/3107 [5:10:18<1:29:44,  7.72s/it]

 78%|███████▊  | 2411/3107 [5:10:25<1:25:07,  7.34s/it]

 78%|███████▊  | 2412/3107 [5:10:32<1:25:49,  7.41s/it]
{'loss': 0.9165, 'grad_norm': 0.18609047142226032, 'learning_rate': 2.51276544430293e-05, 'epoch': 0.78}


 78%|███████▊  | 2414/3107 [5:10:49<1:30:55,  7.87s/it]
{'loss': 0.835, 'grad_norm': 0.1720153461281354, 'learning_rate': 2.4989582577207417e-05, 'epoch': 0.78}

 78%|███████▊  | 2415/3107 [5:11:00<1:39:20,  8.61s/it]


 78%|███████▊  | 2417/3107 [5:11:17<1:40:12,  8.71s/it]

 78%|███████▊  | 2418/3107 [5:11:25<1:36:15,  8.38s/it]

 78%|███████▊  | 2419/3107 [5:11:37<1:49:23,  9.54s/it]

 78%|███████▊  | 2420/3107 [5:11:43<1:37:07,  8.48s/it]
{'loss': 0.9923, 'grad_norm': 0.1869639242414659, 'learning_rate': 2.4577326569619164e-05, 'epoch': 0.78}

 78%|███████▊  | 2421/3107 [5:11:52<1:37:08,  8.50s/it]


 78%|███████▊  | 2423/3107 [5:12:09<1:38:56,  8.68s/it]

 78%|███████▊  | 2424/3107 [5:12:17<1:35:37,  8.40s/it]

 78%|███████▊  | 2425/3107 [5:12:27<1:40:58,  8.88s/it]

 78%|███████▊  | 2426/3107 [5:12:35<1:38:58,  8.72s/it]

 78%|███████▊  | 2427/3107 [5:12:41<1:30:01,  7.94s/it]

 78%|███████▊  | 2428/3107 [5:12:48<1:26:48,  7.67s/it]

 78%|███████▊  | 2429/3107 [5:12:55<1:23:24,  7.38s/it]

 78%|███████▊  | 2430/3107 [5:13:03<1:25:23,  7.57s/it]

 78%|███████▊  | 2431/3107 [5:13:09<1:20:43,  7.17s/it]

 78%|███████▊  | 2432/3107 [5:13:19<1:29:39,  7.97s/it]

 78%|███████▊  | 2433/3107 [5:13:25<1:22:56,  7.38s/it]

 78%|███████▊  | 2434/3107 [5:13:31<1:17:24,  6.90s/it]
{'loss': 1.0915, 'grad_norm': 0.17399082518918244, 'learning_rate': 2.3626903242915267e-05, 'epoch': 0.78}


 78%|███████▊  | 2436/3107 [5:13:51<1:34:47,  8.48s/it]

 78%|███████▊  | 2437/3107 [5:13:57<1:28:50,  7.96s/it]

 78%|███████▊  | 2438/3107 [5:14:05<1:29:17,  8.01s/it]

 79%|███████▊  | 2439/3107 [5:14:14<1:32:31,  8.31s/it]

 79%|███████▊  | 2440/3107 [5:14:22<1:31:15,  8.21s/it]

 79%|███████▊  | 2441/3107 [5:14:33<1:39:06,  8.93s/it]
{'loss': 0.8192, 'grad_norm': 0.15997263862808567, 'learning_rate': 2.3157781749862807e-05, 'epoch': 0.79}

 79%|███████▊  | 2442/3107 [5:14:40<1:33:26,  8.43s/it]

 79%|███████▊  | 2443/3107 [5:14:48<1:31:01,  8.22s/it]


 79%|███████▊  | 2445/3107 [5:15:07<1:37:58,  8.88s/it]

 79%|███████▊  | 2446/3107 [5:15:13<1:28:38,  8.05s/it]

 79%|███████▉  | 2447/3107 [5:15:22<1:33:54,  8.54s/it]

 79%|███████▉  | 2448/3107 [5:15:31<1:35:02,  8.65s/it]
{'loss': 0.8406, 'grad_norm': 0.17391845595868186, 'learning_rate': 2.2692753763717234e-05, 'epoch': 0.79}


 79%|███████▉  | 2450/3107 [5:15:47<1:29:11,  8.14s/it]
{'loss': 1.0106, 'grad_norm': 0.1810456484432609, 'learning_rate': 2.256064396564974e-05, 'epoch': 0.79}

 79%|███████▉  | 2451/3107 [5:15:54<1:25:55,  7.86s/it]

 79%|███████▉  | 2452/3107 [5:16:00<1:20:29,  7.37s/it]


 79%|███████▉  | 2454/3107 [5:16:17<1:23:13,  7.65s/it]
{'loss': 1.0032, 'grad_norm': 0.18400572294498246, 'learning_rate': 2.2297435228485918e-05, 'epoch': 0.79}


 79%|███████▉  | 2456/3107 [5:16:30<1:16:39,  7.06s/it]

 79%|███████▉  | 2457/3107 [5:16:35<1:11:22,  6.59s/it]

 79%|███████▉  | 2458/3107 [5:16:43<1:15:50,  7.01s/it]

 79%|███████▉  | 2459/3107 [5:16:49<1:10:47,  6.55s/it]
{'loss': 1.0166, 'grad_norm': 0.18556509963112564, 'learning_rate': 2.197032556387295e-05, 'epoch': 0.79}


 79%|███████▉  | 2461/3107 [5:17:05<1:17:03,  7.16s/it]

 79%|███████▉  | 2462/3107 [5:17:15<1:28:05,  8.19s/it]
{'loss': 0.8518, 'grad_norm': 0.16819706175625135, 'learning_rate': 2.1775077183874703e-05, 'epoch': 0.79}


 79%|███████▉  | 2464/3107 [5:17:32<1:28:46,  8.28s/it]

 79%|███████▉  | 2465/3107 [5:17:39<1:26:48,  8.11s/it]
{'loss': 0.9445, 'grad_norm': 0.18572721717734272, 'learning_rate': 2.158059420444528e-05, 'epoch': 0.79}


 79%|███████▉  | 2467/3107 [5:17:55<1:23:24,  7.82s/it]
{'loss': 0.9896, 'grad_norm': 0.2063382287412499, 'learning_rate': 2.1451365047396454e-05, 'epoch': 0.79}

 79%|███████▉  | 2468/3107 [5:18:05<1:27:43,  8.24s/it]

 79%|███████▉  | 2469/3107 [5:18:15<1:33:12,  8.77s/it]


 80%|███████▉  | 2471/3107 [5:18:27<1:19:22,  7.49s/it]

 80%|███████▉  | 2472/3107 [5:18:37<1:28:12,  8.33s/it]

 80%|███████▉  | 2473/3107 [5:18:44<1:22:36,  7.82s/it]

 80%|███████▉  | 2474/3107 [5:18:51<1:21:08,  7.69s/it]

 80%|███████▉  | 2475/3107 [5:18:57<1:15:42,  7.19s/it]
{'loss': 1.0011, 'grad_norm': 0.1894236031534915, 'learning_rate': 2.0937869875894423e-05, 'epoch': 0.8}


 80%|███████▉  | 2477/3107 [5:19:16<1:26:02,  8.19s/it]
{'loss': 0.8238, 'grad_norm': 0.19104286721349667, 'learning_rate': 2.081035423850103e-05, 'epoch': 0.8}

 80%|███████▉  | 2478/3107 [5:19:25<1:28:39,  8.46s/it]


 80%|███████▉  | 2480/3107 [5:19:39<1:21:48,  7.83s/it]
{'loss': 0.974, 'grad_norm': 0.16530020472457022, 'learning_rate': 2.061972665559213e-05, 'epoch': 0.8}


 80%|███████▉  | 2482/3107 [5:19:59<1:31:28,  8.78s/it]
{'loss': 0.7937, 'grad_norm': 0.17758713176314564, 'learning_rate': 2.04930729883987e-05, 'epoch': 0.8}

 80%|███████▉  | 2483/3107 [5:20:06<1:27:01,  8.37s/it]


 80%|███████▉  | 2485/3107 [5:20:24<1:28:08,  8.50s/it]

 80%|████████  | 2486/3107 [5:20:29<1:19:42,  7.70s/it]
{'loss': 0.9868, 'grad_norm': 0.1868032403749847, 'learning_rate': 2.0240803463070425e-05, 'epoch': 0.8}


 80%|████████  | 2488/3107 [5:20:43<1:15:23,  7.31s/it]

 80%|████████  | 2489/3107 [5:20:51<1:17:40,  7.54s/it]
{'loss': 0.8366, 'grad_norm': 0.160967206344052, 'learning_rate': 2.005251156107426e-05, 'epoch': 0.8}

 80%|████████  | 2490/3107 [5:20:58<1:15:11,  7.31s/it]

 80%|████████  | 2491/3107 [5:21:04<1:10:49,  6.90s/it]


 80%|████████  | 2493/3107 [5:21:23<1:24:45,  8.28s/it]

 80%|████████  | 2494/3107 [5:21:31<1:22:35,  8.08s/it]
{'loss': 0.8218, 'grad_norm': 0.18963093015891644, 'learning_rate': 1.9740430975661528e-05, 'epoch': 0.8}


 80%|████████  | 2496/3107 [5:21:47<1:22:41,  8.12s/it]

 80%|████████  | 2497/3107 [5:21:56<1:24:40,  8.33s/it]

 80%|████████  | 2498/3107 [5:22:02<1:17:36,  7.65s/it]
{'loss': 1.0129, 'grad_norm': 0.18707807966378914, 'learning_rate': 1.9492336717488235e-05, 'epoch': 0.8}

 80%|████████  | 2499/3107 [5:22:09<1:14:59,  7.40s/it]

 80%|████████  | 2500/3107 [5:22:14<1:09:10,  6.84s/it]


 81%|████████  | 2502/3107 [5:22:29<1:13:23,  7.28s/it]

 81%|████████  | 2503/3107 [5:22:35<1:09:35,  6.91s/it]

 81%|████████  | 2504/3107 [5:22:42<1:08:06,  6.78s/it]

 81%|████████  | 2505/3107 [5:22:48<1:04:54,  6.47s/it]

 81%|████████  | 2506/3107 [5:22:54<1:03:50,  6.37s/it]

 81%|████████  | 2507/3107 [5:22:59<1:00:45,  6.08s/it]
{'loss': 0.8986, 'grad_norm': 0.18955697466956012, 'learning_rate': 1.8939251454356976e-05, 'epoch': 0.81}


 81%|████████  | 2509/3107 [5:23:13<1:04:15,  6.45s/it]
{'loss': 0.8161, 'grad_norm': 0.1827847287790945, 'learning_rate': 1.8817311312374564e-05, 'epoch': 0.81}


 81%|████████  | 2511/3107 [5:23:27<1:06:31,  6.70s/it]

 81%|████████  | 2512/3107 [5:23:34<1:06:44,  6.73s/it]

 81%|████████  | 2513/3107 [5:23:41<1:08:08,  6.88s/it]

 81%|████████  | 2514/3107 [5:23:47<1:05:13,  6.60s/it]

 81%|████████  | 2515/3107 [5:23:56<1:12:23,  7.34s/it]
{'loss': 0.9663, 'grad_norm': 0.17613027956307095, 'learning_rate': 1.845361124394097e-05, 'epoch': 0.81}


 81%|████████  | 2517/3107 [5:24:14<1:17:05,  7.84s/it]

 81%|████████  | 2518/3107 [5:24:19<1:10:51,  7.22s/it]
{'loss': 0.9346, 'grad_norm': 0.17992657951265253, 'learning_rate': 1.8272957171745276e-05, 'epoch': 0.81}


 81%|████████  | 2520/3107 [5:24:38<1:23:04,  8.49s/it]
{'loss': 0.9362, 'grad_norm': 0.18095953198068498, 'learning_rate': 1.8152965274521794e-05, 'epoch': 0.81}


 81%|████████  | 2522/3107 [5:24:54<1:18:22,  8.04s/it]
{'loss': 0.9231, 'grad_norm': 0.15872947347593613, 'learning_rate': 1.80333293070288e-05, 'epoch': 0.81}

 81%|████████  | 2523/3107 [5:25:00<1:14:47,  7.68s/it]


 81%|████████▏ | 2525/3107 [5:25:13<1:08:48,  7.09s/it]
{'loss': 0.9348, 'grad_norm': 0.17115245214106511, 'learning_rate': 1.785454386168587e-05, 'epoch': 0.81}


 81%|████████▏ | 2527/3107 [5:25:29<1:12:08,  7.46s/it]

 81%|████████▏ | 2528/3107 [5:25:40<1:20:18,  8.32s/it]

 81%|████████▏ | 2529/3107 [5:25:46<1:14:18,  7.71s/it]
{'loss': 0.9851, 'grad_norm': 0.1852693571028893, 'learning_rate': 1.7617413864737153e-05, 'epoch': 0.81}


 81%|████████▏ | 2531/3107 [5:26:01<1:14:46,  7.79s/it]
{'loss': 0.8326, 'grad_norm': 0.1672945812609672, 'learning_rate': 1.7499385996888207e-05, 'epoch': 0.81}


 82%|████████▏ | 2533/3107 [5:26:17<1:13:57,  7.73s/it]

 82%|████████▏ | 2534/3107 [5:26:24<1:11:39,  7.50s/it]
{'loss': 0.9063, 'grad_norm': 0.1742471772590789, 'learning_rate': 1.73230170525156e-05, 'epoch': 0.82}


 82%|████████▏ | 2536/3107 [5:26:38<1:09:39,  7.32s/it]

 82%|████████▏ | 2537/3107 [5:26:45<1:08:18,  7.19s/it]

 82%|████████▏ | 2538/3107 [5:26:54<1:12:43,  7.67s/it]

 82%|████████▏ | 2539/3107 [5:27:02<1:12:53,  7.70s/it]
{'loss': 1.1082, 'grad_norm': 0.19277466974983226, 'learning_rate': 1.7030867354405354e-05, 'epoch': 0.82}

 82%|████████▏ | 2540/3107 [5:27:09<1:10:18,  7.44s/it]

 82%|████████▏ | 2541/3107 [5:27:15<1:07:10,  7.12s/it]

 82%|████████▏ | 2542/3107 [5:27:21<1:02:44,  6.66s/it]


 82%|████████▏ | 2544/3107 [5:27:38<1:12:31,  7.73s/it]
{'loss': 0.7781, 'grad_norm': 0.18263308765505354, 'learning_rate': 1.674097271087165e-05, 'epoch': 0.82}

 82%|████████▏ | 2545/3107 [5:27:45<1:10:40,  7.55s/it]

 82%|████████▏ | 2546/3107 [5:27:51<1:06:17,  7.09s/it]

 82%|████████▏ | 2547/3107 [5:28:01<1:14:33,  7.99s/it]


 82%|████████▏ | 2549/3107 [5:28:20<1:19:23,  8.54s/it]

 82%|████████▏ | 2550/3107 [5:28:28<1:15:50,  8.17s/it]
{'loss': 0.9682, 'grad_norm': 0.18159180052531004, 'learning_rate': 1.6396086900221818e-05, 'epoch': 0.82}


 82%|████████▏ | 2552/3107 [5:28:50<1:28:38,  9.58s/it]
{'loss': 0.8595, 'grad_norm': 0.1655962446123422, 'learning_rate': 1.628185143813433e-05, 'epoch': 0.82}


 82%|████████▏ | 2554/3107 [5:29:05<1:19:37,  8.64s/it]

 82%|████████▏ | 2555/3107 [5:29:11<1:12:22,  7.87s/it]

 82%|████████▏ | 2556/3107 [5:29:18<1:09:01,  7.52s/it]

 82%|████████▏ | 2557/3107 [5:29:26<1:11:05,  7.76s/it]

 82%|████████▏ | 2558/3107 [5:29:34<1:10:26,  7.70s/it]

 82%|████████▏ | 2559/3107 [5:29:40<1:04:33,  7.07s/it]

 82%|████████▏ | 2560/3107 [5:29:46<1:01:07,  6.71s/it]

 82%|████████▏ | 2561/3107 [5:29:52<59:19,  6.52s/it]

 82%|████████▏ | 2562/3107 [5:30:02<1:08:59,  7.60s/it]
{'loss': 0.8991, 'grad_norm': 0.19782319478462632, 'learning_rate': 1.571614500797012e-05, 'epoch': 0.82}


 83%|████████▎ | 2564/3107 [5:30:18<1:11:24,  7.89s/it]

 83%|████████▎ | 2565/3107 [5:30:24<1:04:45,  7.17s/it]
{'loss': 0.898, 'grad_norm': 0.18143978314464085, 'learning_rate': 1.5548217109081375e-05, 'epoch': 0.83}

 83%|████████▎ | 2566/3107 [5:30:33<1:10:38,  7.83s/it]

 83%|████████▎ | 2567/3107 [5:30:39<1:05:35,  7.29s/it]


 83%|████████▎ | 2569/3107 [5:30:56<1:10:24,  7.85s/it]

 83%|████████▎ | 2570/3107 [5:31:04<1:11:54,  8.04s/it]

 83%|████████▎ | 2571/3107 [5:31:10<1:05:41,  7.35s/it]

 83%|████████▎ | 2572/3107 [5:31:20<1:12:32,  8.14s/it]

 83%|████████▎ | 2573/3107 [5:31:26<1:07:37,  7.60s/it]
{'loss': 0.9908, 'grad_norm': 0.19038597505933788, 'learning_rate': 1.510445364154406e-05, 'epoch': 0.83}

 83%|████████▎ | 2574/3107 [5:31:33<1:06:08,  7.45s/it]

 83%|████████▎ | 2575/3107 [5:31:41<1:07:23,  7.60s/it]

 83%|████████▎ | 2576/3107 [5:31:47<1:01:59,  7.00s/it]

 83%|████████▎ | 2577/3107 [5:31:53<1:00:00,  6.79s/it]


 83%|████████▎ | 2579/3107 [5:32:10<1:06:56,  7.61s/it]
{'loss': 0.9089, 'grad_norm': 0.18370352021355782, 'learning_rate': 1.4775505808609191e-05, 'epoch': 0.83}

 83%|████████▎ | 2580/3107 [5:32:16<1:01:17,  6.98s/it]

 83%|████████▎ | 2581/3107 [5:32:23<1:00:47,  6.93s/it]

 83%|████████▎ | 2582/3107 [5:32:31<1:04:56,  7.42s/it]

 83%|████████▎ | 2583/3107 [5:32:41<1:10:20,  8.06s/it]


 83%|████████▎ | 2585/3107 [5:32:56<1:07:02,  7.71s/it]

 83%|████████▎ | 2586/3107 [5:33:10<1:23:18,  9.59s/it]

 83%|████████▎ | 2587/3107 [5:33:16<1:14:19,  8.58s/it]

 83%|████████▎ | 2588/3107 [5:33:24<1:13:25,  8.49s/it]
{'loss': 0.9399, 'grad_norm': 0.18731567346175093, 'learning_rate': 1.4288342196475179e-05, 'epoch': 0.83}

 83%|████████▎ | 2589/3107 [5:33:32<1:10:41,  8.19s/it]


 83%|████████▎ | 2591/3107 [5:33:46<1:07:31,  7.85s/it]
{'loss': 0.9256, 'grad_norm': 0.18026223689514673, 'learning_rate': 1.4127629526152187e-05, 'epoch': 0.83}

 83%|████████▎ | 2592/3107 [5:33:56<1:11:28,  8.33s/it]

 83%|████████▎ | 2593/3107 [5:34:06<1:15:37,  8.83s/it]

 83%|████████▎ | 2594/3107 [5:34:14<1:12:57,  8.53s/it]


 84%|████████▎ | 2596/3107 [5:34:30<1:10:11,  8.24s/it]
{'loss': 0.9506, 'grad_norm': 0.174363891524906, 'learning_rate': 1.3861643021512438e-05, 'epoch': 0.84}

 84%|████████▎ | 2597/3107 [5:34:40<1:13:14,  8.62s/it]

 84%|████████▎ | 2598/3107 [5:34:45<1:05:05,  7.67s/it]

 84%|████████▎ | 2599/3107 [5:34:51<1:00:51,  7.19s/it]

 84%|████████▎ | 2600/3107 [5:34:58<59:59,  7.10s/it]

 84%|████████▎ | 2601/3107 [5:35:04<56:58,  6.76s/it]

 84%|████████▎ | 2602/3107 [5:35:10<54:03,  6.42s/it]

 84%|████████▍ | 2603/3107 [5:35:17<56:57,  6.78s/it]

 84%|████████▍ | 2604/3107 [5:35:25<1:00:35,  7.23s/it]

 84%|████████▍ | 2605/3107 [5:35:31<56:55,  6.80s/it]


 84%|████████▍ | 2607/3107 [5:35:50<1:06:41,  8.00s/it]
{'loss': 0.9114, 'grad_norm': 0.17778932739863915, 'learning_rate': 1.328472379312966e-05, 'epoch': 0.84}

 84%|████████▍ | 2608/3107 [5:35:56<1:00:53,  7.32s/it]

 84%|████████▍ | 2609/3107 [5:36:06<1:05:52,  7.94s/it]

 84%|████████▍ | 2610/3107 [5:36:15<1:10:40,  8.53s/it]


 84%|████████▍ | 2612/3107 [5:36:35<1:14:36,  9.04s/it]

 84%|████████▍ | 2613/3107 [5:36:41<1:07:26,  8.19s/it]
{'loss': 1.0212, 'grad_norm': 0.1759594994192522, 'learning_rate': 1.2974843770316969e-05, 'epoch': 0.84}


 84%|████████▍ | 2615/3107 [5:36:58<1:09:43,  8.50s/it]
{'loss': 1.0721, 'grad_norm': 0.18397119941365936, 'learning_rate': 1.2872306727946093e-05, 'epoch': 0.84}


 84%|████████▍ | 2617/3107 [5:37:11<1:00:52,  7.45s/it]
{'loss': 0.8122, 'grad_norm': 0.17719732177426908, 'learning_rate': 1.2770148579404295e-05, 'epoch': 0.84}


 84%|████████▍ | 2619/3107 [5:37:27<1:01:06,  7.51s/it]
{'loss': 0.9965, 'grad_norm': 0.17662816267979528, 'learning_rate': 1.2668369768948608e-05, 'epoch': 0.84}

 84%|████████▍ | 2620/3107 [5:37:32<56:47,  7.00s/it]

 84%|████████▍ | 2621/3107 [5:37:40<59:07,  7.30s/it]


 84%|████████▍ | 2623/3107 [5:38:01<1:12:02,  8.93s/it]

 84%|████████▍ | 2624/3107 [5:38:13<1:19:33,  9.88s/it]

 84%|████████▍ | 2625/3107 [5:38:23<1:18:41,  9.80s/it]
{'loss': 0.8594, 'grad_norm': 0.1789608434396332, 'learning_rate': 1.2365313783912735e-05, 'epoch': 0.84}

 85%|████████▍ | 2626/3107 [5:38:29<1:10:38,  8.81s/it]

 85%|████████▍ | 2627/3107 [5:38:36<1:05:48,  8.23s/it]


 85%|████████▍ | 2629/3107 [5:38:55<1:10:29,  8.85s/it]

 85%|████████▍ | 2630/3107 [5:39:01<1:03:33,  8.00s/it]
{'loss': 1.0225, 'grad_norm': 0.18266566481696486, 'learning_rate': 1.2115386675653751e-05, 'epoch': 0.85}

 85%|████████▍ | 2631/3107 [5:39:06<57:24,  7.24s/it]

 85%|████████▍ | 2632/3107 [5:39:14<58:24,  7.38s/it]

 85%|████████▍ | 2633/3107 [5:39:20<55:12,  6.99s/it]


 85%|████████▍ | 2635/3107 [5:39:39<1:04:07,  8.15s/it]
{'loss': 0.8716, 'grad_norm': 0.18162392427100005, 'learning_rate': 1.1867848221984345e-05, 'epoch': 0.85}


 85%|████████▍ | 2637/3107 [5:39:53<58:54,  7.52s/it]
{'loss': 0.9293, 'grad_norm': 0.1746598898136284, 'learning_rate': 1.1769503173049502e-05, 'epoch': 0.85}

 85%|████████▍ | 2638/3107 [5:40:01<1:01:05,  7.81s/it]


 85%|████████▍ | 2640/3107 [5:40:15<56:53,  7.31s/it]
{'loss': 0.8781, 'grad_norm': 0.17591823712089566, 'learning_rate': 1.1622705150861069e-05, 'epoch': 0.85}

 85%|████████▌ | 2641/3107 [5:40:24<1:01:05,  7.87s/it]

 85%|████████▌ | 2642/3107 [5:40:32<1:01:29,  7.94s/it]

 85%|████████▌ | 2643/3107 [5:40:39<57:51,  7.48s/it]

 85%|████████▌ | 2644/3107 [5:40:44<52:45,  6.84s/it]


 85%|████████▌ | 2646/3107 [5:40:57<52:15,  6.80s/it]
{'loss': 0.9928, 'grad_norm': 0.1905871552691271, 'learning_rate': 1.1331704747174732e-05, 'epoch': 0.85}

 85%|████████▌ | 2647/3107 [5:41:06<56:09,  7.32s/it]

 85%|████████▌ | 2648/3107 [5:41:14<59:17,  7.75s/it]


 85%|████████▌ | 2650/3107 [5:41:29<56:54,  7.47s/it]
{'loss': 0.9764, 'grad_norm': 0.18470592541536535, 'learning_rate': 1.1139631742372425e-05, 'epoch': 0.85}

 85%|████████▌ | 2651/3107 [5:41:35<54:12,  7.13s/it]

 85%|████████▌ | 2652/3107 [5:41:42<53:44,  7.09s/it]

 85%|████████▌ | 2653/3107 [5:41:48<51:10,  6.76s/it]


 85%|████████▌ | 2655/3107 [5:42:05<56:26,  7.49s/it]

 85%|████████▌ | 2656/3107 [5:42:11<52:43,  7.01s/it]
{'loss': 0.8941, 'grad_norm': 0.1843637506204206, 'learning_rate': 1.085442148434469e-05, 'epoch': 0.85}


 86%|████████▌ | 2658/3107 [5:42:31<1:01:59,  8.28s/it]

 86%|████████▌ | 2659/3107 [5:42:37<56:36,  7.58s/it]
{'loss': 0.9385, 'grad_norm': 0.17930695318661471, 'learning_rate': 1.0713124042225165e-05, 'epoch': 0.86}

 86%|████████▌ | 2660/3107 [5:42:45<55:53,  7.50s/it]

 86%|████████▌ | 2661/3107 [5:42:50<51:07,  6.88s/it]

 86%|████████▌ | 2662/3107 [5:42:58<52:49,  7.12s/it]


 86%|████████▌ | 2664/3107 [5:43:17<1:01:51,  8.38s/it]

 86%|████████▌ | 2665/3107 [5:43:23<56:59,  7.74s/it]
{'loss': 0.8603, 'grad_norm': 0.17809053383386234, 'learning_rate': 1.0433151444465018e-05, 'epoch': 0.86}


 86%|████████▌ | 2667/3107 [5:43:39<56:05,  7.65s/it]

 86%|████████▌ | 2668/3107 [5:43:45<53:11,  7.27s/it]

 86%|████████▌ | 2669/3107 [5:43:55<59:00,  8.08s/it]
{'loss': 0.8733, 'grad_norm': 0.1705521222534078, 'learning_rate': 1.0248449874700705e-05, 'epoch': 0.86}

 86%|████████▌ | 2670/3107 [5:44:07<1:06:01,  9.06s/it]

 86%|████████▌ | 2671/3107 [5:44:13<59:21,  8.17s/it]

 86%|████████▌ | 2672/3107 [5:44:19<54:41,  7.54s/it]

 86%|████████▌ | 2673/3107 [5:44:26<53:47,  7.44s/it]


 86%|████████▌ | 2675/3107 [5:44:40<51:21,  7.13s/it]
{'loss': 0.8695, 'grad_norm': 0.18067712550672027, 'learning_rate': 9.974325795298645e-06, 'epoch': 0.86}


 86%|████████▌ | 2677/3107 [5:44:53<49:42,  6.94s/it]

 86%|████████▌ | 2678/3107 [5:44:59<47:32,  6.65s/it]
{'loss': 0.9231, 'grad_norm': 0.18059490365296652, 'learning_rate': 9.838584386724748e-06, 'epoch': 0.86}


 86%|████████▋ | 2680/3107 [5:45:11<46:04,  6.47s/it]
{'loss': 1.0243, 'grad_norm': 0.18974644734743304, 'learning_rate': 9.748580140781694e-06, 'epoch': 0.86}

 86%|████████▋ | 2681/3107 [5:45:18<46:02,  6.48s/it]


 86%|████████▋ | 2683/3107 [5:45:31<46:40,  6.61s/it]
{'loss': 0.9573, 'grad_norm': 0.19724425337826065, 'learning_rate': 9.614309790033859e-06, 'epoch': 0.86}


 86%|████████▋ | 2685/3107 [5:45:48<52:06,  7.41s/it]
{'loss': 0.9434, 'grad_norm': 0.19089928063252554, 'learning_rate': 9.52528746933089e-06, 'epoch': 0.86}

 86%|████████▋ | 2686/3107 [5:45:54<49:39,  7.08s/it]


 87%|████████▋ | 2688/3107 [5:46:07<47:39,  6.82s/it]

 87%|████████▋ | 2689/3107 [5:46:13<44:52,  6.44s/it]

 87%|████████▋ | 2690/3107 [5:46:22<49:10,  7.07s/it]
{'loss': 0.8842, 'grad_norm': 0.1773451709616837, 'learning_rate': 9.304453849916051e-06, 'epoch': 0.87}

 87%|████████▋ | 2691/3107 [5:46:28<48:08,  6.94s/it]

 87%|████████▋ | 2692/3107 [5:46:34<46:35,  6.74s/it]


 87%|████████▋ | 2694/3107 [5:46:51<51:17,  7.45s/it]
{'loss': 0.9637, 'grad_norm': 0.18338753795645021, 'learning_rate': 9.129561507534046e-06, 'epoch': 0.87}


 87%|████████▋ | 2696/3107 [5:47:08<53:28,  7.81s/it]
{'loss': 0.8917, 'grad_norm': 0.18579771144928686, 'learning_rate': 9.042707901595682e-06, 'epoch': 0.87}

 87%|████████▋ | 2697/3107 [5:47:20<1:03:35,  9.31s/it]

 87%|████████▋ | 2698/3107 [5:47:26<56:35,  8.30s/it]

 87%|████████▋ | 2699/3107 [5:47:32<51:10,  7.53s/it]

 87%|████████▋ | 2700/3107 [5:47:40<52:09,  7.69s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.9192, 'grad_norm': 0.17329166189352788, 'learning_rate': 8.827305229826456e-06, 'epoch': 0.87}

 87%|████████▋ | 2702/3107 [5:48:24<1:30:47, 13.45s/it]
{'loss': 0.8923, 'grad_norm': 0.1758570467455288, 'learning_rate': 8.784521872048513e-06, 'epoch': 0.87}

 87%|████████▋ | 2703/3107 [5:48:32<1:20:45, 11.99s/it]

 87%|████████▋ | 2704/3107 [5:48:45<1:21:13, 12.09s/it]

 87%|████████▋ | 2705/3107 [5:48:53<1:12:38, 10.84s/it]

 87%|████████▋ | 2706/3107 [5:49:03<1:10:41, 10.58s/it]

 87%|████████▋ | 2707/3107 [5:49:09<1:01:48,  9.27s/it]

 87%|████████▋ | 2708/3107 [5:49:15<55:00,  8.27s/it]


 87%|████████▋ | 2710/3107 [5:49:30<51:41,  7.81s/it]
{'loss': 1.0563, 'grad_norm': 0.17614819552723715, 'learning_rate': 8.445828929351185e-06, 'epoch': 0.87}


 87%|████████▋ | 2712/3107 [5:49:43<47:52,  7.27s/it]

 87%|████████▋ | 2713/3107 [5:49:49<45:26,  6.92s/it]
{'loss': 1.1095, 'grad_norm': 0.18941010333402108, 'learning_rate': 8.320460156541255e-06, 'epoch': 0.87}


 87%|████████▋ | 2715/3107 [5:50:05<46:46,  7.16s/it]
{'loss': 0.9257, 'grad_norm': 0.18546093195216404, 'learning_rate': 8.237379259743738e-06, 'epoch': 0.87}


 87%|████████▋ | 2717/3107 [5:50:19<47:35,  7.32s/it]
{'loss': 0.8956, 'grad_norm': 0.19373494112592568, 'learning_rate': 8.154697412771029e-06, 'epoch': 0.87}

 87%|████████▋ | 2718/3107 [5:50:25<44:02,  6.79s/it]

 88%|████████▊ | 2719/3107 [5:50:34<48:59,  7.58s/it]


 88%|████████▊ | 2721/3107 [5:50:53<54:44,  8.51s/it]
{'loss': 0.8585, 'grad_norm': 0.19128169595857647, 'learning_rate': 7.990532304803578e-06, 'epoch': 0.88}


 88%|████████▊ | 2723/3107 [5:51:07<50:36,  7.91s/it]
{'loss': 0.8886, 'grad_norm': 0.17310316434044712, 'learning_rate': 7.909049757716691e-06, 'epoch': 0.88}

 88%|████████▊ | 2724/3107 [5:51:14<47:57,  7.51s/it]

 88%|████████▊ | 2725/3107 [5:51:24<52:31,  8.25s/it]

 88%|████████▊ | 2726/3107 [5:51:33<54:03,  8.51s/it]

 88%|████████▊ | 2727/3107 [5:51:40<51:11,  8.08s/it]


 88%|████████▊ | 2729/3107 [5:51:58<53:26,  8.48s/it]
{'loss': 0.8572, 'grad_norm': 0.18307896661709905, 'learning_rate': 7.667006390950248e-06, 'epoch': 0.88}

 88%|████████▊ | 2730/3107 [5:52:07<54:55,  8.74s/it]

 88%|████████▊ | 2731/3107 [5:52:15<52:40,  8.41s/it]

 88%|████████▊ | 2732/3107 [5:52:20<47:00,  7.52s/it]

 88%|████████▊ | 2733/3107 [5:52:29<48:08,  7.72s/it]


 88%|████████▊ | 2735/3107 [5:52:48<52:02,  8.39s/it]
{'loss': 1.0304, 'grad_norm': 0.180836705609475, 'learning_rate': 7.4285767856509095e-06, 'epoch': 0.88}

 88%|████████▊ | 2736/3107 [5:52:54<48:40,  7.87s/it]

 88%|████████▊ | 2737/3107 [5:53:02<48:44,  7.90s/it]


 88%|████████▊ | 2739/3107 [5:53:16<44:18,  7.22s/it]

 88%|████████▊ | 2740/3107 [5:53:28<52:47,  8.63s/it]
{'loss': 0.9321, 'grad_norm': 0.18164045964721753, 'learning_rate': 7.232652696784703e-06, 'epoch': 0.88}

 88%|████████▊ | 2741/3107 [5:53:35<49:37,  8.13s/it]


 88%|████████▊ | 2743/3107 [5:53:52<51:11,  8.44s/it]

 88%|████████▊ | 2744/3107 [5:54:04<57:07,  9.44s/it]

 88%|████████▊ | 2745/3107 [5:54:10<51:20,  8.51s/it]

 88%|████████▊ | 2746/3107 [5:54:16<46:23,  7.71s/it]
{'loss': 0.8221, 'grad_norm': 0.18460151518790194, 'learning_rate': 7.000872455158436e-06, 'epoch': 0.88}


 88%|████████▊ | 2748/3107 [5:54:34<49:29,  8.27s/it]

 88%|████████▊ | 2749/3107 [5:54:46<56:49,  9.52s/it]
{'loss': 0.9095, 'grad_norm': 0.1790393017327301, 'learning_rate': 6.886346710257363e-06, 'epoch': 0.88}

 89%|████████▊ | 2750/3107 [5:54:53<52:00,  8.74s/it]

 89%|████████▊ | 2751/3107 [5:54:59<46:42,  7.87s/it]

 89%|████████▊ | 2752/3107 [5:55:05<43:40,  7.38s/it]

 89%|████████▊ | 2753/3107 [5:55:15<47:21,  8.03s/it]

 89%|████████▊ | 2754/3107 [5:55:21<44:32,  7.57s/it]

 89%|████████▊ | 2755/3107 [5:55:27<40:58,  6.99s/it]


 89%|████████▊ | 2757/3107 [5:55:42<43:24,  7.44s/it]
{'loss': 0.8987, 'grad_norm': 0.1688350548335253, 'learning_rate': 6.58540191310103e-06, 'epoch': 0.89}

 89%|████████▉ | 2758/3107 [5:55:49<42:26,  7.30s/it]


 89%|████████▉ | 2760/3107 [5:56:02<40:23,  6.99s/it]
{'loss': 1.1344, 'grad_norm': 0.18986899195333284, 'learning_rate': 6.474222209251779e-06, 'epoch': 0.89}

 89%|████████▉ | 2761/3107 [5:56:13<46:55,  8.14s/it]

 89%|████████▉ | 2762/3107 [5:56:19<42:21,  7.37s/it]


 89%|████████▉ | 2764/3107 [5:56:34<43:54,  7.68s/it]

 89%|████████▉ | 2765/3107 [5:56:40<41:03,  7.20s/it]
{'loss': 0.9323, 'grad_norm': 0.17971444533637757, 'learning_rate': 6.290956821566618e-06, 'epoch': 0.89}

 89%|████████▉ | 2766/3107 [5:56:50<44:30,  7.83s/it]


 89%|████████▉ | 2768/3107 [5:57:08<48:43,  8.62s/it]

 89%|████████▉ | 2769/3107 [5:57:20<53:28,  9.49s/it]
{'loss': 0.9369, 'grad_norm': 0.18125284924883167, 'learning_rate': 6.146178085372156e-06, 'epoch': 0.89}

 89%|████████▉ | 2770/3107 [5:57:26<48:39,  8.66s/it]

 89%|████████▉ | 2771/3107 [5:57:33<44:48,  8.00s/it]


 89%|████████▉ | 2773/3107 [5:57:54<52:33,  9.44s/it]

 89%|████████▉ | 2774/3107 [5:58:04<52:57,  9.54s/it]
{'loss': 0.8996, 'grad_norm': 0.16757144419998093, 'learning_rate': 5.9675007643269054e-06, 'epoch': 0.89}


 89%|████████▉ | 2776/3107 [5:58:22<51:05,  9.26s/it]
{'loss': 0.8903, 'grad_norm': 0.17567309852744525, 'learning_rate': 5.896745176478113e-06, 'epoch': 0.89}

 89%|████████▉ | 2777/3107 [5:58:30<48:34,  8.83s/it]


 89%|████████▉ | 2779/3107 [5:58:42<40:36,  7.43s/it]
{'loss': 0.9514, 'grad_norm': 0.1974490369719456, 'learning_rate': 5.791379193968505e-06, 'epoch': 0.89}

 89%|████████▉ | 2780/3107 [5:58:53<45:35,  8.36s/it]

 90%|████████▉ | 2781/3107 [5:59:02<46:03,  8.48s/it]

 90%|████████▉ | 2782/3107 [5:59:09<44:55,  8.29s/it]


 90%|████████▉ | 2784/3107 [5:59:26<43:50,  8.14s/it]

 90%|████████▉ | 2785/3107 [5:59:34<43:43,  8.15s/it]
{'loss': 0.9207, 'grad_norm': 0.18722780585649496, 'learning_rate': 5.583413635482082e-06, 'epoch': 0.9}

 90%|████████▉ | 2786/3107 [5:59:41<41:46,  7.81s/it]

 90%|████████▉ | 2787/3107 [5:59:49<41:15,  7.74s/it]


 90%|████████▉ | 2789/3107 [6:00:05<41:15,  7.78s/it]
{'loss': 0.8765, 'grad_norm': 0.16667634431646552, 'learning_rate': 5.446822383260908e-06, 'epoch': 0.9}

 90%|████████▉ | 2790/3107 [6:00:12<40:21,  7.64s/it]


 90%|████████▉ | 2792/3107 [6:00:24<36:38,  6.98s/it]
{'loss': 0.9521, 'grad_norm': 0.17811495689690546, 'learning_rate': 5.3454581751358974e-06, 'epoch': 0.9}


 90%|████████▉ | 2794/3107 [6:00:39<36:06,  6.92s/it]

 90%|████████▉ | 2795/3107 [6:00:47<37:31,  7.22s/it]
{'loss': 0.9119, 'grad_norm': 0.1813394085826575, 'learning_rate': 5.245020125037636e-06, 'epoch': 0.9}

 90%|████████▉ | 2796/3107 [6:00:56<40:27,  7.81s/it]

 90%|█████████ | 2797/3107 [6:01:06<44:10,  8.55s/it]


 90%|█████████ | 2799/3107 [6:01:20<39:46,  7.75s/it]

 90%|█████████ | 2800/3107 [6:01:26<37:04,  7.25s/it]
{'loss': 0.9049, 'grad_norm': 0.17447960957589864, 'learning_rate': 5.0796841689064515e-06, 'epoch': 0.9}


 90%|█████████ | 2802/3107 [6:01:46<44:20,  8.72s/it]
{'loss': 0.9907, 'grad_norm': 0.1800748841144083, 'learning_rate': 5.014271903851908e-06, 'epoch': 0.9}

 90%|█████████ | 2803/3107 [6:01:53<41:36,  8.21s/it]


 90%|█████████ | 2805/3107 [6:02:11<41:27,  8.24s/it]
{'loss': 0.9807, 'grad_norm': 0.1824208354975032, 'learning_rate': 4.91692809382015e-06, 'epoch': 0.9}

 90%|█████████ | 2806/3107 [6:02:20<42:44,  8.52s/it]


 90%|█████████ | 2808/3107 [6:02:34<38:38,  7.76s/it]
{'loss': 1.0558, 'grad_norm': 0.2038012304900812, 'learning_rate': 4.82051463481602e-06, 'epoch': 0.9}

 90%|█████████ | 2809/3107 [6:02:43<40:00,  8.05s/it]


 90%|█████████ | 2811/3107 [6:02:58<39:26,  8.00s/it]

 91%|█████████ | 2812/3107 [6:03:07<39:52,  8.11s/it]
{'loss': 0.8348, 'grad_norm': 0.18125179959758017, 'learning_rate': 4.6934121980543366e-06, 'epoch': 0.91}

 91%|█████████ | 2813/3107 [6:03:13<36:47,  7.51s/it]


 91%|█████████ | 2815/3107 [6:03:28<37:13,  7.65s/it]
{'loss': 0.9231, 'grad_norm': 0.165150698312197, 'learning_rate': 4.599173211018237e-06, 'epoch': 0.91}

 91%|█████████ | 2816/3107 [6:03:34<34:26,  7.10s/it]


 91%|█████████ | 2818/3107 [6:03:46<31:54,  6.62s/it]

 91%|█████████ | 2819/3107 [6:03:52<31:08,  6.49s/it]
{'loss': 0.9919, 'grad_norm': 0.190297862168437, 'learning_rate': 4.474973435462526e-06, 'epoch': 0.91}


 91%|█████████ | 2821/3107 [6:04:09<34:33,  7.25s/it]
{'loss': 0.8689, 'grad_norm': 0.17972039305262094, 'learning_rate': 4.413496530312633e-06, 'epoch': 0.91}

 91%|█████████ | 2822/3107 [6:04:18<37:24,  7.87s/it]

 91%|█████████ | 2823/3107 [6:04:26<37:37,  7.95s/it]

 91%|█████████ | 2824/3107 [6:04:32<33:57,  7.20s/it]

 91%|█████████ | 2825/3107 [6:04:38<32:55,  7.01s/it]


 91%|█████████ | 2827/3107 [6:04:54<36:30,  7.82s/it]
{'loss': 0.8737, 'grad_norm': 0.17325693477005283, 'learning_rate': 4.231560948097502e-06, 'epoch': 0.91}

 91%|█████████ | 2828/3107 [6:05:00<33:08,  7.13s/it]

 91%|█████████ | 2829/3107 [6:05:08<33:43,  7.28s/it]


 91%|█████████ | 2831/3107 [6:05:21<31:46,  6.91s/it]
{'loss': 0.7929, 'grad_norm': 0.18500308668122928, 'learning_rate': 4.112352470413328e-06, 'epoch': 0.91}


 91%|█████████ | 2833/3107 [6:05:35<32:02,  7.02s/it]
{'loss': 0.8979, 'grad_norm': 0.18694937998320946, 'learning_rate': 4.053373585032216e-06, 'epoch': 0.91}

 91%|█████████ | 2834/3107 [6:05:42<31:58,  7.03s/it]

 91%|█████████ | 2835/3107 [6:05:48<30:36,  6.75s/it]

 91%|█████████▏| 2836/3107 [6:05:56<32:31,  7.20s/it]

 91%|█████████▏| 2837/3107 [6:06:03<32:09,  7.15s/it]

 91%|█████████▏| 2838/3107 [6:06:09<30:59,  6.91s/it]

 91%|█████████▏| 2839/3107 [6:06:15<29:14,  6.55s/it]

 91%|█████████▏| 2840/3107 [6:06:23<30:55,  6.95s/it]


 91%|█████████▏| 2842/3107 [6:06:41<36:00,  8.15s/it]

 92%|█████████▏| 2843/3107 [6:06:51<38:10,  8.68s/it]

 92%|█████████▏| 2844/3107 [6:07:01<40:03,  9.14s/it]

 92%|█████████▏| 2845/3107 [6:07:09<38:25,  8.80s/it]
{'loss': 0.8499, 'grad_norm': 0.16907992492355214, 'learning_rate': 3.7082712652200867e-06, 'epoch': 0.92}


 92%|█████████▏| 2847/3107 [6:07:25<37:02,  8.55s/it]
{'loss': 0.778, 'grad_norm': 0.17738112876856976, 'learning_rate': 3.652218378505057e-06, 'epoch': 0.92}

 92%|█████████▏| 2848/3107 [6:07:36<39:44,  9.21s/it]

 92%|█████████▏| 2849/3107 [6:07:44<38:28,  8.95s/it]


 92%|█████████▏| 2851/3107 [6:07:59<34:45,  8.15s/it]
{'loss': 0.9007, 'grad_norm': 0.18841568939162925, 'learning_rate': 3.5413698152102602e-06, 'epoch': 0.92}

 92%|█████████▏| 2852/3107 [6:08:06<33:30,  7.88s/it]

 92%|█████████▏| 2853/3107 [6:08:18<37:52,  8.95s/it]

 92%|█████████▏| 2854/3107 [6:08:24<34:07,  8.09s/it]


 92%|█████████▏| 2856/3107 [6:08:39<33:02,  7.90s/it]
{'loss': 0.9059, 'grad_norm': 0.1777573194342454, 'learning_rate': 3.4051688586085427e-06, 'epoch': 0.92}

 92%|█████████▏| 2857/3107 [6:08:50<36:56,  8.87s/it]

 92%|█████████▏| 2858/3107 [6:08:57<35:24,  8.53s/it]

 92%|█████████▏| 2859/3107 [6:09:05<34:28,  8.34s/it]

 92%|█████████▏| 2860/3107 [6:09:14<35:04,  8.52s/it]

 92%|█████████▏| 2861/3107 [6:09:24<35:55,  8.76s/it]

 92%|█████████▏| 2862/3107 [6:09:29<32:06,  7.86s/it]

 92%|█████████▏| 2863/3107 [6:09:36<30:06,  7.40s/it]


 92%|█████████▏| 2865/3107 [6:09:49<28:31,  7.07s/it]

 92%|█████████▏| 2866/3107 [6:09:59<31:24,  7.82s/it]

 92%|█████████▏| 2867/3107 [6:10:05<29:13,  7.31s/it]
{'loss': 0.8816, 'grad_norm': 0.18619911757865878, 'learning_rate': 3.1147732456982216e-06, 'epoch': 0.92}

 92%|█████████▏| 2868/3107 [6:10:11<27:15,  6.84s/it]

 92%|█████████▏| 2869/3107 [6:10:20<30:12,  7.62s/it]

 92%|█████████▏| 2870/3107 [6:10:29<32:14,  8.16s/it]

 92%|█████████▏| 2871/3107 [6:10:41<35:32,  9.04s/it]

 92%|█████████▏| 2872/3107 [6:10:48<33:15,  8.49s/it]

 92%|█████████▏| 2873/3107 [6:10:56<32:43,  8.39s/it]

 93%|█████████▎| 2874/3107 [6:11:02<30:16,  7.80s/it]


 93%|█████████▎| 2876/3107 [6:11:19<30:20,  7.88s/it]
{'loss': 0.834, 'grad_norm': 0.18712808888874416, 'learning_rate': 2.8866549142537723e-06, 'epoch': 0.93}


 93%|█████████▎| 2878/3107 [6:11:31<26:58,  7.07s/it]
{'loss': 0.8923, 'grad_norm': 0.173628467509582, 'learning_rate': 2.837122627261357e-06, 'epoch': 0.93}

 93%|█████████▎| 2879/3107 [6:11:38<26:48,  7.05s/it]

 93%|█████████▎| 2880/3107 [6:11:44<25:35,  6.77s/it]

 93%|█████████▎| 2881/3107 [6:11:54<28:41,  7.62s/it]

 93%|█████████▎| 2882/3107 [6:12:00<26:57,  7.19s/it]


 93%|█████████▎| 2884/3107 [6:12:13<25:06,  6.75s/it]

 93%|█████████▎| 2885/3107 [6:12:21<26:22,  7.13s/it]

 93%|█████████▎| 2886/3107 [6:12:31<29:59,  8.14s/it]

 93%|█████████▎| 2887/3107 [6:12:39<29:39,  8.09s/it]

 93%|█████████▎| 2888/3107 [6:12:45<27:16,  7.47s/it]
{'loss': 0.9413, 'grad_norm': 0.1961455795091492, 'learning_rate': 2.5958034463351987e-06, 'epoch': 0.93}

 93%|█████████▎| 2889/3107 [6:12:55<29:06,  8.01s/it]

 93%|█████████▎| 2890/3107 [6:13:02<27:51,  7.70s/it]


 93%|█████████▎| 2892/3107 [6:13:19<28:59,  8.09s/it]
{'loss': 0.8427, 'grad_norm': 0.17756819249768183, 'learning_rate': 2.5022394017979123e-06, 'epoch': 0.93}

 93%|█████████▎| 2893/3107 [6:13:27<28:21,  7.95s/it]


 93%|█████████▎| 2895/3107 [6:13:41<27:09,  7.69s/it]
{'loss': 0.813, 'grad_norm': 0.15647192289948367, 'learning_rate': 2.4331792539169173e-06, 'epoch': 0.93}

 93%|█████████▎| 2896/3107 [6:13:48<26:19,  7.48s/it]

 93%|█████████▎| 2897/3107 [6:13:54<24:30,  7.00s/it]

 93%|█████████▎| 2898/3107 [6:14:03<25:44,  7.39s/it]

 93%|█████████▎| 2899/3107 [6:14:10<25:28,  7.35s/it]


 93%|█████████▎| 2901/3107 [6:14:25<25:36,  7.46s/it]

 93%|█████████▎| 2902/3107 [6:14:31<23:49,  6.97s/it]

 93%|█████████▎| 2903/3107 [6:14:37<23:06,  6.80s/it]
{'loss': 1.0512, 'grad_norm': 0.1867265956853794, 'learning_rate': 2.253687860396547e-06, 'epoch': 0.93}

 93%|█████████▎| 2904/3107 [6:14:46<24:28,  7.23s/it]

 93%|█████████▎| 2905/3107 [6:14:52<23:07,  6.87s/it]


 94%|█████████▎| 2907/3107 [6:15:05<22:53,  6.87s/it]
{'loss': 1.0341, 'grad_norm': 0.16662215919702764, 'learning_rate': 2.166491814987293e-06, 'epoch': 0.94}


 94%|█████████▎| 2909/3107 [6:15:19<22:51,  6.93s/it]
{'loss': 0.8397, 'grad_norm': 0.1785436334191432, 'learning_rate': 2.1235318735571164e-06, 'epoch': 0.94}


 94%|█████████▎| 2911/3107 [6:15:36<25:23,  7.77s/it]
{'loss': 0.7236, 'grad_norm': 0.18656569673983633, 'learning_rate': 2.0809975693542262e-06, 'epoch': 0.94}

 94%|█████████▎| 2912/3107 [6:15:44<25:46,  7.93s/it]

 94%|█████████▍| 2913/3107 [6:15:52<26:05,  8.07s/it]

 94%|█████████▍| 2914/3107 [6:16:00<25:54,  8.05s/it]


 94%|█████████▍| 2916/3107 [6:16:13<23:11,  7.28s/it]
{'loss': 0.9525, 'grad_norm': 0.17355921697884558, 'learning_rate': 1.9765251810229036e-06, 'epoch': 0.94}

 94%|█████████▍| 2917/3107 [6:16:19<21:29,  6.79s/it]


 94%|█████████▍| 2919/3107 [6:16:33<22:25,  7.16s/it]
{'loss': 0.8875, 'grad_norm': 0.17399052650606223, 'learning_rate': 1.9151203964285936e-06, 'epoch': 0.94}

 94%|█████████▍| 2920/3107 [6:16:42<23:58,  7.69s/it]

 94%|█████████▍| 2921/3107 [6:16:50<23:54,  7.71s/it]

 94%|█████████▍| 2922/3107 [6:16:56<22:25,  7.27s/it]

 94%|█████████▍| 2923/3107 [6:17:02<20:55,  6.82s/it]


 94%|█████████▍| 2925/3107 [6:17:15<20:24,  6.73s/it]

 94%|█████████▍| 2926/3107 [6:17:24<21:43,  7.20s/it]

 94%|█████████▍| 2927/3107 [6:17:29<20:17,  6.77s/it]

 94%|█████████▍| 2928/3107 [6:17:38<21:24,  7.18s/it]
{'loss': 0.9784, 'grad_norm': 0.1745986688544447, 'learning_rate': 1.7366667342943677e-06, 'epoch': 0.94}

 94%|█████████▍| 2929/3107 [6:17:44<20:46,  7.00s/it]

 94%|█████████▍| 2930/3107 [6:17:53<21:57,  7.45s/it]

 94%|█████████▍| 2931/3107 [6:18:02<23:24,  7.98s/it]

 94%|█████████▍| 2932/3107 [6:18:08<21:58,  7.53s/it]

 94%|█████████▍| 2933/3107 [6:18:14<20:19,  7.01s/it]


 94%|█████████▍| 2935/3107 [6:18:28<19:49,  6.92s/it]
{'loss': 1.0178, 'grad_norm': 0.1956898813406845, 'learning_rate': 1.6038510964251352e-06, 'epoch': 0.94}


 95%|█████████▍| 2937/3107 [6:18:40<18:07,  6.39s/it]

 95%|█████████▍| 2938/3107 [6:18:49<20:52,  7.41s/it]
{'loss': 0.8125, 'grad_norm': 0.1627595500106364, 'learning_rate': 1.548534313950456e-06, 'epoch': 0.95}

 95%|█████████▍| 2939/3107 [6:18:59<22:45,  8.13s/it]


 95%|█████████▍| 2941/3107 [6:19:16<22:09,  8.01s/it]
{'loss': 0.9903, 'grad_norm': 0.17464993540097296, 'learning_rate': 1.494180840931747e-06, 'epoch': 0.95}

 95%|█████████▍| 2942/3107 [6:19:22<20:55,  7.61s/it]

 95%|█████████▍| 2943/3107 [6:19:29<19:51,  7.26s/it]


 95%|█████████▍| 2945/3107 [6:19:42<18:44,  6.94s/it]

 95%|█████████▍| 2946/3107 [6:19:50<19:29,  7.26s/it]
{'loss': 0.9115, 'grad_norm': 0.1790400462270661, 'learning_rate': 1.4057338471151427e-06, 'epoch': 0.95}

 95%|█████████▍| 2947/3107 [6:19:59<20:30,  7.69s/it]

 95%|█████████▍| 2948/3107 [6:20:06<20:23,  7.70s/it]

 95%|█████████▍| 2949/3107 [6:20:12<18:57,  7.20s/it]

 95%|█████████▍| 2950/3107 [6:20:19<18:05,  6.91s/it]


 95%|█████████▌| 2952/3107 [6:20:34<18:35,  7.20s/it]

 95%|█████████▌| 2953/3107 [6:20:40<17:29,  6.81s/it]
{'loss': 1.0268, 'grad_norm': 0.18890587537971745, 'learning_rate': 1.2864105384774782e-06, 'epoch': 0.95}

 95%|█████████▌| 2954/3107 [6:20:46<17:10,  6.74s/it]


 95%|█████████▌| 2956/3107 [6:21:00<17:19,  6.88s/it]

 95%|█████████▌| 2957/3107 [6:21:08<17:53,  7.15s/it]

 95%|█████████▌| 2958/3107 [6:21:14<16:55,  6.82s/it]

 95%|█████████▌| 2959/3107 [6:21:20<16:27,  6.67s/it]

 95%|█████████▌| 2960/3107 [6:21:31<19:48,  8.09s/it]
{'loss': 1.0296, 'grad_norm': 0.18377626844333342, 'learning_rate': 1.1723458593987935e-06, 'epoch': 0.95}


 95%|█████████▌| 2962/3107 [6:21:46<18:33,  7.68s/it]
{'loss': 0.9357, 'grad_norm': 0.19490125985674905, 'learning_rate': 1.1407226791743663e-06, 'epoch': 0.95}

 95%|█████████▌| 2963/3107 [6:21:56<20:43,  8.64s/it]

 95%|█████████▌| 2964/3107 [6:22:02<18:31,  7.77s/it]


 95%|█████████▌| 2966/3107 [6:22:18<18:00,  7.66s/it]
{'loss': 1.0026, 'grad_norm': 0.16874216562858568, 'learning_rate': 1.0787661879403277e-06, 'epoch': 0.95}

 95%|█████████▌| 2967/3107 [6:22:28<20:07,  8.62s/it]


 96%|█████████▌| 2969/3107 [6:22:44<18:30,  8.05s/it]
{'loss': 0.8271, 'grad_norm': 0.1792849606926649, 'learning_rate': 1.0334279846001106e-06, 'epoch': 0.96}

 96%|█████████▌| 2970/3107 [6:22:56<21:29,  9.41s/it]

 96%|█████████▌| 2971/3107 [6:23:03<19:33,  8.63s/it]

 96%|█████████▌| 2972/3107 [6:23:13<20:06,  8.93s/it]

 96%|█████████▌| 2973/3107 [6:23:19<18:18,  8.20s/it]

 96%|█████████▌| 2974/3107 [6:23:29<19:17,  8.70s/it]

 96%|█████████▌| 2975/3107 [6:23:37<18:46,  8.53s/it]


 96%|█████████▌| 2977/3107 [6:23:54<17:47,  8.21s/it]
{'loss': 1.0553, 'grad_norm': 0.1841557913946267, 'learning_rate': 9.172614373484934e-07, 'epoch': 0.96}

 96%|█████████▌| 2978/3107 [6:24:01<17:11,  7.99s/it]


 96%|█████████▌| 2980/3107 [6:24:12<14:15,  6.74s/it]
{'loss': 0.9947, 'grad_norm': 0.1780223519630987, 'learning_rate': 8.754759458285522e-07, 'epoch': 0.96}


 96%|█████████▌| 2982/3107 [6:24:26<14:22,  6.90s/it]

 96%|█████████▌| 2983/3107 [6:24:32<13:30,  6.54s/it]
{'loss': 0.9422, 'grad_norm': 0.18245686663300104, 'learning_rate': 8.346603493800009e-07, 'epoch': 0.96}

 96%|█████████▌| 2984/3107 [6:24:37<12:45,  6.23s/it]


 96%|█████████▌| 2986/3107 [6:24:50<12:41,  6.29s/it]
{'loss': 0.907, 'grad_norm': 0.16199286789520712, 'learning_rate': 7.948150473676585e-07, 'epoch': 0.96}

 96%|█████████▌| 2987/3107 [6:24:59<14:08,  7.07s/it]


 96%|█████████▌| 2989/3107 [6:25:16<15:34,  7.92s/it]
{'loss': 1.024, 'grad_norm': 0.17392426974154016, 'learning_rate': 7.559404296623495e-07, 'epoch': 0.96}

 96%|█████████▌| 2990/3107 [6:25:22<14:27,  7.42s/it]


 96%|█████████▋| 2992/3107 [6:25:36<13:27,  7.03s/it]
{'loss': 0.911, 'grad_norm': 0.18180379631607219, 'learning_rate': 7.180368766371515e-07, 'epoch': 0.96}

 96%|█████████▋| 2993/3107 [6:25:42<13:07,  6.91s/it]


 96%|█████████▋| 2995/3107 [6:25:56<12:46,  6.84s/it]
{'loss': 0.8956, 'grad_norm': 0.19215855064722878, 'learning_rate': 6.811047591636644e-07, 'epoch': 0.96}


 96%|█████████▋| 2997/3107 [6:26:14<14:39,  8.00s/it]

 96%|█████████▋| 2998/3107 [6:26:22<14:40,  8.08s/it]
{'loss': 0.9653, 'grad_norm': 0.18191285178622005, 'learning_rate': 6.45144438608336e-07, 'epoch': 0.96}

 97%|█████████▋| 2999/3107 [6:26:29<13:56,  7.74s/it]

 97%|█████████▋| 3000/3107 [6:26:38<14:40,  8.23s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.013, 'grad_norm': 0.17880228946432014, 'learning_rate': 6.101562668289873e-07, 'epoch': 0.97}
 97%|█████████▋| 3001/3107 [6:27:24<34:06, 19.30s/it]


 97%|█████████▋| 3003/3107 [6:27:38<22:26, 12.95s/it]

 97%|█████████▋| 3004/3107 [6:27:48<20:44, 12.08s/it]
{'loss': 0.905, 'grad_norm': 0.17531095105094535, 'learning_rate': 5.761405861713142e-07, 'epoch': 0.97}

 97%|█████████▋| 3005/3107 [6:27:55<17:46, 10.46s/it]

 97%|█████████▋| 3006/3107 [6:28:02<15:56,  9.47s/it]


 97%|█████████▋| 3008/3107 [6:28:18<14:38,  8.87s/it]
{'loss': 0.9234, 'grad_norm': 0.16669983440914535, 'learning_rate': 5.322996831527038e-07, 'epoch': 0.97}

 97%|█████████▋| 3009/3107 [6:28:24<12:44,  7.80s/it]

 97%|█████████▋| 3010/3107 [6:28:29<11:36,  7.18s/it]

 97%|█████████▋| 3011/3107 [6:28:37<11:39,  7.29s/it]


 97%|█████████▋| 3013/3107 [6:28:48<10:10,  6.49s/it]

 97%|█████████▋| 3014/3107 [6:28:56<10:35,  6.84s/it]
{'loss': 0.8762, 'grad_norm': 0.18298663495614392, 'learning_rate': 4.6978273304646434e-07, 'epoch': 0.97}

 97%|█████████▋| 3015/3107 [6:29:01<09:49,  6.41s/it]

 97%|█████████▋| 3016/3107 [6:29:12<11:27,  7.55s/it]


 97%|█████████▋| 3018/3107 [6:29:26<10:45,  7.26s/it]

 97%|█████████▋| 3019/3107 [6:29:34<11:00,  7.50s/it]
{'loss': 1.0233, 'grad_norm': 0.17662792320538034, 'learning_rate': 4.206608655467403e-07, 'epoch': 0.97}

 97%|█████████▋| 3020/3107 [6:29:45<12:22,  8.54s/it]

 97%|█████████▋| 3021/3107 [6:29:55<12:43,  8.88s/it]


 97%|█████████▋| 3023/3107 [6:30:08<10:59,  7.85s/it]
{'loss': 0.793, 'grad_norm': 0.17804816358183137, 'learning_rate': 3.8331199763008695e-07, 'epoch': 0.97}

 97%|█████████▋| 3024/3107 [6:30:16<10:39,  7.71s/it]

 97%|█████████▋| 3025/3107 [6:30:25<11:07,  8.13s/it]

 97%|█████████▋| 3026/3107 [6:30:32<10:26,  7.74s/it]

 97%|█████████▋| 3027/3107 [6:30:37<09:21,  7.02s/it]

 97%|█████████▋| 3028/3107 [6:30:47<10:26,  7.93s/it]


 98%|█████████▊| 3030/3107 [6:31:04<10:45,  8.38s/it]

 98%|█████████▊| 3031/3107 [6:31:10<09:32,  7.54s/it]

 98%|█████████▊| 3032/3107 [6:31:16<08:54,  7.12s/it]

 98%|█████████▊| 3033/3107 [6:31:23<08:29,  6.89s/it]
{'loss': 0.8769, 'grad_norm': 0.1910859264812951, 'learning_rate': 2.975222532820898e-07, 'epoch': 0.98}

 98%|█████████▊| 3034/3107 [6:31:28<07:51,  6.46s/it]

 98%|█████████▊| 3035/3107 [6:31:37<08:42,  7.26s/it]


 98%|█████████▊| 3037/3107 [6:31:52<08:44,  7.49s/it]
{'loss': 0.7562, 'grad_norm': 0.1730520108654079, 'learning_rate': 2.662408926359494e-07, 'epoch': 0.98}

 98%|█████████▊| 3038/3107 [6:31:59<08:20,  7.25s/it]


 98%|█████████▊| 3040/3107 [6:32:16<09:11,  8.23s/it]
{'loss': 0.7987, 'grad_norm': 0.16498582184194127, 'learning_rate': 2.43918341706928e-07, 'epoch': 0.98}

 98%|█████████▊| 3041/3107 [6:32:23<08:38,  7.85s/it]

 98%|█████████▊| 3042/3107 [6:32:34<09:15,  8.55s/it]

 98%|█████████▊| 3043/3107 [6:32:39<08:07,  7.62s/it]

 98%|█████████▊| 3044/3107 [6:32:46<07:40,  7.30s/it]


 98%|█████████▊| 3046/3107 [6:33:00<07:33,  7.43s/it]
{'loss': 0.878, 'grad_norm': 0.17381843733992647, 'learning_rate': 2.0220167256962407e-07, 'epoch': 0.98}

 98%|█████████▊| 3047/3107 [6:33:10<07:56,  7.94s/it]


 98%|█████████▊| 3049/3107 [6:33:22<06:59,  7.23s/it]
{'loss': 0.8947, 'grad_norm': 0.17945796660730004, 'learning_rate': 1.8280796254279698e-07, 'epoch': 0.98}

 98%|█████████▊| 3050/3107 [6:33:30<06:51,  7.21s/it]

 98%|█████████▊| 3051/3107 [6:33:36<06:32,  7.02s/it]

 98%|█████████▊| 3052/3107 [6:33:46<07:06,  7.76s/it]

 98%|█████████▊| 3053/3107 [6:33:52<06:36,  7.34s/it]

 98%|█████████▊| 3054/3107 [6:34:00<06:40,  7.56s/it]

 98%|█████████▊| 3055/3107 [6:34:11<07:32,  8.71s/it]


 98%|█████████▊| 3057/3107 [6:34:29<07:25,  8.90s/it]

 98%|█████████▊| 3058/3107 [6:34:35<06:33,  8.04s/it]
{'loss': 0.8832, 'grad_norm': 0.1742989262653507, 'learning_rate': 1.30487579074301e-07, 'epoch': 0.98}


 98%|█████████▊| 3060/3107 [6:34:47<05:27,  6.97s/it]
{'loss': 0.9621, 'grad_norm': 0.17110597296858457, 'learning_rate': 1.2005500893441657e-07, 'epoch': 0.98}

 99%|█████████▊| 3061/3107 [6:34:57<06:11,  8.07s/it]


 99%|█████████▊| 3063/3107 [6:35:10<05:17,  7.23s/it]

 99%|█████████▊| 3064/3107 [6:35:16<04:54,  6.85s/it]
{'loss': 0.9667, 'grad_norm': 0.20570816449362034, 'learning_rate': 1.0049296148790799e-07, 'epoch': 0.99}

 99%|█████████▊| 3065/3107 [6:35:23<04:46,  6.83s/it]

 99%|█████████▊| 3066/3107 [6:35:30<04:40,  6.84s/it]

 99%|█████████▊| 3067/3107 [6:35:36<04:19,  6.48s/it]

 99%|█████████▊| 3068/3107 [6:35:43<04:27,  6.85s/it]

 99%|█████████▉| 3069/3107 [6:35:50<04:14,  6.68s/it]


 99%|█████████▉| 3071/3107 [6:36:06<04:39,  7.76s/it]
[2024-05-28 05:00:16,704] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9147, 'grad_norm': 0.16811013500363556, 'learning_rate': 7.044099703641394e-08, 'epoch': 0.99}

 99%|█████████▉| 3072/3107 [6:36:13<04:20,  7.45s/it]

 99%|█████████▉| 3073/3107 [6:36:28<05:28,  9.66s/it]


 99%|█████████▉| 3075/3107 [6:36:41<04:13,  7.93s/it]

 99%|█████████▉| 3076/3107 [6:36:53<04:43,  9.14s/it]
[2024-05-28 05:01:03,053] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9536, 'grad_norm': 0.16000184772480208, 'learning_rate': 5.22344542916553e-08, 'epoch': 0.99}


 99%|█████████▉| 3078/3107 [6:37:07<03:51,  7.99s/it]
{'loss': 0.9106, 'grad_norm': 0.2041259232292559, 'learning_rate': 4.571243877099507e-08, 'epoch': 0.99}


 99%|█████████▉| 3080/3107 [6:37:23<03:37,  8.07s/it]

 99%|█████████▉| 3081/3107 [6:37:31<03:28,  8.01s/it]

 99%|█████████▉| 3082/3107 [6:37:39<03:18,  7.96s/it]
{'loss': 0.9569, 'grad_norm': 0.1753357675141959, 'learning_rate': 3.397245344037847e-08, 'epoch': 0.99}


 99%|█████████▉| 3084/3107 [6:37:53<02:50,  7.42s/it]

 99%|█████████▉| 3085/3107 [6:38:01<02:43,  7.42s/it]

 99%|█████████▉| 3086/3107 [6:38:07<02:28,  7.07s/it]

 99%|█████████▉| 3087/3107 [6:38:15<02:25,  7.30s/it]

 99%|█████████▉| 3088/3107 [6:38:27<02:47,  8.83s/it]
{'loss': 0.8174, 'grad_norm': 0.1765962204517618, 'learning_rate': 1.9622958446907645e-08, 'epoch': 0.99}


 99%|█████████▉| 3090/3107 [6:38:41<02:14,  7.89s/it]
{'loss': 0.9147, 'grad_norm': 0.17024039151347653, 'learning_rate': 1.5709340676206553e-08, 'epoch': 0.99}

 99%|█████████▉| 3091/3107 [6:38:48<02:01,  7.58s/it]

100%|█████████▉| 3092/3107 [6:38:54<01:48,  7.25s/it]

100%|█████████▉| 3093/3107 [6:39:02<01:43,  7.36s/it]

100%|█████████▉| 3094/3107 [6:39:09<01:35,  7.36s/it]

100%|█████████▉| 3095/3107 [6:39:16<01:25,  7.11s/it]

100%|█████████▉| 3096/3107 [6:39:25<01:26,  7.83s/it]

100%|█████████▉| 3097/3107 [6:39:32<01:13,  7.33s/it]

100%|█████████▉| 3098/3107 [6:39:41<01:10,  7.81s/it]


100%|█████████▉| 3100/3107 [6:39:55<00:52,  7.43s/it]

100%|█████████▉| 3101/3107 [6:40:01<00:42,  7.08s/it]
{'loss': 0.9903, 'grad_norm': 0.17556926285291022, 'learning_rate': 1.9569177418743422e-09, 'epoch': 1.0}

100%|█████████▉| 3102/3107 [6:40:06<00:32,  6.56s/it]

100%|█████████▉| 3103/3107 [6:40:15<00:28,  7.08s/it]

100%|█████████▉| 3104/3107 [6:40:20<00:19,  6.64s/it]

100%|█████████▉| 3105/3107 [6:40:28<00:14,  7.02s/it]

100%|█████████▉| 3106/3107 [6:40:36<00:07,  7.14s/it]
{'loss': 0.8875, 'grad_norm': 0.18465362134300103, 'learning_rate': 0.0, 'epoch': 1.0}

100%|██████████| 3107/3107 [6:40:43<00:00,  7.74s/it]
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(