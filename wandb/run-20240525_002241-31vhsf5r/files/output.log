/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
  0%|          | 0/3844 [00:00<?, ?it/s]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Total Loss: 1.223037600517273, NLL Loss: 1.1696040630340576, Router Loss: 5.343358516693115, weight: 0.01
Total Loss: 1.8644511699676514, NLL Loss: 1.814663290977478, Router Loss: 4.978793144226074, weight: 0.01
  0%|          | 1/3844 [00:33<35:49:23, 33.56s/it]
{'loss': 1.9389, 'grad_norm': 1.0720524182782127, 'learning_rate': 1.7241379310344828e-07, 'epoch': 0.0}
Total Loss: 2.022822856903076, NLL Loss: 1.9718846082687378, Router Loss: 5.093820571899414, weight: 0.01

  0%|          | 2/3844 [00:41<19:27:43, 18.24s/it]
{'loss': 1.9475, 'grad_norm': 1.4650231323859624, 'learning_rate': 3.4482758620689656e-07, 'epoch': 0.0}
Total Loss: 1.5191043615341187, NLL Loss: 1.4673352241516113, Router Loss: 5.176910400390625, weight: 0.01

  0%|          | 3/3844 [00:48<14:18:00, 13.40s/it]
{'loss': 1.9947, 'grad_norm': 1.520112779184278, 'learning_rate': 5.172413793103449e-07, 'epoch': 0.0}
Total Loss: 1.5644335746765137, NLL Loss: 1.5178946256637573, Router Loss: 4.65389347076416, weight: 0.01

  0%|          | 4/3844 [00:56<11:57:28, 11.21s/it]
{'loss': 1.8122, 'grad_norm': 1.5256904610166868, 'learning_rate': 6.896551724137931e-07, 'epoch': 0.0}
Total Loss: 1.403770089149475, NLL Loss: 1.3525711297988892, Router Loss: 5.119901657104492, weight: 0.01
Total Loss: 1.9000853300094604, NLL Loss: 1.8488808870315552, Router Loss: 5.120440483093262, weight: 0.01

  0%|          | 5/3844 [01:01<9:36:02,  9.00s/it]
Total Loss: 2.216017484664917, NLL Loss: 2.168147563934326, Router Loss: 4.786987781524658, weight: 0.01

  0%|          | 6/3844 [01:08<8:55:25,  8.37s/it]
{'loss': 1.8652, 'grad_norm': 1.3295443337866184, 'learning_rate': 1.0344827586206898e-06, 'epoch': 0.0}
Total Loss: 1.4309523105621338, NLL Loss: 1.3759334087371826, Router Loss: 5.501886367797852, weight: 0.01

  0%|          | 7/3844 [01:17<8:53:03,  8.34s/it]
{'loss': 1.9603, 'grad_norm': 1.36464283951759, 'learning_rate': 1.2068965517241381e-06, 'epoch': 0.0}
Total Loss: 1.3389002084732056, NLL Loss: 1.2881592512130737, Router Loss: 5.074093818664551, weight: 0.01

  0%|          | 8/3844 [01:23<8:09:56,  7.66s/it]
{'loss': 1.8654, 'grad_norm': 1.306944179221152, 'learning_rate': 1.3793103448275862e-06, 'epoch': 0.0}
Total Loss: 1.9423062801361084, NLL Loss: 1.889729619026184, Router Loss: 5.257670879364014, weight: 0.01

  0%|          | 9/3844 [01:30<7:54:38,  7.43s/it]
{'loss': 1.8536, 'grad_norm': 1.2917220296084249, 'learning_rate': 1.5517241379310346e-06, 'epoch': 0.0}
Total Loss: 2.072874069213867, NLL Loss: 2.0198862552642822, Router Loss: 5.298774719238281, weight: 0.01
Total Loss: 2.3112192153930664, NLL Loss: 2.2624189853668213, Router Loss: 4.880033493041992, weight: 0.01

  0%|          | 10/3844 [01:35<7:15:16,  6.81s/it]
Total Loss: 2.036912441253662, NLL Loss: 1.9868966341018677, Router Loss: 5.001581192016602, weight: 0.01
Total Loss: 2.4185791015625, NLL Loss: 2.3695333003997803, Router Loss: 4.904579162597656, weight: 0.01

  0%|          | 11/3844 [01:41<7:05:24,  6.66s/it]
Total Loss: 1.6263223886489868, NLL Loss: 1.5745426416397095, Router Loss: 5.177974700927734, weight: 0.01
Total Loss: 1.7337729930877686, NLL Loss: 1.6809877157211304, Router Loss: 5.27852725982666, weight: 0.01

  0%|          | 12/3844 [01:47<6:50:57,  6.43s/it]
Total Loss: 2.34753680229187, NLL Loss: 2.298980236053467, Router Loss: 4.855646133422852, weight: 0.01

  0%|          | 13/3844 [01:53<6:29:19,  6.10s/it]
{'loss': 1.9466, 'grad_norm': 1.1718551661512056, 'learning_rate': 2.241379310344828e-06, 'epoch': 0.0}
Total Loss: 1.7123770713806152, NLL Loss: 1.6606136560440063, Router Loss: 5.176339149475098, weight: 0.01

  0%|          | 14/3844 [02:00<6:56:44,  6.53s/it]
{'loss': 1.8131, 'grad_norm': 1.4389879842439286, 'learning_rate': 2.4137931034482762e-06, 'epoch': 0.0}
Total Loss: 2.3774254322052, NLL Loss: 2.3267171382904053, Router Loss: 5.070840835571289, weight: 0.01

  0%|          | 15/3844 [02:06<6:38:16,  6.24s/it]
{'loss': 1.9719, 'grad_norm': 1.4596268812491437, 'learning_rate': 2.5862068965517246e-06, 'epoch': 0.0}
Total Loss: 2.4779739379882812, NLL Loss: 2.4269516468048096, Router Loss: 5.10222053527832, weight: 0.01
Total Loss: 1.92690908908844, NLL Loss: 1.876898169517517, Router Loss: 5.001094818115234, weight: 0.01

  0%|          | 16/3844 [02:11<6:19:53,  5.95s/it]
Total Loss: 2.3884456157684326, NLL Loss: 2.338919162750244, Router Loss: 4.952645778656006, weight: 0.01

  0%|          | 17/3844 [02:18<6:43:17,  6.32s/it]
{'loss': 1.9995, 'grad_norm': 1.238674577609938, 'learning_rate': 2.931034482758621e-06, 'epoch': 0.0}
Total Loss: 1.7433284521102905, NLL Loss: 1.6927169561386108, Router Loss: 5.0611491203308105, weight: 0.01

  0%|          | 18/3844 [02:25<6:42:40,  6.31s/it]
{'loss': 2.0693, 'grad_norm': 1.381585117033719, 'learning_rate': 3.103448275862069e-06, 'epoch': 0.0}
Total Loss: 2.4319746494293213, NLL Loss: 2.382817029953003, Router Loss: 4.915769100189209, weight: 0.01
Total Loss: 2.3737542629241943, NLL Loss: 2.326124429702759, Router Loss: 4.762977123260498, weight: 0.01

  0%|          | 19/3844 [02:31<6:53:02,  6.48s/it]
Total Loss: 2.067127227783203, NLL Loss: 2.015878677368164, Router Loss: 5.124856948852539, weight: 0.01

  1%|          | 20/3844 [02:38<7:03:45,  6.65s/it]
{'loss': 1.9609, 'grad_norm': 1.4593359807997721, 'learning_rate': 3.448275862068966e-06, 'epoch': 0.01}
Total Loss: 2.160395622253418, NLL Loss: 2.1114611625671387, Router Loss: 4.893438339233398, weight: 0.01

  1%|          | 21/3844 [02:44<6:44:27,  6.35s/it]
{'loss': 1.935, 'grad_norm': 1.3212932490053813, 'learning_rate': 3.620689655172414e-06, 'epoch': 0.01}
Total Loss: 1.7514209747314453, NLL Loss: 1.702272653579712, Router Loss: 4.914836883544922, weight: 0.01

  1%|          | 22/3844 [02:51<6:51:00,  6.45s/it]
{'loss': 1.9699, 'grad_norm': 1.2897796781432045, 'learning_rate': 3.793103448275862e-06, 'epoch': 0.01}
Total Loss: 2.171614408493042, NLL Loss: 2.1229429244995117, Router Loss: 4.867137432098389, weight: 0.01
Total Loss: 1.3608319759368896, NLL Loss: 1.3083220720291138, Router Loss: 5.250995635986328, weight: 0.01

  1%|          | 23/3844 [02:59<7:33:43,  7.12s/it]
Total Loss: 1.4970715045928955, NLL Loss: 1.4458816051483154, Router Loss: 5.11898946762085, weight: 0.01

  1%|          | 24/3844 [03:05<6:57:31,  6.56s/it]
{'loss': 1.8445, 'grad_norm': 1.2007854267003235, 'learning_rate': 4.137931034482759e-06, 'epoch': 0.01}
Total Loss: 1.7975122928619385, NLL Loss: 1.7496620416641235, Router Loss: 4.785020351409912, weight: 0.01

  1%|          | 25/3844 [03:14<7:45:54,  7.32s/it]
{'loss': 1.9189, 'grad_norm': 1.5728395903071535, 'learning_rate': 4.310344827586207e-06, 'epoch': 0.01}
Total Loss: 2.2280147075653076, NLL Loss: 2.178959608078003, Router Loss: 4.905501842498779, weight: 0.01
Total Loss: 1.7112990617752075, NLL Loss: 1.6610240936279297, Router Loss: 5.027493000030518, weight: 0.01

  1%|          | 26/3844 [03:23<8:23:51,  7.92s/it]
Total Loss: 1.8780096769332886, NLL Loss: 1.8281347751617432, Router Loss: 4.987485885620117, weight: 0.01

  1%|          | 27/3844 [03:28<7:25:17,  7.00s/it]
{'loss': 1.8598, 'grad_norm': 1.1072441282939147, 'learning_rate': 4.655172413793104e-06, 'epoch': 0.01}
Total Loss: 2.0019686222076416, NLL Loss: 1.9516533613204956, Router Loss: 5.031528472900391, weight: 0.01
Total Loss: 2.072026014328003, NLL Loss: 2.02285099029541, Router Loss: 4.917505264282227, weight: 0.01

  1%|          | 28/3844 [03:34<6:59:28,  6.60s/it]
Total Loss: 2.017815113067627, NLL Loss: 1.9686081409454346, Router Loss: 4.920699119567871, weight: 0.01

  1%|          | 29/3844 [03:38<6:23:42,  6.03s/it]
{'loss': 2.0032, 'grad_norm': 1.1771708333918818, 'learning_rate': 5e-06, 'epoch': 0.01}
Total Loss: 2.0779664516448975, NLL Loss: 2.028299570083618, Router Loss: 4.966691970825195, weight: 0.01

  1%|          | 30/3844 [03:45<6:28:48,  6.12s/it]
{'loss': 1.9694, 'grad_norm': 1.2975465164523474, 'learning_rate': 5.172413793103449e-06, 'epoch': 0.01}
Total Loss: 1.4831823110580444, NLL Loss: 1.435255527496338, Router Loss: 4.7926812171936035, weight: 0.01

  1%|          | 31/3844 [03:50<6:12:21,  5.86s/it]
{'loss': 1.9078, 'grad_norm': 1.1282195351977606, 'learning_rate': 5.344827586206896e-06, 'epoch': 0.01}
Total Loss: 2.380309581756592, NLL Loss: 2.332275390625, Router Loss: 4.803413391113281, weight: 0.01
Total Loss: 2.109799385070801, NLL Loss: 2.0601284503936768, Router Loss: 4.967104911804199, weight: 0.01

  1%|          | 32/3844 [03:55<6:06:10,  5.76s/it]
Total Loss: 2.584643840789795, NLL Loss: 2.5367956161499023, Router Loss: 4.784832000732422, weight: 0.01

  1%|          | 33/3844 [04:03<6:38:36,  6.28s/it]
{'loss': 1.8877, 'grad_norm': 1.3716240088201115, 'learning_rate': 5.689655172413794e-06, 'epoch': 0.01}
Total Loss: 1.535946249961853, NLL Loss: 1.4867616891860962, Router Loss: 4.918455123901367, weight: 0.01

  1%|          | 34/3844 [04:09<6:34:46,  6.22s/it]
{'loss': 1.9144, 'grad_norm': 1.2168013672421172, 'learning_rate': 5.862068965517242e-06, 'epoch': 0.01}
Total Loss: 1.3952487707138062, NLL Loss: 1.342406153678894, Router Loss: 5.2842583656311035, weight: 0.01
Total Loss: 2.2880759239196777, NLL Loss: 2.239884614944458, Router Loss: 4.819130897521973, weight: 0.01

  1%|          | 35/3844 [04:16<6:39:40,  6.30s/it]
Total Loss: 1.0107277631759644, NLL Loss: 0.9575667977333069, Router Loss: 5.316096305847168, weight: 0.01

  1%|          | 36/3844 [04:25<7:33:52,  7.15s/it]
{'loss': 1.7897, 'grad_norm': 1.5434056686104667, 'learning_rate': 6.206896551724138e-06, 'epoch': 0.01}
Total Loss: 2.213709592819214, NLL Loss: 2.1672585010528564, Router Loss: 4.645098686218262, weight: 0.01

  1%|          | 37/3844 [04:30<6:58:31,  6.60s/it]
{'loss': 1.8396, 'grad_norm': 1.2712375600305554, 'learning_rate': 6.379310344827587e-06, 'epoch': 0.01}
Total Loss: 2.3479411602020264, NLL Loss: 2.299031972885132, Router Loss: 4.89093017578125, weight: 0.01

  1%|          | 38/3844 [04:37<7:06:52,  6.73s/it]
{'loss': 2.0723, 'grad_norm': 1.379753328732582, 'learning_rate': 6.551724137931035e-06, 'epoch': 0.01}
Total Loss: 1.949704647064209, NLL Loss: 1.899693489074707, Router Loss: 5.001110076904297, weight: 0.01

  1%|          | 39/3844 [04:42<6:30:06,  6.15s/it]
{'loss': 1.9883, 'grad_norm': 1.0610103831150908, 'learning_rate': 6.724137931034484e-06, 'epoch': 0.01}
Total Loss: 1.901327133178711, NLL Loss: 1.8525687456130981, Router Loss: 4.875838279724121, weight: 0.01

  1%|          | 40/3844 [04:47<6:14:01,  5.90s/it]
{'loss': 1.9753, 'grad_norm': 1.2161284872135145, 'learning_rate': 6.896551724137932e-06, 'epoch': 0.01}
Total Loss: 2.0017049312591553, NLL Loss: 1.951815128326416, Router Loss: 4.988977909088135, weight: 0.01
Total Loss: 1.7774701118469238, NLL Loss: 1.7293916940689087, Router Loss: 4.807840824127197, weight: 0.01

  1%|          | 41/3844 [04:53<6:18:40,  5.97s/it]
Total Loss: 1.3072041273117065, NLL Loss: 1.2557520866394043, Router Loss: 5.145204067230225, weight: 0.01
Total Loss: 2.051334857940674, NLL Loss: 2.002261161804199, Router Loss: 4.907358169555664, weight: 0.01

  1%|          | 42/3844 [04:59<6:15:09,  5.92s/it]
