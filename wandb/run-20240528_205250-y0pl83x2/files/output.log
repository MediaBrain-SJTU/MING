/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
  0%|          | 0/3106 [00:00<?, ?it/s]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/3106 [00:59<51:05:14, 59.23s/it]

  0%|          | 2/3106 [01:11<27:13:04, 31.57s/it]

  0%|          | 3/3106 [01:22<19:16:59, 22.37s/it]
{'loss': 1.5855, 'grad_norm': 3.741322039979158, 'learning_rate': 6.3829787234042555e-06, 'epoch': 0.0}


  0%|          | 5/3106 [01:53<15:31:45, 18.03s/it]
{'loss': 1.4588, 'grad_norm': 3.151205051319702, 'learning_rate': 1.0638297872340426e-05, 'epoch': 0.0}

  0%|          | 6/3106 [02:04<13:36:51, 15.81s/it]

  0%|          | 7/3106 [02:17<12:46:22, 14.84s/it]

  0%|          | 8/3106 [02:32<12:43:53, 14.79s/it]

  0%|          | 9/3106 [02:46<12:41:13, 14.75s/it]

  0%|          | 10/3106 [03:04<13:28:08, 15.66s/it]

  0%|          | 11/3106 [03:18<13:08:12, 15.28s/it]

  0%|          | 12/3106 [03:30<12:14:13, 14.24s/it]

  0%|          | 13/3106 [03:44<12:11:09, 14.18s/it]

  0%|          | 14/3106 [03:59<12:20:16, 14.36s/it]

  0%|          | 15/3106 [04:10<11:29:39, 13.39s/it]

  1%|          | 16/3106 [04:25<11:52:33, 13.84s/it]

  1%|          | 17/3106 [04:39<11:49:16, 13.78s/it]

  1%|          | 18/3106 [04:52<11:45:53, 13.72s/it]

  1%|          | 19/3106 [05:04<11:14:50, 13.12s/it]

  1%|          | 20/3106 [05:16<10:54:54, 12.73s/it]

  1%|          | 21/3106 [05:29<11:01:30, 12.87s/it]

  1%|          | 22/3106 [05:42<11:04:27, 12.93s/it]

  1%|          | 23/3106 [05:56<11:20:49, 13.25s/it]

  1%|          | 24/3106 [06:13<12:23:24, 14.47s/it]

  1%|          | 25/3106 [06:25<11:36:07, 13.56s/it]


  1%|          | 27/3106 [06:49<11:03:19, 12.93s/it]
{'loss': 1.3337, 'grad_norm': 1.2224359709928765, 'learning_rate': 5.744680851063831e-05, 'epoch': 0.01}

  1%|          | 28/3106 [07:03<11:22:05, 13.30s/it]

  1%|          | 29/3106 [07:20<12:14:29, 14.32s/it]

  1%|          | 30/3106 [07:33<11:54:23, 13.93s/it]

  1%|          | 31/3106 [07:48<12:03:25, 14.12s/it]

  1%|          | 32/3106 [08:02<12:07:30, 14.20s/it]


  1%|          | 34/3106 [08:30<11:57:45, 14.02s/it]
{'loss': 1.1904, 'grad_norm': 0.8992622804944844, 'learning_rate': 7.23404255319149e-05, 'epoch': 0.01}

  1%|          | 35/3106 [08:43<11:53:19, 13.94s/it]

  1%|          | 36/3106 [08:57<11:44:14, 13.76s/it]

  1%|          | 37/3106 [09:12<12:07:45, 14.23s/it]

  1%|          | 38/3106 [09:27<12:27:03, 14.61s/it]

  1%|▏         | 39/3106 [09:41<12:17:22, 14.43s/it]

  1%|▏         | 40/3106 [09:58<12:51:05, 15.09s/it]

  1%|▏         | 41/3106 [10:12<12:30:12, 14.69s/it]

  1%|▏         | 42/3106 [10:24<11:53:57, 13.98s/it]

  1%|▏         | 43/3106 [10:36<11:19:45, 13.32s/it]


  1%|▏         | 45/3106 [11:02<11:14:49, 13.23s/it]
{'loss': 1.2541, 'grad_norm': 0.5264169963475851, 'learning_rate': 9.574468085106384e-05, 'epoch': 0.01}

  1%|▏         | 46/3106 [11:16<11:29:37, 13.52s/it]

  2%|▏         | 47/3106 [11:31<12:01:44, 14.16s/it]

  2%|▏         | 48/3106 [11:45<11:55:53, 14.05s/it]

  2%|▏         | 49/3106 [11:57<11:27:37, 13.50s/it]


  2%|▏         | 51/3106 [12:26<11:31:20, 13.58s/it]
{'loss': 1.2434, 'grad_norm': 0.38208216096116526, 'learning_rate': 0.00010851063829787234, 'epoch': 0.02}

  2%|▏         | 52/3106 [12:40<11:41:49, 13.79s/it]

  2%|▏         | 53/3106 [12:52<11:13:40, 13.24s/it]

  2%|▏         | 54/3106 [13:07<11:35:26, 13.67s/it]

  2%|▏         | 55/3106 [13:18<10:58:08, 12.94s/it]

  2%|▏         | 56/3106 [13:30<10:49:09, 12.77s/it]

  2%|▏         | 57/3106 [13:45<11:19:18, 13.37s/it]

  2%|▏         | 58/3106 [13:58<11:15:33, 13.30s/it]

  2%|▏         | 59/3106 [14:11<11:08:00, 13.15s/it]


  2%|▏         | 61/3106 [14:38<11:19:30, 13.39s/it]
{'loss': 1.2114, 'grad_norm': 0.36983233435002744, 'learning_rate': 0.00012978723404255318, 'epoch': 0.02}

  2%|▏         | 62/3106 [14:51<11:15:08, 13.31s/it]


  2%|▏         | 64/3106 [15:24<12:52:56, 15.25s/it]
{'loss': 1.0504, 'grad_norm': 0.3541441886672222, 'learning_rate': 0.00013617021276595746, 'epoch': 0.02}

  2%|▏         | 65/3106 [15:36<11:59:56, 14.20s/it]

  2%|▏         | 66/3106 [15:47<11:15:06, 13.32s/it]

  2%|▏         | 67/3106 [16:02<11:45:03, 13.92s/it]

  2%|▏         | 68/3106 [16:17<11:50:18, 14.03s/it]

  2%|▏         | 69/3106 [16:29<11:21:01, 13.45s/it]

  2%|▏         | 70/3106 [16:41<10:57:54, 13.00s/it]

  2%|▏         | 71/3106 [16:53<10:42:30, 12.70s/it]

  2%|▏         | 72/3106 [17:09<11:40:44, 13.86s/it]

  2%|▏         | 73/3106 [17:26<12:30:42, 14.85s/it]

  2%|▏         | 74/3106 [17:47<13:59:03, 16.60s/it]

  2%|▏         | 75/3106 [18:01<13:14:47, 15.73s/it]

  2%|▏         | 76/3106 [18:13<12:24:24, 14.74s/it]

  2%|▏         | 77/3106 [18:25<11:42:53, 13.92s/it]

  3%|▎         | 78/3106 [18:36<11:00:44, 13.09s/it]

  3%|▎         | 79/3106 [18:48<10:33:34, 12.56s/it]

  3%|▎         | 80/3106 [19:01<10:38:18, 12.66s/it]

  3%|▎         | 81/3106 [19:15<11:10:35, 13.30s/it]

  3%|▎         | 82/3106 [19:28<10:55:21, 13.00s/it]

  3%|▎         | 83/3106 [19:43<11:26:14, 13.62s/it]

  3%|▎         | 84/3106 [19:56<11:15:41, 13.42s/it]

  3%|▎         | 85/3106 [20:10<11:25:19, 13.61s/it]

  3%|▎         | 86/3106 [20:25<11:55:06, 14.21s/it]

  3%|▎         | 87/3106 [20:38<11:32:33, 13.76s/it]

  3%|▎         | 88/3106 [20:52<11:34:44, 13.81s/it]

  3%|▎         | 89/3106 [21:04<11:08:48, 13.30s/it]

  3%|▎         | 90/3106 [21:20<11:47:07, 14.07s/it]

  3%|▎         | 91/3106 [21:31<11:06:02, 13.25s/it]

  3%|▎         | 92/3106 [21:49<12:16:47, 14.67s/it]

  3%|▎         | 93/3106 [22:01<11:25:53, 13.66s/it]

  3%|▎         | 94/3106 [22:16<11:58:18, 14.31s/it]


  3%|▎         | 96/3106 [22:42<11:16:05, 13.48s/it]

  3%|▎         | 97/3106 [22:54<10:54:34, 13.05s/it]
{'loss': 1.1223, 'grad_norm': 0.29078856652792756, 'learning_rate': 0.0001999995104444598, 'epoch': 0.03}

  3%|▎         | 98/3106 [23:10<11:35:27, 13.87s/it]

  3%|▎         | 99/3106 [23:28<12:28:05, 14.93s/it]

  3%|▎         | 100/3106 [23:43<12:28:09, 14.93s/it]

  3%|▎         | 101/3106 [23:54<11:34:11, 13.86s/it]

  3%|▎         | 102/3106 [24:06<11:09:41, 13.38s/it]

  3%|▎         | 103/3106 [24:20<11:08:57, 13.37s/it]


  3%|▎         | 105/3106 [24:46<11:15:43, 13.51s/it]
{'loss': 1.1341, 'grad_norm': 0.3668054965375155, 'learning_rate': 0.00019999341826456703, 'epoch': 0.03}


  3%|▎         | 107/3106 [25:13<11:05:07, 13.31s/it]
{'loss': 1.0308, 'grad_norm': 0.359831158563248, 'learning_rate': 0.00019999080736819987, 'epoch': 0.03}

  3%|▎         | 108/3106 [25:28<11:43:13, 14.07s/it]

  4%|▎         | 109/3106 [25:47<12:48:07, 15.38s/it]

  4%|▎         | 110/3106 [26:00<12:10:53, 14.64s/it]

  4%|▎         | 111/3106 [26:13<11:42:41, 14.08s/it]

  4%|▎         | 112/3106 [26:25<11:20:24, 13.64s/it]

  4%|▎         | 113/3106 [26:40<11:34:04, 13.91s/it]

  4%|▎         | 114/3106 [26:52<11:02:36, 13.29s/it]

  4%|▎         | 115/3106 [27:05<10:58:45, 13.21s/it]

  4%|▎         | 116/3106 [27:18<11:05:57, 13.36s/it]

  4%|▍         | 117/3106 [27:32<11:17:41, 13.60s/it]

  4%|▍         | 118/3106 [27:46<11:21:10, 13.68s/it]

  4%|▍         | 119/3106 [27:59<11:04:31, 13.35s/it]

  4%|▍         | 120/3106 [28:10<10:32:22, 12.71s/it]

  4%|▍         | 121/3106 [28:25<11:04:53, 13.36s/it]

  4%|▍         | 122/3106 [28:36<10:27:52, 12.62s/it]


  4%|▍         | 124/3106 [29:05<11:17:58, 13.64s/it]
{'loss': 1.0284, 'grad_norm': 0.3315492257269989, 'learning_rate': 0.00019995104840032238, 'epoch': 0.04}

  4%|▍         | 125/3106 [29:16<10:42:19, 12.93s/it]

  4%|▍         | 126/3106 [29:30<10:54:24, 13.18s/it]


  4%|▍         | 128/3106 [30:03<12:18:21, 14.88s/it]
{'loss': 0.9461, 'grad_norm': 0.32813911933483497, 'learning_rate': 0.00019993712584901116, 'epoch': 0.04}

  4%|▍         | 129/3106 [30:15<11:43:05, 14.17s/it]

  4%|▍         | 130/3106 [30:27<11:04:19, 13.39s/it]


  4%|▍         | 132/3106 [30:55<11:15:38, 13.63s/it]
{'loss': 1.2122, 'grad_norm': 0.3103889253386124, 'learning_rate': 0.00019992146375129703, 'epoch': 0.04}

  4%|▍         | 133/3106 [31:09<11:26:17, 13.85s/it]

  4%|▍         | 134/3106 [31:22<11:15:05, 13.63s/it]


  4%|▍         | 136/3106 [31:51<11:39:07, 14.12s/it]
{'loss': 1.1238, 'grad_norm': 0.31522755251586054, 'learning_rate': 0.0001999040623798008, 'epoch': 0.04}

  4%|▍         | 137/3106 [32:04<11:25:31, 13.85s/it]

  4%|▍         | 138/3106 [32:18<11:19:24, 13.73s/it]

  4%|▍         | 139/3106 [32:29<10:48:59, 13.12s/it]

  5%|▍         | 140/3106 [32:41<10:30:42, 12.76s/it]

  5%|▍         | 141/3106 [33:00<11:58:11, 14.53s/it]

  5%|▍         | 142/3106 [33:11<11:02:50, 13.42s/it]

  5%|▍         | 143/3106 [33:24<10:56:43, 13.30s/it]

  5%|▍         | 144/3106 [33:36<10:36:53, 12.90s/it]

  5%|▍         | 145/3106 [33:49<10:34:19, 12.85s/it]

  5%|▍         | 146/3106 [34:02<10:41:56, 13.01s/it]

  5%|▍         | 147/3106 [34:14<10:30:15, 12.78s/it]

  5%|▍         | 148/3106 [34:31<11:29:09, 13.98s/it]

  5%|▍         | 149/3106 [34:45<11:26:46, 13.94s/it]

  5%|▍         | 150/3106 [34:58<11:22:30, 13.85s/it]

  5%|▍         | 151/3106 [35:11<10:59:36, 13.39s/it]

  5%|▍         | 152/3106 [35:24<11:03:11, 13.47s/it]

  5%|▍         | 153/3106 [35:36<10:40:26, 13.01s/it]

  5%|▍         | 154/3106 [35:49<10:41:10, 13.03s/it]

  5%|▍         | 155/3106 [36:05<11:13:55, 13.70s/it]

  5%|▌         | 156/3106 [36:20<11:30:46, 14.05s/it]


  5%|▌         | 158/3106 [36:43<10:37:12, 12.97s/it]
{'loss': 1.0355, 'grad_norm': 0.29515076779563876, 'learning_rate': 0.00019977728037488053, 'epoch': 0.05}

  5%|▌         | 159/3106 [36:55<10:20:49, 12.64s/it]

  5%|▌         | 160/3106 [37:08<10:25:08, 12.73s/it]

  5%|▌         | 161/3106 [37:20<10:09:40, 12.42s/it]

  5%|▌         | 162/3106 [37:32<9:59:44, 12.22s/it]

  5%|▌         | 163/3106 [37:44<10:09:32, 12.43s/it]

  5%|▌         | 164/3106 [37:56<9:51:36, 12.07s/it]

  5%|▌         | 165/3106 [38:07<9:48:16, 12.00s/it]

  5%|▌         | 166/3106 [38:22<10:18:06, 12.61s/it]

  5%|▌         | 167/3106 [38:43<12:26:37, 15.24s/it]

  5%|▌         | 168/3106 [38:59<12:37:14, 15.46s/it]

  5%|▌         | 169/3106 [39:14<12:34:36, 15.42s/it]

  5%|▌         | 170/3106 [39:30<12:33:57, 15.41s/it]

  6%|▌         | 171/3106 [39:45<12:35:16, 15.44s/it]

  6%|▌         | 172/3106 [39:57<11:39:48, 14.31s/it]

  6%|▌         | 173/3106 [40:13<12:00:55, 14.75s/it]

  6%|▌         | 174/3106 [40:27<12:00:29, 14.74s/it]


  6%|▌         | 176/3106 [41:00<12:38:57, 15.54s/it]
{'loss': 1.0243, 'grad_norm': 0.27845288460523165, 'learning_rate': 0.00019963447022199884, 'epoch': 0.06}

  6%|▌         | 177/3106 [41:11<11:36:34, 14.27s/it]

  6%|▌         | 178/3106 [41:24<11:16:28, 13.86s/it]

  6%|▌         | 179/3106 [41:38<11:28:22, 14.11s/it]

  6%|▌         | 180/3106 [41:53<11:39:21, 14.34s/it]

  6%|▌         | 181/3106 [42:07<11:34:28, 14.25s/it]

  6%|▌         | 182/3106 [42:18<10:43:07, 13.20s/it]

  6%|▌         | 183/3106 [42:31<10:33:34, 13.01s/it]

  6%|▌         | 184/3106 [42:44<10:44:39, 13.24s/it]

  6%|▌         | 185/3106 [42:59<11:07:32, 13.71s/it]

  6%|▌         | 186/3106 [43:11<10:38:27, 13.12s/it]

  6%|▌         | 187/3106 [43:22<10:12:39, 12.59s/it]

  6%|▌         | 188/3106 [43:37<10:40:33, 13.17s/it]

  6%|▌         | 189/3106 [43:50<10:31:50, 13.00s/it]

  6%|▌         | 190/3106 [44:01<10:10:53, 12.57s/it]
[2024-05-28 21:37:19,417] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 191/3106 [44:17<10:54:12, 13.47s/it]

  6%|▌         | 192/3106 [44:28<10:30:23, 12.98s/it]

  6%|▌         | 193/3106 [44:41<10:29:08, 12.96s/it]

  6%|▌         | 194/3106 [44:55<10:42:34, 13.24s/it]

  6%|▋         | 195/3106 [45:12<11:27:10, 14.16s/it]

  6%|▋         | 196/3106 [45:26<11:29:51, 14.22s/it]

  6%|▋         | 197/3106 [45:39<11:06:38, 13.75s/it]

  6%|▋         | 198/3106 [45:53<11:16:59, 13.97s/it]

  6%|▋         | 199/3106 [46:06<10:55:15, 13.52s/it]


  6%|▋         | 201/3106 [46:32<10:46:51, 13.36s/it]
{'loss': 1.1625, 'grad_norm': 0.2866030595189415, 'learning_rate': 0.00019937787658454482, 'epoch': 0.06}

  7%|▋         | 202/3106 [46:45<10:42:58, 13.28s/it]


  7%|▋         | 204/3106 [47:14<10:58:33, 13.62s/it]
{'loss': 1.038, 'grad_norm': 0.2979608852543498, 'learning_rate': 0.00019934254092316716, 'epoch': 0.07}

  7%|▋         | 205/3106 [47:29<11:19:13, 14.05s/it]

  7%|▋         | 206/3106 [47:42<11:05:24, 13.77s/it]

  7%|▋         | 207/3106 [47:55<10:55:44, 13.57s/it]

  7%|▋         | 208/3106 [48:06<10:20:25, 12.85s/it]

  7%|▋         | 209/3106 [48:19<10:22:40, 12.90s/it]

  7%|▋         | 210/3106 [48:32<10:10:40, 12.65s/it]

  7%|▋         | 211/3106 [48:45<10:18:08, 12.81s/it]


  7%|▋         | 213/3106 [49:08<9:47:41, 12.19s/it]
{'loss': 1.0116, 'grad_norm': 0.27267625130157624, 'learning_rate': 0.00019923069932759554, 'epoch': 0.07}

  7%|▋         | 214/3106 [49:21<9:55:03, 12.35s/it]

  7%|▋         | 215/3106 [49:35<10:19:02, 12.85s/it]

  7%|▋         | 216/3106 [49:51<11:09:38, 13.90s/it]


  7%|▋         | 218/3106 [50:19<11:15:38, 14.04s/it]

  7%|▋         | 219/3106 [50:33<11:16:46, 14.07s/it]

  7%|▋         | 220/3106 [50:45<10:44:10, 13.39s/it]

  7%|▋         | 221/3106 [50:56<10:21:22, 12.92s/it]

  7%|▋         | 222/3106 [51:08<10:00:45, 12.50s/it]

  7%|▋         | 223/3106 [51:20<9:53:06, 12.34s/it]

  7%|▋         | 224/3106 [51:32<9:53:25, 12.35s/it]

  7%|▋         | 225/3106 [51:45<10:01:57, 12.54s/it]

  7%|▋         | 226/3106 [52:01<10:46:04, 13.46s/it]

  7%|▋         | 227/3106 [52:17<11:22:21, 14.22s/it]

  7%|▋         | 228/3106 [52:30<11:11:39, 14.00s/it]

  7%|▋         | 229/3106 [52:47<11:45:41, 14.72s/it]

  7%|▋         | 230/3106 [52:59<11:11:12, 14.00s/it]

  7%|▋         | 231/3106 [53:15<11:41:06, 14.63s/it]

  7%|▋         | 232/3106 [53:29<11:30:33, 14.42s/it]

  8%|▊         | 233/3106 [53:41<10:51:45, 13.61s/it]

  8%|▊         | 234/3106 [53:53<10:27:16, 13.10s/it]

  8%|▊         | 235/3106 [54:06<10:31:05, 13.19s/it]

  8%|▊         | 236/3106 [54:19<10:26:12, 13.09s/it]

  8%|▊         | 237/3106 [54:31<10:13:17, 12.83s/it]

  8%|▊         | 238/3106 [54:47<10:52:04, 13.64s/it]

  8%|▊         | 239/3106 [54:59<10:35:34, 13.30s/it]

  8%|▊         | 240/3106 [55:14<11:01:44, 13.85s/it]

  8%|▊         | 241/3106 [55:30<11:24:35, 14.34s/it]

  8%|▊         | 242/3106 [55:42<10:46:31, 13.54s/it]

  8%|▊         | 243/3106 [55:59<11:41:20, 14.70s/it]

  8%|▊         | 244/3106 [56:15<12:04:06, 15.18s/it]

  8%|▊         | 245/3106 [56:31<12:06:09, 15.23s/it]

  8%|▊         | 246/3106 [56:46<12:10:59, 15.34s/it]

  8%|▊         | 247/3106 [57:00<11:45:07, 14.80s/it]

  8%|▊         | 248/3106 [57:15<11:47:59, 14.86s/it]

  8%|▊         | 249/3106 [57:28<11:30:42, 14.51s/it]

  8%|▊         | 250/3106 [57:44<11:46:59, 14.85s/it]

  8%|▊         | 251/3106 [57:56<11:03:36, 13.95s/it]

  8%|▊         | 252/3106 [58:10<11:11:34, 14.12s/it]

  8%|▊         | 253/3106 [58:24<11:02:13, 13.93s/it]

  8%|▊         | 254/3106 [58:38<10:59:37, 13.88s/it]

  8%|▊         | 255/3106 [58:52<11:06:48, 14.03s/it]

  8%|▊         | 256/3106 [59:08<11:33:01, 14.59s/it]

  8%|▊         | 257/3106 [59:22<11:18:22, 14.29s/it]

  8%|▊         | 258/3106 [59:34<10:49:49, 13.69s/it]

  8%|▊         | 259/3106 [59:54<12:14:06, 15.47s/it]

  8%|▊         | 260/3106 [1:00:07<11:40:35, 14.77s/it]

  8%|▊         | 261/3106 [1:00:18<10:56:38, 13.85s/it]

  8%|▊         | 262/3106 [1:00:30<10:30:12, 13.30s/it]

  8%|▊         | 263/3106 [1:00:49<11:45:57, 14.90s/it]

  8%|▊         | 264/3106 [1:01:01<11:05:40, 14.05s/it]

  9%|▊         | 265/3106 [1:01:14<10:47:26, 13.67s/it]

  9%|▊         | 266/3106 [1:01:28<10:57:30, 13.89s/it]

  9%|▊         | 267/3106 [1:01:43<11:14:19, 14.25s/it]

  9%|▊         | 268/3106 [1:01:56<10:49:51, 13.74s/it]

  9%|▊         | 269/3106 [1:02:08<10:31:56, 13.37s/it]

  9%|▊         | 270/3106 [1:02:22<10:33:27, 13.40s/it]

  9%|▊         | 271/3106 [1:02:35<10:23:50, 13.20s/it]

  9%|▉         | 272/3106 [1:02:48<10:29:09, 13.32s/it]

  9%|▉         | 273/3106 [1:03:07<11:46:31, 14.96s/it]

  9%|▉         | 274/3106 [1:03:29<13:20:50, 16.97s/it]

  9%|▉         | 275/3106 [1:03:43<12:37:41, 16.06s/it]

  9%|▉         | 276/3106 [1:03:57<12:20:44, 15.70s/it]

  9%|▉         | 277/3106 [1:04:12<11:58:59, 15.25s/it]

  9%|▉         | 278/3106 [1:04:23<11:09:13, 14.20s/it]

  9%|▉         | 279/3106 [1:04:39<11:34:10, 14.73s/it]

  9%|▉         | 280/3106 [1:04:53<11:11:40, 14.26s/it]

  9%|▉         | 281/3106 [1:05:07<11:07:32, 14.18s/it]

  9%|▉         | 282/3106 [1:05:21<11:11:35, 14.27s/it]

  9%|▉         | 283/3106 [1:05:34<10:48:53, 13.79s/it]

  9%|▉         | 284/3106 [1:05:46<10:27:46, 13.35s/it]

  9%|▉         | 285/3106 [1:06:00<10:37:57, 13.57s/it]

  9%|▉         | 286/3106 [1:06:12<10:07:34, 12.93s/it]

  9%|▉         | 287/3106 [1:06:25<10:09:24, 12.97s/it]

  9%|▉         | 288/3106 [1:06:42<11:10:49, 14.28s/it]

  9%|▉         | 289/3106 [1:06:55<10:56:42, 13.99s/it]

  9%|▉         | 290/3106 [1:07:09<10:52:19, 13.90s/it]

  9%|▉         | 291/3106 [1:07:25<11:27:52, 14.66s/it]

  9%|▉         | 292/3106 [1:07:45<12:42:01, 16.25s/it]

  9%|▉         | 293/3106 [1:07:59<12:04:02, 15.44s/it]

  9%|▉         | 294/3106 [1:08:09<10:55:56, 14.00s/it]

  9%|▉         | 295/3106 [1:08:25<11:21:13, 14.54s/it]

 10%|▉         | 296/3106 [1:08:39<11:15:09, 14.42s/it]

 10%|▉         | 297/3106 [1:08:52<10:50:23, 13.89s/it]

 10%|▉         | 298/3106 [1:09:07<11:09:53, 14.31s/it]

 10%|▉         | 299/3106 [1:09:20<10:46:11, 13.81s/it]

 10%|▉         | 300/3106 [1:09:32<10:19:49, 13.25s/it]
 10%|▉         | 300/3106 [1:09:32<10:19:49, 13.25s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 10%|▉         | 301/3106 [1:10:06<15:07:08, 19.40s/it]

 10%|▉         | 302/3106 [1:10:21<14:12:52, 18.25s/it]

 10%|▉         | 303/3106 [1:10:36<13:16:13, 17.04s/it]

 10%|▉         | 304/3106 [1:10:50<12:44:47, 16.38s/it]

 10%|▉         | 305/3106 [1:11:04<12:05:25, 15.54s/it]

 10%|▉         | 306/3106 [1:11:16<11:21:41, 14.61s/it]

 10%|▉         | 307/3106 [1:11:31<11:24:38, 14.68s/it]

 10%|▉         | 308/3106 [1:11:44<10:59:41, 14.15s/it]

 10%|▉         | 309/3106 [1:11:57<10:39:41, 13.72s/it]

 10%|▉         | 310/3106 [1:12:12<11:02:19, 14.21s/it]

 10%|█         | 311/3106 [1:12:26<10:59:40, 14.16s/it]

 10%|█         | 312/3106 [1:12:38<10:21:23, 13.34s/it]

 10%|█         | 313/3106 [1:12:51<10:23:28, 13.39s/it]

 10%|█         | 314/3106 [1:13:03<10:01:17, 12.92s/it]

 10%|█         | 315/3106 [1:13:17<10:14:29, 13.21s/it]

 10%|█         | 316/3106 [1:13:30<10:13:45, 13.20s/it]

 10%|█         | 317/3106 [1:13:43<10:04:53, 13.01s/it]

 10%|█         | 318/3106 [1:13:55<9:58:53, 12.89s/it]

 10%|█         | 319/3106 [1:14:09<10:10:32, 13.14s/it]

 10%|█         | 320/3106 [1:14:24<10:33:01, 13.63s/it]

 10%|█         | 321/3106 [1:14:39<10:52:50, 14.06s/it]

 10%|█         | 322/3106 [1:14:53<10:53:56, 14.09s/it]

 10%|█         | 323/3106 [1:15:08<11:06:18, 14.37s/it]

 10%|█         | 324/3106 [1:15:20<10:31:53, 13.63s/it]

 10%|█         | 325/3106 [1:15:34<10:41:49, 13.85s/it]

 10%|█         | 326/3106 [1:15:52<11:29:10, 14.87s/it]

 11%|█         | 327/3106 [1:16:04<10:59:43, 14.24s/it]

 11%|█         | 328/3106 [1:16:17<10:34:08, 13.70s/it]

 11%|█         | 329/3106 [1:16:28<10:02:46, 13.02s/it]

 11%|█         | 330/3106 [1:16:41<10:05:22, 13.08s/it]

 11%|█         | 331/3106 [1:16:56<10:26:24, 13.54s/it]

 11%|█         | 332/3106 [1:17:09<10:24:41, 13.51s/it]

 11%|█         | 333/3106 [1:17:22<10:09:55, 13.20s/it]

 11%|█         | 334/3106 [1:17:33<9:47:02, 12.71s/it]

 11%|█         | 335/3106 [1:17:46<9:51:05, 12.80s/it]

 11%|█         | 336/3106 [1:17:59<9:51:03, 12.80s/it]

 11%|█         | 337/3106 [1:18:12<9:54:36, 12.88s/it]

 11%|█         | 338/3106 [1:18:24<9:32:48, 12.42s/it]

 11%|█         | 339/3106 [1:18:38<9:59:28, 13.00s/it]

 11%|█         | 340/3106 [1:18:51<10:01:31, 13.05s/it]

 11%|█         | 341/3106 [1:19:03<9:46:54, 12.74s/it]

 11%|█         | 342/3106 [1:19:20<10:36:24, 13.81s/it]

 11%|█         | 343/3106 [1:19:36<11:19:11, 14.75s/it]

 11%|█         | 344/3106 [1:19:51<11:10:02, 14.56s/it]

 11%|█         | 345/3106 [1:20:05<11:02:48, 14.40s/it]

 11%|█         | 346/3106 [1:20:16<10:17:45, 13.43s/it]

 11%|█         | 347/3106 [1:20:28<9:53:52, 12.91s/it]

 11%|█         | 348/3106 [1:20:41<9:58:41, 13.02s/it]

 11%|█         | 349/3106 [1:20:58<10:54:33, 14.25s/it]

 11%|█▏        | 350/3106 [1:21:10<10:31:19, 13.74s/it]

 11%|█▏        | 351/3106 [1:21:23<10:18:15, 13.46s/it]

 11%|█▏        | 352/3106 [1:21:36<10:06:26, 13.21s/it]

 11%|█▏        | 353/3106 [1:21:49<10:10:29, 13.31s/it]

 11%|█▏        | 354/3106 [1:22:04<10:21:13, 13.54s/it]

 11%|█▏        | 355/3106 [1:22:15<9:57:02, 13.02s/it]

 11%|█▏        | 356/3106 [1:22:28<9:57:54, 13.05s/it]

 11%|█▏        | 357/3106 [1:22:44<10:31:53, 13.79s/it]

 12%|█▏        | 358/3106 [1:22:57<10:14:23, 13.41s/it]

 12%|█▏        | 359/3106 [1:23:08<9:48:05, 12.84s/it]

 12%|█▏        | 360/3106 [1:23:20<9:30:43, 12.47s/it]

 12%|█▏        | 361/3106 [1:23:36<10:21:45, 13.59s/it]

 12%|█▏        | 362/3106 [1:23:55<11:43:47, 15.39s/it]

 12%|█▏        | 363/3106 [1:24:10<11:37:36, 15.26s/it]

 12%|█▏        | 364/3106 [1:24:24<11:14:21, 14.76s/it]

 12%|█▏        | 365/3106 [1:24:37<10:51:03, 14.25s/it]

 12%|█▏        | 366/3106 [1:24:54<11:32:27, 15.16s/it]

 12%|█▏        | 367/3106 [1:25:06<10:51:19, 14.27s/it]

 12%|█▏        | 368/3106 [1:25:20<10:36:16, 13.94s/it]

 12%|█▏        | 369/3106 [1:25:32<10:14:53, 13.48s/it]

 12%|█▏        | 370/3106 [1:25:45<10:06:16, 13.30s/it]

 12%|█▏        | 371/3106 [1:26:01<10:40:44, 14.06s/it]

 12%|█▏        | 372/3106 [1:26:17<11:16:34, 14.85s/it]

 12%|█▏        | 373/3106 [1:26:30<10:45:25, 14.17s/it]

 12%|█▏        | 374/3106 [1:26:43<10:34:40, 13.94s/it]

 12%|█▏        | 375/3106 [1:26:55<9:59:27, 13.17s/it]

 12%|█▏        | 376/3106 [1:27:06<9:35:13, 12.64s/it]

 12%|█▏        | 377/3106 [1:27:22<10:24:03, 13.72s/it]

 12%|█▏        | 378/3106 [1:27:35<10:03:39, 13.28s/it]

 12%|█▏        | 379/3106 [1:27:51<10:41:36, 14.12s/it]

 12%|█▏        | 380/3106 [1:28:03<10:18:33, 13.61s/it]

 12%|█▏        | 381/3106 [1:28:17<10:26:45, 13.80s/it]

 12%|█▏        | 382/3106 [1:28:33<10:50:48, 14.34s/it]

 12%|█▏        | 383/3106 [1:28:46<10:28:16, 13.84s/it]

 12%|█▏        | 384/3106 [1:29:01<10:47:41, 14.28s/it]

 12%|█▏        | 385/3106 [1:29:16<10:50:53, 14.35s/it]

 12%|█▏        | 386/3106 [1:29:27<10:09:51, 13.45s/it]

 12%|█▏        | 387/3106 [1:29:41<10:16:25, 13.60s/it]

 12%|█▏        | 388/3106 [1:29:54<10:06:26, 13.39s/it]

 13%|█▎        | 389/3106 [1:30:06<9:56:19, 13.17s/it]

 13%|█▎        | 390/3106 [1:30:19<9:42:32, 12.87s/it]

 13%|█▎        | 391/3106 [1:30:33<9:59:18, 13.24s/it]

 13%|█▎        | 392/3106 [1:30:49<10:36:15, 14.07s/it]

 13%|█▎        | 393/3106 [1:31:01<10:13:59, 13.58s/it]

 13%|█▎        | 394/3106 [1:31:16<10:29:23, 13.92s/it]

 13%|█▎        | 395/3106 [1:31:28<10:02:52, 13.34s/it]

 13%|█▎        | 396/3106 [1:31:39<9:39:44, 12.84s/it]

 13%|█▎        | 397/3106 [1:31:53<9:54:42, 13.17s/it]

 13%|█▎        | 398/3106 [1:32:07<10:00:03, 13.30s/it]

 13%|█▎        | 399/3106 [1:32:21<10:08:49, 13.49s/it]

 13%|█▎        | 400/3106 [1:32:32<9:40:14, 12.87s/it]

 13%|█▎        | 401/3106 [1:32:46<9:47:30, 13.03s/it]

 13%|█▎        | 402/3106 [1:32:59<9:46:41, 13.02s/it]

 13%|█▎        | 403/3106 [1:33:10<9:20:45, 12.45s/it]

 13%|█▎        | 404/3106 [1:33:27<10:21:22, 13.80s/it]

 13%|█▎        | 405/3106 [1:33:39<9:55:43, 13.23s/it]

 13%|█▎        | 406/3106 [1:33:51<9:43:08, 12.96s/it]

 13%|█▎        | 407/3106 [1:34:04<9:42:00, 12.94s/it]

 13%|█▎        | 408/3106 [1:34:20<10:16:48, 13.72s/it]

 13%|█▎        | 409/3106 [1:34:32<10:05:07, 13.46s/it]

 13%|█▎        | 410/3106 [1:34:44<9:39:00, 12.89s/it]

 13%|█▎        | 411/3106 [1:34:59<10:10:27, 13.59s/it]

 13%|█▎        | 412/3106 [1:35:15<10:37:11, 14.19s/it]

 13%|█▎        | 413/3106 [1:35:28<10:26:45, 13.96s/it]

 13%|█▎        | 414/3106 [1:35:40<10:01:23, 13.40s/it]

 13%|█▎        | 415/3106 [1:35:53<9:51:17, 13.18s/it]

 13%|█▎        | 416/3106 [1:36:08<10:18:16, 13.79s/it]

 13%|█▎        | 417/3106 [1:36:21<10:07:58, 13.57s/it]

 13%|█▎        | 418/3106 [1:36:35<10:05:32, 13.52s/it]

 13%|█▎        | 419/3106 [1:36:50<10:29:26, 14.06s/it]

 14%|█▎        | 420/3106 [1:37:06<10:52:55, 14.59s/it]

 14%|█▎        | 421/3106 [1:37:18<10:23:23, 13.93s/it]

 14%|█▎        | 422/3106 [1:37:30<9:58:19, 13.38s/it]

 14%|█▎        | 423/3106 [1:37:44<10:00:02, 13.42s/it]

 14%|█▎        | 424/3106 [1:37:55<9:34:31, 12.85s/it]

 14%|█▎        | 425/3106 [1:38:10<10:05:34, 13.55s/it]

 14%|█▎        | 426/3106 [1:38:23<9:54:22, 13.31s/it]

 14%|█▎        | 427/3106 [1:38:36<9:44:14, 13.09s/it]

 14%|█▍        | 428/3106 [1:38:52<10:27:41, 14.06s/it]

 14%|█▍        | 429/3106 [1:39:08<10:46:30, 14.49s/it]

 14%|█▍        | 430/3106 [1:39:20<10:14:14, 13.77s/it]

 14%|█▍        | 431/3106 [1:39:35<10:32:54, 14.20s/it]

 14%|█▍        | 432/3106 [1:39:48<10:23:49, 14.00s/it]

 14%|█▍        | 433/3106 [1:40:02<10:18:27, 13.88s/it]

 14%|█▍        | 434/3106 [1:40:16<10:16:31, 13.84s/it]

 14%|█▍        | 435/3106 [1:40:32<10:42:45, 14.44s/it]

 14%|█▍        | 436/3106 [1:40:44<10:09:50, 13.70s/it]

 14%|█▍        | 437/3106 [1:41:00<10:40:40, 14.40s/it]

 14%|█▍        | 438/3106 [1:41:13<10:26:23, 14.09s/it]

 14%|█▍        | 439/3106 [1:41:27<10:26:44, 14.10s/it]

 14%|█▍        | 440/3106 [1:41:39<9:54:27, 13.38s/it]

 14%|█▍        | 441/3106 [1:41:50<9:31:05, 12.86s/it]

 14%|█▍        | 442/3106 [1:42:02<9:16:26, 12.53s/it]

 14%|█▍        | 443/3106 [1:42:17<9:46:37, 13.22s/it]

 14%|█▍        | 444/3106 [1:42:30<9:46:32, 13.22s/it]

 14%|█▍        | 445/3106 [1:42:43<9:42:41, 13.14s/it]

 14%|█▍        | 446/3106 [1:42:57<9:46:22, 13.23s/it]

 14%|█▍        | 447/3106 [1:43:10<9:47:16, 13.25s/it]

 14%|█▍        | 448/3106 [1:43:23<9:40:18, 13.10s/it]

 14%|█▍        | 449/3106 [1:43:40<10:32:59, 14.29s/it]

 14%|█▍        | 450/3106 [1:43:53<10:23:11, 14.08s/it]

 15%|█▍        | 451/3106 [1:44:06<9:58:33, 13.53s/it]

 15%|█▍        | 452/3106 [1:44:17<9:34:50, 13.00s/it]

 15%|█▍        | 453/3106 [1:44:32<9:55:39, 13.47s/it]

 15%|█▍        | 454/3106 [1:44:48<10:26:15, 14.17s/it]

 15%|█▍        | 455/3106 [1:45:00<10:02:25, 13.63s/it]

 15%|█▍        | 456/3106 [1:45:12<9:34:39, 13.01s/it]

 15%|█▍        | 457/3106 [1:45:24<9:29:37, 12.90s/it]

 15%|█▍        | 458/3106 [1:45:37<9:28:43, 12.89s/it]

 15%|█▍        | 459/3106 [1:45:49<9:20:41, 12.71s/it]

 15%|█▍        | 460/3106 [1:46:02<9:16:41, 12.62s/it]

 15%|█▍        | 461/3106 [1:46:15<9:24:36, 12.81s/it]

 15%|█▍        | 462/3106 [1:46:28<9:24:29, 12.81s/it]

 15%|█▍        | 463/3106 [1:46:41<9:24:56, 12.82s/it]

 15%|█▍        | 464/3106 [1:46:57<10:10:21, 13.86s/it]

 15%|█▍        | 465/3106 [1:47:10<9:51:51, 13.45s/it]

 15%|█▌        | 466/3106 [1:47:21<9:27:08, 12.89s/it]

 15%|█▌        | 467/3106 [1:47:37<10:11:35, 13.91s/it]

 15%|█▌        | 468/3106 [1:47:52<10:19:29, 14.09s/it]

 15%|█▌        | 469/3106 [1:48:05<10:01:31, 13.69s/it]

 15%|█▌        | 470/3106 [1:48:17<9:47:12, 13.37s/it]

 15%|█▌        | 471/3106 [1:48:31<9:48:18, 13.40s/it]

 15%|█▌        | 472/3106 [1:48:44<9:51:49, 13.48s/it]

 15%|█▌        | 473/3106 [1:48:58<9:48:19, 13.41s/it]

 15%|█▌        | 474/3106 [1:49:10<9:35:41, 13.12s/it]

 15%|█▌        | 475/3106 [1:49:26<10:12:05, 13.96s/it]

 15%|█▌        | 476/3106 [1:49:40<10:12:10, 13.97s/it]

 15%|█▌        | 477/3106 [1:49:53<9:56:14, 13.61s/it]

 15%|█▌        | 478/3106 [1:50:06<9:46:22, 13.39s/it]

 15%|█▌        | 479/3106 [1:50:25<11:06:11, 15.22s/it]

 15%|█▌        | 480/3106 [1:50:38<10:30:15, 14.40s/it]

 15%|█▌        | 481/3106 [1:50:50<10:01:36, 13.75s/it]

 16%|█▌        | 482/3106 [1:51:02<9:44:23, 13.36s/it]

 16%|█▌        | 483/3106 [1:51:15<9:37:10, 13.20s/it]

 16%|█▌        | 484/3106 [1:51:28<9:29:18, 13.03s/it]

 16%|█▌        | 485/3106 [1:51:47<10:53:43, 14.97s/it]

 16%|█▌        | 486/3106 [1:52:03<10:56:41, 15.04s/it]

 16%|█▌        | 487/3106 [1:52:20<11:34:36, 15.91s/it]

 16%|█▌        | 488/3106 [1:52:33<10:54:19, 15.00s/it]

 16%|█▌        | 489/3106 [1:52:48<10:53:08, 14.97s/it]

 16%|█▌        | 490/3106 [1:53:01<10:29:28, 14.44s/it]

 16%|█▌        | 491/3106 [1:53:17<10:45:49, 14.82s/it]

 16%|█▌        | 492/3106 [1:53:30<10:18:10, 14.19s/it]

 16%|█▌        | 493/3106 [1:53:43<9:58:35, 13.75s/it]

 16%|█▌        | 494/3106 [1:53:57<10:05:06, 13.90s/it]

 16%|█▌        | 495/3106 [1:54:16<11:17:12, 15.56s/it]

 16%|█▌        | 496/3106 [1:54:34<11:42:37, 16.15s/it]

 16%|█▌        | 497/3106 [1:54:48<11:18:11, 15.60s/it]

 16%|█▌        | 498/3106 [1:55:01<10:40:42, 14.74s/it]

 16%|█▌        | 499/3106 [1:55:13<10:10:40, 14.05s/it]

 16%|█▌        | 500/3106 [1:55:27<10:09:50, 14.04s/it]

 16%|█▌        | 501/3106 [1:55:39<9:38:54, 13.33s/it]

 16%|█▌        | 502/3106 [1:55:53<9:41:41, 13.40s/it]

 16%|█▌        | 503/3106 [1:56:05<9:33:24, 13.22s/it]

 16%|█▌        | 504/3106 [1:56:18<9:25:11, 13.03s/it]

 16%|█▋        | 505/3106 [1:56:31<9:23:11, 12.99s/it]

 16%|█▋        | 506/3106 [1:56:45<9:40:17, 13.39s/it]

 16%|█▋        | 507/3106 [1:56:59<9:52:14, 13.67s/it]

 16%|█▋        | 508/3106 [1:57:13<9:51:49, 13.67s/it]

 16%|█▋        | 509/3106 [1:57:33<11:13:30, 15.56s/it]

 16%|█▋        | 510/3106 [1:57:47<10:46:00, 14.93s/it]

 16%|█▋        | 511/3106 [1:58:00<10:21:59, 14.38s/it]

 16%|█▋        | 512/3106 [1:58:11<9:43:30, 13.50s/it]

 17%|█▋        | 513/3106 [1:58:24<9:37:07, 13.35s/it]

 17%|█▋        | 514/3106 [1:58:38<9:46:53, 13.59s/it]

 17%|█▋        | 515/3106 [1:58:54<10:16:30, 14.28s/it]

 17%|█▋        | 516/3106 [1:59:12<10:56:15, 15.20s/it]

 17%|█▋        | 517/3106 [1:59:30<11:44:42, 16.33s/it]
{'loss': 0.9826, 'grad_norm': 0.27842876422509755, 'learning_rate': 0.00019042399848733532, 'epoch': 0.17}


 17%|█▋        | 519/3106 [2:00:00<10:59:03, 15.29s/it]
{'loss': 1.0592, 'grad_norm': 0.27672342835568253, 'learning_rate': 0.00019033472229208214, 'epoch': 0.17}


 17%|█▋        | 521/3106 [2:00:36<11:56:20, 16.63s/it]

 17%|█▋        | 522/3106 [2:00:51<11:33:41, 16.11s/it]

 17%|█▋        | 523/3106 [2:01:05<11:03:59, 15.42s/it]

 17%|█▋        | 524/3106 [2:01:20<10:58:22, 15.30s/it]

 17%|█▋        | 525/3106 [2:01:32<10:19:57, 14.41s/it]

 17%|█▋        | 526/3106 [2:01:45<10:05:36, 14.08s/it]

 17%|█▋        | 527/3106 [2:01:58<9:53:45, 13.81s/it]

 17%|█▋        | 528/3106 [2:02:12<9:52:02, 13.78s/it]
{'loss': 0.8533, 'grad_norm': 0.21216126515840122, 'learning_rate': 0.00018992812043523087, 'epoch': 0.17}


 17%|█▋        | 530/3106 [2:02:43<10:35:11, 14.79s/it]

 17%|█▋        | 531/3106 [2:02:57<10:22:59, 14.52s/it]

 17%|█▋        | 532/3106 [2:03:13<10:43:34, 15.00s/it]

 17%|█▋        | 533/3106 [2:03:29<10:45:22, 15.05s/it]

 17%|█▋        | 534/3106 [2:03:42<10:18:24, 14.43s/it]

 17%|█▋        | 535/3106 [2:03:55<10:02:42, 14.07s/it]

 17%|█▋        | 536/3106 [2:04:09<9:58:35, 13.97s/it]

 17%|█▋        | 537/3106 [2:04:21<9:34:50, 13.43s/it]

 17%|█▋        | 538/3106 [2:04:34<9:32:16, 13.37s/it]

 17%|█▋        | 539/3106 [2:04:48<9:45:17, 13.68s/it]

 17%|█▋        | 540/3106 [2:05:06<10:31:26, 14.76s/it]
{'loss': 1.0083, 'grad_norm': 0.24969281032607754, 'learning_rate': 0.00018937366405327217, 'epoch': 0.17}


 17%|█▋        | 542/3106 [2:05:36<10:46:44, 15.13s/it]

 17%|█▋        | 543/3106 [2:05:50<10:28:49, 14.72s/it]

 18%|█▊        | 544/3106 [2:06:02<9:53:44, 13.91s/it]

 18%|█▊        | 545/3106 [2:06:16<9:52:29, 13.88s/it]

 18%|█▊        | 546/3106 [2:06:34<10:49:28, 15.22s/it]

 18%|█▊        | 547/3106 [2:06:50<10:58:03, 15.43s/it]
{'loss': 0.9815, 'grad_norm': 0.2657226514899806, 'learning_rate': 0.00018904375980467473, 'epoch': 0.18}


 18%|█▊        | 549/3106 [2:07:14<9:42:02, 13.66s/it]

 18%|█▊        | 550/3106 [2:07:27<9:31:53, 13.42s/it]

 18%|█▊        | 551/3106 [2:07:42<10:02:17, 14.14s/it]
{'loss': 1.0268, 'grad_norm': 0.3000744393951879, 'learning_rate': 0.00018885311080260695, 'epoch': 0.18}


 18%|█▊        | 553/3106 [2:08:17<11:19:06, 15.96s/it]
{'loss': 1.1233, 'grad_norm': 0.25109144876813594, 'learning_rate': 0.00018875720611304626, 'epoch': 0.18}


 18%|█▊        | 555/3106 [2:08:44<10:27:13, 14.75s/it]

 18%|█▊        | 556/3106 [2:08:59<10:28:09, 14.78s/it]

 18%|█▊        | 557/3106 [2:09:16<10:51:15, 15.33s/it]

 18%|█▊        | 558/3106 [2:09:30<10:32:33, 14.90s/it]

 18%|█▊        | 559/3106 [2:09:42<10:00:25, 14.14s/it]

 18%|█▊        | 560/3106 [2:09:56<9:59:23, 14.13s/it]

 18%|█▊        | 561/3106 [2:10:11<10:08:30, 14.35s/it]

 18%|█▊        | 562/3106 [2:10:23<9:36:38, 13.60s/it]

 18%|█▊        | 563/3106 [2:10:37<9:47:35, 13.86s/it]

 18%|█▊        | 564/3106 [2:10:55<10:33:55, 14.96s/it]

 18%|█▊        | 565/3106 [2:11:09<10:16:00, 14.55s/it]

 18%|█▊        | 566/3106 [2:11:21<9:48:47, 13.91s/it]

 18%|█▊        | 567/3106 [2:11:35<9:50:48, 13.96s/it]
{'loss': 1.0215, 'grad_norm': 0.2431783514493661, 'learning_rate': 0.00018807508224781438, 'epoch': 0.18}

 18%|█▊        | 568/3106 [2:11:52<10:25:54, 14.80s/it]


 18%|█▊        | 570/3106 [2:12:17<9:37:45, 13.67s/it]

 18%|█▊        | 571/3106 [2:12:30<9:35:10, 13.61s/it]
{'loss': 0.9686, 'grad_norm': 0.2331578733239645, 'learning_rate': 0.00018787673390086856, 'epoch': 0.18}


 18%|█▊        | 573/3106 [2:12:53<8:51:37, 12.59s/it]

 18%|█▊        | 574/3106 [2:13:09<9:25:23, 13.40s/it]

 19%|█▊        | 575/3106 [2:13:23<9:40:45, 13.77s/it]

 19%|█▊        | 576/3106 [2:13:37<9:35:37, 13.65s/it]

 19%|█▊        | 577/3106 [2:13:50<9:25:56, 13.43s/it]

 19%|█▊        | 578/3106 [2:14:06<9:58:33, 14.21s/it]

 19%|█▊        | 579/3106 [2:14:18<9:40:43, 13.79s/it]

 19%|█▊        | 580/3106 [2:14:32<9:40:45, 13.79s/it]

 19%|█▊        | 581/3106 [2:14:45<9:29:02, 13.52s/it]
{'loss': 1.0247, 'grad_norm': 0.2652511339122216, 'learning_rate': 0.00018737417857137202, 'epoch': 0.19}


 19%|█▉        | 583/3106 [2:15:12<9:27:08, 13.49s/it]

 19%|█▉        | 584/3106 [2:15:27<9:38:16, 13.76s/it]
{'loss': 1.0057, 'grad_norm': 0.2611284744403519, 'learning_rate': 0.00018722155591086544, 'epoch': 0.19}

 19%|█▉        | 585/3106 [2:15:38<9:04:15, 12.95s/it]


 19%|█▉        | 587/3106 [2:16:06<9:37:48, 13.76s/it]

 19%|█▉        | 588/3106 [2:16:20<9:43:00, 13.89s/it]

 19%|█▉        | 589/3106 [2:16:35<9:53:09, 14.14s/it]

 19%|█▉        | 590/3106 [2:16:48<9:39:42, 13.82s/it]

 19%|█▉        | 591/3106 [2:17:03<9:44:27, 13.94s/it]

 19%|█▉        | 592/3106 [2:17:15<9:31:40, 13.64s/it]

 19%|█▉        | 593/3106 [2:17:30<9:46:44, 14.01s/it]

 19%|█▉        | 594/3106 [2:17:45<9:58:12, 14.29s/it]

 19%|█▉        | 595/3106 [2:17:58<9:34:56, 13.74s/it]

 19%|█▉        | 596/3106 [2:18:09<9:09:27, 13.13s/it]

 19%|█▉        | 597/3106 [2:18:22<8:58:55, 12.89s/it]
{'loss': 1.0022, 'grad_norm': 0.2421883732063512, 'learning_rate': 0.00018655034200789185, 'epoch': 0.19}


 19%|█▉        | 599/3106 [2:18:47<8:51:01, 12.71s/it]

 19%|█▉        | 600/3106 [2:18:59<8:48:13, 12.65s/it]
 19%|█▉        | 600/3106 [2:18:59<8:48:13, 12.65s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 19%|█▉        | 601/3106 [2:19:32<13:03:58, 18.78s/it]

 19%|█▉        | 602/3106 [2:19:47<12:05:50, 17.39s/it]

 19%|█▉        | 603/3106 [2:20:03<11:48:41, 16.99s/it]

 19%|█▉        | 604/3106 [2:20:19<11:37:21, 16.72s/it]

 19%|█▉        | 605/3106 [2:20:33<11:10:04, 16.08s/it]

 20%|█▉        | 606/3106 [2:20:45<10:20:18, 14.89s/it]

 20%|█▉        | 607/3106 [2:21:00<10:15:01, 14.77s/it]

 20%|█▉        | 608/3106 [2:21:17<10:49:39, 15.60s/it]
{'loss': 0.8236, 'grad_norm': 0.3010706734539956, 'learning_rate': 0.00018596995805096614, 'epoch': 0.2}


 20%|█▉        | 610/3106 [2:21:45<10:07:46, 14.61s/it]

 20%|█▉        | 611/3106 [2:22:01<10:28:14, 15.11s/it]

 20%|█▉        | 612/3106 [2:22:15<10:19:52, 14.91s/it]

 20%|█▉        | 613/3106 [2:22:27<9:42:20, 14.02s/it]

 20%|█▉        | 614/3106 [2:22:43<10:07:54, 14.64s/it]
{'loss': 1.0661, 'grad_norm': 0.2520189512319426, 'learning_rate': 0.00018564861022452242, 'epoch': 0.2}


 20%|█▉        | 616/3106 [2:23:10<9:36:09, 13.88s/it]

 20%|█▉        | 617/3106 [2:23:23<9:25:10, 13.62s/it]

 20%|█▉        | 618/3106 [2:23:37<9:30:33, 13.76s/it]
{'loss': 0.9721, 'grad_norm': 0.2354044840539633, 'learning_rate': 0.00018543251401798374, 'epoch': 0.2}


 20%|█▉        | 620/3106 [2:24:00<8:48:16, 12.75s/it]

 20%|█▉        | 621/3106 [2:24:13<8:49:20, 12.78s/it]

 20%|██        | 622/3106 [2:24:29<9:27:53, 13.72s/it]

 20%|██        | 623/3106 [2:24:43<9:32:20, 13.83s/it]

 20%|██        | 624/3106 [2:24:59<9:56:04, 14.41s/it]

 20%|██        | 625/3106 [2:25:13<9:55:06, 14.39s/it]

 20%|██        | 626/3106 [2:25:27<9:47:45, 14.22s/it]

 20%|██        | 627/3106 [2:25:42<9:58:35, 14.49s/it]
{'loss': 0.927, 'grad_norm': 0.23645541429061512, 'learning_rate': 0.0001849408662140907, 'epoch': 0.2}


 20%|██        | 629/3106 [2:26:18<11:07:00, 16.16s/it]

 20%|██        | 630/3106 [2:26:31<10:29:57, 15.27s/it]
{'loss': 0.9243, 'grad_norm': 0.2639098704101934, 'learning_rate': 0.0001847753181343046, 'epoch': 0.2}


 20%|██        | 632/3106 [2:26:57<9:35:49, 13.96s/it]

 20%|██        | 633/3106 [2:27:12<9:44:39, 14.19s/it]

 20%|██        | 634/3106 [2:27:26<9:46:21, 14.23s/it]

 20%|██        | 635/3106 [2:27:41<9:57:18, 14.50s/it]

 20%|██        | 636/3106 [2:27:53<9:32:12, 13.90s/it]

 21%|██        | 637/3106 [2:28:07<9:28:49, 13.82s/it]

 21%|██        | 638/3106 [2:28:20<9:17:12, 13.55s/it]

 21%|██        | 639/3106 [2:28:32<8:52:13, 12.94s/it]

 21%|██        | 640/3106 [2:28:46<9:14:28, 13.49s/it]

 21%|██        | 641/3106 [2:28:59<9:06:42, 13.31s/it]
{'loss': 1.0372, 'grad_norm': 0.2402015476933461, 'learning_rate': 0.00018416121943064617, 'epoch': 0.21}


 21%|██        | 643/3106 [2:29:23<8:39:17, 12.65s/it]

 21%|██        | 644/3106 [2:29:35<8:24:22, 12.29s/it]

 21%|██        | 645/3106 [2:29:49<8:45:10, 12.80s/it]

 21%|██        | 646/3106 [2:30:02<8:48:19, 12.89s/it]
{'loss': 0.9876, 'grad_norm': 0.26198269176465794, 'learning_rate': 0.00018387841641716223, 'epoch': 0.21}

 21%|██        | 647/3106 [2:30:15<8:53:07, 13.01s/it]


 21%|██        | 649/3106 [2:30:46<9:43:14, 14.24s/it]

 21%|██        | 650/3106 [2:31:07<11:01:03, 16.15s/it]

 21%|██        | 651/3106 [2:31:24<11:18:11, 16.57s/it]

 21%|██        | 652/3106 [2:31:37<10:29:27, 15.39s/it]

 21%|██        | 653/3106 [2:31:49<9:45:43, 14.33s/it]
{'loss': 0.9019, 'grad_norm': 0.25241471464208753, 'learning_rate': 0.0001834786613785091, 'epoch': 0.21}


 21%|██        | 655/3106 [2:32:17<9:39:29, 14.19s/it]

 21%|██        | 656/3106 [2:32:31<9:35:45, 14.10s/it]

 21%|██        | 657/3106 [2:32:47<10:00:47, 14.72s/it]

 21%|██        | 658/3106 [2:33:00<9:28:55, 13.94s/it]

 21%|██        | 659/3106 [2:33:12<9:14:57, 13.61s/it]

 21%|██        | 660/3106 [2:33:26<9:13:56, 13.59s/it]

 21%|██▏       | 661/3106 [2:33:38<8:49:58, 13.01s/it]

 21%|██▏       | 662/3106 [2:33:56<9:59:27, 14.72s/it]

 21%|██▏       | 663/3106 [2:34:09<9:39:03, 14.22s/it]

 21%|██▏       | 664/3106 [2:34:24<9:37:26, 14.19s/it]

 21%|██▏       | 665/3106 [2:34:40<10:07:02, 14.92s/it]

 21%|██▏       | 666/3106 [2:34:53<9:35:49, 14.16s/it]

 21%|██▏       | 667/3106 [2:35:05<9:12:17, 13.59s/it]

 22%|██▏       | 668/3106 [2:35:17<8:58:55, 13.26s/it]

 22%|██▏       | 669/3106 [2:35:34<9:44:14, 14.38s/it]

 22%|██▏       | 670/3106 [2:35:47<9:18:59, 13.77s/it]

 22%|██▏       | 671/3106 [2:36:04<9:59:23, 14.77s/it]

 22%|██▏       | 672/3106 [2:36:18<9:52:51, 14.61s/it]

 22%|██▏       | 673/3106 [2:36:33<9:57:49, 14.74s/it]

 22%|██▏       | 674/3106 [2:36:49<10:14:13, 15.15s/it]

 22%|██▏       | 675/3106 [2:37:01<9:29:31, 14.06s/it]

 22%|██▏       | 676/3106 [2:37:17<9:51:57, 14.62s/it]

 22%|██▏       | 677/3106 [2:37:29<9:25:56, 13.98s/it]

 22%|██▏       | 678/3106 [2:37:40<8:54:28, 13.21s/it]

 22%|██▏       | 679/3106 [2:37:54<9:02:34, 13.41s/it]

 22%|██▏       | 680/3106 [2:38:11<9:41:59, 14.39s/it]

 22%|██▏       | 681/3106 [2:38:25<9:36:46, 14.27s/it]
{'loss': 1.0101, 'grad_norm': 0.2548641863369851, 'learning_rate': 0.0001818353579312772, 'epoch': 0.22}


 22%|██▏       | 683/3106 [2:38:51<9:07:57, 13.57s/it]

 22%|██▏       | 684/3106 [2:39:05<9:18:32, 13.84s/it]

 22%|██▏       | 685/3106 [2:39:18<9:06:00, 13.53s/it]

 22%|██▏       | 686/3106 [2:39:31<8:55:54, 13.29s/it]

 22%|██▏       | 687/3106 [2:39:46<9:18:46, 13.86s/it]

 22%|██▏       | 688/3106 [2:40:01<9:33:57, 14.24s/it]
{'loss': 1.114, 'grad_norm': 0.24590994493140436, 'learning_rate': 0.00018141357074629837, 'epoch': 0.22}


 22%|██▏       | 690/3106 [2:40:32<10:07:16, 15.08s/it]

 22%|██▏       | 691/3106 [2:40:49<10:27:51, 15.60s/it]

 22%|██▏       | 692/3106 [2:41:03<10:02:04, 14.96s/it]

 22%|██▏       | 693/3106 [2:41:15<9:27:30, 14.11s/it]
{'loss': 0.9651, 'grad_norm': 0.2270083642225281, 'learning_rate': 0.0001811096357773965, 'epoch': 0.22}


 22%|██▏       | 695/3106 [2:41:40<8:53:25, 13.27s/it]
{'loss': 1.1291, 'grad_norm': 0.24741432402608976, 'learning_rate': 0.0001809874436509115, 'epoch': 0.22}


 22%|██▏       | 697/3106 [2:42:07<9:00:05, 13.45s/it]

 22%|██▏       | 698/3106 [2:42:19<8:43:13, 13.04s/it]

 23%|██▎       | 699/3106 [2:42:31<8:23:15, 12.54s/it]

 23%|██▎       | 700/3106 [2:42:42<8:14:10, 12.32s/it]

 23%|██▎       | 701/3106 [2:42:55<8:12:08, 12.28s/it]

 23%|██▎       | 702/3106 [2:43:10<8:48:42, 13.20s/it]

 23%|██▎       | 703/3106 [2:43:22<8:36:19, 12.89s/it]

 23%|██▎       | 704/3106 [2:43:41<9:45:59, 14.64s/it]
[2024-05-28 23:36:43,623] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 705/3106 [2:43:55<9:44:03, 14.60s/it]

 23%|██▎       | 706/3106 [2:44:10<9:45:44, 14.64s/it]

 23%|██▎       | 707/3106 [2:44:23<9:25:38, 14.15s/it]

 23%|██▎       | 708/3106 [2:44:36<9:12:16, 13.82s/it]

 23%|██▎       | 709/3106 [2:44:51<9:26:02, 14.17s/it]

 23%|██▎       | 710/3106 [2:45:05<9:27:46, 14.22s/it]

 23%|██▎       | 711/3106 [2:45:18<9:12:04, 13.83s/it]

 23%|██▎       | 712/3106 [2:45:33<9:25:29, 14.17s/it]
{'loss': 0.9908, 'grad_norm': 0.28585773413539806, 'learning_rate': 0.00017993463547314045, 'epoch': 0.23}


 23%|██▎       | 714/3106 [2:46:00<9:13:08, 13.87s/it]

 23%|██▎       | 715/3106 [2:46:14<9:06:41, 13.72s/it]

 23%|██▎       | 716/3106 [2:46:27<9:04:51, 13.68s/it]

 23%|██▎       | 717/3106 [2:46:43<9:25:33, 14.20s/it]

 23%|██▎       | 718/3106 [2:46:57<9:22:21, 14.13s/it]

 23%|██▎       | 719/3106 [2:47:12<9:43:01, 14.66s/it]

 23%|██▎       | 720/3106 [2:47:32<10:38:25, 16.05s/it]

 23%|██▎       | 721/3106 [2:47:49<10:52:43, 16.42s/it]
{'loss': 0.8831, 'grad_norm': 0.24490446151555442, 'learning_rate': 0.00017936707092220365, 'epoch': 0.23}


 23%|██▎       | 723/3106 [2:48:19<10:15:09, 15.49s/it]

 23%|██▎       | 724/3106 [2:48:32<9:50:30, 14.87s/it]

 23%|██▎       | 725/3106 [2:48:45<9:27:15, 14.29s/it]

 23%|██▎       | 726/3106 [2:49:01<9:44:15, 14.73s/it]

 23%|██▎       | 727/3106 [2:49:25<11:28:39, 17.37s/it]

 23%|██▎       | 728/3106 [2:49:38<10:40:13, 16.15s/it]

 23%|██▎       | 729/3106 [2:49:53<10:22:02, 15.70s/it]
{'loss': 0.9581, 'grad_norm': 0.2622886473774689, 'learning_rate': 0.0001788566962083946, 'epoch': 0.23}

 24%|██▎       | 730/3106 [2:50:08<10:21:03, 15.68s/it]


 24%|██▎       | 732/3106 [2:50:38<9:56:29, 15.08s/it]

 24%|██▎       | 733/3106 [2:50:49<9:16:32, 14.07s/it]

 24%|██▎       | 734/3106 [2:51:02<9:03:58, 13.76s/it]
{'loss': 0.9729, 'grad_norm': 0.23694476994904962, 'learning_rate': 0.00017853492163500304, 'epoch': 0.24}


 24%|██▎       | 736/3106 [2:51:32<9:31:34, 14.47s/it]

 24%|██▎       | 737/3106 [2:51:47<9:34:19, 14.55s/it]

 24%|██▍       | 738/3106 [2:52:01<9:32:50, 14.51s/it]

 24%|██▍       | 739/3106 [2:52:17<9:45:38, 14.84s/it]

 24%|██▍       | 740/3106 [2:52:30<9:24:31, 14.32s/it]

 24%|██▍       | 741/3106 [2:52:43<9:05:26, 13.84s/it]

 24%|██▍       | 742/3106 [2:53:03<10:15:21, 15.62s/it]

 24%|██▍       | 743/3106 [2:53:16<9:48:53, 14.95s/it]

 24%|██▍       | 744/3106 [2:53:29<9:29:11, 14.46s/it]

 24%|██▍       | 745/3106 [2:53:45<9:44:52, 14.86s/it]

 24%|██▍       | 746/3106 [2:53:58<9:23:56, 14.34s/it]

 24%|██▍       | 747/3106 [2:54:10<8:54:41, 13.60s/it]

 24%|██▍       | 748/3106 [2:54:23<8:46:49, 13.41s/it]

 24%|██▍       | 749/3106 [2:54:38<9:07:26, 13.94s/it]

 24%|██▍       | 750/3106 [2:54:53<9:14:47, 14.13s/it]

 24%|██▍       | 751/3106 [2:55:05<8:53:09, 13.58s/it]

 24%|██▍       | 752/3106 [2:55:17<8:34:00, 13.10s/it]

 24%|██▍       | 753/3106 [2:55:31<8:41:06, 13.29s/it]
{'loss': 1.006, 'grad_norm': 0.30671281664371886, 'learning_rate': 0.0001772927735750435, 'epoch': 0.24}


 24%|██▍       | 755/3106 [2:55:58<8:38:36, 13.24s/it]

 24%|██▍       | 756/3106 [2:56:10<8:28:15, 12.98s/it]

 24%|██▍       | 757/3106 [2:56:22<8:07:18, 12.45s/it]

 24%|██▍       | 758/3106 [2:56:36<8:33:42, 13.13s/it]
{'loss': 1.0049, 'grad_norm': 0.22688053083654097, 'learning_rate': 0.00017696082726290823, 'epoch': 0.24}


 24%|██▍       | 760/3106 [2:57:02<8:26:56, 12.97s/it]

 25%|██▍       | 761/3106 [2:57:18<9:02:35, 13.88s/it]

 25%|██▍       | 762/3106 [2:57:31<8:57:37, 13.76s/it]
{'loss': 0.9664, 'grad_norm': 0.25704123960744285, 'learning_rate': 0.00017669376271614755, 'epoch': 0.25}

 25%|██▍       | 763/3106 [2:57:47<9:17:38, 14.28s/it]


 25%|██▍       | 765/3106 [2:58:15<9:09:05, 14.07s/it]

 25%|██▍       | 766/3106 [2:58:28<9:01:11, 13.88s/it]

 25%|██▍       | 767/3106 [2:58:42<8:59:52, 13.85s/it]

 25%|██▍       | 768/3106 [2:58:58<9:27:04, 14.55s/it]

 25%|██▍       | 769/3106 [2:59:16<10:07:22, 15.59s/it]
{'loss': 0.9236, 'grad_norm': 0.23967110423178353, 'learning_rate': 0.00017622319031429995, 'epoch': 0.25}


 25%|██▍       | 771/3106 [2:59:46<10:04:08, 15.52s/it]

 25%|██▍       | 772/3106 [2:59:59<9:37:12, 14.84s/it]

 25%|██▍       | 773/3106 [3:00:12<9:08:48, 14.11s/it]

 25%|██▍       | 774/3106 [3:00:23<8:39:27, 13.37s/it]
{'loss': 1.0909, 'grad_norm': 0.24800716574043233, 'learning_rate': 0.00017588457800888342, 'epoch': 0.25}

 25%|██▍       | 775/3106 [3:00:37<8:39:41, 13.38s/it]


 25%|██▌       | 777/3106 [3:01:04<8:47:32, 13.59s/it]
{'loss': 1.0219, 'grad_norm': 0.2452941114406953, 'learning_rate': 0.0001756804193762484, 'epoch': 0.25}


 25%|██▌       | 779/3106 [3:01:31<8:43:06, 13.49s/it]

 25%|██▌       | 780/3106 [3:01:42<8:17:25, 12.83s/it]

 25%|██▌       | 781/3106 [3:01:53<8:02:39, 12.46s/it]

 25%|██▌       | 782/3106 [3:02:07<8:17:46, 12.85s/it]

 25%|██▌       | 783/3106 [3:02:24<9:07:11, 14.13s/it]

 25%|██▌       | 784/3106 [3:02:36<8:37:52, 13.38s/it]

 25%|██▌       | 785/3106 [3:02:50<8:51:11, 13.73s/it]

 25%|██▌       | 786/3106 [3:03:03<8:39:54, 13.45s/it]

 25%|██▌       | 787/3106 [3:03:18<8:59:27, 13.96s/it]

 25%|██▌       | 788/3106 [3:03:31<8:48:59, 13.69s/it]

 25%|██▌       | 789/3106 [3:03:51<9:52:21, 15.34s/it]

 25%|██▌       | 790/3106 [3:04:07<10:03:18, 15.63s/it]

 25%|██▌       | 791/3106 [3:04:21<9:40:07, 15.04s/it]

 25%|██▌       | 792/3106 [3:04:37<9:51:27, 15.34s/it]

 26%|██▌       | 793/3106 [3:04:52<9:52:23, 15.37s/it]

 26%|██▌       | 794/3106 [3:05:06<9:30:30, 14.81s/it]

 26%|██▌       | 795/3106 [3:05:18<9:06:02, 14.18s/it]

 26%|██▌       | 796/3106 [3:05:34<9:28:27, 14.77s/it]
{'loss': 1.0227, 'grad_norm': 0.2594690372313573, 'learning_rate': 0.00017437029029037233, 'epoch': 0.26}


 26%|██▌       | 798/3106 [3:06:06<9:54:02, 15.44s/it]

 26%|██▌       | 799/3106 [3:06:18<9:15:49, 14.46s/it]

 26%|██▌       | 800/3106 [3:06:30<8:46:21, 13.70s/it]

 26%|██▌       | 801/3106 [3:06:43<8:37:32, 13.47s/it]

 26%|██▌       | 802/3106 [3:06:55<8:21:49, 13.07s/it]

 26%|██▌       | 803/3106 [3:07:09<8:29:44, 13.28s/it]

 26%|██▌       | 804/3106 [3:07:21<8:21:10, 13.06s/it]

 26%|██▌       | 805/3106 [3:07:37<8:53:33, 13.91s/it]

 26%|██▌       | 806/3106 [3:07:50<8:45:55, 13.72s/it]

 26%|██▌       | 807/3106 [3:08:02<8:25:38, 13.20s/it]

 26%|██▌       | 808/3106 [3:08:15<8:20:51, 13.08s/it]

 26%|██▌       | 809/3106 [3:08:30<8:44:25, 13.70s/it]

 26%|██▌       | 810/3106 [3:08:42<8:20:52, 13.09s/it]

 26%|██▌       | 811/3106 [3:08:56<8:28:44, 13.30s/it]

 26%|██▌       | 812/3106 [3:09:12<9:08:03, 14.33s/it]

 26%|██▌       | 813/3106 [3:09:28<9:21:53, 14.70s/it]

 26%|██▌       | 814/3106 [3:09:43<9:28:04, 14.87s/it]

 26%|██▌       | 815/3106 [3:10:01<10:00:06, 15.72s/it]

 26%|██▋       | 816/3106 [3:10:19<10:22:07, 16.30s/it]

 26%|██▋       | 817/3106 [3:10:36<10:30:51, 16.54s/it]

 26%|██▋       | 818/3106 [3:10:49<9:50:28, 15.48s/it]

 26%|██▋       | 819/3106 [3:11:07<10:18:45, 16.23s/it]

 26%|██▋       | 820/3106 [3:11:19<9:33:39, 15.06s/it]

 26%|██▋       | 821/3106 [3:11:36<9:53:41, 15.59s/it]

 26%|██▋       | 822/3106 [3:11:50<9:38:02, 15.19s/it]

 26%|██▋       | 823/3106 [3:12:03<9:13:48, 14.55s/it]

 27%|██▋       | 824/3106 [3:12:18<9:13:27, 14.55s/it]
{'loss': 0.9828, 'grad_norm': 0.24792894119351636, 'learning_rate': 0.00017238648923576747, 'epoch': 0.27}


 27%|██▋       | 826/3106 [3:12:43<8:40:13, 13.69s/it]

 27%|██▋       | 827/3106 [3:12:57<8:44:03, 13.80s/it]

 27%|██▋       | 828/3106 [3:13:11<8:46:08, 13.86s/it]

 27%|██▋       | 829/3106 [3:13:24<8:35:39, 13.59s/it]
{'loss': 1.0918, 'grad_norm': 0.25361629925605444, 'learning_rate': 0.00017202569309971244, 'epoch': 0.27}


 27%|██▋       | 831/3106 [3:13:52<8:35:35, 13.60s/it]

 27%|██▋       | 832/3106 [3:14:04<8:17:16, 13.12s/it]

 27%|██▋       | 833/3106 [3:14:21<9:03:36, 14.35s/it]
{'loss': 0.842, 'grad_norm': 0.23247656142236633, 'learning_rate': 0.00017173564529702627, 'epoch': 0.27}


 27%|██▋       | 835/3106 [3:14:49<8:52:59, 14.08s/it]

 27%|██▋       | 836/3106 [3:15:05<9:16:59, 14.72s/it]

 27%|██▋       | 837/3106 [3:15:17<8:47:28, 13.95s/it]

 27%|██▋       | 838/3106 [3:15:30<8:33:57, 13.60s/it]

 27%|██▋       | 839/3106 [3:15:42<8:13:38, 13.07s/it]

 27%|██▋       | 840/3106 [3:15:54<8:03:15, 12.80s/it]

 27%|██▋       | 841/3106 [3:16:09<8:25:56, 13.40s/it]

 27%|██▋       | 842/3106 [3:16:23<8:31:42, 13.56s/it]

 27%|██▋       | 843/3106 [3:16:39<9:02:13, 14.38s/it]

 27%|██▋       | 844/3106 [3:16:52<8:48:31, 14.02s/it]

 27%|██▋       | 845/3106 [3:17:05<8:34:18, 13.65s/it]

 27%|██▋       | 846/3106 [3:17:22<9:12:03, 14.66s/it]

 27%|██▋       | 847/3106 [3:17:41<10:03:18, 16.02s/it]

 27%|██▋       | 848/3106 [3:17:54<9:21:41, 14.93s/it]

 27%|██▋       | 849/3106 [3:18:13<10:05:39, 16.10s/it]

 27%|██▋       | 850/3106 [3:18:24<9:16:16, 14.79s/it]

 27%|██▋       | 851/3106 [3:18:39<9:13:50, 14.74s/it]

 27%|██▋       | 852/3106 [3:18:51<8:44:02, 13.95s/it]

 27%|██▋       | 853/3106 [3:19:07<9:02:08, 14.44s/it]

 27%|██▋       | 854/3106 [3:19:26<9:55:12, 15.86s/it]

 28%|██▊       | 855/3106 [3:19:39<9:21:16, 14.96s/it]

 28%|██▊       | 856/3106 [3:19:53<9:11:35, 14.71s/it]

 28%|██▊       | 857/3106 [3:20:05<8:47:20, 14.07s/it]

 28%|██▊       | 858/3106 [3:20:19<8:40:55, 13.90s/it]

 28%|██▊       | 859/3106 [3:20:36<9:16:26, 14.86s/it]

 28%|██▊       | 860/3106 [3:20:51<9:21:55, 15.01s/it]

 28%|██▊       | 861/3106 [3:21:06<9:13:55, 14.80s/it]

 28%|██▊       | 862/3106 [3:21:21<9:24:54, 15.10s/it]

 28%|██▊       | 863/3106 [3:21:35<9:02:57, 14.52s/it]

 28%|██▊       | 864/3106 [3:21:48<8:54:03, 14.29s/it]

 28%|██▊       | 865/3106 [3:22:01<8:30:27, 13.67s/it]
{'loss': 1.0619, 'grad_norm': 0.25169983558489456, 'learning_rate': 0.00016937073975031573, 'epoch': 0.28}


 28%|██▊       | 867/3106 [3:22:25<8:01:39, 12.91s/it]

 28%|██▊       | 868/3106 [3:22:37<7:51:17, 12.64s/it]

 28%|██▊       | 869/3106 [3:22:50<7:54:14, 12.72s/it]

 28%|██▊       | 870/3106 [3:23:07<8:49:20, 14.20s/it]

 28%|██▊       | 871/3106 [3:23:26<9:38:31, 15.53s/it]

 28%|██▊       | 872/3106 [3:23:41<9:26:48, 15.22s/it]

 28%|██▊       | 873/3106 [3:23:55<9:18:24, 15.00s/it]

 28%|██▊       | 874/3106 [3:24:15<10:11:57, 16.45s/it]
{'loss': 1.0264, 'grad_norm': 0.2620769361857656, 'learning_rate': 0.00016869157154728436, 'epoch': 0.28}


 28%|██▊       | 876/3106 [3:24:43<9:26:38, 15.25s/it]

 28%|██▊       | 877/3106 [3:24:56<9:05:31, 14.68s/it]
{'loss': 1.1524, 'grad_norm': 0.25104638574806526, 'learning_rate': 0.00016846383405060906, 'epoch': 0.28}


 28%|██▊       | 879/3106 [3:25:24<8:51:29, 14.32s/it]

 28%|██▊       | 880/3106 [3:25:36<8:28:35, 13.71s/it]

 28%|██▊       | 881/3106 [3:25:49<8:26:14, 13.65s/it]

 28%|██▊       | 882/3106 [3:26:01<8:07:46, 13.16s/it]

 28%|██▊       | 883/3106 [3:26:15<8:15:13, 13.37s/it]

 28%|██▊       | 884/3106 [3:26:32<8:48:25, 14.27s/it]

 28%|██▊       | 885/3106 [3:26:48<9:09:49, 14.85s/it]

 29%|██▊       | 886/3106 [3:27:04<9:18:23, 15.09s/it]

 29%|██▊       | 887/3106 [3:27:19<9:26:23, 15.31s/it]

 29%|██▊       | 888/3106 [3:27:34<9:21:34, 15.19s/it]

 29%|██▊       | 889/3106 [3:27:46<8:45:30, 14.22s/it]

 29%|██▊       | 890/3106 [3:27:58<8:12:13, 13.33s/it]

 29%|██▊       | 891/3106 [3:28:09<7:56:10, 12.90s/it]

 29%|██▊       | 892/3106 [3:28:21<7:42:28, 12.53s/it]

 29%|██▉       | 893/3106 [3:28:33<7:37:22, 12.40s/it]
{'loss': 0.9717, 'grad_norm': 0.21598604162289203, 'learning_rate': 0.00016723796751054925, 'epoch': 0.29}


 29%|██▉       | 895/3106 [3:29:01<8:05:10, 13.17s/it]

 29%|██▉       | 896/3106 [3:29:14<8:07:52, 13.25s/it]

 29%|██▉       | 897/3106 [3:29:31<8:41:05, 14.15s/it]

 29%|██▉       | 898/3106 [3:29:47<9:05:39, 14.83s/it]
{'loss': 1.01, 'grad_norm': 0.2308967250759075, 'learning_rate': 0.0001668510278314833, 'epoch': 0.29}

 29%|██▉       | 899/3106 [3:29:59<8:31:44, 13.91s/it]

 29%|██▉       | 900/3106 [3:30:15<8:54:04, 14.53s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 29%|██▉       | 901/3106 [3:30:46<11:56:12, 19.49s/it]

 29%|██▉       | 902/3106 [3:30:58<10:38:21, 17.38s/it]

 29%|██▉       | 903/3106 [3:31:13<10:10:20, 16.62s/it]

 29%|██▉       | 904/3106 [3:31:27<9:36:17, 15.70s/it]

 29%|██▉       | 905/3106 [3:31:39<8:56:09, 14.62s/it]

 29%|██▉       | 906/3106 [3:31:53<8:54:45, 14.58s/it]

 29%|██▉       | 907/3106 [3:32:08<8:55:46, 14.62s/it]

 29%|██▉       | 908/3106 [3:32:22<8:54:59, 14.60s/it]

 29%|██▉       | 909/3106 [3:32:35<8:29:35, 13.92s/it]

 29%|██▉       | 910/3106 [3:32:48<8:17:54, 13.60s/it]

 29%|██▉       | 911/3106 [3:33:02<8:28:52, 13.91s/it]

 29%|██▉       | 912/3106 [3:33:14<8:03:35, 13.23s/it]

 29%|██▉       | 913/3106 [3:33:25<7:43:31, 12.68s/it]

 29%|██▉       | 914/3106 [3:33:38<7:42:01, 12.65s/it]

 29%|██▉       | 915/3106 [3:33:55<8:35:53, 14.13s/it]

 29%|██▉       | 916/3106 [3:34:12<9:04:45, 14.92s/it]

 30%|██▉       | 917/3106 [3:34:26<8:52:17, 14.59s/it]

 30%|██▉       | 918/3106 [3:34:43<9:16:26, 15.26s/it]

 30%|██▉       | 919/3106 [3:34:59<9:21:48, 15.41s/it]

 30%|██▉       | 920/3106 [3:35:10<8:40:37, 14.29s/it]

 30%|██▉       | 921/3106 [3:35:24<8:31:38, 14.05s/it]

 30%|██▉       | 922/3106 [3:35:37<8:20:23, 13.75s/it]

 30%|██▉       | 923/3106 [3:35:50<8:09:50, 13.46s/it]
{'loss': 0.9477, 'grad_norm': 0.27118931108488026, 'learning_rate': 0.00016488926893364276, 'epoch': 0.3}


 30%|██▉       | 925/3106 [3:36:16<8:07:10, 13.40s/it]

 30%|██▉       | 926/3106 [3:36:29<7:54:59, 13.07s/it]

 30%|██▉       | 927/3106 [3:36:42<7:58:18, 13.17s/it]

 30%|██▉       | 928/3106 [3:36:54<7:43:55, 12.78s/it]

 30%|██▉       | 929/3106 [3:37:07<7:40:55, 12.70s/it]

 30%|██▉       | 930/3106 [3:37:22<8:12:13, 13.57s/it]

 30%|██▉       | 931/3106 [3:37:36<8:10:41, 13.54s/it]

 30%|███       | 932/3106 [3:37:48<7:54:31, 13.10s/it]

 30%|███       | 933/3106 [3:38:00<7:48:43, 12.94s/it]

 30%|███       | 934/3106 [3:38:12<7:35:49, 12.59s/it]

 30%|███       | 935/3106 [3:38:24<7:30:20, 12.45s/it]
{'loss': 1.0586, 'grad_norm': 0.25102029397091286, 'learning_rate': 0.00016393187059154344, 'epoch': 0.3}


 30%|███       | 937/3106 [3:38:51<7:50:25, 13.01s/it]

 30%|███       | 938/3106 [3:39:05<7:56:55, 13.20s/it]

 30%|███       | 939/3106 [3:39:17<7:48:59, 12.99s/it]

 30%|███       | 940/3106 [3:39:30<7:43:18, 12.83s/it]

 30%|███       | 941/3106 [3:39:46<8:20:53, 13.88s/it]

 30%|███       | 942/3106 [3:39:57<7:51:00, 13.06s/it]

 30%|███       | 943/3106 [3:40:09<7:33:39, 12.58s/it]

 30%|███       | 944/3106 [3:40:22<7:41:25, 12.81s/it]
{'loss': 0.9712, 'grad_norm': 0.2444655873738257, 'learning_rate': 0.000163207241031752, 'epoch': 0.3}


 30%|███       | 946/3106 [3:40:51<8:11:12, 13.64s/it]

 30%|███       | 947/3106 [3:41:04<8:12:32, 13.69s/it]

 31%|███       | 948/3106 [3:41:16<7:50:52, 13.09s/it]

 31%|███       | 949/3106 [3:41:31<8:05:57, 13.52s/it]

 31%|███       | 950/3106 [3:41:43<7:52:31, 13.15s/it]

 31%|███       | 951/3106 [3:41:59<8:23:12, 14.01s/it]

 31%|███       | 952/3106 [3:42:13<8:20:33, 13.94s/it]

 31%|███       | 953/3106 [3:42:25<8:06:25, 13.56s/it]
{'loss': 1.0581, 'grad_norm': 0.2589979319393627, 'learning_rate': 0.000162477041686412, 'epoch': 0.31}


 31%|███       | 955/3106 [3:42:53<8:08:22, 13.62s/it]

 31%|███       | 956/3106 [3:43:08<8:29:15, 14.21s/it]

 31%|███       | 957/3106 [3:43:21<8:07:23, 13.61s/it]

 31%|███       | 958/3106 [3:43:34<7:58:49, 13.37s/it]

 31%|███       | 959/3106 [3:43:48<8:10:52, 13.72s/it]

 31%|███       | 960/3106 [3:44:03<8:21:56, 14.03s/it]

 31%|███       | 961/3106 [3:44:19<8:45:01, 14.69s/it]

 31%|███       | 962/3106 [3:44:35<9:02:59, 15.20s/it]

 31%|███       | 963/3106 [3:44:47<8:28:37, 14.24s/it]

 31%|███       | 964/3106 [3:45:01<8:26:21, 14.18s/it]

 31%|███       | 965/3106 [3:45:17<8:43:39, 14.67s/it]

 31%|███       | 966/3106 [3:45:31<8:28:15, 14.25s/it]

 31%|███       | 967/3106 [3:45:43<8:13:43, 13.85s/it]

 31%|███       | 968/3106 [3:45:55<7:52:34, 13.26s/it]

 31%|███       | 969/3106 [3:46:10<8:03:47, 13.58s/it]

 31%|███       | 970/3106 [3:46:26<8:28:19, 14.28s/it]

 31%|███▏      | 971/3106 [3:46:40<8:32:42, 14.41s/it]

 31%|███▏      | 972/3106 [3:46:54<8:29:53, 14.34s/it]

 31%|███▏      | 973/3106 [3:47:07<8:09:47, 13.78s/it]

 31%|███▏      | 974/3106 [3:47:19<7:47:14, 13.15s/it]

 31%|███▏      | 975/3106 [3:47:33<7:59:35, 13.50s/it]

 31%|███▏      | 976/3106 [3:47:47<8:05:44, 13.68s/it]

 31%|███▏      | 977/3106 [3:48:00<8:02:03, 13.59s/it]

 31%|███▏      | 978/3106 [3:48:16<8:20:47, 14.12s/it]

 32%|███▏      | 979/3106 [3:48:30<8:24:56, 14.24s/it]

 32%|███▏      | 980/3106 [3:48:45<8:25:04, 14.25s/it]

 32%|███▏      | 981/3106 [3:48:58<8:18:41, 14.08s/it]

 32%|███▏      | 982/3106 [3:49:10<7:51:17, 13.31s/it]

 32%|███▏      | 983/3106 [3:49:22<7:35:38, 12.88s/it]

 32%|███▏      | 984/3106 [3:49:36<7:53:25, 13.39s/it]

 32%|███▏      | 985/3106 [3:49:49<7:45:35, 13.17s/it]

 32%|███▏      | 986/3106 [3:50:07<8:36:54, 14.63s/it]

 32%|███▏      | 987/3106 [3:50:19<8:11:05, 13.91s/it]
{'loss': 1.0381, 'grad_norm': 0.2670729061340934, 'learning_rate': 0.00015966936943054934, 'epoch': 0.32}


 32%|███▏      | 989/3106 [3:50:42<7:23:04, 12.56s/it]

 32%|███▏      | 990/3106 [3:50:54<7:19:56, 12.47s/it]

 32%|███▏      | 991/3106 [3:51:10<8:03:01, 13.70s/it]

 32%|███▏      | 992/3106 [3:51:23<7:45:48, 13.22s/it]
{'loss': 0.9688, 'grad_norm': 0.24325741504750525, 'learning_rate': 0.00015925006205909654, 'epoch': 0.32}


 32%|███▏      | 994/3106 [3:51:50<7:47:50, 13.29s/it]

 32%|███▏      | 995/3106 [3:52:02<7:39:08, 13.05s/it]

 32%|███▏      | 996/3106 [3:52:17<7:50:37, 13.38s/it]

 32%|███▏      | 997/3106 [3:52:29<7:39:05, 13.06s/it]

 32%|███▏      | 998/3106 [3:52:44<7:55:00, 13.52s/it]

 32%|███▏      | 999/3106 [3:53:00<8:24:07, 14.36s/it]

 32%|███▏      | 1000/3106 [3:53:13<8:14:05, 14.08s/it]

 32%|███▏      | 1001/3106 [3:53:26<8:00:31, 13.70s/it]

 32%|███▏      | 1002/3106 [3:53:40<8:00:48, 13.71s/it]

 32%|███▏      | 1003/3106 [3:53:53<7:53:53, 13.52s/it]

 32%|███▏      | 1004/3106 [3:54:07<8:01:28, 13.74s/it]

 32%|███▏      | 1005/3106 [3:54:20<7:54:22, 13.55s/it]

 32%|███▏      | 1006/3106 [3:54:33<7:41:31, 13.19s/it]

 32%|███▏      | 1007/3106 [3:54:48<8:06:58, 13.92s/it]

 32%|███▏      | 1008/3106 [3:55:00<7:45:36, 13.32s/it]

 32%|███▏      | 1009/3106 [3:55:12<7:29:33, 12.86s/it]

 33%|███▎      | 1010/3106 [3:55:24<7:16:02, 12.48s/it]

 33%|███▎      | 1011/3106 [3:55:36<7:16:54, 12.51s/it]
{'loss': 0.9493, 'grad_norm': 0.2291163167160251, 'learning_rate': 0.00015764209520750536, 'epoch': 0.33}

 33%|███▎      | 1012/3106 [3:55:49<7:21:04, 12.64s/it]

 33%|███▎      | 1013/3106 [3:56:02<7:29:15, 12.88s/it]


 33%|███▎      | 1015/3106 [3:56:32<8:03:26, 13.87s/it]

 33%|███▎      | 1016/3106 [3:56:50<8:40:42, 14.95s/it]

 33%|███▎      | 1017/3106 [3:57:05<8:48:19, 15.17s/it]
{'loss': 0.939, 'grad_norm': 0.2928409679543123, 'learning_rate': 0.00015712958301635993, 'epoch': 0.33}


 33%|███▎      | 1019/3106 [3:57:32<8:21:07, 14.41s/it]

 33%|███▎      | 1020/3106 [3:57:49<8:53:15, 15.34s/it]

 33%|███▎      | 1021/3106 [3:58:02<8:26:58, 14.59s/it]

 33%|███▎      | 1022/3106 [3:58:16<8:16:58, 14.31s/it]

 33%|███▎      | 1023/3106 [3:58:28<7:58:09, 13.77s/it]

 33%|███▎      | 1024/3106 [3:58:40<7:38:18, 13.21s/it]

 33%|███▎      | 1025/3106 [3:58:52<7:27:01, 12.89s/it]
{'loss': 1.1317, 'grad_norm': 0.2582962202622884, 'learning_rate': 0.0001564427564434431, 'epoch': 0.33}

 33%|███▎      | 1026/3106 [3:59:07<7:44:03, 13.39s/it]


 33%|███▎      | 1028/3106 [3:59:35<7:49:30, 13.56s/it]

 33%|███▎      | 1029/3106 [3:59:48<7:44:15, 13.41s/it]

 33%|███▎      | 1030/3106 [4:00:02<7:49:58, 13.58s/it]

 33%|███▎      | 1031/3106 [4:00:14<7:33:30, 13.11s/it]

 33%|███▎      | 1032/3106 [4:00:26<7:21:32, 12.77s/it]

 33%|███▎      | 1033/3106 [4:00:38<7:13:42, 12.55s/it]

 33%|███▎      | 1034/3106 [4:00:50<7:11:56, 12.51s/it]

 33%|███▎      | 1035/3106 [4:01:04<7:26:01, 12.92s/it]
{'loss': 1.02, 'grad_norm': 0.24425059724413484, 'learning_rate': 0.00015557870251209658, 'epoch': 0.33}


 33%|███▎      | 1037/3106 [4:01:30<7:33:51, 13.16s/it]
{'loss': 0.947, 'grad_norm': 0.24201414416279066, 'learning_rate': 0.00015540516314253283, 'epoch': 0.33}


 33%|███▎      | 1039/3106 [4:01:56<7:26:39, 12.97s/it]

 33%|███▎      | 1040/3106 [4:02:08<7:20:01, 12.78s/it]

 34%|███▎      | 1041/3106 [4:02:20<7:14:11, 12.62s/it]

 34%|███▎      | 1042/3106 [4:02:32<7:05:52, 12.38s/it]

 34%|███▎      | 1043/3106 [4:02:46<7:17:01, 12.71s/it]

 34%|███▎      | 1044/3106 [4:02:59<7:20:36, 12.82s/it]
{'loss': 0.9848, 'grad_norm': 0.26280849577106974, 'learning_rate': 0.00015479588164017392, 'epoch': 0.34}


 34%|███▎      | 1046/3106 [4:03:24<7:14:10, 12.65s/it]

 34%|███▎      | 1047/3106 [4:03:44<8:29:13, 14.84s/it]
{'loss': 0.9149, 'grad_norm': 0.24258391761125064, 'learning_rate': 0.00015453386491261922, 'epoch': 0.34}


 34%|███▍      | 1049/3106 [4:04:08<7:46:43, 13.61s/it]

 34%|███▍      | 1050/3106 [4:04:20<7:28:09, 13.08s/it]

 34%|███▍      | 1051/3106 [4:04:36<7:58:42, 13.98s/it]

 34%|███▍      | 1052/3106 [4:04:50<7:54:55, 13.87s/it]

 34%|███▍      | 1053/3106 [4:05:03<7:45:46, 13.61s/it]

 34%|███▍      | 1054/3106 [4:05:17<7:47:07, 13.66s/it]
{'loss': 1.0203, 'grad_norm': 0.23068963002277362, 'learning_rate': 0.00015392042053119699, 'epoch': 0.34}


 34%|███▍      | 1056/3106 [4:05:45<7:54:02, 13.87s/it]

 34%|███▍      | 1057/3106 [4:06:00<8:08:02, 14.29s/it]

 34%|███▍      | 1058/3106 [4:06:12<7:41:22, 13.52s/it]
{'loss': 1.0255, 'grad_norm': 0.24237676404707145, 'learning_rate': 0.00015356858826359542, 'epoch': 0.34}


 34%|███▍      | 1060/3106 [4:06:39<7:42:19, 13.56s/it]

 34%|███▍      | 1061/3106 [4:06:52<7:35:24, 13.36s/it]
{'loss': 0.9078, 'grad_norm': 0.21993584493985865, 'learning_rate': 0.0001533041018157771, 'epoch': 0.34}

 34%|███▍      | 1062/3106 [4:07:03<7:16:17, 12.81s/it]

 34%|███▍      | 1063/3106 [4:07:16<7:10:15, 12.64s/it]


 34%|███▍      | 1065/3106 [4:07:45<7:39:22, 13.50s/it]

 34%|███▍      | 1066/3106 [4:08:00<7:54:41, 13.96s/it]

 34%|███▍      | 1067/3106 [4:08:12<7:38:01, 13.48s/it]

 34%|███▍      | 1068/3106 [4:08:24<7:19:09, 12.93s/it]

 34%|███▍      | 1069/3106 [4:08:37<7:19:03, 12.93s/it]

 34%|███▍      | 1070/3106 [4:08:51<7:27:11, 13.18s/it]

 34%|███▍      | 1071/3106 [4:09:06<7:52:49, 13.94s/it]

 35%|███▍      | 1072/3106 [4:09:19<7:35:39, 13.44s/it]

 35%|███▍      | 1073/3106 [4:09:31<7:22:13, 13.05s/it]

 35%|███▍      | 1074/3106 [4:09:45<7:33:29, 13.39s/it]

 35%|███▍      | 1075/3106 [4:09:57<7:18:03, 12.94s/it]

 35%|███▍      | 1076/3106 [4:10:08<7:00:51, 12.44s/it]

 35%|███▍      | 1077/3106 [4:10:21<7:06:00, 12.60s/it]
{'loss': 0.9741, 'grad_norm': 0.2530551495565167, 'learning_rate': 0.000151884756410397, 'epoch': 0.35}


 35%|███▍      | 1079/3106 [4:10:52<8:05:32, 14.37s/it]
{'loss': 1.1084, 'grad_norm': 0.25411937752095515, 'learning_rate': 0.00015170631408799938, 'epoch': 0.35}


 35%|███▍      | 1081/3106 [4:11:21<7:58:52, 14.19s/it]

 35%|███▍      | 1082/3106 [4:11:33<7:37:48, 13.57s/it]
{'loss': 1.0709, 'grad_norm': 0.23988509593085902, 'learning_rate': 0.0001514382289619305, 'epoch': 0.35}

 35%|███▍      | 1083/3106 [4:11:44<7:14:15, 12.88s/it]


 35%|███▍      | 1085/3106 [4:12:13<7:48:30, 13.91s/it]

 35%|███▍      | 1086/3106 [4:12:33<8:53:22, 15.84s/it]
{'loss': 0.8924, 'grad_norm': 0.22364567015566364, 'learning_rate': 0.00015107999914560618, 'epoch': 0.35}


 35%|███▌      | 1088/3106 [4:12:59<8:07:51, 14.51s/it]
{'loss': 0.9268, 'grad_norm': 0.2489385909462772, 'learning_rate': 0.0001509005504273771, 'epoch': 0.35}


 35%|███▌      | 1090/3106 [4:13:27<7:57:16, 14.20s/it]

 35%|███▌      | 1091/3106 [4:13:42<8:05:27, 14.46s/it]
{'loss': 0.9329, 'grad_norm': 0.24641454826052572, 'learning_rate': 0.00015063096228336265, 'epoch': 0.35}


 35%|███▌      | 1093/3106 [4:14:10<7:52:53, 14.10s/it]

 35%|███▌      | 1094/3106 [4:14:26<8:03:10, 14.41s/it]

 35%|███▌      | 1095/3106 [4:14:39<7:49:09, 14.00s/it]

 35%|███▌      | 1096/3106 [4:14:53<7:51:47, 14.08s/it]

 35%|███▌      | 1097/3106 [4:15:06<7:37:11, 13.65s/it]

 35%|███▌      | 1098/3106 [4:15:17<7:13:45, 12.96s/it]
{'loss': 1.1093, 'grad_norm': 0.2716041313007358, 'learning_rate': 0.00015000000000000001, 'epoch': 0.35}


 35%|███▌      | 1100/3106 [4:15:39<6:42:57, 12.05s/it]
{'loss': 0.9239, 'grad_norm': 0.2377580284119149, 'learning_rate': 0.00014981923403366095, 'epoch': 0.35}


 35%|███▌      | 1102/3106 [4:16:11<7:36:36, 13.67s/it]

 36%|███▌      | 1103/3106 [4:16:23<7:19:43, 13.17s/it]
{'loss': 0.9256, 'grad_norm': 0.2561970878751867, 'learning_rate': 0.00014954767884201186, 'epoch': 0.36}


 36%|███▌      | 1105/3106 [4:16:57<8:17:18, 14.91s/it]

 36%|███▌      | 1106/3106 [4:17:09<7:43:47, 13.91s/it]

 36%|███▌      | 1107/3106 [4:17:21<7:22:18, 13.28s/it]

 36%|███▌      | 1108/3106 [4:17:41<8:32:10, 15.38s/it]
{'loss': 0.941, 'grad_norm': 0.23397856074686915, 'learning_rate': 0.0001490940101114961, 'epoch': 0.36}

 36%|███▌      | 1109/3106 [4:17:54<8:10:51, 14.75s/it]

 36%|███▌      | 1110/3106 [4:18:12<8:42:44, 15.71s/it]

 36%|███▌      | 1111/3106 [4:18:26<8:22:42, 15.12s/it]

 36%|███▌      | 1112/3106 [4:18:38<7:52:41, 14.22s/it]

 36%|███▌      | 1113/3106 [4:18:50<7:30:21, 13.56s/it]

 36%|███▌      | 1114/3106 [4:19:06<7:57:06, 14.37s/it]


 36%|███▌      | 1116/3106 [4:19:36<8:05:27, 14.64s/it]
{'loss': 0.971, 'grad_norm': 0.24862061618663797, 'learning_rate': 0.00014836536800269287, 'epoch': 0.36}


 36%|███▌      | 1118/3106 [4:20:03<7:42:46, 13.97s/it]

 36%|███▌      | 1119/3106 [4:20:15<7:27:25, 13.51s/it]

 36%|███▌      | 1120/3106 [4:20:31<7:48:30, 14.15s/it]

 36%|███▌      | 1121/3106 [4:20:45<7:47:35, 14.13s/it]

 36%|███▌      | 1122/3106 [4:20:58<7:33:20, 13.71s/it]
{'loss': 1.0798, 'grad_norm': 0.22841233401717292, 'learning_rate': 0.00014781667374569747, 'epoch': 0.36}


 36%|███▌      | 1124/3106 [4:21:23<7:16:01, 13.20s/it]

 36%|███▌      | 1125/3106 [4:21:36<7:11:59, 13.08s/it]

 36%|███▋      | 1126/3106 [4:21:49<7:11:11, 13.07s/it]

 36%|███▋      | 1127/3106 [4:22:05<7:43:20, 14.05s/it]

 36%|███▋      | 1128/3106 [4:22:19<7:43:58, 14.07s/it]
{'loss': 1.0366, 'grad_norm': 0.22642736568766775, 'learning_rate': 0.0001472661067798823, 'epoch': 0.36}

 36%|███▋      | 1129/3106 [4:22:32<7:32:10, 13.72s/it]

 36%|███▋      | 1130/3106 [4:22:44<7:13:40, 13.17s/it]


 36%|███▋      | 1132/3106 [4:23:09<7:05:07, 12.92s/it]

 36%|███▋      | 1133/3106 [4:23:24<7:19:34, 13.37s/it]

 37%|███▋      | 1134/3106 [4:23:40<7:45:15, 14.16s/it]
{'loss': 0.9131, 'grad_norm': 0.2249519758810578, 'learning_rate': 0.00014671368866784338, 'epoch': 0.37}


 37%|███▋      | 1136/3106 [4:24:07<7:33:01, 13.80s/it]

 37%|███▋      | 1137/3106 [4:24:19<7:17:48, 13.34s/it]

 37%|███▋      | 1138/3106 [4:24:32<7:11:59, 13.17s/it]

 37%|███▋      | 1139/3106 [4:24:49<7:49:43, 14.33s/it]

 37%|███▋      | 1140/3106 [4:25:02<7:34:06, 13.86s/it]

 37%|███▋      | 1141/3106 [4:25:15<7:29:43, 13.73s/it]

 37%|███▋      | 1142/3106 [4:25:30<7:34:46, 13.89s/it]
{'loss': 0.8911, 'grad_norm': 0.24364856857714018, 'learning_rate': 0.00014597428902865972, 'epoch': 0.37}


 37%|███▋      | 1144/3106 [4:25:56<7:25:55, 13.64s/it]

 37%|███▋      | 1145/3106 [4:26:10<7:29:53, 13.77s/it]
{'loss': 1.0095, 'grad_norm': 0.2410972703526153, 'learning_rate': 0.0001456961861403566, 'epoch': 0.37}


 37%|███▋      | 1147/3106 [4:26:35<7:10:26, 13.18s/it]

 37%|███▋      | 1148/3106 [4:26:49<7:21:41, 13.54s/it]

 37%|███▋      | 1149/3106 [4:27:03<7:23:41, 13.60s/it]

 37%|███▋      | 1150/3106 [4:27:20<7:51:12, 14.45s/it]

 37%|███▋      | 1151/3106 [4:27:31<7:25:16, 13.67s/it]

 37%|███▋      | 1152/3106 [4:27:46<7:31:38, 13.87s/it]

 37%|███▋      | 1153/3106 [4:28:03<8:08:37, 15.01s/it]

 37%|███▋      | 1154/3106 [4:28:17<7:56:21, 14.64s/it]
{'loss': 0.9727, 'grad_norm': 0.26565621439534387, 'learning_rate': 0.00014485920389053784, 'epoch': 0.37}


 37%|███▋      | 1156/3106 [4:28:44<7:31:00, 13.88s/it]

 37%|███▋      | 1157/3106 [4:28:58<7:34:23, 13.99s/it]

 37%|███▋      | 1158/3106 [4:29:12<7:35:52, 14.04s/it]

 37%|███▋      | 1159/3106 [4:29:26<7:30:13, 13.87s/it]
{'loss': 0.9812, 'grad_norm': 0.23484655882368036, 'learning_rate': 0.0001443925009438538, 'epoch': 0.37}


 37%|███▋      | 1161/3106 [4:29:52<7:19:34, 13.56s/it]

 37%|███▋      | 1162/3106 [4:30:06<7:23:32, 13.69s/it]

 37%|███▋      | 1163/3106 [4:30:24<8:07:09, 15.04s/it]

 37%|███▋      | 1164/3106 [4:30:36<7:38:02, 14.15s/it]

 38%|███▊      | 1165/3106 [4:30:50<7:28:47, 13.87s/it]

 38%|███▊      | 1166/3106 [4:31:12<8:49:16, 16.37s/it]
[2024-05-29 01:24:14,606] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9331, 'grad_norm': 0.2475147057659067, 'learning_rate': 0.000143737091295451, 'epoch': 0.38}


 38%|███▊      | 1168/3106 [4:31:38<7:51:26, 14.60s/it]
{'loss': 1.0657, 'grad_norm': 0.2518392780729742, 'learning_rate': 0.00014354940163173485, 'epoch': 0.38}

 38%|███▊      | 1169/3106 [4:31:53<7:55:48, 14.74s/it]

 38%|███▊      | 1170/3106 [4:32:09<8:04:37, 15.02s/it]

 38%|███▊      | 1171/3106 [4:32:21<7:34:13, 14.08s/it]


 38%|███▊      | 1173/3106 [4:32:50<7:48:23, 14.54s/it]

 38%|███▊      | 1174/3106 [4:33:06<7:59:33, 14.89s/it]

 38%|███▊      | 1175/3106 [4:33:20<7:50:10, 14.61s/it]

 38%|███▊      | 1176/3106 [4:33:32<7:26:32, 13.88s/it]

 38%|███▊      | 1177/3106 [4:33:46<7:29:36, 13.98s/it]

 38%|███▊      | 1178/3106 [4:33:58<7:12:40, 13.47s/it]

 38%|███▊      | 1179/3106 [4:34:12<7:15:40, 13.57s/it]
{'loss': 0.9027, 'grad_norm': 0.27117435186757194, 'learning_rate': 0.00014251374293283554, 'epoch': 0.38}

 38%|███▊      | 1180/3106 [4:34:27<7:27:35, 13.94s/it]


 38%|███▊      | 1182/3106 [4:35:01<8:15:33, 15.45s/it]
{'loss': 0.9836, 'grad_norm': 0.23823000348189047, 'learning_rate': 0.0001422303135508798, 'epoch': 0.38}

 38%|███▊      | 1183/3106 [4:35:15<8:04:02, 15.10s/it]


 38%|███▊      | 1185/3106 [4:35:42<7:44:58, 14.52s/it]
{'loss': 0.9202, 'grad_norm': 0.2212070730836574, 'learning_rate': 0.0001419464706872448, 'epoch': 0.38}

 38%|███▊      | 1186/3106 [4:35:55<7:28:25, 14.01s/it]


 38%|███▊      | 1188/3106 [4:36:22<7:17:10, 13.68s/it]
{'loss': 0.8719, 'grad_norm': 0.238164577394997, 'learning_rate': 0.0001416622171210675, 'epoch': 0.38}


 38%|███▊      | 1190/3106 [4:36:50<7:14:47, 13.62s/it]
{'loss': 0.9533, 'grad_norm': 0.2757651840477594, 'learning_rate': 0.00014147248794977126, 'epoch': 0.38}


 38%|███▊      | 1192/3106 [4:37:28<8:29:06, 15.96s/it]

 38%|███▊      | 1193/3106 [4:37:42<8:12:54, 15.46s/it]

 38%|███▊      | 1194/3106 [4:37:57<8:07:14, 15.29s/it]

 38%|███▊      | 1195/3106 [4:38:09<7:34:19, 14.26s/it]
{'loss': 1.0417, 'grad_norm': 0.25136923098007496, 'learning_rate': 0.0001409973772646982, 'epoch': 0.38}


 39%|███▊      | 1197/3106 [4:38:37<7:32:11, 14.21s/it]

 39%|███▊      | 1198/3106 [4:38:49<7:12:22, 13.60s/it]

 39%|███▊      | 1199/3106 [4:39:04<7:27:22, 14.08s/it]

 39%|███▊      | 1200/3106 [4:39:16<7:06:02, 13.41s/it]
 39%|███▊      | 1200/3106 [4:39:16<7:06:02, 13.41s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.8906, 'grad_norm': 0.21490947461342608, 'learning_rate': 0.00014042577374783833, 'epoch': 0.39}
 39%|███▊      | 1201/3106 [4:39:50<10:18:43, 19.49s/it]


 39%|███▊      | 1203/3106 [4:40:14<8:21:25, 15.81s/it]

 39%|███▉      | 1204/3106 [4:40:28<8:06:06, 15.33s/it]
{'loss': 0.913, 'grad_norm': 0.24698537621396843, 'learning_rate': 0.0001401393768694292, 'epoch': 0.39}


 39%|███▉      | 1206/3106 [4:40:54<7:25:32, 14.07s/it]

 39%|███▉      | 1207/3106 [4:41:10<7:42:25, 14.61s/it]

 39%|███▉      | 1208/3106 [4:41:26<7:57:49, 15.10s/it]

 39%|███▉      | 1209/3106 [4:41:40<7:46:16, 14.75s/it]

 39%|███▉      | 1210/3106 [4:41:53<7:24:19, 14.06s/it]
{'loss': 1.0068, 'grad_norm': 0.2776031554794988, 'learning_rate': 0.00013956540689334285, 'epoch': 0.39}


 39%|███▉      | 1212/3106 [4:42:18<7:02:33, 13.39s/it]

 39%|███▉      | 1213/3106 [4:42:30<6:49:16, 12.97s/it]
{'loss': 1.0109, 'grad_norm': 0.2520185228729046, 'learning_rate': 0.0001392778394154693, 'epoch': 0.39}

 39%|███▉      | 1214/3106 [4:42:43<6:50:38, 13.02s/it]


 39%|███▉      | 1216/3106 [4:43:08<6:43:15, 12.80s/it]

 39%|███▉      | 1217/3106 [4:43:21<6:43:43, 12.82s/it]

 39%|███▉      | 1218/3106 [4:43:32<6:27:47, 12.32s/it]

 39%|███▉      | 1219/3106 [4:43:51<7:28:55, 14.27s/it]

 39%|███▉      | 1220/3106 [4:44:03<7:07:56, 13.61s/it]
{'loss': 0.9926, 'grad_norm': 0.23894432030306156, 'learning_rate': 0.00013860535794298643, 'epoch': 0.39}

 39%|███▉      | 1221/3106 [4:44:20<7:33:18, 14.43s/it]


 39%|███▉      | 1223/3106 [4:44:45<7:04:56, 13.54s/it]

 39%|███▉      | 1224/3106 [4:44:57<6:46:04, 12.95s/it]
{'loss': 1.0799, 'grad_norm': 0.25339552671506943, 'learning_rate': 0.0001382201565414374, 'epoch': 0.39}


 39%|███▉      | 1226/3106 [4:45:21<6:39:10, 12.74s/it]

 40%|███▉      | 1227/3106 [4:45:33<6:27:33, 12.38s/it]

 40%|███▉      | 1228/3106 [4:45:49<7:02:56, 13.51s/it]

 40%|███▉      | 1229/3106 [4:46:04<7:12:06, 13.81s/it]

 40%|███▉      | 1230/3106 [4:46:18<7:21:42, 14.13s/it]

 40%|███▉      | 1231/3106 [4:46:31<7:03:21, 13.55s/it]

 40%|███▉      | 1232/3106 [4:46:42<6:47:06, 13.03s/it]

 40%|███▉      | 1233/3106 [4:46:59<7:17:08, 14.00s/it]

 40%|███▉      | 1234/3106 [4:47:15<7:39:29, 14.73s/it]

 40%|███▉      | 1235/3106 [4:47:28<7:18:29, 14.06s/it]

 40%|███▉      | 1236/3106 [4:47:41<7:07:35, 13.72s/it]

 40%|███▉      | 1237/3106 [4:47:53<6:51:59, 13.23s/it]

 40%|███▉      | 1238/3106 [4:48:05<6:43:29, 12.96s/it]

 40%|███▉      | 1239/3106 [4:48:17<6:38:47, 12.82s/it]
{'loss': 0.9606, 'grad_norm': 0.24181487599056034, 'learning_rate': 0.00013676978104965623, 'epoch': 0.4}


 40%|███▉      | 1241/3106 [4:48:43<6:40:42, 12.89s/it]

 40%|███▉      | 1242/3106 [4:48:56<6:34:41, 12.70s/it]

 40%|████      | 1243/3106 [4:49:09<6:40:55, 12.91s/it]

 40%|████      | 1244/3106 [4:49:21<6:32:45, 12.66s/it]

 40%|████      | 1245/3106 [4:49:33<6:30:42, 12.60s/it]

 40%|████      | 1246/3106 [4:49:51<7:11:54, 13.93s/it]
{'loss': 0.793, 'grad_norm': 0.23568141053549038, 'learning_rate': 0.00013608983738590413, 'epoch': 0.4}


 40%|████      | 1248/3106 [4:50:17<7:02:50, 13.65s/it]

 40%|████      | 1249/3106 [4:50:31<7:08:30, 13.85s/it]
{'loss': 1.106, 'grad_norm': 0.23972052575668007, 'learning_rate': 0.00013579784191095022, 'epoch': 0.4}


 40%|████      | 1251/3106 [4:50:57<6:50:37, 13.28s/it]

 40%|████      | 1252/3106 [4:51:09<6:43:21, 13.05s/it]
{'loss': 1.0542, 'grad_norm': 0.25689319384270287, 'learning_rate': 0.00013550549593535963, 'epoch': 0.4}


 40%|████      | 1254/3106 [4:51:35<6:43:17, 13.07s/it]

 40%|████      | 1255/3106 [4:51:51<7:04:43, 13.77s/it]
{'loss': 1.0815, 'grad_norm': 0.24169890575221017, 'learning_rate': 0.0001352128023215242, 'epoch': 0.4}


 40%|████      | 1257/3106 [4:52:19<7:10:33, 13.97s/it]

 41%|████      | 1258/3106 [4:52:31<6:52:15, 13.38s/it]

 41%|████      | 1259/3106 [4:52:45<6:58:31, 13.60s/it]

 41%|████      | 1260/3106 [4:52:57<6:44:04, 13.13s/it]

 41%|████      | 1261/3106 [4:53:09<6:30:48, 12.71s/it]
{'loss': 1.1589, 'grad_norm': 0.25490158134780044, 'learning_rate': 0.00013462638364567688, 'epoch': 0.41}


 41%|████      | 1263/3106 [4:53:35<6:38:49, 12.98s/it]

 41%|████      | 1264/3106 [4:53:52<7:16:26, 14.22s/it]

 41%|████      | 1265/3106 [4:54:05<7:09:31, 14.00s/it]
{'loss': 0.8456, 'grad_norm': 0.22648960848899805, 'learning_rate': 0.00013423468304204274, 'epoch': 0.41}


 41%|████      | 1267/3106 [4:54:30<6:41:18, 13.09s/it]

 41%|████      | 1268/3106 [4:54:47<7:17:20, 14.28s/it]
{'loss': 0.9977, 'grad_norm': 0.23470652982938583, 'learning_rate': 0.00013394051615480516, 'epoch': 0.41}


 41%|████      | 1270/3106 [4:55:11<6:44:41, 13.23s/it]
{'loss': 0.9961, 'grad_norm': 0.27220353786198315, 'learning_rate': 0.00013374422009907984, 'epoch': 0.41}


 41%|████      | 1272/3106 [4:55:37<6:39:57, 13.08s/it]

 41%|████      | 1273/3106 [4:55:49<6:28:16, 12.71s/it]
{'loss': 1.0925, 'grad_norm': 0.2457916780125328, 'learning_rate': 0.00013344950095464872, 'epoch': 0.41}


 41%|████      | 1275/3106 [4:56:16<6:34:59, 12.94s/it]
{'loss': 0.8407, 'grad_norm': 0.25548954803933027, 'learning_rate': 0.00013325283939800934, 'epoch': 0.41}


 41%|████      | 1277/3106 [4:56:45<7:09:31, 14.09s/it]

 41%|████      | 1278/3106 [4:56:58<6:54:17, 13.60s/it]

 41%|████      | 1279/3106 [4:57:12<6:58:40, 13.75s/it]

 41%|████      | 1280/3106 [4:57:27<7:13:44, 14.25s/it]
{'loss': 0.8927, 'grad_norm': 0.23543581490576612, 'learning_rate': 0.0001327605543031532, 'epoch': 0.41}


 41%|████▏     | 1282/3106 [4:57:56<7:11:26, 14.19s/it]

 41%|████▏     | 1283/3106 [4:58:09<7:00:52, 13.85s/it]

 41%|████▏     | 1284/3106 [4:58:24<7:08:29, 14.11s/it]

 41%|████▏     | 1285/3106 [4:58:35<6:42:37, 13.27s/it]
{'loss': 1.1061, 'grad_norm': 0.2685426334827614, 'learning_rate': 0.00013226737820343064, 'epoch': 0.41}

 41%|████▏     | 1286/3106 [4:58:55<7:42:34, 15.25s/it]


 41%|████▏     | 1288/3106 [4:59:22<7:18:19, 14.47s/it]

 42%|████▏     | 1289/3106 [4:59:33<6:49:06, 13.51s/it]

 42%|████▏     | 1290/3106 [4:59:47<6:53:41, 13.67s/it]
{'loss': 1.0589, 'grad_norm': 0.24189135761345537, 'learning_rate': 0.00013177332451199403, 'epoch': 0.42}

 42%|████▏     | 1291/3106 [5:00:01<6:51:54, 13.62s/it]


 42%|████▏     | 1293/3106 [5:00:32<7:15:58, 14.43s/it]
{'loss': 1.0245, 'grad_norm': 0.23359855966348791, 'learning_rate': 0.00013147647664192788, 'epoch': 0.42}


 42%|████▏     | 1295/3106 [5:00:57<6:46:53, 13.48s/it]
{'loss': 0.9879, 'grad_norm': 0.2466750651824571, 'learning_rate': 0.0001312784066658639, 'epoch': 0.42}

 42%|████▏     | 1296/3106 [5:01:09<6:30:01, 12.93s/it]


 42%|████▏     | 1298/3106 [5:01:38<6:46:48, 13.50s/it]
{'loss': 1.0353, 'grad_norm': 0.25456832600179363, 'learning_rate': 0.00013098104676254396, 'epoch': 0.42}


 42%|████▏     | 1300/3106 [5:02:04<6:43:32, 13.41s/it]

 42%|████▏     | 1301/3106 [5:02:18<6:49:22, 13.61s/it]

 42%|████▏     | 1302/3106 [5:02:31<6:49:27, 13.62s/it]

 42%|████▏     | 1303/3106 [5:02:45<6:46:05, 13.51s/it]
{'loss': 0.9393, 'grad_norm': 0.26980152574298627, 'learning_rate': 0.00013048477427643322, 'epoch': 0.42}

 42%|████▏     | 1304/3106 [5:02:59<6:55:04, 13.82s/it]

 42%|████▏     | 1305/3106 [5:03:13<6:54:04, 13.79s/it]


 42%|████▏     | 1307/3106 [5:03:46<7:39:06, 15.31s/it]
{'loss': 1.0235, 'grad_norm': 0.2431129765235929, 'learning_rate': 0.00013008715868017073, 'epoch': 0.42}


 42%|████▏     | 1309/3106 [5:04:16<7:23:27, 14.81s/it]

 42%|████▏     | 1310/3106 [5:04:28<6:57:37, 13.95s/it]

 42%|████▏     | 1311/3106 [5:04:46<7:34:51, 15.20s/it]
{'loss': 1.0173, 'grad_norm': 0.2499913386172063, 'learning_rate': 0.0001296890193745439, 'epoch': 0.42}

 42%|████▏     | 1312/3106 [5:04:59<7:18:48, 14.68s/it]


 42%|████▏     | 1314/3106 [5:05:24<6:42:45, 13.49s/it]

 42%|████▏     | 1315/3106 [5:05:36<6:22:51, 12.83s/it]

 42%|████▏     | 1316/3106 [5:05:48<6:22:54, 12.83s/it]

 42%|████▏     | 1317/3106 [5:06:02<6:32:27, 13.16s/it]
{'loss': 0.9934, 'grad_norm': 0.24309271739798696, 'learning_rate': 0.00012909084362326668, 'epoch': 0.42}

 42%|████▏     | 1318/3106 [5:06:15<6:29:41, 13.08s/it]


 42%|████▏     | 1320/3106 [5:06:39<6:06:18, 12.31s/it]
{'loss': 1.0516, 'grad_norm': 0.26593183172481294, 'learning_rate': 0.00012879132703521248, 'epoch': 0.42}


 43%|████▎     | 1322/3106 [5:07:05<6:12:48, 12.54s/it]
{'loss': 1.0936, 'grad_norm': 0.26932920581720476, 'learning_rate': 0.00012859149251810822, 'epoch': 0.43}

 43%|████▎     | 1323/3106 [5:07:17<6:15:35, 12.64s/it]

 43%|████▎     | 1324/3106 [5:07:33<6:44:52, 13.63s/it]

 43%|████▎     | 1325/3106 [5:07:45<6:27:28, 13.05s/it]

 43%|████▎     | 1326/3106 [5:07:59<6:35:54, 13.35s/it]


 43%|████▎     | 1328/3106 [5:08:25<6:29:54, 13.16s/it]
{'loss': 0.9863, 'grad_norm': 0.23539144576327178, 'learning_rate': 0.0001279912459343085, 'epoch': 0.43}

 43%|████▎     | 1329/3106 [5:08:39<6:41:50, 13.57s/it]


 43%|████▎     | 1331/3106 [5:09:05<6:25:42, 13.04s/it]

 43%|████▎     | 1332/3106 [5:09:20<6:42:03, 13.60s/it]

 43%|████▎     | 1333/3106 [5:09:36<7:06:33, 14.44s/it]
{'loss': 0.9682, 'grad_norm': 0.23212855456435047, 'learning_rate': 0.00012749020202888485, 'epoch': 0.43}


 43%|████▎     | 1335/3106 [5:10:10<7:43:46, 15.71s/it]

 43%|████▎     | 1336/3106 [5:10:23<7:14:31, 14.73s/it]
{'loss': 0.9688, 'grad_norm': 0.23936029638172235, 'learning_rate': 0.00012718921593367875, 'epoch': 0.43}


 43%|████▎     | 1338/3106 [5:10:47<6:38:30, 13.52s/it]

 43%|████▎     | 1339/3106 [5:11:01<6:44:05, 13.72s/it]

 43%|████▎     | 1340/3106 [5:11:16<6:54:00, 14.07s/it]

 43%|████▎     | 1341/3106 [5:11:31<6:57:38, 14.20s/it]

 43%|████▎     | 1342/3106 [5:11:46<7:12:13, 14.70s/it]

 43%|████▎     | 1343/3106 [5:12:01<7:11:49, 14.70s/it]
{'loss': 0.9639, 'grad_norm': 0.23857482344962094, 'learning_rate': 0.00012648588487197842, 'epoch': 0.43}


 43%|████▎     | 1345/3106 [5:12:27<6:41:57, 13.70s/it]

 43%|████▎     | 1346/3106 [5:12:38<6:19:50, 12.95s/it]

 43%|████▎     | 1347/3106 [5:12:52<6:28:53, 13.27s/it]
{'loss': 0.9046, 'grad_norm': 0.2488892019344542, 'learning_rate': 0.00012608334509398752, 'epoch': 0.43}


 43%|████▎     | 1349/3106 [5:13:21<6:44:27, 13.81s/it]

 43%|████▎     | 1350/3106 [5:13:32<6:25:06, 13.16s/it]

 43%|████▎     | 1351/3106 [5:13:46<6:32:17, 13.41s/it]

 44%|████▎     | 1352/3106 [5:14:05<7:15:24, 14.89s/it]

 44%|████▎     | 1353/3106 [5:14:18<7:03:12, 14.48s/it]
{'loss': 0.9645, 'grad_norm': 0.26626936923600597, 'learning_rate': 0.00012547868633624857, 'epoch': 0.44}


 44%|████▎     | 1355/3106 [5:14:53<7:58:32, 16.40s/it]
{'loss': 0.9547, 'grad_norm': 0.23948424594689155, 'learning_rate': 0.00012527691050062743, 'epoch': 0.44}


 44%|████▎     | 1357/3106 [5:15:25<7:52:28, 16.21s/it]

 44%|████▎     | 1358/3106 [5:15:38<7:23:26, 15.22s/it]
{'loss': 1.0115, 'grad_norm': 0.22964193201290578, 'learning_rate': 0.00012497404078076397, 'epoch': 0.44}


 44%|████▍     | 1360/3106 [5:16:04<6:56:02, 14.30s/it]

 44%|████▍     | 1361/3106 [5:16:17<6:42:55, 13.85s/it]
{'loss': 1.0268, 'grad_norm': 0.2941045703453935, 'learning_rate': 0.0001246709265373, 'epoch': 0.44}


 44%|████▍     | 1363/3106 [5:16:47<6:54:42, 14.28s/it]
{'loss': 0.9174, 'grad_norm': 0.22994892468000883, 'learning_rate': 0.00012446871599404094, 'epoch': 0.44}


 44%|████▍     | 1365/3106 [5:17:09<6:10:05, 12.75s/it]
{'loss': 0.9449, 'grad_norm': 0.2572970232864347, 'learning_rate': 0.00012426639897255166, 'epoch': 0.44}


 44%|████▍     | 1367/3106 [5:17:41<7:01:02, 14.53s/it]
{'loss': 1.0321, 'grad_norm': 0.2482371555121275, 'learning_rate': 0.00012406397635323616, 'epoch': 0.44}


 44%|████▍     | 1369/3106 [5:18:09<6:55:52, 14.37s/it]
{'loss': 1.0017, 'grad_norm': 0.23765128966870455, 'learning_rate': 0.00012386144901695818, 'epoch': 0.44}

 44%|████▍     | 1370/3106 [5:18:24<6:57:26, 14.43s/it]


 44%|████▍     | 1372/3106 [5:18:51<6:44:21, 13.99s/it]
{'loss': 1.0046, 'grad_norm': 0.24625493474256446, 'learning_rate': 0.0001235574635962462, 'epoch': 0.44}


 44%|████▍     | 1374/3106 [5:19:23<7:18:18, 15.18s/it]
{'loss': 0.924, 'grad_norm': 0.25661050340843683, 'learning_rate': 0.00012335467832432135, 'epoch': 0.44}

 44%|████▍     | 1375/3106 [5:19:40<7:37:59, 15.88s/it]

 44%|████▍     | 1376/3106 [5:19:54<7:24:17, 15.41s/it]

 44%|████▍     | 1377/3106 [5:20:08<7:09:15, 14.90s/it]


 44%|████▍     | 1379/3106 [5:20:33<6:32:27, 13.63s/it]

 44%|████▍     | 1380/3106 [5:20:45<6:20:06, 13.21s/it]

 44%|████▍     | 1381/3106 [5:21:00<6:32:49, 13.66s/it]

 44%|████▍     | 1382/3106 [5:21:11<6:15:40, 13.07s/it]

 45%|████▍     | 1383/3106 [5:21:24<6:07:53, 12.81s/it]

 45%|████▍     | 1384/3106 [5:21:37<6:11:44, 12.95s/it]

 45%|████▍     | 1385/3106 [5:21:50<6:09:55, 12.90s/it]
{'loss': 0.9712, 'grad_norm': 0.24223964011205773, 'learning_rate': 0.00012223756636832472, 'epoch': 0.45}

 45%|████▍     | 1386/3106 [5:22:04<6:22:17, 13.34s/it]


 45%|████▍     | 1388/3106 [5:22:31<6:31:12, 13.66s/it]

 45%|████▍     | 1389/3106 [5:22:44<6:20:03, 13.28s/it]

 45%|████▍     | 1390/3106 [5:22:57<6:19:24, 13.27s/it]
{'loss': 0.7921, 'grad_norm': 0.2412085828292152, 'learning_rate': 0.00012172881167238514, 'epoch': 0.45}


 45%|████▍     | 1392/3106 [5:23:23<6:20:02, 13.30s/it]

 45%|████▍     | 1393/3106 [5:23:37<6:22:03, 13.38s/it]
{'loss': 1.0827, 'grad_norm': 0.25137379115297975, 'learning_rate': 0.00012142327430339778, 'epoch': 0.45}


 45%|████▍     | 1395/3106 [5:24:00<5:55:33, 12.47s/it]
{'loss': 1.0106, 'grad_norm': 0.2683886493505585, 'learning_rate': 0.00012121946600729523, 'epoch': 0.45}


 45%|████▍     | 1397/3106 [5:24:32<6:44:16, 14.19s/it]

 45%|████▌     | 1398/3106 [5:24:45<6:33:26, 13.82s/it]
{'loss': 1.0959, 'grad_norm': 0.27693343670254483, 'learning_rate': 0.00012091358070520813, 'epoch': 0.45}


 45%|████▌     | 1400/3106 [5:25:15<6:44:11, 14.22s/it]

 45%|████▌     | 1401/3106 [5:25:28<6:29:26, 13.70s/it]

 45%|████▌     | 1402/3106 [5:25:39<6:11:24, 13.08s/it]

 45%|████▌     | 1403/3106 [5:25:51<6:01:39, 12.74s/it]
{'loss': 1.0542, 'grad_norm': 0.24673507220642366, 'learning_rate': 0.0001204033183101047, 'epoch': 0.45}


 45%|████▌     | 1405/3106 [5:26:22<6:41:49, 14.17s/it]

 45%|████▌     | 1406/3106 [5:26:35<6:33:07, 13.88s/it]

 45%|████▌     | 1407/3106 [5:26:47<6:15:22, 13.26s/it]
{'loss': 0.9503, 'grad_norm': 0.22519390293220745, 'learning_rate': 0.00011999470818565354, 'epoch': 0.45}


 45%|████▌     | 1409/3106 [5:27:13<6:14:37, 13.25s/it]
{'loss': 0.8283, 'grad_norm': 0.23053113014131688, 'learning_rate': 0.00011979027216514329, 'epoch': 0.45}

 45%|████▌     | 1410/3106 [5:27:24<5:58:02, 12.67s/it]

 45%|████▌     | 1411/3106 [5:27:36<5:50:25, 12.40s/it]

 45%|████▌     | 1412/3106 [5:27:52<6:23:07, 13.57s/it]


 46%|████▌     | 1414/3106 [5:28:20<6:29:22, 13.81s/it]
{'loss': 1.1501, 'grad_norm': 0.21752586867174173, 'learning_rate': 0.00011927880728810849, 'epoch': 0.46}


 46%|████▌     | 1416/3106 [5:28:44<6:03:39, 12.91s/it]
{'loss': 0.9366, 'grad_norm': 0.25307303500596173, 'learning_rate': 0.00011907407374396973, 'epoch': 0.46}


 46%|████▌     | 1418/3106 [5:29:14<6:22:30, 13.60s/it]
{'loss': 1.0293, 'grad_norm': 0.2700046643405981, 'learning_rate': 0.00011886925719696242, 'epoch': 0.46}

 46%|████▌     | 1419/3106 [5:29:28<6:21:03, 13.55s/it]

 46%|████▌     | 1420/3106 [5:29:41<6:19:27, 13.50s/it]


 46%|████▌     | 1422/3106 [5:30:06<6:06:08, 13.05s/it]

 46%|████▌     | 1423/3106 [5:30:20<6:11:55, 13.26s/it]
{'loss': 0.9352, 'grad_norm': 0.2639175151424598, 'learning_rate': 0.0001183568585418049, 'epoch': 0.46}


 46%|████▌     | 1425/3106 [5:30:46<6:06:36, 13.09s/it]
{'loss': 0.9154, 'grad_norm': 0.2824983792293643, 'learning_rate': 0.00011815175850593158, 'epoch': 0.46}

 46%|████▌     | 1426/3106 [5:31:01<6:20:08, 13.58s/it]

 46%|████▌     | 1427/3106 [5:31:13<6:11:44, 13.28s/it]

 46%|████▌     | 1428/3106 [5:31:25<6:02:02, 12.95s/it]


 46%|████▌     | 1430/3106 [5:31:56<6:46:22, 14.55s/it]

 46%|████▌     | 1431/3106 [5:32:08<6:23:50, 13.75s/it]

 46%|████▌     | 1432/3106 [5:32:22<6:25:12, 13.81s/it]

 46%|████▌     | 1433/3106 [5:32:36<6:27:33, 13.90s/it]
{'loss': 0.9313, 'grad_norm': 0.2567093030711767, 'learning_rate': 0.0001173305773995653, 'epoch': 0.46}

 46%|████▌     | 1434/3106 [5:32:51<6:35:35, 14.20s/it]


 46%|████▌     | 1436/3106 [5:33:16<6:15:16, 13.48s/it]
{'loss': 0.9586, 'grad_norm': 0.24884829648134832, 'learning_rate': 0.00011702232032231212, 'epoch': 0.46}


 46%|████▋     | 1438/3106 [5:33:46<6:39:34, 14.37s/it]
{'loss': 0.9566, 'grad_norm': 0.25479654888493053, 'learning_rate': 0.00011681672282475495, 'epoch': 0.46}

 46%|████▋     | 1439/3106 [5:33:59<6:24:11, 13.83s/it]

 46%|████▋     | 1440/3106 [5:34:11<6:10:30, 13.34s/it]


 46%|████▋     | 1442/3106 [5:34:39<6:14:56, 13.52s/it]
{'loss': 0.8926, 'grad_norm': 0.23494769876405444, 'learning_rate': 0.00011640530918534361, 'epoch': 0.46}

 46%|████▋     | 1443/3106 [5:34:51<6:04:22, 13.15s/it]


 47%|████▋     | 1445/3106 [5:35:20<6:27:29, 14.00s/it]

 47%|████▋     | 1446/3106 [5:35:36<6:40:20, 14.47s/it]

 47%|████▋     | 1447/3106 [5:35:52<6:54:35, 14.99s/it]

 47%|████▋     | 1448/3106 [5:36:08<7:02:13, 15.28s/it]
{'loss': 0.9879, 'grad_norm': 0.25309207120842625, 'learning_rate': 0.00011578765554514773, 'epoch': 0.47}


 47%|████▋     | 1450/3106 [5:36:37<6:50:36, 14.88s/it]
{'loss': 0.9219, 'grad_norm': 0.24293939118414581, 'learning_rate': 0.00011558163240020207, 'epoch': 0.47}

 47%|████▋     | 1451/3106 [5:36:54<7:10:08, 15.59s/it]


 47%|████▋     | 1453/3106 [5:37:19<6:24:05, 13.94s/it]

 47%|████▋     | 1454/3106 [5:37:30<6:05:49, 13.29s/it]

 47%|████▋     | 1455/3106 [5:37:44<6:11:05, 13.49s/it]

 47%|████▋     | 1456/3106 [5:37:58<6:15:01, 13.64s/it]
{'loss': 0.9078, 'grad_norm': 0.2323815488870799, 'learning_rate': 0.00011496315972214075, 'epoch': 0.47}

 47%|████▋     | 1457/3106 [5:38:10<5:58:27, 13.04s/it]


 47%|████▋     | 1459/3106 [5:38:34<5:48:08, 12.68s/it]

 47%|████▋     | 1460/3106 [5:38:52<6:30:33, 14.24s/it]
{'loss': 0.9487, 'grad_norm': 0.23285502365083308, 'learning_rate': 0.00011455051753929669, 'epoch': 0.47}


 47%|████▋     | 1462/3106 [5:39:19<6:20:20, 13.88s/it]
{'loss': 0.9745, 'grad_norm': 0.29502717257641126, 'learning_rate': 0.00011434410102169462, 'epoch': 0.47}


 47%|████▋     | 1464/3106 [5:39:46<6:21:09, 13.93s/it]

 47%|████▋     | 1465/3106 [5:39:59<6:10:19, 13.54s/it]

 47%|████▋     | 1466/3106 [5:40:15<6:28:47, 14.22s/it]

 47%|████▋     | 1467/3106 [5:40:29<6:27:35, 14.19s/it]
{'loss': 1.0089, 'grad_norm': 0.2555721381955356, 'learning_rate': 0.00011382778860625825, 'epoch': 0.47}

 47%|████▋     | 1468/3106 [5:40:42<6:19:29, 13.90s/it]

 47%|████▋     | 1469/3106 [5:40:56<6:15:15, 13.75s/it]

 47%|████▋     | 1470/3106 [5:41:08<6:04:36, 13.37s/it]

 47%|████▋     | 1471/3106 [5:41:24<6:22:56, 14.05s/it]

 47%|████▋     | 1472/3106 [5:41:36<6:07:57, 13.51s/it]


 47%|████▋     | 1474/3106 [5:42:00<5:50:07, 12.87s/it]
{'loss': 1.1867, 'grad_norm': 0.25810200141215467, 'learning_rate': 0.00011310432255576944, 'epoch': 0.47}

 47%|████▋     | 1475/3106 [5:42:12<5:40:25, 12.52s/it]


 48%|████▊     | 1477/3106 [5:42:40<6:07:40, 13.54s/it]
{'loss': 0.9889, 'grad_norm': 0.23745490571624983, 'learning_rate': 0.00011279404958456572, 'epoch': 0.48}


 48%|████▊     | 1479/3106 [5:43:07<5:59:53, 13.27s/it]

 48%|████▊     | 1480/3106 [5:43:18<5:48:23, 12.86s/it]

 48%|████▊     | 1481/3106 [5:43:31<5:47:11, 12.82s/it]
{'loss': 1.027, 'grad_norm': 0.2535054502930624, 'learning_rate': 0.0001123801579536101, 'epoch': 0.48}

 48%|████▊     | 1482/3106 [5:43:44<5:48:32, 12.88s/it]

 48%|████▊     | 1483/3106 [5:43:58<5:56:35, 13.18s/it]

 48%|████▊     | 1484/3106 [5:44:12<6:03:04, 13.43s/it]


 48%|████▊     | 1486/3106 [5:44:45<6:39:21, 14.79s/it]
{'loss': 0.9754, 'grad_norm': 0.2490785739518422, 'learning_rate': 0.00011186249122098283, 'epoch': 0.48}

 48%|████▊     | 1487/3106 [5:44:58<6:23:53, 14.23s/it]


 48%|████▊     | 1489/3106 [5:45:21<5:45:18, 12.81s/it]
{'loss': 1.0076, 'grad_norm': 0.2333128013071958, 'learning_rate': 0.0001115517354175692, 'epoch': 0.48}


 48%|████▊     | 1491/3106 [5:45:51<6:19:33, 14.10s/it]

 48%|████▊     | 1492/3106 [5:46:05<6:13:35, 13.89s/it]

 48%|████▊     | 1493/3106 [5:46:19<6:18:57, 14.10s/it]

 48%|████▊     | 1494/3106 [5:46:33<6:15:24, 13.97s/it]
{'loss': 0.9422, 'grad_norm': 0.2570288881209155, 'learning_rate': 0.00011103355923865267, 'epoch': 0.48}

 48%|████▊     | 1495/3106 [5:46:46<6:05:48, 13.62s/it]

 48%|████▊     | 1496/3106 [5:46:58<5:51:50, 13.11s/it]


 48%|████▊     | 1498/3106 [5:47:31<6:46:24, 15.16s/it]

 48%|████▊     | 1499/3106 [5:47:43<6:23:15, 14.31s/it]
{'loss': 1.0994, 'grad_norm': 0.22738308588647688, 'learning_rate': 0.00011051508297461287, 'epoch': 0.48}

 48%|████▊     | 1500/3106 [5:47:56<6:12:37, 13.92s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.989, 'grad_norm': 0.2482395926310051, 'learning_rate': 0.00011030761160357772, 'epoch': 0.48}
 48%|████▊     | 1501/3106 [5:48:28<8:35:07, 19.26s/it]

 48%|████▊     | 1502/3106 [5:48:40<7:35:48, 17.05s/it]


 48%|████▊     | 1504/3106 [5:49:05<6:37:47, 14.90s/it]
{'loss': 0.8907, 'grad_norm': 0.24200172158774166, 'learning_rate': 0.00010999632072670314, 'epoch': 0.48}

 48%|████▊     | 1505/3106 [5:49:18<6:21:35, 14.30s/it]

 48%|████▊     | 1506/3106 [5:49:30<6:03:52, 13.65s/it]

 49%|████▊     | 1507/3106 [5:49:46<6:17:30, 14.17s/it]


 49%|████▊     | 1509/3106 [5:50:10<5:45:03, 12.96s/it]

 49%|████▊     | 1510/3106 [5:50:22<5:37:15, 12.68s/it]

 49%|████▊     | 1511/3106 [5:50:33<5:27:32, 12.32s/it]

 49%|████▊     | 1512/3106 [5:50:45<5:23:45, 12.19s/it]

 49%|████▊     | 1513/3106 [5:50:59<5:39:34, 12.79s/it]
{'loss': 1.043, 'grad_norm': 0.242618390518, 'learning_rate': 0.00010906187304187174, 'epoch': 0.49}


 49%|████▉     | 1515/3106 [5:51:31<6:16:08, 14.19s/it]
{'loss': 1.1208, 'grad_norm': 0.2480467367484731, 'learning_rate': 0.00010885410665829503, 'epoch': 0.49}

 49%|████▉     | 1516/3106 [5:51:45<6:08:34, 13.91s/it]

 49%|████▉     | 1517/3106 [5:51:58<6:07:00, 13.86s/it]


 49%|████▉     | 1519/3106 [5:52:24<5:52:36, 13.33s/it]

 49%|████▉     | 1520/3106 [5:52:39<6:06:54, 13.88s/it]

 49%|████▉     | 1521/3106 [5:52:52<5:58:20, 13.56s/it]

 49%|████▉     | 1522/3106 [5:53:04<5:46:09, 13.11s/it]

 49%|████▉     | 1523/3106 [5:53:18<5:50:11, 13.27s/it]

 49%|████▉     | 1524/3106 [5:53:34<6:14:20, 14.20s/it]
{'loss': 0.9855, 'grad_norm': 0.2515203935985751, 'learning_rate': 0.00010791869418560255, 'epoch': 0.49}


 49%|████▉     | 1526/3106 [5:54:06<6:31:59, 14.89s/it]
{'loss': 0.9666, 'grad_norm': 0.23894613817067997, 'learning_rate': 0.00010771072708213652, 'epoch': 0.49}


 49%|████▉     | 1528/3106 [5:54:30<5:51:51, 13.38s/it]

 49%|████▉     | 1529/3106 [5:54:46<6:12:32, 14.17s/it]
{'loss': 0.9645, 'grad_norm': 0.2341314717765343, 'learning_rate': 0.00010739871379593935, 'epoch': 0.49}


 49%|████▉     | 1531/3106 [5:55:09<5:40:13, 12.96s/it]
{'loss': 0.9694, 'grad_norm': 0.24796530188923, 'learning_rate': 0.00010719066450451943, 'epoch': 0.49}

 49%|████▉     | 1532/3106 [5:55:22<5:41:05, 13.00s/it]

 49%|████▉     | 1533/3106 [5:55:37<5:52:37, 13.45s/it]

 49%|████▉     | 1534/3106 [5:55:49<5:43:01, 13.09s/it]


 49%|████▉     | 1536/3106 [5:56:20<6:18:54, 14.48s/it]
{'loss': 0.9774, 'grad_norm': 0.23065434450780423, 'learning_rate': 0.00010667040635887231, 'epoch': 0.49}

 49%|████▉     | 1537/3106 [5:56:33<6:07:36, 14.06s/it]

 50%|████▉     | 1538/3106 [5:56:48<6:19:32, 14.52s/it]

 50%|████▉     | 1539/3106 [5:57:01<6:02:59, 13.90s/it]

 50%|████▉     | 1540/3106 [5:57:17<6:19:25, 14.54s/it]

 50%|████▉     | 1541/3106 [5:57:35<6:50:50, 15.75s/it]

 50%|████▉     | 1542/3106 [5:57:47<6:18:10, 14.51s/it]


 50%|████▉     | 1544/3106 [5:58:16<6:22:35, 14.70s/it]

 50%|████▉     | 1545/3106 [5:58:29<6:15:26, 14.43s/it]

 50%|████▉     | 1546/3106 [5:58:44<6:14:36, 14.41s/it]
{'loss': 0.8796, 'grad_norm': 0.21648505596162995, 'learning_rate': 0.00010562935996728629, 'epoch': 0.5}


 50%|████▉     | 1548/3106 [5:59:11<6:09:25, 14.23s/it]

 50%|████▉     | 1549/3106 [5:59:30<6:39:16, 15.39s/it]

 50%|████▉     | 1550/3106 [5:59:42<6:15:02, 14.46s/it]
{'loss': 0.924, 'grad_norm': 0.234025334980928, 'learning_rate': 0.00010521276359018728, 'epoch': 0.5}

 50%|████▉     | 1551/3106 [5:59:55<6:07:54, 14.20s/it]


 50%|█████     | 1553/3106 [6:00:24<6:10:16, 14.31s/it]
{'loss': 0.9326, 'grad_norm': 0.23721633652390184, 'learning_rate': 0.0001049002563655732, 'epoch': 0.5}


 50%|█████     | 1555/3106 [6:00:48<5:38:40, 13.10s/it]
{'loss': 1.0517, 'grad_norm': 0.2620523102217388, 'learning_rate': 0.0001046918913719608, 'epoch': 0.5}

 50%|█████     | 1556/3106 [6:01:01<5:39:08, 13.13s/it]

 50%|█████     | 1557/3106 [6:01:13<5:28:21, 12.72s/it]


 50%|█████     | 1559/3106 [6:01:38<5:28:22, 12.74s/it]

 50%|█████     | 1560/3106 [6:01:52<5:35:54, 13.04s/it]

 50%|█████     | 1561/3106 [6:02:06<5:44:24, 13.38s/it]
{'loss': 0.9327, 'grad_norm': 0.22451071170322545, 'learning_rate': 0.00010406667751485629, 'epoch': 0.5}

 50%|█████     | 1562/3106 [6:02:21<5:53:46, 13.75s/it]

 50%|█████     | 1563/3106 [6:02:37<6:11:09, 14.43s/it]


 50%|█████     | 1565/3106 [6:03:06<6:12:29, 14.50s/it]

 50%|█████     | 1566/3106 [6:03:20<6:05:55, 14.26s/it]

 50%|█████     | 1567/3106 [6:03:34<6:02:26, 14.13s/it]

 50%|█████     | 1568/3106 [6:03:46<5:48:29, 13.60s/it]
{'loss': 0.8346, 'grad_norm': 0.25568909756632824, 'learning_rate': 0.00010333706176987696, 'epoch': 0.5}


 51%|█████     | 1570/3106 [6:04:14<5:54:41, 13.86s/it]
{'loss': 1.0189, 'grad_norm': 0.24831706545828588, 'learning_rate': 0.00010312856575389017, 'epoch': 0.51}

 51%|█████     | 1571/3106 [6:04:27<5:48:33, 13.62s/it]


 51%|█████     | 1573/3106 [6:04:56<6:00:46, 14.12s/it]
{'loss': 0.8745, 'grad_norm': 0.23494011717712351, 'learning_rate': 0.00010281579648666533, 'epoch': 0.51}

 51%|█████     | 1574/3106 [6:05:08<5:42:03, 13.40s/it]

 51%|█████     | 1575/3106 [6:05:21<5:44:37, 13.51s/it]

 51%|█████     | 1576/3106 [6:05:33<5:31:41, 13.01s/it]


 51%|█████     | 1578/3106 [6:06:00<5:39:45, 13.34s/it]

 51%|█████     | 1579/3106 [6:06:13<5:34:30, 13.14s/it]

 51%|█████     | 1580/3106 [6:06:24<5:20:34, 12.60s/it]

 51%|█████     | 1581/3106 [6:06:37<5:19:59, 12.59s/it]
{'loss': 0.8858, 'grad_norm': 0.2424202715218664, 'learning_rate': 0.00010198161864019025, 'epoch': 0.51}

 51%|█████     | 1582/3106 [6:06:49<5:18:42, 12.55s/it]

 51%|█████     | 1583/3106 [6:07:04<5:32:44, 13.11s/it]

 51%|█████     | 1584/3106 [6:07:16<5:26:22, 12.87s/it]


 51%|█████     | 1586/3106 [6:07:41<5:19:20, 12.61s/it]
{'loss': 1.0842, 'grad_norm': 0.27896178752707834, 'learning_rate': 0.00010146018373566113, 'epoch': 0.51}


 51%|█████     | 1588/3106 [6:08:08<5:34:30, 13.22s/it]
{'loss': 1.0385, 'grad_norm': 0.25402952630479947, 'learning_rate': 0.00010125159785989933, 'epoch': 0.51}

 51%|█████     | 1589/3106 [6:08:22<5:36:55, 13.33s/it]

 51%|█████     | 1590/3106 [6:08:36<5:41:22, 13.51s/it]


 51%|█████▏    | 1592/3106 [6:09:03<5:41:23, 13.53s/it]
{'loss': 0.8905, 'grad_norm': 0.2398775148823614, 'learning_rate': 0.00010083441067669796, 'epoch': 0.51}


 51%|█████▏    | 1594/3106 [6:09:28<5:32:55, 13.21s/it]

 51%|█████▏    | 1595/3106 [6:09:42<5:39:05, 13.47s/it]

 51%|█████▏    | 1596/3106 [6:09:57<5:46:19, 13.76s/it]

 51%|█████▏    | 1597/3106 [6:10:10<5:44:18, 13.69s/it]

 51%|█████▏    | 1598/3106 [6:10:22<5:31:18, 13.18s/it]
{'loss': 1.0494, 'grad_norm': 0.2371121629500959, 'learning_rate': 0.00010020860493858524, 'epoch': 0.51}


 52%|█████▏    | 1600/3106 [6:10:50<5:46:07, 13.79s/it]
{'loss': 0.9258, 'grad_norm': 0.261161538725778, 'learning_rate': 0.0001, 'epoch': 0.52}

 52%|█████▏    | 1601/3106 [6:11:03<5:39:59, 13.55s/it]


 52%|█████▏    | 1603/3106 [6:11:31<5:35:44, 13.40s/it]

 52%|█████▏    | 1604/3106 [6:11:42<5:22:22, 12.88s/it]

 52%|█████▏    | 1605/3106 [6:11:55<5:17:55, 12.71s/it]
{'loss': 0.9691, 'grad_norm': 0.2482421903161928, 'learning_rate': 9.947848963927556e-05, 'epoch': 0.52}

 52%|█████▏    | 1606/3106 [6:12:06<5:06:39, 12.27s/it]

 52%|█████▏    | 1607/3106 [6:12:19<5:14:13, 12.58s/it]


 52%|█████▏    | 1609/3106 [6:12:44<5:14:37, 12.61s/it]

 52%|█████▏    | 1610/3106 [6:12:57<5:12:24, 12.53s/it]
{'loss': 0.9707, 'grad_norm': 0.24434802703263195, 'learning_rate': 9.895699346232421e-05, 'epoch': 0.52}

 52%|█████▏    | 1611/3106 [6:13:12<5:32:32, 13.35s/it]

 52%|█████▏    | 1612/3106 [6:13:26<5:37:39, 13.56s/it]


 52%|█████▏    | 1614/3106 [6:13:55<5:50:29, 14.10s/it]
{'loss': 0.8921, 'grad_norm': 0.2573258193803909, 'learning_rate': 9.853981626433889e-05, 'epoch': 0.52}


 52%|█████▏    | 1616/3106 [6:14:19<5:27:21, 13.18s/it]
{'loss': 0.9039, 'grad_norm': 0.25052560250554445, 'learning_rate': 9.833123674272252e-05, 'epoch': 0.52}

 52%|█████▏    | 1617/3106 [6:14:40<6:21:01, 15.35s/it]

 52%|█████▏    | 1618/3106 [6:14:52<5:55:28, 14.33s/it]


 52%|█████▏    | 1620/3106 [6:15:27<6:28:17, 15.68s/it]

 52%|█████▏    | 1621/3106 [6:15:45<6:45:10, 16.37s/it]

 52%|█████▏    | 1622/3106 [6:15:59<6:32:17, 15.86s/it]
{'loss': 0.9799, 'grad_norm': 0.2845203422892729, 'learning_rate': 9.77055453791447e-05, 'epoch': 0.52}

 52%|█████▏    | 1623/3106 [6:16:14<6:21:51, 15.45s/it]

 52%|█████▏    | 1624/3106 [6:16:30<6:25:53, 15.62s/it]

 52%|█████▏    | 1625/3106 [6:16:43<6:03:37, 14.73s/it]

 52%|█████▏    | 1626/3106 [6:16:54<5:42:37, 13.89s/it]


 52%|█████▏    | 1628/3106 [6:17:21<5:32:20, 13.49s/it]

 52%|█████▏    | 1629/3106 [6:17:33<5:23:53, 13.16s/it]

 52%|█████▏    | 1630/3106 [6:17:46<5:16:46, 12.88s/it]
{'loss': 1.0058, 'grad_norm': 0.2633127577770043, 'learning_rate': 9.687143424610986e-05, 'epoch': 0.52}


 53%|█████▎    | 1632/3106 [6:18:11<5:13:56, 12.78s/it]
{'loss': 0.8911, 'grad_norm': 0.25923133428971556, 'learning_rate': 9.666293823012306e-05, 'epoch': 0.53}

 53%|█████▎    | 1633/3106 [6:18:32<6:13:33, 15.22s/it]

 53%|█████▎    | 1634/3106 [6:18:46<6:04:51, 14.87s/it]


 53%|█████▎    | 1636/3106 [6:19:09<5:22:14, 13.15s/it]

 53%|█████▎    | 1637/3106 [6:19:23<5:31:46, 13.55s/it]
{'loss': 1.0109, 'grad_norm': 0.2257785829372627, 'learning_rate': 9.61417637066174e-05, 'epoch': 0.53}


 53%|█████▎    | 1639/3106 [6:19:55<6:03:11, 14.85s/it]
{'loss': 1.0597, 'grad_norm': 0.24795190627962943, 'learning_rate': 9.593332248514374e-05, 'epoch': 0.53}


 53%|█████▎    | 1641/3106 [6:20:25<6:00:39, 14.77s/it]

 53%|█████▎    | 1642/3106 [6:20:39<5:55:55, 14.59s/it]

 53%|█████▎    | 1643/3106 [6:20:55<6:04:59, 14.97s/it]
{'loss': 0.9446, 'grad_norm': 0.2400910536427964, 'learning_rate': 9.551649403891791e-05, 'epoch': 0.53}

 53%|█████▎    | 1644/3106 [6:21:10<6:06:47, 15.05s/it]


 53%|█████▎    | 1646/3106 [6:21:41<6:05:48, 15.03s/it]
{'loss': 0.9799, 'grad_norm': 0.2512051298211558, 'learning_rate': 9.520392352240246e-05, 'epoch': 0.53}

 53%|█████▎    | 1647/3106 [6:21:54<5:48:29, 14.33s/it]


 53%|█████▎    | 1649/3106 [6:22:23<5:53:43, 14.57s/it]
{'loss': 0.9387, 'grad_norm': 0.23996944360810757, 'learning_rate': 9.489139996480323e-05, 'epoch': 0.53}


 53%|█████▎    | 1651/3106 [6:22:56<6:09:22, 15.23s/it]
{'loss': 1.0153, 'grad_norm': 0.2237942484033612, 'learning_rate': 9.468307852579816e-05, 'epoch': 0.53}

 53%|█████▎    | 1652/3106 [6:23:08<5:49:08, 14.41s/it]

 53%|█████▎    | 1653/3106 [6:23:22<5:46:14, 14.30s/it]

 53%|█████▎    | 1654/3106 [6:23:38<5:57:44, 14.78s/it]

 53%|█████▎    | 1655/3106 [6:23:52<5:52:41, 14.58s/it]

 53%|█████▎    | 1656/3106 [6:24:05<5:38:42, 14.02s/it]


 53%|█████▎    | 1658/3106 [6:24:31<5:27:27, 13.57s/it]
{'loss': 1.0008, 'grad_norm': 0.2346017828499577, 'learning_rate': 9.395414164255199e-05, 'epoch': 0.53}


 53%|█████▎    | 1660/3106 [6:25:02<5:49:48, 14.52s/it]

 53%|█████▎    | 1661/3106 [6:25:13<5:28:50, 13.65s/it]
{'loss': 0.9395, 'grad_norm': 0.2528114492247061, 'learning_rate': 9.364183651509826e-05, 'epoch': 0.53}


 54%|█████▎    | 1663/3106 [6:25:42<5:37:12, 14.02s/it]

 54%|█████▎    | 1664/3106 [6:25:53<5:19:57, 13.31s/it]
{'loss': 1.0594, 'grad_norm': 0.2849791697551425, 'learning_rate': 9.332959364112772e-05, 'epoch': 0.54}

 54%|█████▎    | 1665/3106 [6:26:05<5:08:02, 12.83s/it]


 54%|█████▎    | 1667/3106 [6:26:37<5:47:10, 14.48s/it]
{'loss': 1.0197, 'grad_norm': 0.23940450109760503, 'learning_rate': 9.301741607784494e-05, 'epoch': 0.54}

 54%|█████▎    | 1668/3106 [6:26:49<5:24:54, 13.56s/it]


 54%|█████▍    | 1670/3106 [6:27:14<5:08:52, 12.91s/it]
{'loss': 0.9241, 'grad_norm': 0.2454984617866804, 'learning_rate': 9.270530688181506e-05, 'epoch': 0.54}

 54%|█████▍    | 1671/3106 [6:27:28<5:20:49, 13.41s/it]

 54%|█████▍    | 1672/3106 [6:27:41<5:16:21, 13.24s/it]


 54%|█████▍    | 1674/3106 [6:28:08<5:15:40, 13.23s/it]
{'loss': 0.9298, 'grad_norm': 0.26018985983177656, 'learning_rate': 9.22892729178635e-05, 'epoch': 0.54}

 54%|█████▍    | 1675/3106 [6:28:21<5:11:49, 13.07s/it]

 54%|█████▍    | 1676/3106 [6:28:33<5:02:31, 12.69s/it]

 54%|█████▍    | 1677/3106 [6:28:47<5:13:00, 13.14s/it]


 54%|█████▍    | 1679/3106 [6:29:16<5:31:36, 13.94s/it]

 54%|█████▍    | 1680/3106 [6:29:29<5:27:43, 13.79s/it]

 54%|█████▍    | 1681/3106 [6:29:54<6:42:55, 16.97s/it]
[2024-05-29 03:22:56,487] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.8412, 'grad_norm': 0.23496801586015112, 'learning_rate': 9.156154079334469e-05, 'epoch': 0.54}

 54%|█████▍    | 1682/3106 [6:30:07<6:15:56, 15.84s/it]

 54%|█████▍    | 1683/3106 [6:30:19<5:47:50, 14.67s/it]

 54%|█████▍    | 1684/3106 [6:30:30<5:25:37, 13.74s/it]


 54%|█████▍    | 1686/3106 [6:30:54<4:58:56, 12.63s/it]
{'loss': 0.9646, 'grad_norm': 0.2533722565013619, 'learning_rate': 9.104200527720651e-05, 'epoch': 0.54}


 54%|█████▍    | 1688/3106 [6:31:18<4:56:30, 12.55s/it]
{'loss': 0.7746, 'grad_norm': 0.24579127031700232, 'learning_rate': 9.083425849747979e-05, 'epoch': 0.54}


 54%|█████▍    | 1690/3106 [6:31:42<4:49:54, 12.28s/it]

 54%|█████▍    | 1691/3106 [6:32:00<5:26:41, 13.85s/it]

 54%|█████▍    | 1692/3106 [6:32:14<5:30:43, 14.03s/it]
{'loss': 0.9526, 'grad_norm': 0.2579892269787305, 'learning_rate': 9.041888549899352e-05, 'epoch': 0.54}

 55%|█████▍    | 1693/3106 [6:32:31<5:50:39, 14.89s/it]

 55%|█████▍    | 1694/3106 [6:32:44<5:32:18, 14.12s/it]

 55%|█████▍    | 1695/3106 [6:32:57<5:27:39, 13.93s/it]

 55%|█████▍    | 1696/3106 [6:33:11<5:27:20, 13.93s/it]


 55%|█████▍    | 1698/3106 [6:33:38<5:25:21, 13.87s/it]

 55%|█████▍    | 1699/3106 [6:33:50<5:12:52, 13.34s/it]
{'loss': 1.0027, 'grad_norm': 0.2499241697189794, 'learning_rate': 8.969238839642232e-05, 'epoch': 0.55}


 55%|█████▍    | 1701/3106 [6:34:18<5:18:13, 13.59s/it]

 55%|█████▍    | 1702/3106 [6:34:32<5:23:09, 13.81s/it]

 55%|█████▍    | 1703/3106 [6:34:46<5:20:58, 13.73s/it]
{'loss': 0.9131, 'grad_norm': 0.24295258439115777, 'learning_rate': 8.927749141185833e-05, 'epoch': 0.55}

 55%|█████▍    | 1704/3106 [6:34:57<5:03:25, 12.99s/it]


 55%|█████▍    | 1706/3106 [6:35:26<5:18:30, 13.65s/it]
{'loss': 0.9775, 'grad_norm': 0.25681569221761635, 'learning_rate': 8.896644076134738e-05, 'epoch': 0.55}


 55%|█████▍    | 1708/3106 [6:35:54<5:25:18, 13.96s/it]

 55%|█████▌    | 1709/3106 [6:36:06<5:09:51, 13.31s/it]

 55%|█████▌    | 1710/3106 [6:36:18<5:00:59, 12.94s/it]
{'loss': 1.0477, 'grad_norm': 0.234459764961227, 'learning_rate': 8.855187513481527e-05, 'epoch': 0.55}


 55%|█████▌    | 1712/3106 [6:36:43<4:52:46, 12.60s/it]

 55%|█████▌    | 1713/3106 [6:36:54<4:48:00, 12.41s/it]
{'loss': 1.017, 'grad_norm': 0.2273376008419909, 'learning_rate': 8.824108129183426e-05, 'epoch': 0.55}


 55%|█████▌    | 1715/3106 [6:37:20<4:50:24, 12.53s/it]

 55%|█████▌    | 1716/3106 [6:37:35<5:04:47, 13.16s/it]
{'loss': 1.0242, 'grad_norm': 0.23016607190099028, 'learning_rate': 8.793040258172926e-05, 'epoch': 0.55}


 55%|█████▌    | 1718/3106 [6:38:06<5:39:02, 14.66s/it]
{'loss': 1.0447, 'grad_norm': 0.2470160342059469, 'learning_rate': 8.772334890658316e-05, 'epoch': 0.55}

 55%|█████▌    | 1719/3106 [6:38:24<5:58:22, 15.50s/it]


 55%|█████▌    | 1721/3106 [6:38:48<5:19:08, 13.83s/it]

 55%|█████▌    | 1722/3106 [6:39:03<5:23:17, 14.02s/it]
{'loss': 0.9723, 'grad_norm': 0.23685923156813976, 'learning_rate': 8.73094027265489e-05, 'epoch': 0.55}

 55%|█████▌    | 1723/3106 [6:39:16<5:15:54, 13.71s/it]

 56%|█████▌    | 1724/3106 [6:39:32<5:32:03, 14.42s/it]


 56%|█████▌    | 1726/3106 [6:40:06<5:55:12, 15.44s/it]
{'loss': 0.823, 'grad_norm': 0.24028748836943795, 'learning_rate': 8.68956774442306e-05, 'epoch': 0.56}


 56%|█████▌    | 1728/3106 [6:40:35<5:43:12, 14.94s/it]
{'loss': 0.9163, 'grad_norm': 0.2553953590101393, 'learning_rate': 8.668889989032829e-05, 'epoch': 0.56}


 56%|█████▌    | 1730/3106 [6:41:08<5:54:40, 15.47s/it]

 56%|█████▌    | 1731/3106 [6:41:23<5:47:12, 15.15s/it]
{'loss': 0.9399, 'grad_norm': 0.23466161752869702, 'learning_rate': 8.637884244936068e-05, 'epoch': 0.56}

 56%|█████▌    | 1732/3106 [6:41:35<5:29:16, 14.38s/it]

 56%|█████▌    | 1733/3106 [6:41:47<5:14:14, 13.73s/it]


 56%|█████▌    | 1735/3106 [6:42:13<5:02:20, 13.23s/it]

 56%|█████▌    | 1736/3106 [6:42:26<5:03:57, 13.31s/it]

 56%|█████▌    | 1737/3106 [6:42:39<4:58:15, 13.07s/it]
{'loss': 1.0051, 'grad_norm': 0.2595703608800864, 'learning_rate': 8.575913070071501e-05, 'epoch': 0.56}


 56%|█████▌    | 1739/3106 [6:43:09<5:24:55, 14.26s/it]
{'loss': 1.0124, 'grad_norm': 0.2562661799858107, 'learning_rate': 8.555268286087188e-05, 'epoch': 0.56}

 56%|█████▌    | 1740/3106 [6:43:24<5:27:42, 14.39s/it]


 56%|█████▌    | 1742/3106 [6:43:48<5:04:11, 13.38s/it]

 56%|█████▌    | 1743/3106 [6:44:01<4:56:52, 13.07s/it]
{'loss': 0.9459, 'grad_norm': 0.2344304075624003, 'learning_rate': 8.513997668642116e-05, 'epoch': 0.56}


 56%|█████▌    | 1745/3106 [6:44:25<4:45:28, 12.59s/it]

 56%|█████▌    | 1746/3106 [6:44:38<4:52:14, 12.89s/it]

 56%|█████▌    | 1747/3106 [6:44:53<5:03:23, 13.39s/it]

 56%|█████▋    | 1748/3106 [6:45:05<4:54:02, 12.99s/it]
{'loss': 0.9162, 'grad_norm': 0.27028613673966606, 'learning_rate': 8.462445854988072e-05, 'epoch': 0.56}


 56%|█████▋    | 1750/3106 [6:45:35<5:13:05, 13.85s/it]
{'loss': 0.8977, 'grad_norm': 0.3225171709385492, 'learning_rate': 8.441836759979795e-05, 'epoch': 0.56}


 56%|█████▋    | 1752/3106 [6:46:03<5:13:37, 13.90s/it]
{'loss': 0.9941, 'grad_norm': 0.3219668232919507, 'learning_rate': 8.421234445485232e-05, 'epoch': 0.56}


 56%|█████▋    | 1754/3106 [6:46:33<5:27:15, 14.52s/it]

 57%|█████▋    | 1755/3106 [6:46:47<5:20:56, 14.25s/it]

 57%|█████▋    | 1756/3106 [6:46:59<5:03:58, 13.51s/it]

 57%|█████▋    | 1757/3106 [6:47:13<5:10:15, 13.80s/it]
{'loss': 0.9822, 'grad_norm': 0.23683601756449993, 'learning_rate': 8.369758912271572e-05, 'epoch': 0.57}

 57%|█████▋    | 1758/3106 [6:47:30<5:28:37, 14.63s/it]

 57%|█████▋    | 1759/3106 [6:47:42<5:11:13, 13.86s/it]

 57%|█████▋    | 1760/3106 [6:47:54<4:57:03, 13.24s/it]

 57%|█████▋    | 1761/3106 [6:48:07<5:00:38, 13.41s/it]

 57%|█████▋    | 1762/3106 [6:48:20<4:53:18, 13.09s/it]

 57%|█████▋    | 1763/3106 [6:48:32<4:47:04, 12.83s/it]

 57%|█████▋    | 1764/3106 [6:48:45<4:44:59, 12.74s/it]

 57%|█████▋    | 1765/3106 [6:49:00<5:02:05, 13.52s/it]


 57%|█████▋    | 1767/3106 [6:49:23<4:40:29, 12.57s/it]
{'loss': 0.9334, 'grad_norm': 0.24162788821517328, 'learning_rate': 8.266942260043473e-05, 'epoch': 0.57}


 57%|█████▋    | 1769/3106 [6:49:49<4:42:18, 12.67s/it]

 57%|█████▋    | 1770/3106 [6:50:01<4:40:03, 12.58s/it]
{'loss': 0.9853, 'grad_norm': 0.25451342901316637, 'learning_rate': 8.236133520878517e-05, 'epoch': 0.57}

 57%|█████▋    | 1771/3106 [6:50:14<4:43:33, 12.74s/it]

 57%|█████▋    | 1772/3106 [6:50:26<4:35:48, 12.40s/it]

 57%|█████▋    | 1773/3106 [6:50:38<4:35:00, 12.38s/it]


 57%|█████▋    | 1775/3106 [6:51:05<4:45:45, 12.88s/it]

 57%|█████▋    | 1776/3106 [6:51:20<4:56:41, 13.38s/it]
{'loss': 0.9422, 'grad_norm': 0.25424639046913566, 'learning_rate': 8.174568154667711e-05, 'epoch': 0.57}

 57%|█████▋    | 1777/3106 [6:51:32<4:48:43, 13.04s/it]


 57%|█████▋    | 1779/3106 [6:52:04<5:25:04, 14.70s/it]
{'loss': 0.9267, 'grad_norm': 0.24688526159239393, 'learning_rate': 8.143812130415182e-05, 'epoch': 0.57}


 57%|█████▋    | 1781/3106 [6:52:30<5:06:03, 13.86s/it]
{'loss': 0.9889, 'grad_norm': 0.24874493063827113, 'learning_rate': 8.123318192410561e-05, 'epoch': 0.57}

 57%|█████▋    | 1782/3106 [6:52:44<5:07:56, 13.96s/it]


 57%|█████▋    | 1784/3106 [6:53:13<5:15:11, 14.31s/it]
{'loss': 1.0292, 'grad_norm': 0.24162910982987648, 'learning_rate': 8.092592625603033e-05, 'epoch': 0.57}


 58%|█████▊    | 1786/3106 [6:53:39<4:58:46, 13.58s/it]
{'loss': 0.9706, 'grad_norm': 0.2527027065994354, 'learning_rate': 8.072119271189156e-05, 'epoch': 0.57}
[2024-05-29 03:47:00,650] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 58%|█████▊    | 1787/3106 [6:53:58<5:32:52, 15.14s/it]


 58%|█████▊    | 1789/3106 [6:54:25<5:14:56, 14.35s/it]

 58%|█████▊    | 1790/3106 [6:54:40<5:15:46, 14.40s/it]

 58%|█████▊    | 1791/3106 [6:54:54<5:11:41, 14.22s/it]
{'loss': 0.888, 'grad_norm': 0.24088244205453402, 'learning_rate': 8.02097278348567e-05, 'epoch': 0.58}


 58%|█████▊    | 1793/3106 [6:55:26<5:30:21, 15.10s/it]

 58%|█████▊    | 1794/3106 [6:55:38<5:11:29, 14.25s/it]

 58%|█████▊    | 1795/3106 [6:55:51<5:06:24, 14.02s/it]

 58%|█████▊    | 1796/3106 [6:56:06<5:08:54, 14.15s/it]
{'loss': 1.1132, 'grad_norm': 0.2443007721642281, 'learning_rate': 7.969880120356228e-05, 'epoch': 0.58}

 58%|█████▊    | 1797/3106 [6:56:19<5:00:53, 13.79s/it]

 58%|█████▊    | 1798/3106 [6:56:31<4:49:39, 13.29s/it]


 58%|█████▊    | 1800/3106 [6:56:57<4:47:43, 13.22s/it]
 58%|█████▊    | 1800/3106 [6:56:57<4:47:43, 13.22s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 58%|█████▊    | 1801/3106 [6:57:27<6:37:57, 18.30s/it]

 58%|█████▊    | 1802/3106 [6:57:40<5:59:27, 16.54s/it]
{'loss': 0.8852, 'grad_norm': 0.2361479350016747, 'learning_rate': 7.908641929479187e-05, 'epoch': 0.58}

 58%|█████▊    | 1803/3106 [6:58:00<6:23:55, 17.68s/it]

 58%|█████▊    | 1804/3106 [6:58:15<6:05:22, 16.84s/it]

 58%|█████▊    | 1805/3106 [6:58:27<5:33:27, 15.38s/it]

 58%|█████▊    | 1806/3106 [6:58:38<5:06:53, 14.16s/it]


 58%|█████▊    | 1808/3106 [6:59:04<4:52:26, 13.52s/it]

 58%|█████▊    | 1809/3106 [6:59:15<4:39:02, 12.91s/it]

 58%|█████▊    | 1810/3106 [6:59:28<4:34:40, 12.72s/it]

 58%|█████▊    | 1811/3106 [6:59:42<4:42:21, 13.08s/it]
{'loss': 1.0021, 'grad_norm': 0.245534507673085, 'learning_rate': 7.816938966788185e-05, 'epoch': 0.58}

 58%|█████▊    | 1812/3106 [6:59:58<5:05:19, 14.16s/it]

 58%|█████▊    | 1813/3106 [7:00:13<5:08:52, 14.33s/it]


 58%|█████▊    | 1815/3106 [7:00:37<4:45:49, 13.28s/it]
{'loss': 0.9599, 'grad_norm': 0.2660006652345301, 'learning_rate': 7.776243363167528e-05, 'epoch': 0.58}

 58%|█████▊    | 1816/3106 [7:00:50<4:44:05, 13.21s/it]

 58%|█████▊    | 1817/3106 [7:01:03<4:40:22, 13.05s/it]

 59%|█████▊    | 1818/3106 [7:01:16<4:42:14, 13.15s/it]

 59%|█████▊    | 1819/3106 [7:01:30<4:47:16, 13.39s/it]


 59%|█████▊    | 1821/3106 [7:02:00<4:55:21, 13.79s/it]

 59%|█████▊    | 1822/3106 [7:02:14<4:57:49, 13.92s/it]

 59%|█████▊    | 1823/3106 [7:02:26<4:44:13, 13.29s/it]

 59%|█████▊    | 1824/3106 [7:02:38<4:39:57, 13.10s/it]

 59%|█████▉    | 1825/3106 [7:02:50<4:30:58, 12.69s/it]
{'loss': 1.0173, 'grad_norm': 0.2667443748615714, 'learning_rate': 7.674675247820216e-05, 'epoch': 0.59}

 59%|█████▉    | 1826/3106 [7:03:01<4:21:01, 12.24s/it]

 59%|█████▉    | 1827/3106 [7:03:15<4:33:40, 12.84s/it]


 59%|█████▉    | 1829/3106 [7:03:38<4:17:57, 12.12s/it]
{'loss': 1.0576, 'grad_norm': 0.25230504480571886, 'learning_rate': 7.634118215496298e-05, 'epoch': 0.59}


 59%|█████▉    | 1831/3106 [7:04:04<4:24:17, 12.44s/it]
{'loss': 1.0459, 'grad_norm': 0.24708600307089593, 'learning_rate': 7.61385509830418e-05, 'epoch': 0.59}

 59%|█████▉    | 1832/3106 [7:04:15<4:18:41, 12.18s/it]

 59%|█████▉    | 1833/3106 [7:04:29<4:26:10, 12.55s/it]


 59%|█████▉    | 1835/3106 [7:04:58<4:45:16, 13.47s/it]

 59%|█████▉    | 1836/3106 [7:05:10<4:38:12, 13.14s/it]
{'loss': 1.0498, 'grad_norm': 0.24522901098633287, 'learning_rate': 7.563242926193936e-05, 'epoch': 0.59}

 59%|█████▉    | 1837/3106 [7:05:23<4:31:59, 12.86s/it]

 59%|█████▉    | 1838/3106 [7:05:35<4:30:55, 12.82s/it]

 59%|█████▉    | 1839/3106 [7:05:48<4:27:03, 12.65s/it]

 59%|█████▉    | 1840/3106 [7:06:03<4:47:33, 13.63s/it]


 59%|█████▉    | 1842/3106 [7:06:32<5:01:18, 14.30s/it]
{'loss': 0.9775, 'grad_norm': 0.24762894122357257, 'learning_rate': 7.502595921923606e-05, 'epoch': 0.59}

 59%|█████▉    | 1843/3106 [7:06:47<5:03:00, 14.39s/it]

 59%|█████▉    | 1844/3106 [7:07:00<4:54:22, 14.00s/it]

 59%|█████▉    | 1845/3106 [7:07:13<4:46:10, 13.62s/it]

 59%|█████▉    | 1846/3106 [7:07:26<4:43:05, 13.48s/it]

 59%|█████▉    | 1847/3106 [7:07:39<4:41:10, 13.40s/it]

 59%|█████▉    | 1848/3106 [7:07:52<4:35:52, 13.16s/it]

 60%|█████▉    | 1849/3106 [7:08:07<4:50:46, 13.88s/it]


 60%|█████▉    | 1851/3106 [7:08:35<4:45:53, 13.67s/it]

 60%|█████▉    | 1852/3106 [7:08:51<5:01:29, 14.43s/it]
[2024-05-29 04:01:53,525] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 1.1469, 'grad_norm': 0.22850860432179906, 'learning_rate': 7.401736106459792e-05, 'epoch': 0.6}

 60%|█████▉    | 1853/3106 [7:09:05<5:01:17, 14.43s/it]


 60%|█████▉    | 1855/3106 [7:09:29<4:32:20, 13.06s/it]
{'loss': 1.0364, 'grad_norm': 0.268163507807492, 'learning_rate': 7.371532782673831e-05, 'epoch': 0.6}

 60%|█████▉    | 1856/3106 [7:09:44<4:46:30, 13.75s/it]

 60%|█████▉    | 1857/3106 [7:10:00<4:57:57, 14.31s/it]

 60%|█████▉    | 1858/3106 [7:10:12<4:45:39, 13.73s/it]

 60%|█████▉    | 1859/3106 [7:10:24<4:32:24, 13.11s/it]

 60%|█████▉    | 1860/3106 [7:10:40<4:52:28, 14.08s/it]

 60%|█████▉    | 1861/3106 [7:10:53<4:46:38, 13.81s/it]


 60%|█████▉    | 1863/3106 [7:11:21<4:42:46, 13.65s/it]
{'loss': 0.9366, 'grad_norm': 0.24391625302207384, 'learning_rate': 7.291117206869028e-05, 'epoch': 0.6}

 60%|██████    | 1864/3106 [7:11:32<4:28:13, 12.96s/it]

 60%|██████    | 1865/3106 [7:11:44<4:25:23, 12.83s/it]

 60%|██████    | 1866/3106 [7:11:56<4:18:29, 12.51s/it]

 60%|██████    | 1867/3106 [7:12:10<4:23:34, 12.76s/it]

 60%|██████    | 1868/3106 [7:12:21<4:16:24, 12.43s/it]

 60%|██████    | 1869/3106 [7:12:34<4:15:37, 12.40s/it]

 60%|██████    | 1870/3106 [7:12:49<4:31:43, 13.19s/it]


 60%|██████    | 1872/3106 [7:13:13<4:21:16, 12.70s/it]
{'loss': 0.8036, 'grad_norm': 0.2304916050775577, 'learning_rate': 7.20087540656915e-05, 'epoch': 0.6}

 60%|██████    | 1873/3106 [7:13:24<4:12:44, 12.30s/it]

 60%|██████    | 1874/3106 [7:13:37<4:13:07, 12.33s/it]

 60%|██████    | 1875/3106 [7:13:48<4:05:21, 11.96s/it]

 60%|██████    | 1876/3106 [7:14:01<4:14:53, 12.43s/it]


 60%|██████    | 1878/3106 [7:14:31<4:44:07, 13.88s/it]
{'loss': 0.9519, 'grad_norm': 0.24461731988665658, 'learning_rate': 7.140850748189177e-05, 'epoch': 0.6}

 60%|██████    | 1879/3106 [7:14:44<4:35:50, 13.49s/it]

 61%|██████    | 1880/3106 [7:15:00<4:50:26, 14.21s/it]

 61%|██████    | 1881/3106 [7:15:12<4:36:21, 13.54s/it]

 61%|██████    | 1882/3106 [7:15:29<5:01:35, 14.78s/it]

 61%|██████    | 1883/3106 [7:15:44<4:59:27, 14.69s/it]

 61%|██████    | 1884/3106 [7:16:02<5:21:00, 15.76s/it]

 61%|██████    | 1885/3106 [7:16:14<4:58:38, 14.68s/it]

 61%|██████    | 1886/3106 [7:16:28<4:55:14, 14.52s/it]

 61%|██████    | 1887/3106 [7:16:40<4:38:24, 13.70s/it]

 61%|██████    | 1888/3106 [7:16:56<4:51:07, 14.34s/it]


 61%|██████    | 1890/3106 [7:17:25<4:56:31, 14.63s/it]

 61%|██████    | 1891/3106 [7:17:37<4:42:06, 13.93s/it]
{'loss': 1.0978, 'grad_norm': 0.24176563653455274, 'learning_rate': 7.011184594189589e-05, 'epoch': 0.61}


 61%|██████    | 1893/3106 [7:18:09<4:57:30, 14.72s/it]

 61%|██████    | 1894/3106 [7:18:23<4:52:59, 14.50s/it]

 61%|██████    | 1895/3106 [7:18:35<4:37:44, 13.76s/it]
{'loss': 1.0933, 'grad_norm': 0.2539586018051538, 'learning_rate': 6.971396762524622e-05, 'epoch': 0.61}


 61%|██████    | 1897/3106 [7:18:59<4:19:10, 12.86s/it]
{'loss': 1.042, 'grad_norm': 0.26208799270939054, 'learning_rate': 6.951522572356682e-05, 'epoch': 0.61}

 61%|██████    | 1898/3106 [7:19:12<4:19:36, 12.89s/it]

 61%|██████    | 1899/3106 [7:19:25<4:15:21, 12.69s/it]

 61%|██████    | 1900/3106 [7:19:38<4:22:09, 13.04s/it]

 61%|██████    | 1901/3106 [7:19:56<4:50:37, 14.47s/it]

 61%|██████    | 1902/3106 [7:20:08<4:35:59, 13.75s/it]

 61%|██████▏   | 1903/3106 [7:20:21<4:28:17, 13.38s/it]

 61%|██████▏   | 1904/3106 [7:20:34<4:25:54, 13.27s/it]

 61%|██████▏   | 1905/3106 [7:20:47<4:22:33, 13.12s/it]


 61%|██████▏   | 1907/3106 [7:21:13<4:28:23, 13.43s/it]
{'loss': 0.895, 'grad_norm': 0.2559123450944295, 'learning_rate': 6.852352335807212e-05, 'epoch': 0.61}

 61%|██████▏   | 1908/3106 [7:21:27<4:27:52, 13.42s/it]

 61%|██████▏   | 1909/3106 [7:21:38<4:13:58, 12.73s/it]

 61%|██████▏   | 1910/3106 [7:21:52<4:23:19, 13.21s/it]


 62%|██████▏   | 1912/3106 [7:22:18<4:14:34, 12.79s/it]

 62%|██████▏   | 1913/3106 [7:22:33<4:32:12, 13.69s/it]
{'loss': 0.8915, 'grad_norm': 0.2313375208707001, 'learning_rate': 6.793013871408076e-05, 'epoch': 0.62}

 62%|██████▏   | 1914/3106 [7:22:47<4:29:19, 13.56s/it]

 62%|██████▏   | 1915/3106 [7:23:02<4:38:23, 14.02s/it]

 62%|██████▏   | 1916/3106 [7:23:17<4:43:00, 14.27s/it]

 62%|██████▏   | 1917/3106 [7:23:28<4:26:40, 13.46s/it]

 62%|██████▏   | 1918/3106 [7:23:41<4:23:59, 13.33s/it]


 62%|██████▏   | 1920/3106 [7:24:06<4:12:46, 12.79s/it]
{'loss': 0.9824, 'grad_norm': 0.2534165322456732, 'learning_rate': 6.723944569684683e-05, 'epoch': 0.62}


 62%|██████▏   | 1922/3106 [7:24:31<4:14:43, 12.91s/it]

 62%|██████▏   | 1923/3106 [7:24:43<4:08:40, 12.61s/it]

 62%|██████▏   | 1924/3106 [7:24:58<4:17:43, 13.08s/it]
{'loss': 0.8319, 'grad_norm': 0.25781230792569376, 'learning_rate': 6.684554569755258e-05, 'epoch': 0.62}

 62%|██████▏   | 1925/3106 [7:25:13<4:32:11, 13.83s/it]

 62%|██████▏   | 1926/3106 [7:25:29<4:44:58, 14.49s/it]

 62%|██████▏   | 1927/3106 [7:25:43<4:39:56, 14.25s/it]

 62%|██████▏   | 1928/3106 [7:25:57<4:36:45, 14.10s/it]

 62%|██████▏   | 1929/3106 [7:26:11<4:37:12, 14.13s/it]


 62%|██████▏   | 1931/3106 [7:26:40<4:43:15, 14.46s/it]
{'loss': 1.0436, 'grad_norm': 0.22609574474706803, 'learning_rate': 6.61576134644577e-05, 'epoch': 0.62}


 62%|██████▏   | 1933/3106 [7:27:08<4:37:51, 14.21s/it]

 62%|██████▏   | 1934/3106 [7:27:24<4:47:10, 14.70s/it]
{'loss': 0.8987, 'grad_norm': 0.26907736744051713, 'learning_rate': 6.586333548524957e-05, 'epoch': 0.62}

 62%|██████▏   | 1935/3106 [7:27:35<4:29:53, 13.83s/it]


 62%|██████▏   | 1937/3106 [7:28:02<4:24:27, 13.57s/it]
{'loss': 1.0715, 'grad_norm': 0.2503501223358451, 'learning_rate': 6.556939174190615e-05, 'epoch': 0.62}

 62%|██████▏   | 1938/3106 [7:28:17<4:33:15, 14.04s/it]

 62%|██████▏   | 1939/3106 [7:28:29<4:21:26, 13.44s/it]

 62%|██████▏   | 1940/3106 [7:28:43<4:24:13, 13.60s/it]


 63%|██████▎   | 1942/3106 [7:29:12<4:29:14, 13.88s/it]
{'loss': 0.8783, 'grad_norm': 0.25490431886679693, 'learning_rate': 6.508023606476052e-05, 'epoch': 0.63}

 63%|██████▎   | 1943/3106 [7:29:24<4:15:47, 13.20s/it]

 63%|██████▎   | 1944/3106 [7:29:35<4:06:56, 12.75s/it]

 63%|██████▎   | 1945/3106 [7:29:50<4:19:02, 13.39s/it]

 63%|██████▎   | 1946/3106 [7:30:02<4:11:01, 12.98s/it]


 63%|██████▎   | 1948/3106 [7:30:30<4:17:06, 13.32s/it]
{'loss': 0.8729, 'grad_norm': 0.27339857414296226, 'learning_rate': 6.449450406464039e-05, 'epoch': 0.63}

 63%|██████▎   | 1949/3106 [7:30:42<4:08:43, 12.90s/it]

 63%|██████▎   | 1950/3106 [7:30:54<4:07:30, 12.85s/it]

 63%|██████▎   | 1951/3106 [7:31:08<4:09:40, 12.97s/it]


 63%|██████▎   | 1953/3106 [7:31:36<4:25:21, 13.81s/it]
{'loss': 0.9083, 'grad_norm': 0.25382656039398177, 'learning_rate': 6.40074553180154e-05, 'epoch': 0.63}

 63%|██████▎   | 1954/3106 [7:31:54<4:47:57, 15.00s/it]

 63%|██████▎   | 1955/3106 [7:32:07<4:37:27, 14.46s/it]

 63%|██████▎   | 1956/3106 [7:32:21<4:32:28, 14.22s/it]

 63%|██████▎   | 1957/3106 [7:32:33<4:20:12, 13.59s/it]

 63%|██████▎   | 1958/3106 [7:32:45<4:12:41, 13.21s/it]


 63%|██████▎   | 1960/3106 [7:33:12<4:19:44, 13.60s/it]
{'loss': 0.9327, 'grad_norm': 0.2409474901220704, 'learning_rate': 6.332723459847861e-05, 'epoch': 0.63}


 63%|██████▎   | 1962/3106 [7:33:40<4:21:15, 13.70s/it]
{'loss': 0.9968, 'grad_norm': 0.26835948883707006, 'learning_rate': 6.313324330412692e-05, 'epoch': 0.63}

 63%|██████▎   | 1963/3106 [7:33:53<4:15:57, 13.44s/it]

 63%|██████▎   | 1964/3106 [7:34:07<4:18:00, 13.56s/it]

 63%|██████▎   | 1965/3106 [7:34:19<4:10:10, 13.16s/it]

 63%|██████▎   | 1966/3106 [7:34:33<4:10:49, 13.20s/it]

 63%|██████▎   | 1967/3106 [7:34:45<4:06:01, 12.96s/it]


 63%|██████▎   | 1969/3106 [7:35:10<4:01:34, 12.75s/it]
{'loss': 0.9752, 'grad_norm': 0.24058116387239706, 'learning_rate': 6.245554269079929e-05, 'epoch': 0.63}


 63%|██████▎   | 1971/3106 [7:35:36<4:03:35, 12.88s/it]
{'loss': 0.8509, 'grad_norm': 0.2605753741354982, 'learning_rate': 6.226227996753102e-05, 'epoch': 0.63}

 63%|██████▎   | 1972/3106 [7:35:49<4:00:17, 12.71s/it]

 64%|██████▎   | 1973/3106 [7:36:01<3:59:35, 12.69s/it]

 64%|██████▎   | 1974/3106 [7:36:15<4:07:31, 13.12s/it]


 64%|██████▎   | 1976/3106 [7:36:42<4:12:45, 13.42s/it]
{'loss': 0.8285, 'grad_norm': 0.24644490575302963, 'learning_rate': 6.177984345856262e-05, 'epoch': 0.64}

 64%|██████▎   | 1977/3106 [7:36:54<4:00:53, 12.80s/it]


 64%|██████▎   | 1979/3106 [7:37:20<4:06:51, 13.14s/it]
{'loss': 0.9958, 'grad_norm': 0.2556958880657244, 'learning_rate': 6.149087967093195e-05, 'epoch': 0.64}

 64%|██████▎   | 1980/3106 [7:37:35<4:15:09, 13.60s/it]

 64%|██████▍   | 1981/3106 [7:37:50<4:22:55, 14.02s/it]

 64%|██████▍   | 1982/3106 [7:38:07<4:42:32, 15.08s/it]

 64%|██████▍   | 1983/3106 [7:38:19<4:23:11, 14.06s/it]

 64%|██████▍   | 1984/3106 [7:38:37<4:43:27, 15.16s/it]


 64%|██████▍   | 1986/3106 [7:39:04<4:26:50, 14.29s/it]
{'loss': 0.9629, 'grad_norm': 0.22799909785776545, 'learning_rate': 6.081810201045681e-05, 'epoch': 0.64}

 64%|██████▍   | 1987/3106 [7:39:22<4:46:31, 15.36s/it]


 64%|██████▍   | 1989/3106 [7:39:53<4:44:30, 15.28s/it]
{'loss': 0.9506, 'grad_norm': 0.26152621384596875, 'learning_rate': 6.05304060283258e-05, 'epoch': 0.64}

 64%|██████▍   | 1990/3106 [7:40:04<4:21:10, 14.04s/it]

 64%|██████▍   | 1991/3106 [7:40:20<4:34:51, 14.79s/it]

 64%|██████▍   | 1992/3106 [7:40:33<4:24:58, 14.27s/it]

 64%|██████▍   | 1993/3106 [7:40:46<4:15:25, 13.77s/it]

 64%|██████▍   | 1994/3106 [7:41:01<4:22:10, 14.15s/it]


 64%|██████▍   | 1996/3106 [7:41:27<4:08:23, 13.43s/it]
{'loss': 0.9702, 'grad_norm': 0.2404099460626191, 'learning_rate': 5.986062313057084e-05, 'epoch': 0.64}

 64%|██████▍   | 1997/3106 [7:41:38<3:56:50, 12.81s/it]


 64%|██████▍   | 1999/3106 [7:42:03<3:49:30, 12.44s/it]
{'loss': 0.932, 'grad_norm': 0.26923804996238976, 'learning_rate': 5.957422625216168e-05, 'epoch': 0.64}

 64%|██████▍   | 2000/3106 [7:42:15<3:49:10, 12.43s/it]

 64%|██████▍   | 2001/3106 [7:42:32<4:10:46, 13.62s/it]


 64%|██████▍   | 2003/3106 [7:43:03<4:30:31, 14.72s/it]
{'loss': 0.8911, 'grad_norm': 0.24098848655555505, 'learning_rate': 5.9192979941194323e-05, 'epoch': 0.64}

 65%|██████▍   | 2004/3106 [7:43:17<4:30:11, 14.71s/it]

 65%|██████▍   | 2005/3106 [7:43:30<4:17:50, 14.05s/it]

 65%|██████▍   | 2006/3106 [7:43:42<4:05:59, 13.42s/it]

 65%|██████▍   | 2007/3106 [7:43:56<4:10:39, 13.68s/it]

 65%|██████▍   | 2008/3106 [7:44:12<4:22:18, 14.33s/it]

 65%|██████▍   | 2009/3106 [7:44:24<4:09:32, 13.65s/it]


 65%|██████▍   | 2011/3106 [7:44:51<4:06:39, 13.52s/it]
{'loss': 0.9402, 'grad_norm': 0.24380073914352568, 'learning_rate': 5.84326248539656e-05, 'epoch': 0.65}

 65%|██████▍   | 2012/3106 [7:45:04<4:02:41, 13.31s/it]

 65%|██████▍   | 2013/3106 [7:45:16<3:55:00, 12.90s/it]


 65%|██████▍   | 2015/3106 [7:45:41<3:53:14, 12.83s/it]

 65%|██████▍   | 2016/3106 [7:45:59<4:21:41, 14.40s/it]
{'loss': 1.013, 'grad_norm': 0.24013413339715858, 'learning_rate': 5.7958869253936724e-05, 'epoch': 0.65}


 65%|██████▍   | 2018/3106 [7:46:25<4:06:05, 13.57s/it]

 65%|██████▌   | 2019/3106 [7:46:37<3:57:20, 13.10s/it]

 65%|██████▌   | 2020/3106 [7:46:49<3:50:53, 12.76s/it]

 65%|██████▌   | 2021/3106 [7:47:03<3:58:04, 13.17s/it]

 65%|██████▌   | 2022/3106 [7:47:19<4:14:59, 14.11s/it]
{'loss': 0.9421, 'grad_norm': 0.2338971140964486, 'learning_rate': 5.739187297109223e-05, 'epoch': 0.65}

 65%|██████▌   | 2023/3106 [7:47:34<4:19:39, 14.39s/it]

 65%|██████▌   | 2024/3106 [7:47:48<4:14:30, 14.11s/it]


 65%|██████▌   | 2026/3106 [7:48:13<3:59:38, 13.31s/it]
{'loss': 0.9038, 'grad_norm': 0.24813090567545965, 'learning_rate': 5.7014801147514316e-05, 'epoch': 0.65}

 65%|██████▌   | 2027/3106 [7:48:25<3:51:29, 12.87s/it]


 65%|██████▌   | 2029/3106 [7:48:49<3:45:59, 12.59s/it]
{'loss': 0.8255, 'grad_norm': 0.2738131738525813, 'learning_rate': 5.6732487939387345e-05, 'epoch': 0.65}

 65%|██████▌   | 2030/3106 [7:49:03<3:50:34, 12.86s/it]

 65%|██████▌   | 2031/3106 [7:49:14<3:43:15, 12.46s/it]

 65%|██████▌   | 2032/3106 [7:49:26<3:40:00, 12.29s/it]


 65%|██████▌   | 2034/3106 [7:49:53<3:49:37, 12.85s/it]

 66%|██████▌   | 2035/3106 [7:50:05<3:46:35, 12.69s/it]
{'loss': 0.9671, 'grad_norm': 0.25827656226537843, 'learning_rate': 5.6169135194159826e-05, 'epoch': 0.66}


 66%|██████▌   | 2037/3106 [7:50:33<3:57:22, 13.32s/it]

 66%|██████▌   | 2038/3106 [7:50:45<3:50:17, 12.94s/it]

 66%|██████▌   | 2039/3106 [7:50:59<3:56:13, 13.28s/it]
{'loss': 0.8951, 'grad_norm': 0.25307024571902853, 'learning_rate': 5.579451900883833e-05, 'epoch': 0.66}

 66%|██████▌   | 2040/3106 [7:51:11<3:46:56, 12.77s/it]


 66%|██████▌   | 2042/3106 [7:51:37<3:48:42, 12.90s/it]

 66%|██████▌   | 2043/3106 [7:51:51<3:54:23, 13.23s/it]

 66%|██████▌   | 2044/3106 [7:52:05<3:59:15, 13.52s/it]

 66%|██████▌   | 2045/3106 [7:52:23<4:22:21, 14.84s/it]

 66%|██████▌   | 2046/3106 [7:52:39<4:27:39, 15.15s/it]
{'loss': 1.0204, 'grad_norm': 0.2590186340140722, 'learning_rate': 5.5140796109462164e-05, 'epoch': 0.66}

 66%|██████▌   | 2047/3106 [7:52:51<4:09:52, 14.16s/it]

 66%|██████▌   | 2048/3106 [7:53:09<4:29:17, 15.27s/it]

 66%|██████▌   | 2049/3106 [7:53:21<4:10:51, 14.24s/it]


 66%|██████▌   | 2051/3106 [7:53:48<4:05:06, 13.94s/it]
{'loss': 1.0098, 'grad_norm': 0.25112179896128467, 'learning_rate': 5.467531322055247e-05, 'epoch': 0.66}

 66%|██████▌   | 2052/3106 [7:54:00<3:57:44, 13.53s/it]

 66%|██████▌   | 2053/3106 [7:54:15<4:01:59, 13.79s/it]

 66%|██████▌   | 2054/3106 [7:54:26<3:50:35, 13.15s/it]


 66%|██████▌   | 2056/3106 [7:54:56<4:03:53, 13.94s/it]
{'loss': 1.0409, 'grad_norm': 0.24123170595579432, 'learning_rate': 5.421106304938356e-05, 'epoch': 0.66}

 66%|██████▌   | 2057/3106 [7:55:11<4:09:53, 14.29s/it]

 66%|██████▋   | 2058/3106 [7:55:25<4:06:52, 14.13s/it]

 66%|██████▋   | 2059/3106 [7:55:37<3:58:20, 13.66s/it]

 66%|██████▋   | 2060/3106 [7:55:57<4:28:38, 15.41s/it]

 66%|██████▋   | 2061/3106 [7:56:08<4:07:58, 14.24s/it]


 66%|██████▋   | 2063/3106 [7:56:38<4:13:35, 14.59s/it]

 66%|██████▋   | 2064/3106 [7:56:53<4:18:27, 14.88s/it]
{'loss': 1.0674, 'grad_norm': 0.25270445594794777, 'learning_rate': 5.347085833133688e-05, 'epoch': 0.66}

 66%|██████▋   | 2065/3106 [7:57:06<4:07:03, 14.24s/it]

 67%|██████▋   | 2066/3106 [7:57:21<4:08:50, 14.36s/it]

 67%|██████▋   | 2067/3106 [7:57:34<4:04:51, 14.14s/it]

 67%|██████▋   | 2068/3106 [7:57:49<4:08:19, 14.35s/it]

 67%|██████▋   | 2069/3106 [7:58:03<4:04:29, 14.15s/it]


 67%|██████▋   | 2071/3106 [7:58:28<3:50:02, 13.34s/it]
{'loss': 0.8752, 'grad_norm': 0.26166970481568824, 'learning_rate': 5.282583493702471e-05, 'epoch': 0.67}


 67%|██████▋   | 2073/3106 [7:58:52<3:38:37, 12.70s/it]

 67%|██████▋   | 2074/3106 [7:59:10<4:06:35, 14.34s/it]

 67%|██████▋   | 2075/3106 [7:59:22<3:55:10, 13.69s/it]
{'loss': 0.9985, 'grad_norm': 0.2485307999975243, 'learning_rate': 5.245837699456082e-05, 'epoch': 0.67}


 67%|██████▋   | 2077/3106 [7:59:50<4:00:22, 14.02s/it]
{'loss': 0.8335, 'grad_norm': 0.24452325392826876, 'learning_rate': 5.227495794746806e-05, 'epoch': 0.67}


 67%|██████▋   | 2079/3106 [8:00:22<4:20:44, 15.23s/it]
{'loss': 0.9637, 'grad_norm': 0.25138360366945034, 'learning_rate': 5.2091746580991615e-05, 'epoch': 0.67}

 67%|██████▋   | 2080/3106 [8:00:35<4:12:13, 14.75s/it]

 67%|██████▋   | 2081/3106 [8:00:49<4:07:20, 14.48s/it]


 67%|██████▋   | 2083/3106 [8:01:16<3:57:08, 13.91s/it]
{'loss': 0.9288, 'grad_norm': 0.25720267043581857, 'learning_rate': 5.172595007803567e-05, 'epoch': 0.67}

 67%|██████▋   | 2084/3106 [8:01:29<3:51:58, 13.62s/it]


 67%|██████▋   | 2086/3106 [8:01:56<3:52:26, 13.67s/it]
{'loss': 0.9211, 'grad_norm': 0.2522048973964019, 'learning_rate': 5.145215378547825e-05, 'epoch': 0.67}

 67%|██████▋   | 2087/3106 [8:02:08<3:42:01, 13.07s/it]

 67%|██████▋   | 2088/3106 [8:02:19<3:34:08, 12.62s/it]

 67%|██████▋   | 2089/3106 [8:02:31<3:28:38, 12.31s/it]


 67%|██████▋   | 2091/3106 [8:03:02<3:56:56, 14.01s/it]

 67%|██████▋   | 2092/3106 [8:03:14<3:47:40, 13.47s/it]
{'loss': 1.0909, 'grad_norm': 0.24797733216259316, 'learning_rate': 5.0905989888503924e-05, 'epoch': 0.67}

 67%|██████▋   | 2093/3106 [8:03:26<3:37:57, 12.91s/it]

 67%|██████▋   | 2094/3106 [8:03:38<3:32:33, 12.60s/it]


 67%|██████▋   | 2096/3106 [8:04:06<3:48:01, 13.55s/it]
{'loss': 0.9635, 'grad_norm': 0.2469436972654046, 'learning_rate': 5.0542947492600334e-05, 'epoch': 0.67}


 68%|██████▊   | 2098/3106 [8:04:38<4:07:25, 14.73s/it]
{'loss': 0.8428, 'grad_norm': 0.2444838746423494, 'learning_rate': 5.036174872639443e-05, 'epoch': 0.68}

 68%|██████▊   | 2099/3106 [8:04:50<3:49:42, 13.69s/it]

 68%|██████▊   | 2100/3106 [8:05:03<3:47:49, 13.59s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 68%|██████▊   | 2101/3106 [8:05:30<4:56:35, 17.71s/it]
{'loss': 0.9621, 'grad_norm': 0.23257345279248948, 'learning_rate': 5.0090355834768975e-05, 'epoch': 0.68}

 68%|██████▊   | 2102/3106 [8:05:44<4:34:43, 16.42s/it]

 68%|██████▊   | 2103/3106 [8:06:01<4:38:01, 16.63s/it]

 68%|██████▊   | 2104/3106 [8:06:17<4:36:11, 16.54s/it]


 68%|██████▊   | 2106/3106 [8:06:51<4:43:15, 17.00s/it]

 68%|██████▊   | 2107/3106 [8:07:04<4:26:41, 16.02s/it]
{'loss': 0.8553, 'grad_norm': 0.25961850325243085, 'learning_rate': 4.9549038716539865e-05, 'epoch': 0.68}


 68%|██████▊   | 2109/3106 [8:07:34<4:17:10, 15.48s/it]
{'loss': 0.7618, 'grad_norm': 0.26114168501146, 'learning_rate': 4.936903771663737e-05, 'epoch': 0.68}

 68%|██████▊   | 2110/3106 [8:07:48<4:07:11, 14.89s/it]


 68%|██████▊   | 2112/3106 [8:08:20<4:17:41, 15.55s/it]
{'loss': 1.0334, 'grad_norm': 0.28136862173482713, 'learning_rate': 4.909944957262298e-05, 'epoch': 0.68}

 68%|██████▊   | 2113/3106 [8:08:33<4:04:04, 14.75s/it]

 68%|██████▊   | 2114/3106 [8:08:45<3:50:37, 13.95s/it]

 68%|██████▊   | 2115/3106 [8:08:59<3:48:35, 13.84s/it]

 68%|██████▊   | 2116/3106 [8:09:13<3:49:53, 13.93s/it]

 68%|██████▊   | 2117/3106 [8:09:26<3:43:23, 13.55s/it]

 68%|██████▊   | 2118/3106 [8:09:38<3:36:17, 13.14s/it]


 68%|██████▊   | 2120/3106 [8:10:07<3:48:38, 13.91s/it]
{'loss': 0.9496, 'grad_norm': 0.24149296056597683, 'learning_rate': 4.8382991498849615e-05, 'epoch': 0.68}

 68%|██████▊   | 2121/3106 [8:10:19<3:42:08, 13.53s/it]

 68%|██████▊   | 2122/3106 [8:10:32<3:38:09, 13.30s/it]

 68%|██████▊   | 2123/3106 [8:10:45<3:35:19, 13.14s/it]

 68%|██████▊   | 2124/3106 [8:10:58<3:35:48, 13.19s/it]

 68%|██████▊   | 2125/3106 [8:11:16<3:56:38, 14.47s/it]

 68%|██████▊   | 2126/3106 [8:11:29<3:50:05, 14.09s/it]

 68%|██████▊   | 2127/3106 [8:11:44<3:55:33, 14.44s/it]


 69%|██████▊   | 2129/3106 [8:12:17<4:09:49, 15.34s/it]
{'loss': 0.9798, 'grad_norm': 0.25138734455757045, 'learning_rate': 4.758127441588257e-05, 'epoch': 0.69}

 69%|██████▊   | 2130/3106 [8:12:32<4:10:09, 15.38s/it]

 69%|██████▊   | 2131/3106 [8:12:44<3:52:11, 14.29s/it]


 69%|██████▊   | 2133/3106 [8:13:07<3:26:40, 12.74s/it]
{'loss': 0.9062, 'grad_norm': 0.26671662612977265, 'learning_rate': 4.722643420423493e-05, 'epoch': 0.69}


 69%|██████▊   | 2135/3106 [8:13:37<3:45:06, 13.91s/it]
{'loss': 0.9294, 'grad_norm': 0.22833062234712512, 'learning_rate': 4.7049358187338476e-05, 'epoch': 0.69}

 69%|██████▉   | 2136/3106 [8:13:49<3:39:28, 13.58s/it]

 69%|██████▉   | 2137/3106 [8:14:01<3:29:54, 13.00s/it]


 69%|██████▉   | 2139/3106 [8:14:35<4:03:33, 15.11s/it]
{'loss': 0.9031, 'grad_norm': 0.2569566055143643, 'learning_rate': 4.6695898184222906e-05, 'epoch': 0.69}

 69%|██████▉   | 2140/3106 [8:14:50<4:06:32, 15.31s/it]


 69%|██████▉   | 2142/3106 [8:15:17<3:46:33, 14.10s/it]

 69%|██████▉   | 2143/3106 [8:15:31<3:43:59, 13.96s/it]
{'loss': 0.8065, 'grad_norm': 0.25179426107021563, 'learning_rate': 4.634336601406023e-05, 'epoch': 0.69}

 69%|██████▉   | 2144/3106 [8:15:44<3:39:28, 13.69s/it]


 69%|██████▉   | 2146/3106 [8:16:11<3:37:30, 13.59s/it]

 69%|██████▉   | 2147/3106 [8:16:23<3:28:29, 13.04s/it]
{'loss': 0.8964, 'grad_norm': 0.2911375408021466, 'learning_rate': 4.599176781316922e-05, 'epoch': 0.69}


 69%|██████▉   | 2149/3106 [8:16:47<3:21:36, 12.64s/it]

 69%|██████▉   | 2150/3106 [8:17:01<3:25:57, 12.93s/it]
{'loss': 0.9463, 'grad_norm': 0.21259920232125207, 'learning_rate': 4.5728685762049414e-05, 'epoch': 0.69}

 69%|██████▉   | 2151/3106 [8:17:16<3:37:44, 13.68s/it]

 69%|██████▉   | 2152/3106 [8:17:31<3:40:52, 13.89s/it]

 69%|██████▉   | 2153/3106 [8:17:43<3:31:31, 13.32s/it]

 69%|██████▉   | 2154/3106 [8:17:56<3:31:39, 13.34s/it]

 69%|██████▉   | 2155/3106 [8:18:08<3:23:43, 12.85s/it]

 69%|██████▉   | 2156/3106 [8:18:24<3:41:32, 13.99s/it]


 69%|██████▉   | 2158/3106 [8:18:51<3:36:48, 13.72s/it]
{'loss': 0.9975, 'grad_norm': 0.2407439290556246, 'learning_rate': 4.5029738445839143e-05, 'epoch': 0.69}

 70%|██████▉   | 2159/3106 [8:19:05<3:36:01, 13.69s/it]

 70%|██████▉   | 2160/3106 [8:19:16<3:24:14, 12.95s/it]

 70%|██████▉   | 2161/3106 [8:19:34<3:48:27, 14.51s/it]

 70%|██████▉   | 2162/3106 [8:19:52<4:05:31, 15.61s/it]

 70%|██████▉   | 2163/3106 [8:20:07<4:04:24, 15.55s/it]


 70%|██████▉   | 2165/3106 [8:20:39<4:07:18, 15.77s/it]
{'loss': 0.9312, 'grad_norm': 0.2584871254558278, 'learning_rate': 4.442129748790343e-05, 'epoch': 0.7}

 70%|██████▉   | 2166/3106 [8:20:52<3:53:08, 14.88s/it]

 70%|██████▉   | 2167/3106 [8:21:04<3:38:13, 13.94s/it]

 70%|██████▉   | 2168/3106 [8:21:16<3:29:47, 13.42s/it]

 70%|██████▉   | 2169/3106 [8:21:28<3:23:12, 13.01s/it]

 70%|██████▉   | 2170/3106 [8:21:40<3:19:21, 12.78s/it]

 70%|██████▉   | 2171/3106 [8:21:52<3:13:14, 12.40s/it]

 70%|██████▉   | 2172/3106 [8:22:04<3:13:00, 12.40s/it]


 70%|██████▉   | 2174/3106 [8:22:31<3:21:33, 12.98s/it]
{'loss': 1.0058, 'grad_norm': 0.25128961733264676, 'learning_rate': 4.364337417912395e-05, 'epoch': 0.7}

 70%|███████   | 2175/3106 [8:22:44<3:22:02, 13.02s/it]

 70%|███████   | 2176/3106 [8:22:57<3:17:34, 12.75s/it]

 70%|███████   | 2177/3106 [8:23:15<3:43:41, 14.45s/it]


 70%|███████   | 2179/3106 [8:23:43<3:41:47, 14.36s/it]
{'loss': 0.8543, 'grad_norm': 0.29314614937549516, 'learning_rate': 4.321333604417304e-05, 'epoch': 0.7}

 70%|███████   | 2180/3106 [8:23:55<3:28:46, 13.53s/it]

 70%|███████   | 2181/3106 [8:24:10<3:36:11, 14.02s/it]

 70%|███████   | 2182/3106 [8:24:23<3:28:57, 13.57s/it]

 70%|███████   | 2183/3106 [8:24:35<3:21:28, 13.10s/it]


 70%|███████   | 2185/3106 [8:25:02<3:23:38, 13.27s/it]

 70%|███████   | 2186/3106 [8:25:14<3:17:38, 12.89s/it]
{'loss': 1.0431, 'grad_norm': 0.24677083800774857, 'learning_rate': 4.2613879951137326e-05, 'epoch': 0.7}


 70%|███████   | 2188/3106 [8:25:40<3:17:37, 12.92s/it]
{'loss': 0.966, 'grad_norm': 0.25678121887728256, 'learning_rate': 4.244316726012446e-05, 'epoch': 0.7}

 70%|███████   | 2189/3106 [8:25:54<3:24:07, 13.36s/it]

 71%|███████   | 2190/3106 [8:26:08<3:29:18, 13.71s/it]

 71%|███████   | 2191/3106 [8:26:27<3:50:34, 15.12s/it]

 71%|███████   | 2192/3106 [8:26:41<3:47:25, 14.93s/it]


 71%|███████   | 2194/3106 [8:27:09<3:40:25, 14.50s/it]
{'loss': 0.9111, 'grad_norm': 0.24436018074214527, 'learning_rate': 4.1932534941350545e-05, 'epoch': 0.71}

 71%|███████   | 2195/3106 [8:27:24<3:42:03, 14.63s/it]


 71%|███████   | 2197/3106 [8:27:51<3:33:23, 14.08s/it]
{'loss': 0.9183, 'grad_norm': 0.245815523495877, 'learning_rate': 4.1678070350911494e-05, 'epoch': 0.71}

 71%|███████   | 2198/3106 [8:28:07<3:37:54, 14.40s/it]

 71%|███████   | 2199/3106 [8:28:19<3:27:10, 13.70s/it]


 71%|███████   | 2201/3106 [8:28:44<3:18:07, 13.14s/it]
{'loss': 0.9243, 'grad_norm': 0.23807856255568133, 'learning_rate': 4.133967293911124e-05, 'epoch': 0.71}


 71%|███████   | 2203/3106 [8:29:08<3:10:42, 12.67s/it]
{'loss': 0.8577, 'grad_norm': 0.26132654870123073, 'learning_rate': 4.117085676535979e-05, 'epoch': 0.71}

 71%|███████   | 2204/3106 [8:29:19<3:03:29, 12.21s/it]


 71%|███████   | 2206/3106 [8:29:48<3:21:09, 13.41s/it]

 71%|███████   | 2207/3106 [8:30:00<3:14:07, 12.96s/it]
{'loss': 1.0824, 'grad_norm': 0.2626360539974716, 'learning_rate': 4.083399315525925e-05, 'epoch': 0.71}

 71%|███████   | 2208/3106 [8:30:13<3:15:28, 13.06s/it]

 71%|███████   | 2209/3106 [8:30:25<3:08:11, 12.59s/it]


 71%|███████   | 2211/3106 [8:30:52<3:16:33, 13.18s/it]
{'loss': 0.9533, 'grad_norm': 0.2728968526965012, 'learning_rate': 4.049815941282307e-05, 'epoch': 0.71}


 71%|███████   | 2213/3106 [8:31:16<3:06:53, 12.56s/it]
{'loss': 0.9736, 'grad_norm': 0.2575348925624344, 'learning_rate': 4.033063056945067e-05, 'epoch': 0.71}

 71%|███████▏  | 2214/3106 [8:31:29<3:08:12, 12.66s/it]


 71%|███████▏  | 2216/3106 [8:31:54<3:07:35, 12.65s/it]
{'loss': 1.1089, 'grad_norm': 0.253329507924607, 'learning_rate': 4.0079824389962254e-05, 'epoch': 0.71}

 71%|███████▏  | 2217/3106 [8:32:07<3:08:28, 12.72s/it]

 71%|███████▏  | 2218/3106 [8:32:21<3:13:59, 13.11s/it]

 71%|███████▏  | 2219/3106 [8:32:32<3:06:46, 12.63s/it]

 71%|███████▏  | 2220/3106 [8:32:45<3:04:46, 12.51s/it]


 72%|███████▏  | 2222/3106 [8:33:12<3:14:51, 13.23s/it]
{'loss': 0.9427, 'grad_norm': 0.24671300251300074, 'learning_rate': 3.957997453614859e-05, 'epoch': 0.72}


 72%|███████▏  | 2224/3106 [8:33:38<3:11:29, 13.03s/it]

 72%|███████▏  | 2225/3106 [8:33:52<3:15:58, 13.35s/it]
{'loss': 1.0057, 'grad_norm': 0.24160335665430974, 'learning_rate': 3.933093575590866e-05, 'epoch': 0.72}

 72%|███████▏  | 2226/3106 [8:34:07<3:22:04, 13.78s/it]

 72%|███████▏  | 2227/3106 [8:34:21<3:22:09, 13.80s/it]

 72%|███████▏  | 2228/3106 [8:34:33<3:14:04, 13.26s/it]

 72%|███████▏  | 2229/3106 [8:34:45<3:09:25, 12.96s/it]

 72%|███████▏  | 2230/3106 [8:35:00<3:16:39, 13.47s/it]

 72%|███████▏  | 2231/3106 [8:35:16<3:27:57, 14.26s/it]

 72%|███████▏  | 2232/3106 [8:35:31<3:30:35, 14.46s/it]

 72%|███████▏  | 2233/3106 [8:35:47<3:38:25, 15.01s/it]

 72%|███████▏  | 2234/3106 [8:35:59<3:25:40, 14.15s/it]

 72%|███████▏  | 2235/3106 [8:36:13<3:25:35, 14.16s/it]

 72%|███████▏  | 2236/3106 [8:36:27<3:24:17, 14.09s/it]

 72%|███████▏  | 2237/3106 [8:36:42<3:25:28, 14.19s/it]

 72%|███████▏  | 2238/3106 [8:36:54<3:15:15, 13.50s/it]


 72%|███████▏  | 2240/3106 [8:37:18<3:05:52, 12.88s/it]
{'loss': 0.9398, 'grad_norm': 0.2641968147920448, 'learning_rate': 3.809470068092772e-05, 'epoch': 0.72}
[2024-05-29 05:30:40,758] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 72%|███████▏  | 2242/3106 [8:37:53<3:33:43, 14.84s/it]
{'loss': 0.9116, 'grad_norm': 0.26712367481341004, 'learning_rate': 3.793100764964299e-05, 'epoch': 0.72}

 72%|███████▏  | 2243/3106 [8:38:10<3:44:35, 15.61s/it]

 72%|███████▏  | 2244/3106 [8:38:24<3:36:31, 15.07s/it]

 72%|███████▏  | 2245/3106 [8:38:37<3:29:30, 14.60s/it]


 72%|███████▏  | 2247/3106 [8:39:00<3:06:22, 13.02s/it]
{'loss': 0.9137, 'grad_norm': 0.26070718946577265, 'learning_rate': 3.7522958313587994e-05, 'epoch': 0.72}

 72%|███████▏  | 2248/3106 [8:39:18<3:26:08, 14.42s/it]


 72%|███████▏  | 2250/3106 [8:39:46<3:25:15, 14.39s/it]
{'loss': 0.9807, 'grad_norm': 0.25651718005309976, 'learning_rate': 3.727894362860799e-05, 'epoch': 0.72}

 72%|███████▏  | 2251/3106 [8:40:00<3:22:12, 14.19s/it]

 73%|███████▎  | 2252/3106 [8:40:17<3:35:25, 15.14s/it]

 73%|███████▎  | 2253/3106 [8:40:29<3:22:09, 14.22s/it]

 73%|███████▎  | 2254/3106 [8:40:42<3:14:42, 13.71s/it]

 73%|███████▎  | 2255/3106 [8:40:57<3:20:11, 14.11s/it]


 73%|███████▎  | 2257/3106 [8:41:20<3:02:08, 12.87s/it]
{'loss': 0.955, 'grad_norm': 0.2653783881121983, 'learning_rate': 3.671196834943599e-05, 'epoch': 0.73}


 73%|███████▎  | 2259/3106 [8:41:48<3:11:03, 13.53s/it]
{'loss': 0.8529, 'grad_norm': 0.24725283029257078, 'learning_rate': 3.6550593753155896e-05, 'epoch': 0.73}

 73%|███████▎  | 2260/3106 [8:42:06<3:27:58, 14.75s/it]

 73%|███████▎  | 2261/3106 [8:42:17<3:12:06, 13.64s/it]


 73%|███████▎  | 2263/3106 [8:42:43<3:05:22, 13.19s/it]
{'loss': 0.9238, 'grad_norm': 0.27075860830899695, 'learning_rate': 3.622867358223122e-05, 'epoch': 0.73}

 73%|███████▎  | 2264/3106 [8:42:56<3:05:01, 13.18s/it]

 73%|███████▎  | 2265/3106 [8:43:12<3:15:20, 13.94s/it]

 73%|███████▎  | 2266/3106 [8:43:25<3:14:56, 13.92s/it]

 73%|███████▎  | 2267/3106 [8:43:40<3:15:20, 13.97s/it]

 73%|███████▎  | 2268/3106 [8:43:56<3:24:21, 14.63s/it]

 73%|███████▎  | 2269/3106 [8:44:09<3:18:58, 14.26s/it]


 73%|███████▎  | 2271/3106 [8:44:37<3:17:35, 14.20s/it]
{'loss': 0.9662, 'grad_norm': 0.25495425130369653, 'learning_rate': 3.558816891374387e-05, 'epoch': 0.73}


 73%|███████▎  | 2273/3106 [8:45:04<3:10:42, 13.74s/it]

 73%|███████▎  | 2274/3106 [8:45:21<3:24:49, 14.77s/it]
{'loss': 0.9792, 'grad_norm': 0.25954116832070384, 'learning_rate': 3.534913348815176e-05, 'epoch': 0.73}

 73%|███████▎  | 2275/3106 [8:45:34<3:18:12, 14.31s/it]


 73%|███████▎  | 2277/3106 [8:46:03<3:21:11, 14.56s/it]

 73%|███████▎  | 2278/3106 [8:46:16<3:13:25, 14.02s/it]
{'loss': 0.9425, 'grad_norm': 0.24929022835574505, 'learning_rate': 3.503140466356151e-05, 'epoch': 0.73}

 73%|███████▎  | 2279/3106 [8:46:29<3:08:46, 13.70s/it]


 73%|███████▎  | 2281/3106 [8:47:04<3:34:50, 15.62s/it]
{'loss': 0.8886, 'grad_norm': 0.24840489467136628, 'learning_rate': 3.479384987677187e-05, 'epoch': 0.73}

 73%|███████▎  | 2282/3106 [8:47:18<3:31:18, 15.39s/it]

 74%|███████▎  | 2283/3106 [8:47:32<3:23:41, 14.85s/it]

 74%|███████▎  | 2284/3106 [8:47:47<3:23:16, 14.84s/it]

 74%|███████▎  | 2285/3106 [8:47:59<3:10:27, 13.92s/it]

 74%|███████▎  | 2286/3106 [8:48:12<3:09:39, 13.88s/it]

 74%|███████▎  | 2287/3106 [8:48:25<3:02:49, 13.39s/it]


 74%|███████▎  | 2289/3106 [8:48:50<2:57:11, 13.01s/it]

 74%|███████▎  | 2290/3106 [8:49:03<3:00:06, 13.24s/it]
{'loss': 0.9091, 'grad_norm': 0.23716741606931735, 'learning_rate': 3.4085025432671746e-05, 'epoch': 0.74}

 74%|███████▍  | 2291/3106 [8:49:16<2:57:24, 13.06s/it]

 74%|███████▍  | 2292/3106 [8:49:31<3:05:40, 13.69s/it]

 74%|███████▍  | 2293/3106 [8:49:46<3:10:52, 14.09s/it]

 74%|███████▍  | 2294/3106 [8:50:01<3:12:26, 14.22s/it]

 74%|███████▍  | 2295/3106 [8:50:14<3:10:01, 14.06s/it]

 74%|███████▍  | 2296/3106 [8:50:30<3:17:10, 14.61s/it]


 74%|███████▍  | 2298/3106 [8:50:59<3:16:22, 14.58s/it]
{'loss': 0.8961, 'grad_norm': 0.24166875375096966, 'learning_rate': 3.345983350831798e-05, 'epoch': 0.74}

 74%|███████▍  | 2299/3106 [8:51:13<3:11:23, 14.23s/it]

 74%|███████▍  | 2300/3106 [8:51:24<3:00:09, 13.41s/it]

 74%|███████▍  | 2301/3106 [8:51:36<2:53:39, 12.94s/it]

 74%|███████▍  | 2302/3106 [8:51:51<3:00:48, 13.49s/it]


 74%|███████▍  | 2304/3106 [8:52:21<3:11:49, 14.35s/it]
{'loss': 1.014, 'grad_norm': 0.24531571366848845, 'learning_rate': 3.299397752482361e-05, 'epoch': 0.74}


 74%|███████▍  | 2306/3106 [8:52:48<3:04:38, 13.85s/it]
{'loss': 0.9378, 'grad_norm': 0.23616157471173382, 'learning_rate': 3.283927446499185e-05, 'epoch': 0.74}

 74%|███████▍  | 2307/3106 [8:53:01<3:04:06, 13.82s/it]


 74%|███████▍  | 2309/3106 [8:53:30<3:03:54, 13.85s/it]
{'loss': 1.1685, 'grad_norm': 0.2554760248912144, 'learning_rate': 3.260776806727657e-05, 'epoch': 0.74}

 74%|███████▍  | 2310/3106 [8:53:44<3:06:46, 14.08s/it]

 74%|███████▍  | 2311/3106 [8:53:57<2:59:31, 13.55s/it]


 74%|███████▍  | 2313/3106 [8:54:22<2:51:55, 13.01s/it]
{'loss': 0.9121, 'grad_norm': 0.28055334887085626, 'learning_rate': 3.2300119686429176e-05, 'epoch': 0.74}

 75%|███████▍  | 2314/3106 [8:54:34<2:50:57, 12.95s/it]

 75%|███████▍  | 2315/3106 [8:54:47<2:50:38, 12.94s/it]

 75%|███████▍  | 2316/3106 [8:55:02<2:55:42, 13.35s/it]

 75%|███████▍  | 2317/3106 [8:55:16<2:58:01, 13.54s/it]

 75%|███████▍  | 2318/3106 [8:55:27<2:51:00, 13.02s/it]

 75%|███████▍  | 2319/3106 [8:55:41<2:52:23, 13.14s/it]

 75%|███████▍  | 2320/3106 [8:55:53<2:46:38, 12.72s/it]

 75%|███████▍  | 2321/3106 [8:56:05<2:44:26, 12.57s/it]

 75%|███████▍  | 2322/3106 [8:56:21<2:57:52, 13.61s/it]


 75%|███████▍  | 2324/3106 [8:56:46<2:51:30, 13.16s/it]
{'loss': 0.9101, 'grad_norm': 0.25368080728391124, 'learning_rate': 3.1460178858362955e-05, 'epoch': 0.75}

 75%|███████▍  | 2325/3106 [8:57:01<2:56:20, 13.55s/it]

 75%|███████▍  | 2326/3106 [8:57:15<3:00:20, 13.87s/it]

 75%|███████▍  | 2327/3106 [8:57:28<2:53:28, 13.36s/it]

 75%|███████▍  | 2328/3106 [8:57:39<2:46:29, 12.84s/it]

 75%|███████▍  | 2329/3106 [8:57:58<3:07:48, 14.50s/it]

 75%|███████▌  | 2330/3106 [8:58:09<2:56:05, 13.62s/it]


 75%|███████▌  | 2332/3106 [8:58:38<3:06:02, 14.42s/it]

 75%|███████▌  | 2333/3106 [8:58:52<3:04:23, 14.31s/it]

 75%|███████▌  | 2334/3106 [8:59:04<2:53:42, 13.50s/it]
{'loss': 0.9216, 'grad_norm': 0.23118411655639942, 'learning_rate': 3.070442260125939e-05, 'epoch': 0.75}


 75%|███████▌  | 2336/3106 [8:59:30<2:52:05, 13.41s/it]
{'loss': 0.974, 'grad_norm': 0.2728244215271987, 'learning_rate': 3.0554173366674944e-05, 'epoch': 0.75}


 75%|███████▌  | 2338/3106 [9:00:02<3:06:32, 14.57s/it]
{'loss': 0.9978, 'grad_norm': 0.26886891685954845, 'learning_rate': 3.0404226333020114e-05, 'epoch': 0.75}

 75%|███████▌  | 2339/3106 [9:00:15<2:59:08, 14.01s/it]

 75%|███████▌  | 2340/3106 [9:00:28<2:54:22, 13.66s/it]

 75%|███████▌  | 2341/3106 [9:00:41<2:50:56, 13.41s/it]

 75%|███████▌  | 2342/3106 [9:00:53<2:47:45, 13.17s/it]

 75%|███████▌  | 2343/3106 [9:01:07<2:48:37, 13.26s/it]

 75%|███████▌  | 2344/3106 [9:01:19<2:44:59, 12.99s/it]


 76%|███████▌  | 2346/3106 [9:01:46<2:46:53, 13.18s/it]
{'loss': 0.9408, 'grad_norm': 0.23109183453092688, 'learning_rate': 2.9807473238122098e-05, 'epoch': 0.76}


 76%|███████▌  | 2348/3106 [9:02:10<2:38:23, 12.54s/it]
{'loss': 1.0728, 'grad_norm': 0.2678320331420091, 'learning_rate': 2.965904697037287e-05, 'epoch': 0.76}


 76%|███████▌  | 2350/3106 [9:02:39<2:50:14, 13.51s/it]

 76%|███████▌  | 2351/3106 [9:02:50<2:43:35, 13.00s/it]

 76%|███████▌  | 2352/3106 [9:03:07<2:55:01, 13.93s/it]
{'loss': 0.9352, 'grad_norm': 0.22953851937046416, 'learning_rate': 2.936311336793831e-05, 'epoch': 0.76}

 76%|███████▌  | 2353/3106 [9:03:19<2:49:53, 13.54s/it]


 76%|███████▌  | 2355/3106 [9:03:46<2:48:40, 13.48s/it]
{'loss': 0.9578, 'grad_norm': 0.2661345001180335, 'learning_rate': 2.9141969767215605e-05, 'epoch': 0.76}

 76%|███████▌  | 2356/3106 [9:03:58<2:40:20, 12.83s/it]

 76%|███████▌  | 2357/3106 [9:04:13<2:50:58, 13.70s/it]

 76%|███████▌  | 2358/3106 [9:04:30<3:02:42, 14.66s/it]

 76%|███████▌  | 2359/3106 [9:04:44<2:59:29, 14.42s/it]

 76%|███████▌  | 2360/3106 [9:04:56<2:48:29, 13.55s/it]

 76%|███████▌  | 2361/3106 [9:05:12<2:57:17, 14.28s/it]

 76%|███████▌  | 2362/3106 [9:05:27<3:01:16, 14.62s/it]

 76%|███████▌  | 2363/3106 [9:05:42<3:02:28, 14.74s/it]

 76%|███████▌  | 2364/3106 [9:05:54<2:52:40, 13.96s/it]

 76%|███████▌  | 2365/3106 [9:06:06<2:44:28, 13.32s/it]

 76%|███████▌  | 2366/3106 [9:06:18<2:39:26, 12.93s/it]


 76%|███████▌  | 2368/3106 [9:06:45<2:42:05, 13.18s/it]
{'loss': 0.7904, 'grad_norm': 0.25741141838018705, 'learning_rate': 2.819172549284792e-05, 'epoch': 0.76}


 76%|███████▋  | 2370/3106 [9:07:11<2:41:13, 13.14s/it]
{'loss': 0.926, 'grad_norm': 0.27640915462520727, 'learning_rate': 2.804670151261891e-05, 'epoch': 0.76}

 76%|███████▋  | 2371/3106 [9:07:23<2:37:53, 12.89s/it]

 76%|███████▋  | 2372/3106 [9:07:36<2:38:58, 12.99s/it]

 76%|███████▋  | 2373/3106 [9:07:49<2:38:32, 12.98s/it]

 76%|███████▋  | 2374/3106 [9:08:04<2:45:57, 13.60s/it]


 76%|███████▋  | 2376/3106 [9:08:29<2:36:30, 12.86s/it]
{'loss': 0.9579, 'grad_norm': 0.25357045671914064, 'learning_rate': 2.7613510764232542e-05, 'epoch': 0.76}


 77%|███████▋  | 2378/3106 [9:08:57<2:43:17, 13.46s/it]
{'loss': 0.939, 'grad_norm': 0.236202736687353, 'learning_rate': 2.7469743006732963e-05, 'epoch': 0.77}


 77%|███████▋  | 2380/3106 [9:09:21<2:35:04, 12.82s/it]
{'loss': 0.9945, 'grad_norm': 0.24066309379766804, 'learning_rate': 2.732629087239106e-05, 'epoch': 0.77}

 77%|███████▋  | 2381/3106 [9:09:34<2:35:34, 12.88s/it]

 77%|███████▋  | 2382/3106 [9:09:52<2:55:10, 14.52s/it]

 77%|███████▋  | 2383/3106 [9:10:04<2:43:31, 13.57s/it]

 77%|███████▋  | 2384/3106 [9:10:16<2:39:00, 13.21s/it]

 77%|███████▋  | 2385/3106 [9:10:29<2:39:52, 13.30s/it]

 77%|███████▋  | 2386/3106 [9:10:45<2:46:08, 13.84s/it]

 77%|███████▋  | 2387/3106 [9:10:59<2:46:31, 13.90s/it]


 77%|███████▋  | 2389/3106 [9:11:27<2:46:14, 13.91s/it]

 77%|███████▋  | 2390/3106 [9:11:39<2:39:52, 13.40s/it]

 77%|███████▋  | 2391/3106 [9:11:53<2:40:30, 13.47s/it]
{'loss': 0.8168, 'grad_norm': 0.28374624340454396, 'learning_rate': 2.6542973724223476e-05, 'epoch': 0.77}


 77%|███████▋  | 2393/3106 [9:12:21<2:44:08, 13.81s/it]
{'loss': 0.9576, 'grad_norm': 0.2524944262608573, 'learning_rate': 2.6401588294799574e-05, 'epoch': 0.77}


 77%|███████▋  | 2395/3106 [9:12:47<2:38:33, 13.38s/it]
{'loss': 1.0255, 'grad_norm': 0.2520114454538273, 'learning_rate': 2.626052313672267e-05, 'epoch': 0.77}


 77%|███████▋  | 2397/3106 [9:13:15<2:44:53, 13.95s/it]
{'loss': 0.9319, 'grad_norm': 0.22488545255824186, 'learning_rate': 2.6119778863852816e-05, 'epoch': 0.77}

 77%|███████▋  | 2398/3106 [9:13:29<2:43:24, 13.85s/it]

 77%|███████▋  | 2399/3106 [9:13:40<2:35:00, 13.16s/it]

 77%|███████▋  | 2400/3106 [9:13:54<2:37:57, 13.42s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.9224, 'grad_norm': 0.2832809188913829, 'learning_rate': 2.5839255422190134e-05, 'epoch': 0.77}

 77%|███████▋  | 2402/3106 [9:14:35<3:10:51, 16.27s/it]
{'loss': 0.9482, 'grad_norm': 0.2522776940689748, 'learning_rate': 2.5769326070308676e-05, 'epoch': 0.77}

 77%|███████▋  | 2403/3106 [9:14:48<2:58:45, 15.26s/it]


 77%|███████▋  | 2405/3106 [9:15:19<3:04:50, 15.82s/it]
{'loss': 0.8993, 'grad_norm': 0.2371643151387145, 'learning_rate': 2.5560022852717114e-05, 'epoch': 0.77}

 77%|███████▋  | 2406/3106 [9:15:33<2:54:59, 15.00s/it]

 77%|███████▋  | 2407/3106 [9:15:46<2:51:06, 14.69s/it]


 78%|███████▊  | 2409/3106 [9:16:17<2:54:12, 15.00s/it]

 78%|███████▊  | 2410/3106 [9:16:29<2:43:40, 14.11s/it]
{'loss': 1.0145, 'grad_norm': 0.2760967159651684, 'learning_rate': 2.5212804832316784e-05, 'epoch': 0.78}

 78%|███████▊  | 2411/3106 [9:16:42<2:39:27, 13.77s/it]

 78%|███████▊  | 2412/3106 [9:16:55<2:34:56, 13.40s/it]

 78%|███████▊  | 2413/3106 [9:17:10<2:42:24, 14.06s/it]


 78%|███████▊  | 2415/3106 [9:17:41<2:50:46, 14.83s/it]

 78%|███████▊  | 2416/3106 [9:17:56<2:49:24, 14.73s/it]
{'loss': 0.9268, 'grad_norm': 0.23908427998035983, 'learning_rate': 2.4798828946694807e-05, 'epoch': 0.78}

 78%|███████▊  | 2417/3106 [9:18:11<2:49:54, 14.80s/it]

 78%|███████▊  | 2418/3106 [9:18:22<2:39:42, 13.93s/it]

 78%|███████▊  | 2419/3106 [9:18:41<2:55:18, 15.31s/it]

 78%|███████▊  | 2420/3106 [9:18:52<2:41:35, 14.13s/it]

 78%|███████▊  | 2421/3106 [9:19:07<2:43:36, 14.33s/it]

 78%|███████▊  | 2422/3106 [9:19:23<2:48:14, 14.76s/it]

 78%|███████▊  | 2423/3106 [9:19:38<2:48:50, 14.83s/it]

 78%|███████▊  | 2424/3106 [9:19:54<2:53:37, 15.27s/it]


 78%|███████▊  | 2426/3106 [9:20:23<2:48:01, 14.83s/it]
{'loss': 1.012, 'grad_norm': 0.2510456830563537, 'learning_rate': 2.4115421991116606e-05, 'epoch': 0.78}

 78%|███████▊  | 2427/3106 [9:20:36<2:39:53, 14.13s/it]

 78%|███████▊  | 2428/3106 [9:20:49<2:36:30, 13.85s/it]

 78%|███████▊  | 2429/3106 [9:21:03<2:36:32, 13.87s/it]

 78%|███████▊  | 2430/3106 [9:21:18<2:40:35, 14.25s/it]

 78%|███████▊  | 2431/3106 [9:21:32<2:39:42, 14.20s/it]

 78%|███████▊  | 2432/3106 [9:21:51<2:54:17, 15.51s/it]

 78%|███████▊  | 2433/3106 [9:22:03<2:42:22, 14.48s/it]


 78%|███████▊  | 2435/3106 [9:22:32<2:42:43, 14.55s/it]
{'loss': 0.9652, 'grad_norm': 0.26858619005820905, 'learning_rate': 2.350741201844714e-05, 'epoch': 0.78}


 78%|███████▊  | 2437/3106 [9:23:02<2:42:17, 14.56s/it]
{'loss': 0.9554, 'grad_norm': 0.2515811020263862, 'learning_rate': 2.337321219060007e-05, 'epoch': 0.78}

 78%|███████▊  | 2438/3106 [9:23:15<2:39:48, 14.35s/it]


 79%|███████▊  | 2440/3106 [9:23:44<2:38:27, 14.28s/it]
{'loss': 0.9371, 'grad_norm': 0.2498718080491947, 'learning_rate': 2.317253784901976e-05, 'epoch': 0.79}


 79%|███████▊  | 2442/3106 [9:24:14<2:39:17, 14.39s/it]
{'loss': 0.9786, 'grad_norm': 0.2738738622775169, 'learning_rate': 2.303917273709181e-05, 'epoch': 0.79}

 79%|███████▊  | 2443/3106 [9:24:27<2:33:32, 13.90s/it]

 79%|███████▊  | 2444/3106 [9:24:41<2:36:15, 14.16s/it]


 79%|███████▉  | 2446/3106 [9:25:12<2:39:17, 14.48s/it]
{'loss': 0.9369, 'grad_norm': 0.2600467296943181, 'learning_rate': 2.277344780190286e-05, 'epoch': 0.79}

 79%|███████▉  | 2447/3106 [9:25:27<2:38:39, 14.45s/it]

 79%|███████▉  | 2448/3106 [9:25:41<2:38:28, 14.45s/it]


 79%|███████▉  | 2450/3106 [9:26:08<2:32:55, 13.99s/it]
{'loss': 1.0164, 'grad_norm': 0.26585472606970967, 'learning_rate': 2.2509067103602356e-05, 'epoch': 0.79}

 79%|███████▉  | 2451/3106 [9:26:22<2:30:55, 13.82s/it]

 79%|███████▉  | 2452/3106 [9:26:33<2:22:24, 13.07s/it]

 79%|███████▉  | 2453/3106 [9:26:51<2:38:40, 14.58s/it]


 79%|███████▉  | 2455/3106 [9:27:16<2:26:34, 13.51s/it]
{'loss': 0.8834, 'grad_norm': 0.2700410778228509, 'learning_rate': 2.2180488572351664e-05, 'epoch': 0.79}

 79%|███████▉  | 2456/3106 [9:27:30<2:26:53, 13.56s/it]

 79%|███████▉  | 2457/3106 [9:27:42<2:21:33, 13.09s/it]

 79%|███████▉  | 2458/3106 [9:27:56<2:24:43, 13.40s/it]

 79%|███████▉  | 2459/3106 [9:28:07<2:18:08, 12.81s/it]

 79%|███████▉  | 2460/3106 [9:28:24<2:29:26, 13.88s/it]


 79%|███████▉  | 2462/3106 [9:28:52<2:34:27, 14.39s/it]
{'loss': 0.8543, 'grad_norm': 0.24993655900424583, 'learning_rate': 2.1724036331742835e-05, 'epoch': 0.79}

 79%|███████▉  | 2463/3106 [9:29:05<2:30:18, 14.03s/it]

 79%|███████▉  | 2464/3106 [9:29:20<2:30:53, 14.10s/it]

 79%|███████▉  | 2465/3106 [9:29:33<2:26:48, 13.74s/it]

 79%|███████▉  | 2466/3106 [9:29:52<2:44:01, 15.38s/it]


 79%|███████▉  | 2468/3106 [9:30:18<2:33:33, 14.44s/it]
{'loss': 1.0925, 'grad_norm': 0.25721583997737407, 'learning_rate': 2.1336111729919926e-05, 'epoch': 0.79}


 80%|███████▉  | 2470/3106 [9:30:46<2:27:46, 13.94s/it]
{'loss': 0.915, 'grad_norm': 0.27598342420666266, 'learning_rate': 2.120748740915198e-05, 'epoch': 0.8}

 80%|███████▉  | 2471/3106 [9:30:59<2:23:43, 13.58s/it]


 80%|███████▉  | 2473/3106 [9:31:28<2:27:28, 13.98s/it]
{'loss': 1.0172, 'grad_norm': 0.24835860911126478, 'learning_rate': 2.1015193991314574e-05, 'epoch': 0.8}

 80%|███████▉  | 2474/3106 [9:31:43<2:29:16, 14.17s/it]

 80%|███████▉  | 2475/3106 [9:31:55<2:23:11, 13.62s/it]

 80%|███████▉  | 2476/3106 [9:32:10<2:25:48, 13.89s/it]


 80%|███████▉  | 2478/3106 [9:32:42<2:37:59, 15.09s/it]
{'loss': 0.9164, 'grad_norm': 0.2436938079888879, 'learning_rate': 2.069642444122504e-05, 'epoch': 0.8}

 80%|███████▉  | 2479/3106 [9:32:57<2:36:21, 14.96s/it]

 80%|███████▉  | 2480/3106 [9:33:11<2:32:52, 14.65s/it]

 80%|███████▉  | 2481/3106 [9:33:28<2:39:58, 15.36s/it]


 80%|███████▉  | 2483/3106 [9:33:54<2:27:31, 14.21s/it]
{'loss': 1.0807, 'grad_norm': 0.2517377272779929, 'learning_rate': 2.0379811749383148e-05, 'epoch': 0.8}

 80%|███████▉  | 2484/3106 [9:34:08<2:26:24, 14.12s/it]


 80%|████████  | 2486/3106 [9:34:35<2:19:51, 13.53s/it]
{'loss': 1.0286, 'grad_norm': 0.2605686101947245, 'learning_rate': 2.0190883010889615e-05, 'epoch': 0.8}

 80%|████████  | 2487/3106 [9:34:48<2:18:56, 13.47s/it]


 80%|████████  | 2489/3106 [9:35:15<2:19:22, 13.55s/it]
{'loss': 0.887, 'grad_norm': 0.23354331464739564, 'learning_rate': 2.0002735692303697e-05, 'epoch': 0.8}

 80%|████████  | 2490/3106 [9:35:28<2:17:45, 13.42s/it]


 80%|████████  | 2492/3106 [9:35:54<2:17:53, 13.47s/it]
{'loss': 0.9696, 'grad_norm': 0.27325438146611974, 'learning_rate': 1.9815371635796633e-05, 'epoch': 0.8}


 80%|████████  | 2494/3106 [9:36:22<2:19:04, 13.64s/it]

 80%|████████  | 2495/3106 [9:36:37<2:20:29, 13.80s/it]

 80%|████████  | 2496/3106 [9:36:53<2:27:06, 14.47s/it]
{'loss': 0.9086, 'grad_norm': 0.2317691046885501, 'learning_rate': 1.95667744711032e-05, 'epoch': 0.8}

 80%|████████  | 2497/3106 [9:37:07<2:28:01, 14.58s/it]

 80%|████████  | 2498/3106 [9:37:19<2:19:32, 13.77s/it]

 80%|████████  | 2499/3106 [9:37:32<2:16:45, 13.52s/it]

 80%|████████  | 2500/3106 [9:37:44<2:10:18, 12.90s/it]

 81%|████████  | 2501/3106 [9:37:57<2:11:49, 13.07s/it]

 81%|████████  | 2502/3106 [9:38:12<2:16:25, 13.55s/it]

 81%|████████  | 2503/3106 [9:38:24<2:11:56, 13.13s/it]

 81%|████████  | 2504/3106 [9:38:38<2:14:13, 13.38s/it]

 81%|████████  | 2505/3106 [9:38:49<2:08:22, 12.82s/it]


 81%|████████  | 2507/3106 [9:39:13<2:01:48, 12.20s/it]
{'loss': 0.9016, 'grad_norm': 0.26771977310265316, 'learning_rate': 1.8890364222603497e-05, 'epoch': 0.81}


 81%|████████  | 2509/3106 [9:39:39<2:04:54, 12.55s/it]

 81%|████████  | 2510/3106 [9:39:53<2:10:12, 13.11s/it]

 81%|████████  | 2511/3106 [9:40:05<2:07:04, 12.81s/it]
{'loss': 1.0975, 'grad_norm': 0.3073255510998419, 'learning_rate': 1.8647039371551124e-05, 'epoch': 0.81}

 81%|████████  | 2512/3106 [9:40:16<2:02:01, 12.33s/it]

 81%|████████  | 2513/3106 [9:40:30<2:06:52, 12.84s/it]

 81%|████████  | 2514/3106 [9:40:42<2:03:06, 12.48s/it]

 81%|████████  | 2515/3106 [9:40:55<2:05:37, 12.75s/it]


 81%|████████  | 2517/3106 [9:41:25<2:12:46, 13.53s/it]
{'loss': 1.0844, 'grad_norm': 0.25458650686596446, 'learning_rate': 1.8284708529621685e-05, 'epoch': 0.81}

 81%|████████  | 2518/3106 [9:41:37<2:06:38, 12.92s/it]


 81%|████████  | 2520/3106 [9:42:07<2:19:56, 14.33s/it]
{'loss': 0.9532, 'grad_norm': 0.25176969736172133, 'learning_rate': 1.810474234891547e-05, 'epoch': 0.81}


 81%|████████  | 2522/3106 [9:42:35<2:16:47, 14.05s/it]
{'loss': 0.9353, 'grad_norm': 0.22938404715953353, 'learning_rate': 1.798521025641009e-05, 'epoch': 0.81}


 81%|████████▏ | 2524/3106 [9:43:01<2:10:03, 13.41s/it]
{'loss': 0.8736, 'grad_norm': 0.27129589370892065, 'learning_rate': 1.7866035060019335e-05, 'epoch': 0.81}

 81%|████████▏ | 2525/3106 [9:43:14<2:08:16, 13.25s/it]


 81%|████████▏ | 2527/3106 [9:43:43<2:13:13, 13.81s/it]
{'loss': 0.894, 'grad_norm': 0.27284902137732664, 'learning_rate': 1.7687942579668314e-05, 'epoch': 0.81}

 81%|████████▏ | 2528/3106 [9:43:59<2:18:48, 14.41s/it]

 81%|████████▏ | 2529/3106 [9:44:12<2:15:16, 14.07s/it]

 81%|████████▏ | 2530/3106 [9:44:24<2:10:00, 13.54s/it]


 82%|████████▏ | 2532/3106 [9:44:55<2:17:57, 14.42s/it]

 82%|████████▏ | 2533/3106 [9:45:07<2:12:00, 13.82s/it]
{'loss': 0.8636, 'grad_norm': 0.25590248647916874, 'learning_rate': 1.7334177134222695e-05, 'epoch': 0.82}


 82%|████████▏ | 2535/3106 [9:45:33<2:06:34, 13.30s/it]
{'loss': 0.8975, 'grad_norm': 0.2637171114793256, 'learning_rate': 1.7216974094746764e-05, 'epoch': 0.82}


 82%|████████▏ | 2537/3106 [9:46:01<2:08:57, 13.60s/it]
{'loss': 0.9973, 'grad_norm': 0.25841939632704797, 'learning_rate': 1.7100131294447162e-05, 'epoch': 0.82}


 82%|████████▏ | 2539/3106 [9:46:31<2:12:43, 14.04s/it]
{'loss': 1.1218, 'grad_norm': 0.2834781994978459, 'learning_rate': 1.698364924177781e-05, 'epoch': 0.82}

 82%|████████▏ | 2540/3106 [9:46:44<2:08:28, 13.62s/it]

 82%|████████▏ | 2541/3106 [9:46:56<2:04:52, 13.26s/it]

 82%|████████▏ | 2542/3106 [9:47:07<1:58:56, 12.65s/it]

 82%|████████▏ | 2543/3106 [9:47:22<2:04:19, 13.25s/it]

 82%|████████▏ | 2544/3106 [9:47:37<2:08:54, 13.76s/it]


 82%|████████▏ | 2546/3106 [9:48:03<2:04:20, 13.32s/it]
{'loss': 0.9055, 'grad_norm': 0.26655267214732986, 'learning_rate': 1.6578810248971144e-05, 'epoch': 0.82}

 82%|████████▏ | 2547/3106 [9:48:19<2:11:02, 14.06s/it]

 82%|████████▏ | 2548/3106 [9:48:37<2:23:11, 15.40s/it]


 82%|████████▏ | 2550/3106 [9:49:03<2:10:35, 14.09s/it]
{'loss': 1.0126, 'grad_norm': 0.24880700355718263, 'learning_rate': 1.6349468888260767e-05, 'epoch': 0.82}

 82%|████████▏ | 2551/3106 [9:49:22<2:23:23, 15.50s/it]

 82%|████████▏ | 2552/3106 [9:49:40<2:29:08, 16.15s/it]

 82%|████████▏ | 2553/3106 [9:49:54<2:23:18, 15.55s/it]

 82%|████████▏ | 2554/3106 [9:50:06<2:12:51, 14.44s/it]

 82%|████████▏ | 2555/3106 [9:50:17<2:05:28, 13.66s/it]

 82%|████████▏ | 2556/3106 [9:50:29<1:59:53, 13.08s/it]

 82%|████████▏ | 2557/3106 [9:50:44<2:03:34, 13.50s/it]

 82%|████████▏ | 2558/3106 [9:50:57<2:01:49, 13.34s/it]

 82%|████████▏ | 2559/3106 [9:51:08<1:55:53, 12.71s/it]

 82%|████████▏ | 2560/3106 [9:51:20<1:52:59, 12.42s/it]


 82%|████████▏ | 2562/3106 [9:51:49<2:06:11, 13.92s/it]
{'loss': 0.9762, 'grad_norm': 0.28914130080303146, 'learning_rate': 1.5670196979098838e-05, 'epoch': 0.82}

 83%|████████▎ | 2563/3106 [9:52:04<2:07:41, 14.11s/it]

 83%|████████▎ | 2564/3106 [9:52:17<2:03:55, 13.72s/it]

 83%|████████▎ | 2565/3106 [9:52:28<1:57:09, 12.99s/it]

 83%|████████▎ | 2566/3106 [9:52:43<2:01:39, 13.52s/it]

 83%|████████▎ | 2567/3106 [9:52:55<1:57:14, 13.05s/it]

 83%|████████▎ | 2568/3106 [9:53:09<2:00:13, 13.41s/it]

 83%|████████▎ | 2569/3106 [9:53:25<2:05:51, 14.06s/it]

 83%|████████▎ | 2570/3106 [9:53:39<2:06:11, 14.13s/it]

 83%|████████▎ | 2571/3106 [9:53:51<2:00:34, 13.52s/it]


 83%|████████▎ | 2573/3106 [9:54:22<2:05:26, 14.12s/it]
{'loss': 1.0497, 'grad_norm': 0.27315699097692697, 'learning_rate': 1.5059133785909318e-05, 'epoch': 0.83}

 83%|████████▎ | 2574/3106 [9:54:37<2:09:00, 14.55s/it]

 83%|████████▎ | 2575/3106 [9:54:52<2:09:55, 14.68s/it]

 83%|████████▎ | 2576/3106 [9:55:04<2:02:00, 13.81s/it]

 83%|████████▎ | 2577/3106 [9:55:16<1:57:30, 13.33s/it]

 83%|████████▎ | 2578/3106 [9:55:31<2:01:33, 13.81s/it]

 83%|████████▎ | 2579/3106 [9:55:45<2:02:43, 13.97s/it]


 83%|████████▎ | 2581/3106 [9:56:10<1:55:02, 13.15s/it]
{'loss': 1.0287, 'grad_norm': 0.2555596107877466, 'learning_rate': 1.4621742536341133e-05, 'epoch': 0.83}

 83%|████████▎ | 2582/3106 [9:56:23<1:55:13, 13.19s/it]

 83%|████████▎ | 2583/3106 [9:56:39<2:02:00, 14.00s/it]

 83%|████████▎ | 2584/3106 [9:56:53<2:03:06, 14.15s/it]

 83%|████████▎ | 2585/3106 [9:57:07<2:00:52, 13.92s/it]


 83%|████████▎ | 2587/3106 [9:57:40<2:08:51, 14.90s/it]
{'loss': 0.9858, 'grad_norm': 0.24372703648921204, 'learning_rate': 1.4297598520397471e-05, 'epoch': 0.83}

 83%|████████▎ | 2588/3106 [9:57:53<2:05:05, 14.49s/it]

 83%|████████▎ | 2589/3106 [9:58:07<2:02:40, 14.24s/it]

 83%|████████▎ | 2590/3106 [9:58:19<1:56:38, 13.56s/it]

 83%|████████▎ | 2591/3106 [9:58:34<1:58:45, 13.84s/it]

 83%|████████▎ | 2592/3106 [9:58:50<2:05:21, 14.63s/it]

 83%|████████▎ | 2593/3106 [9:59:07<2:10:05, 15.22s/it]

 84%|████████▎ | 2594/3106 [9:59:20<2:04:40, 14.61s/it]

 84%|████████▎ | 2595/3106 [9:59:37<2:09:56, 15.26s/it]

 84%|████████▎ | 2596/3106 [9:59:52<2:08:53, 15.16s/it]

 84%|████████▎ | 2597/3106 [10:00:08<2:11:10, 15.46s/it]

 84%|████████▎ | 2598/3106 [10:00:21<2:05:35, 14.83s/it]

 84%|████████▎ | 2599/3106 [10:00:34<1:59:22, 14.13s/it]

 84%|████████▎ | 2600/3106 [10:00:46<1:54:16, 13.55s/it]

 84%|████████▎ | 2601/3106 [10:00:58<1:49:58, 13.07s/it]

 84%|████████▍ | 2602/3106 [10:01:09<1:45:03, 12.51s/it]

 84%|████████▍ | 2603/3106 [10:01:22<1:47:28, 12.82s/it]

 84%|████████▍ | 2604/3106 [10:01:37<1:50:34, 13.22s/it]

 84%|████████▍ | 2605/3106 [10:01:48<1:44:54, 12.56s/it]

 84%|████████▍ | 2606/3106 [10:02:04<1:53:35, 13.63s/it]


 84%|████████▍ | 2608/3106 [10:02:30<1:50:00, 13.25s/it]
{'loss': 0.9568, 'grad_norm': 0.2501347322102028, 'learning_rate': 1.3189608856437053e-05, 'epoch': 0.84}

 84%|████████▍ | 2609/3106 [10:02:46<1:57:26, 14.18s/it]

 84%|████████▍ | 2610/3106 [10:03:02<2:00:44, 14.61s/it]

 84%|████████▍ | 2611/3106 [10:03:18<2:04:56, 15.14s/it]

 84%|████████▍ | 2612/3106 [10:03:35<2:08:29, 15.61s/it]

 84%|████████▍ | 2613/3106 [10:03:48<2:00:18, 14.64s/it]

 84%|████████▍ | 2614/3106 [10:04:03<2:00:52, 14.74s/it]

 84%|████████▍ | 2615/3106 [10:04:18<2:01:46, 14.88s/it]

 84%|████████▍ | 2616/3106 [10:04:29<1:52:21, 13.76s/it]


 84%|████████▍ | 2618/3106 [10:04:58<1:56:45, 14.36s/it]

 84%|████████▍ | 2619/3106 [10:05:11<1:51:55, 13.79s/it]

 84%|████████▍ | 2620/3106 [10:05:22<1:46:18, 13.12s/it]

 84%|████████▍ | 2621/3106 [10:05:37<1:48:23, 13.41s/it]
{'loss': 0.9167, 'grad_norm': 0.2668761772374316, 'learning_rate': 1.2524548168760042e-05, 'epoch': 0.84}

 84%|████████▍ | 2622/3106 [10:05:53<1:54:55, 14.25s/it]

 84%|████████▍ | 2623/3106 [10:06:11<2:05:14, 15.56s/it]

 84%|████████▍ | 2624/3106 [10:06:31<2:14:13, 16.71s/it]

 85%|████████▍ | 2625/3106 [10:06:47<2:12:15, 16.50s/it]

 85%|████████▍ | 2626/3106 [10:07:00<2:03:19, 15.42s/it]

 85%|████████▍ | 2627/3106 [10:07:12<1:56:04, 14.54s/it]

 85%|████████▍ | 2628/3106 [10:07:28<1:59:52, 15.05s/it]

 85%|████████▍ | 2629/3106 [10:07:47<2:08:40, 16.18s/it]

 85%|████████▍ | 2630/3106 [10:08:00<1:59:40, 15.09s/it]

 85%|████████▍ | 2631/3106 [10:08:11<1:50:03, 13.90s/it]

 85%|████████▍ | 2632/3106 [10:08:25<1:51:25, 14.10s/it]

 85%|████████▍ | 2633/3106 [10:08:37<1:46:14, 13.48s/it]

 85%|████████▍ | 2634/3106 [10:08:56<1:56:53, 14.86s/it]

 85%|████████▍ | 2635/3106 [10:09:09<1:53:56, 14.51s/it]

 85%|████████▍ | 2636/3106 [10:09:22<1:49:56, 14.03s/it]

 85%|████████▍ | 2637/3106 [10:09:35<1:45:46, 13.53s/it]

 85%|████████▍ | 2638/3106 [10:09:51<1:52:51, 14.47s/it]

 85%|████████▍ | 2639/3106 [10:10:04<1:48:38, 13.96s/it]

 85%|████████▍ | 2640/3106 [10:10:17<1:46:07, 13.66s/it]

 85%|████████▌ | 2641/3106 [10:10:33<1:50:58, 14.32s/it]

 85%|████████▌ | 2642/3106 [10:10:48<1:51:52, 14.47s/it]

 85%|████████▌ | 2643/3106 [10:11:00<1:47:24, 13.92s/it]

 85%|████████▌ | 2644/3106 [10:11:11<1:41:04, 13.13s/it]

 85%|████████▌ | 2645/3106 [10:11:24<1:38:20, 12.80s/it]

 85%|████████▌ | 2646/3106 [10:11:37<1:40:19, 13.09s/it]

 85%|████████▌ | 2647/3106 [10:11:51<1:42:00, 13.33s/it]


 85%|████████▌ | 2649/3106 [10:12:19<1:42:46, 13.49s/it]
{'loss': 0.9552, 'grad_norm': 0.24958121229242222, 'learning_rate': 1.1146889197393051e-05, 'epoch': 0.85}

 85%|████████▌ | 2650/3106 [10:12:30<1:36:54, 12.75s/it]

 85%|████████▌ | 2651/3106 [10:12:42<1:35:56, 12.65s/it]

 85%|████████▌ | 2652/3106 [10:12:55<1:36:00, 12.69s/it]

 85%|████████▌ | 2653/3106 [10:13:07<1:33:28, 12.38s/it]

 85%|████████▌ | 2654/3106 [10:13:25<1:46:19, 14.11s/it]
{'loss': 0.9576, 'grad_norm': 0.249120544256076, 'learning_rate': 1.090881999265051e-05, 'epoch': 0.85}

 85%|████████▌ | 2655/3106 [10:13:38<1:44:28, 13.90s/it]

 86%|████████▌ | 2656/3106 [10:13:50<1:40:14, 13.37s/it]

 86%|████████▌ | 2657/3106 [10:14:09<1:52:45, 15.07s/it]

 86%|████████▌ | 2658/3106 [10:14:21<1:45:34, 14.14s/it]

 86%|████████▌ | 2659/3106 [10:14:33<1:39:28, 13.35s/it]

 86%|████████▌ | 2660/3106 [10:14:46<1:38:27, 13.25s/it]

 86%|████████▌ | 2661/3106 [10:14:58<1:35:03, 12.82s/it]

 86%|████████▌ | 2662/3106 [10:15:11<1:36:31, 13.04s/it]

 86%|████████▌ | 2663/3106 [10:15:27<1:42:31, 13.89s/it]

 86%|████████▌ | 2664/3106 [10:15:42<1:44:32, 14.19s/it]

 86%|████████▌ | 2665/3106 [10:15:54<1:39:36, 13.55s/it]


 86%|████████▌ | 2667/3106 [10:16:21<1:38:06, 13.41s/it]
{'loss': 1.0049, 'grad_norm': 0.2655476003916997, 'learning_rate': 1.0301195936957763e-05, 'epoch': 0.86}

 86%|████████▌ | 2668/3106 [10:16:34<1:36:00, 13.15s/it]

 86%|████████▌ | 2669/3106 [10:16:49<1:41:39, 13.96s/it]

 86%|████████▌ | 2670/3106 [10:17:08<1:52:22, 15.47s/it]

 86%|████████▌ | 2671/3106 [10:17:21<1:45:25, 14.54s/it]

 86%|████████▌ | 2672/3106 [10:17:33<1:39:36, 13.77s/it]

 86%|████████▌ | 2673/3106 [10:17:47<1:39:22, 13.77s/it]

 86%|████████▌ | 2674/3106 [10:17:59<1:36:26, 13.39s/it]

 86%|████████▌ | 2675/3106 [10:18:12<1:35:33, 13.30s/it]

 86%|████████▌ | 2676/3106 [10:18:25<1:34:20, 13.16s/it]

 86%|████████▌ | 2677/3106 [10:18:38<1:32:56, 13.00s/it]

 86%|████████▌ | 2678/3106 [10:18:50<1:32:26, 12.96s/it]

 86%|████████▋ | 2679/3106 [10:19:02<1:29:05, 12.52s/it]

 86%|████████▋ | 2680/3106 [10:19:14<1:28:01, 12.40s/it]


 86%|████████▋ | 2682/3106 [10:19:41<1:32:39, 13.11s/it]
{'loss': 0.8607, 'grad_norm': 0.26636025960264337, 'learning_rate': 9.620590448321554e-06, 'epoch': 0.86}

 86%|████████▋ | 2683/3106 [10:19:53<1:29:37, 12.71s/it]

 86%|████████▋ | 2684/3106 [10:20:06<1:29:54, 12.78s/it]

 86%|████████▋ | 2685/3106 [10:20:21<1:34:25, 13.46s/it]

 86%|████████▋ | 2686/3106 [10:20:33<1:31:19, 13.05s/it]

 87%|████████▋ | 2687/3106 [10:20:48<1:35:06, 13.62s/it]

 87%|████████▋ | 2688/3106 [10:21:00<1:31:05, 13.07s/it]

 87%|████████▋ | 2689/3106 [10:21:12<1:28:48, 12.78s/it]

 87%|████████▋ | 2690/3106 [10:21:27<1:33:52, 13.54s/it]

 87%|████████▋ | 2691/3106 [10:21:40<1:31:16, 13.20s/it]

 87%|████████▋ | 2692/3106 [10:21:52<1:30:07, 13.06s/it]

 87%|████████▋ | 2693/3106 [10:22:07<1:33:37, 13.60s/it]

 87%|████████▋ | 2694/3106 [10:22:21<1:33:21, 13.60s/it]

 87%|████████▋ | 2695/3106 [10:22:36<1:36:52, 14.14s/it]

 87%|████████▋ | 2696/3106 [10:22:50<1:35:28, 13.97s/it]

 87%|████████▋ | 2697/3106 [10:23:13<1:53:48, 16.70s/it]


 87%|████████▋ | 2699/3106 [10:23:36<1:34:35, 13.95s/it]
{'loss': 1.0198, 'grad_norm': 0.27533052480232856, 'learning_rate': 8.875989852839983e-06, 'epoch': 0.87}

 87%|████████▋ | 2700/3106 [10:23:49<1:33:44, 13.85s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.959, 'grad_norm': 0.2619827946901932, 'learning_rate': 8.79026884473343e-06, 'epoch': 0.87}
 87%|████████▋ | 2701/3106 [10:24:17<2:01:50, 18.05s/it]

 87%|████████▋ | 2702/3106 [10:24:29<1:49:08, 16.21s/it]

 87%|████████▋ | 2703/3106 [10:24:44<1:46:30, 15.86s/it]

 87%|████████▋ | 2704/3106 [10:25:01<1:48:51, 16.25s/it]

 87%|████████▋ | 2705/3106 [10:25:14<1:41:36, 15.20s/it]

 87%|████████▋ | 2706/3106 [10:25:29<1:40:53, 15.13s/it]

 87%|████████▋ | 2707/3106 [10:25:41<1:35:35, 14.38s/it]

 87%|████████▋ | 2708/3106 [10:25:53<1:30:28, 13.64s/it]

 87%|████████▋ | 2709/3106 [10:26:07<1:30:14, 13.64s/it]

 87%|████████▋ | 2710/3106 [10:26:19<1:27:35, 13.27s/it]

 87%|████████▋ | 2711/3106 [10:26:34<1:29:53, 13.65s/it]

 87%|████████▋ | 2712/3106 [10:26:46<1:26:36, 13.19s/it]

 87%|████████▋ | 2713/3106 [10:26:58<1:24:51, 12.95s/it]

 87%|████████▋ | 2714/3106 [10:27:13<1:27:00, 13.32s/it]

 87%|████████▋ | 2715/3106 [10:27:25<1:24:27, 12.96s/it]

 87%|████████▋ | 2716/3106 [10:27:38<1:23:54, 12.91s/it]

 87%|████████▋ | 2717/3106 [10:27:53<1:28:07, 13.59s/it]

 88%|████████▊ | 2718/3106 [10:28:04<1:23:29, 12.91s/it]

 88%|████████▊ | 2719/3106 [10:28:18<1:24:30, 13.10s/it]

 88%|████████▊ | 2720/3106 [10:28:34<1:30:53, 14.13s/it]

 88%|████████▊ | 2721/3106 [10:28:49<1:31:49, 14.31s/it]

 88%|████████▊ | 2722/3106 [10:29:00<1:25:50, 13.41s/it]


 88%|████████▊ | 2724/3106 [10:29:28<1:26:32, 13.59s/it]
{'loss': 0.9261, 'grad_norm': 0.2487304618268191, 'learning_rate': 7.83309744740891e-06, 'epoch': 0.88}

 88%|████████▊ | 2725/3106 [10:29:44<1:31:45, 14.45s/it]

 88%|████████▊ | 2726/3106 [10:29:59<1:32:42, 14.64s/it]

 88%|████████▊ | 2727/3106 [10:30:12<1:28:49, 14.06s/it]

 88%|████████▊ | 2728/3106 [10:30:27<1:29:38, 14.23s/it]

 88%|████████▊ | 2729/3106 [10:30:43<1:34:02, 14.97s/it]


 88%|████████▊ | 2731/3106 [10:31:12<1:31:00, 14.56s/it]
{'loss': 0.9773, 'grad_norm': 0.29651949020830726, 'learning_rate': 7.552287562099103e-06, 'epoch': 0.88}

 88%|████████▊ | 2732/3106 [10:31:23<1:24:32, 13.56s/it]

 88%|████████▊ | 2733/3106 [10:31:39<1:27:40, 14.10s/it]

 88%|████████▊ | 2734/3106 [10:31:58<1:36:43, 15.60s/it]


 88%|████████▊ | 2736/3106 [10:32:24<1:28:19, 14.32s/it]

 88%|████████▊ | 2737/3106 [10:32:38<1:27:27, 14.22s/it]
{'loss': 0.9603, 'grad_norm': 0.25568150628002523, 'learning_rate': 7.315515185347222e-06, 'epoch': 0.88}

 88%|████████▊ | 2738/3106 [10:32:53<1:28:53, 14.49s/it]

 88%|████████▊ | 2739/3106 [10:33:05<1:23:28, 13.65s/it]

 88%|████████▊ | 2740/3106 [10:33:22<1:28:46, 14.55s/it]

 88%|████████▊ | 2741/3106 [10:33:35<1:26:08, 14.16s/it]


 88%|████████▊ | 2743/3106 [10:34:04<1:26:54, 14.37s/it]
{'loss': 0.9474, 'grad_norm': 0.2670636141525309, 'learning_rate': 7.082372735952592e-06, 'epoch': 0.88}


 88%|████████▊ | 2745/3106 [10:34:35<1:27:33, 14.55s/it]
{'loss': 1.005, 'grad_norm': 0.2752505644664292, 'learning_rate': 7.005466818955753e-06, 'epoch': 0.88}

 88%|████████▊ | 2746/3106 [10:34:47<1:23:22, 13.90s/it]

 88%|████████▊ | 2747/3106 [10:35:03<1:27:23, 14.61s/it]

 88%|████████▊ | 2748/3106 [10:35:17<1:26:08, 14.44s/it]

 89%|████████▊ | 2749/3106 [10:35:37<1:35:14, 16.01s/it]

 89%|████████▊ | 2750/3106 [10:35:49<1:28:27, 14.91s/it]

 89%|████████▊ | 2751/3106 [10:36:01<1:23:10, 14.06s/it]

 89%|████████▊ | 2752/3106 [10:36:13<1:18:57, 13.38s/it]

 89%|████████▊ | 2753/3106 [10:36:28<1:20:48, 13.73s/it]

 89%|████████▊ | 2754/3106 [10:36:40<1:17:44, 13.25s/it]

 89%|████████▊ | 2755/3106 [10:36:52<1:15:49, 12.96s/it]


 89%|████████▉ | 2757/3106 [10:37:18<1:16:43, 13.19s/it]
{'loss': 0.9679, 'grad_norm': 0.24059725688557534, 'learning_rate': 6.55254109532728e-06, 'epoch': 0.89}

 89%|████████▉ | 2758/3106 [10:37:32<1:16:30, 13.19s/it]


 89%|████████▉ | 2760/3106 [10:37:56<1:13:44, 12.79s/it]
{'loss': 1.148, 'grad_norm': 0.2565780025372206, 'learning_rate': 6.441594301172527e-06, 'epoch': 0.89}


 89%|████████▉ | 2762/3106 [10:38:26<1:18:01, 13.61s/it]
{'loss': 1.0752, 'grad_norm': 0.2727340513278698, 'learning_rate': 6.368138616559283e-06, 'epoch': 0.89}

 89%|████████▉ | 2763/3106 [10:38:38<1:14:44, 13.07s/it]

 89%|████████▉ | 2764/3106 [10:38:54<1:19:21, 13.92s/it]

 89%|████████▉ | 2765/3106 [10:39:06<1:16:14, 13.42s/it]

 89%|████████▉ | 2766/3106 [10:39:22<1:20:15, 14.16s/it]

 89%|████████▉ | 2767/3106 [10:39:38<1:22:56, 14.68s/it]

 89%|████████▉ | 2768/3106 [10:39:55<1:26:03, 15.28s/it]

 89%|████████▉ | 2769/3106 [10:40:14<1:32:42, 16.51s/it]

 89%|████████▉ | 2770/3106 [10:40:27<1:25:24, 15.25s/it]

 89%|████████▉ | 2771/3106 [10:40:38<1:19:02, 14.16s/it]

 89%|████████▉ | 2772/3106 [10:40:53<1:19:51, 14.35s/it]

 89%|████████▉ | 2773/3106 [10:41:10<1:23:34, 15.06s/it]

 89%|████████▉ | 2774/3106 [10:41:26<1:25:22, 15.43s/it]

 89%|████████▉ | 2775/3106 [10:41:41<1:25:04, 15.42s/it]

 89%|████████▉ | 2776/3106 [10:41:58<1:26:46, 15.78s/it]

 89%|████████▉ | 2777/3106 [10:42:12<1:23:13, 15.18s/it]

 89%|████████▉ | 2778/3106 [10:42:25<1:20:22, 14.70s/it]

 89%|████████▉ | 2779/3106 [10:42:38<1:15:58, 13.94s/it]

 90%|████████▉ | 2780/3106 [10:42:52<1:17:24, 14.25s/it]

 90%|████████▉ | 2781/3106 [10:43:08<1:19:45, 14.72s/it]

 90%|████████▉ | 2782/3106 [10:43:23<1:19:30, 14.72s/it]

 90%|████████▉ | 2783/3106 [10:43:41<1:24:32, 15.70s/it]

 90%|████████▉ | 2784/3106 [10:43:54<1:20:19, 14.97s/it]

 90%|████████▉ | 2785/3106 [10:44:09<1:20:21, 15.02s/it]

 90%|████████▉ | 2786/3106 [10:44:22<1:16:49, 14.41s/it]

 90%|████████▉ | 2787/3106 [10:44:39<1:19:33, 14.96s/it]


 90%|████████▉ | 2789/3106 [10:45:05<1:14:10, 14.04s/it]
{'loss': 0.8812, 'grad_norm': 0.2430780166728521, 'learning_rate': 5.416493499769093e-06, 'epoch': 0.9}

 90%|████████▉ | 2790/3106 [10:45:18<1:12:19, 13.73s/it]

 90%|████████▉ | 2791/3106 [10:45:30<1:09:02, 13.15s/it]

 90%|████████▉ | 2792/3106 [10:45:42<1:07:41, 12.93s/it]

 90%|████████▉ | 2793/3106 [10:45:56<1:08:09, 13.07s/it]

 90%|████████▉ | 2794/3106 [10:46:07<1:05:51, 12.66s/it]

 90%|████████▉ | 2795/3106 [10:46:21<1:07:45, 13.07s/it]

 90%|█████████ | 2796/3106 [10:46:36<1:09:59, 13.55s/it]

 90%|█████████ | 2797/3106 [10:46:53<1:14:30, 14.47s/it]

 90%|█████████ | 2798/3106 [10:47:06<1:12:22, 14.10s/it]

 90%|█████████ | 2799/3106 [10:47:18<1:09:24, 13.57s/it]

 90%|█████████ | 2800/3106 [10:47:31<1:07:27, 13.23s/it]

 90%|█████████ | 2801/3106 [10:47:46<1:11:03, 13.98s/it]

 90%|█████████ | 2802/3106 [10:48:04<1:15:38, 14.93s/it]

 90%|█████████ | 2803/3106 [10:48:16<1:11:18, 14.12s/it]

 90%|█████████ | 2804/3106 [10:48:34<1:16:37, 15.22s/it]

 90%|█████████ | 2805/3106 [10:48:45<1:10:38, 14.08s/it]

 90%|█████████ | 2806/3106 [10:49:02<1:14:27, 14.89s/it]

 90%|█████████ | 2807/3106 [10:49:15<1:11:22, 14.32s/it]

 90%|█████████ | 2808/3106 [10:49:27<1:07:43, 13.64s/it]

 90%|█████████ | 2809/3106 [10:49:42<1:10:24, 14.23s/it]

 90%|█████████ | 2810/3106 [10:49:56<1:09:13, 14.03s/it]

 91%|█████████ | 2811/3106 [10:50:11<1:10:53, 14.42s/it]

 91%|█████████ | 2812/3106 [10:50:25<1:09:51, 14.26s/it]

 91%|█████████ | 2813/3106 [10:50:38<1:06:59, 13.72s/it]

 91%|█████████ | 2814/3106 [10:50:51<1:06:19, 13.63s/it]

 91%|█████████ | 2815/3106 [10:51:05<1:06:28, 13.71s/it]

 91%|█████████ | 2816/3106 [10:51:16<1:02:50, 13.00s/it]

 91%|█████████ | 2817/3106 [10:51:28<1:00:11, 12.50s/it]

 91%|█████████ | 2818/3106 [10:51:39<58:48, 12.25s/it]

 91%|█████████ | 2819/3106 [10:51:52<59:24, 12.42s/it]

 91%|█████████ | 2820/3106 [10:52:06<1:01:37, 12.93s/it]

 91%|█████████ | 2821/3106 [10:52:20<1:02:54, 13.24s/it]

 91%|█████████ | 2822/3106 [10:52:36<1:06:03, 13.96s/it]

 91%|█████████ | 2823/3106 [10:52:50<1:06:05, 14.01s/it]

 91%|█████████ | 2824/3106 [10:53:02<1:02:39, 13.33s/it]

 91%|█████████ | 2825/3106 [10:53:16<1:04:00, 13.67s/it]

 91%|█████████ | 2826/3106 [10:53:28<1:00:53, 13.05s/it]

 91%|█████████ | 2827/3106 [10:53:44<1:05:34, 14.10s/it]

 91%|█████████ | 2828/3106 [10:53:56<1:01:49, 13.34s/it]

 91%|█████████ | 2829/3106 [10:54:10<1:02:30, 13.54s/it]

 91%|█████████ | 2830/3106 [10:54:23<1:01:46, 13.43s/it]

 91%|█████████ | 2831/3106 [10:54:38<1:03:25, 13.84s/it]

 91%|█████████ | 2832/3106 [10:54:50<1:00:37, 13.28s/it]

 91%|█████████ | 2833/3106 [10:55:02<58:59, 12.96s/it]

 91%|█████████ | 2834/3106 [10:55:16<1:00:14, 13.29s/it]

 91%|█████████▏| 2835/3106 [10:55:28<58:15, 12.90s/it]

 91%|█████████▏| 2836/3106 [10:55:43<1:00:29, 13.44s/it]

 91%|█████████▏| 2837/3106 [10:55:56<1:00:00, 13.39s/it]

 91%|█████████▏| 2838/3106 [10:56:09<59:16, 13.27s/it]

 91%|█████████▏| 2839/3106 [10:56:21<57:10, 12.85s/it]

 91%|█████████▏| 2840/3106 [10:56:35<58:19, 13.16s/it]

 91%|█████████▏| 2841/3106 [10:56:47<57:25, 13.00s/it]

 92%|█████████▏| 2842/3106 [10:57:04<1:02:04, 14.11s/it]

 92%|█████████▏| 2843/3106 [10:57:20<1:03:58, 14.60s/it]

 92%|█████████▏| 2844/3106 [10:57:36<1:05:30, 15.00s/it]

 92%|█████████▏| 2845/3106 [10:57:50<1:03:35, 14.62s/it]

 92%|█████████▏| 2846/3106 [10:58:02<1:00:30, 13.96s/it]

 92%|█████████▏| 2847/3106 [10:58:18<1:02:28, 14.47s/it]

 92%|█████████▏| 2848/3106 [10:58:36<1:06:42, 15.51s/it]

 92%|█████████▏| 2849/3106 [10:58:51<1:05:58, 15.40s/it]

 92%|█████████▏| 2850/3106 [10:59:05<1:04:37, 15.15s/it]

 92%|█████████▏| 2851/3106 [10:59:18<1:00:58, 14.35s/it]

 92%|█████████▏| 2852/3106 [10:59:30<58:16, 13.76s/it]

 92%|█████████▏| 2853/3106 [10:59:49<1:04:56, 15.40s/it]

 92%|█████████▏| 2854/3106 [11:00:01<59:40, 14.21s/it]

 92%|█████████▏| 2855/3106 [11:00:13<56:56, 13.61s/it]

 92%|█████████▏| 2856/3106 [11:00:28<58:11, 13.97s/it]

 92%|█████████▏| 2857/3106 [11:00:45<1:02:04, 14.96s/it]

 92%|█████████▏| 2858/3106 [11:00:59<1:00:49, 14.72s/it]

 92%|█████████▏| 2859/3106 [11:01:13<59:23, 14.43s/it]

 92%|█████████▏| 2860/3106 [11:01:28<59:26, 14.50s/it]

 92%|█████████▏| 2861/3106 [11:01:43<1:00:19, 14.77s/it]

 92%|█████████▏| 2862/3106 [11:01:55<56:12, 13.82s/it]

 92%|█████████▏| 2863/3106 [11:02:07<54:21, 13.42s/it]

 92%|█████████▏| 2864/3106 [11:02:20<53:08, 13.18s/it]

 92%|█████████▏| 2865/3106 [11:02:32<52:00, 12.95s/it]
[2024-05-29 07:55:53,183] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 92%|█████████▏| 2866/3106 [11:02:50<58:09, 14.54s/it]

 92%|█████████▏| 2867/3106 [11:03:03<55:11, 13.86s/it]

 92%|█████████▏| 2868/3106 [11:03:15<52:38, 13.27s/it]

 92%|█████████▏| 2869/3106 [11:03:30<54:42, 13.85s/it]

 92%|█████████▏| 2870/3106 [11:03:45<56:38, 14.40s/it]

 92%|█████████▏| 2871/3106 [11:04:05<1:02:36, 15.99s/it]

 92%|█████████▏| 2872/3106 [11:04:20<1:00:39, 15.55s/it]

 92%|█████████▏| 2873/3106 [11:04:34<58:46, 15.14s/it]

 93%|█████████▎| 2874/3106 [11:04:47<56:36, 14.64s/it]

 93%|█████████▎| 2875/3106 [11:05:04<58:17, 15.14s/it]


 93%|█████████▎| 2877/3106 [11:05:29<52:50, 13.85s/it]
{'loss': 0.8977, 'grad_norm': 0.27130606723384243, 'learning_rate': 2.838997853174874e-06, 'epoch': 0.93}

 93%|█████████▎| 2878/3106 [11:05:41<50:40, 13.33s/it]

 93%|█████████▎| 2879/3106 [11:05:54<50:09, 13.26s/it]

 93%|█████████▎| 2880/3106 [11:06:06<48:56, 13.00s/it]

 93%|█████████▎| 2881/3106 [11:06:23<52:38, 14.04s/it]

 93%|█████████▎| 2882/3106 [11:06:35<50:34, 13.55s/it]

 93%|█████████▎| 2883/3106 [11:06:48<49:13, 13.24s/it]

 93%|█████████▎| 2884/3106 [11:07:00<48:13, 13.03s/it]

 93%|█████████▎| 2885/3106 [11:07:15<49:20, 13.39s/it]

 93%|█████████▎| 2886/3106 [11:07:30<51:30, 14.05s/it]

 93%|█████████▎| 2887/3106 [11:07:44<50:37, 13.87s/it]

 93%|█████████▎| 2888/3106 [11:07:55<48:07, 13.25s/it]

 93%|█████████▎| 2889/3106 [11:08:11<50:42, 14.02s/it]

 93%|█████████▎| 2890/3106 [11:08:23<48:28, 13.47s/it]

 93%|█████████▎| 2891/3106 [11:08:40<51:28, 14.36s/it]

 93%|█████████▎| 2892/3106 [11:08:53<49:26, 13.86s/it]

 93%|█████████▎| 2893/3106 [11:09:06<48:46, 13.74s/it]

 93%|█████████▎| 2894/3106 [11:09:19<48:10, 13.64s/it]

 93%|█████████▎| 2895/3106 [11:09:35<49:32, 14.09s/it]

 93%|█████████▎| 2896/3106 [11:09:50<50:44, 14.50s/it]

 93%|█████████▎| 2897/3106 [11:10:02<47:32, 13.65s/it]

 93%|█████████▎| 2898/3106 [11:10:16<48:15, 13.92s/it]

 93%|█████████▎| 2899/3106 [11:10:28<45:58, 13.33s/it]

 93%|█████████▎| 2900/3106 [11:10:44<47:57, 13.97s/it]

 93%|█████████▎| 2901/3106 [11:10:56<46:11, 13.52s/it]

 93%|█████████▎| 2902/3106 [11:11:09<45:32, 13.39s/it]

 93%|█████████▎| 2903/3106 [11:11:22<44:57, 13.29s/it]

 93%|█████████▎| 2904/3106 [11:11:36<45:22, 13.48s/it]


 94%|█████████▎| 2906/3106 [11:12:01<43:24, 13.02s/it]
{'loss': 0.8066, 'grad_norm': 0.2492833404257434, 'learning_rate': 2.1679254059727595e-06, 'epoch': 0.94}

 94%|█████████▎| 2907/3106 [11:12:14<42:34, 12.83s/it]

 94%|█████████▎| 2908/3106 [11:12:26<41:49, 12.67s/it]

 94%|█████████▎| 2909/3106 [11:12:40<42:56, 13.08s/it]

 94%|█████████▎| 2910/3106 [11:12:52<41:34, 12.72s/it]

 94%|█████████▎| 2911/3106 [11:13:08<44:14, 13.61s/it]

 94%|█████████▍| 2912/3106 [11:13:21<43:54, 13.58s/it]

 94%|█████████▍| 2913/3106 [11:13:36<45:01, 14.00s/it]

 94%|█████████▍| 2914/3106 [11:13:49<43:27, 13.58s/it]

 94%|█████████▍| 2915/3106 [11:14:00<41:23, 13.00s/it]

 94%|█████████▍| 2916/3106 [11:14:13<40:50, 12.90s/it]


 94%|█████████▍| 2918/3106 [11:14:37<39:30, 12.61s/it]
{'loss': 1.0776, 'grad_norm': 0.2887814216738257, 'learning_rate': 1.9163881898345835e-06, 'epoch': 0.94}

 94%|█████████▍| 2919/3106 [11:14:55<43:51, 14.07s/it]


 94%|█████████▍| 2921/3106 [11:15:23<43:22, 14.07s/it]
{'loss': 0.9612, 'grad_norm': 0.25102656072862317, 'learning_rate': 1.855903238789225e-06, 'epoch': 0.94}

 94%|█████████▍| 2922/3106 [11:15:36<41:57, 13.68s/it]

 94%|█████████▍| 2923/3106 [11:15:48<39:59, 13.11s/it]

 94%|█████████▍| 2924/3106 [11:16:00<39:04, 12.88s/it]

 94%|█████████▍| 2925/3106 [11:16:13<38:26, 12.75s/it]

 94%|█████████▍| 2926/3106 [11:16:27<39:48, 13.27s/it]

 94%|█████████▍| 2927/3106 [11:16:40<39:01, 13.08s/it]


 94%|█████████▍| 2929/3106 [11:17:05<37:53, 12.85s/it]
{'loss': 0.9083, 'grad_norm': 0.25846597537735916, 'learning_rate': 1.699309542220584e-06, 'epoch': 0.94}

 94%|█████████▍| 2930/3106 [11:17:19<38:26, 13.11s/it]

 94%|█████████▍| 2931/3106 [11:17:34<40:01, 13.72s/it]

 94%|█████████▍| 2932/3106 [11:17:46<38:23, 13.24s/it]

 94%|█████████▍| 2933/3106 [11:17:58<36:57, 12.82s/it]

 94%|█████████▍| 2934/3106 [11:18:11<36:26, 12.71s/it]

 94%|█████████▍| 2935/3106 [11:18:24<36:43, 12.88s/it]

 95%|█████████▍| 2936/3106 [11:18:36<35:57, 12.69s/it]

 95%|█████████▍| 2937/3106 [11:18:48<35:09, 12.48s/it]

 95%|█████████▍| 2938/3106 [11:19:04<38:04, 13.60s/it]

 95%|█████████▍| 2939/3106 [11:19:21<40:42, 14.63s/it]

 95%|█████████▍| 2940/3106 [11:19:39<42:36, 15.40s/it]


 95%|█████████▍| 2942/3106 [11:20:06<39:28, 14.44s/it]

 95%|█████████▍| 2943/3106 [11:20:18<37:19, 13.74s/it]

 95%|█████████▍| 2944/3106 [11:20:30<35:39, 13.21s/it]
{'loss': 0.8473, 'grad_norm': 0.2793597138604689, 'learning_rate': 1.4241518756477169e-06, 'epoch': 0.95}

 95%|█████████▍| 2945/3106 [11:20:42<34:52, 12.99s/it]

 95%|█████████▍| 2946/3106 [11:20:56<35:29, 13.31s/it]

 95%|█████████▍| 2947/3106 [11:21:11<36:13, 13.67s/it]

 95%|█████████▍| 2948/3106 [11:21:25<36:30, 13.86s/it]

 95%|█████████▍| 2949/3106 [11:21:37<34:23, 13.15s/it]

 95%|█████████▍| 2950/3106 [11:21:49<33:30, 12.89s/it]

 95%|█████████▌| 2951/3106 [11:22:02<33:38, 13.03s/it]

 95%|█████████▌| 2952/3106 [11:22:14<32:39, 12.72s/it]


 95%|█████████▌| 2954/3106 [11:22:40<32:32, 12.84s/it]
{'loss': 0.794, 'grad_norm': 0.259194380750409, 'learning_rate': 1.2541143521019095e-06, 'epoch': 0.95}

 95%|█████████▌| 2955/3106 [11:22:52<31:48, 12.64s/it]

 95%|█████████▌| 2956/3106 [11:23:06<32:15, 12.90s/it]

 95%|█████████▌| 2957/3106 [11:23:20<32:50, 13.22s/it]

 95%|█████████▌| 2958/3106 [11:23:31<31:31, 12.78s/it]

 95%|█████████▌| 2959/3106 [11:23:43<30:39, 12.52s/it]

 95%|█████████▌| 2960/3106 [11:24:01<34:34, 14.21s/it]

 95%|█████████▌| 2961/3106 [11:24:14<33:01, 13.66s/it]

 95%|█████████▌| 2962/3106 [11:24:28<33:05, 13.79s/it]

 95%|█████████▌| 2963/3106 [11:24:47<36:24, 15.28s/it]

 95%|█████████▌| 2964/3106 [11:24:58<33:34, 14.19s/it]

 95%|█████████▌| 2965/3106 [11:25:13<34:06, 14.52s/it]

 95%|█████████▌| 2966/3106 [11:25:26<32:39, 14.00s/it]

 96%|█████████▌| 2967/3106 [11:25:43<34:39, 14.96s/it]

 96%|█████████▌| 2968/3106 [11:25:57<33:24, 14.52s/it]

 96%|█████████▌| 2969/3106 [11:26:10<31:53, 13.97s/it]

 96%|█████████▌| 2970/3106 [11:26:30<35:41, 15.75s/it]

 96%|█████████▌| 2971/3106 [11:26:43<33:55, 15.08s/it]

 96%|█████████▌| 2972/3106 [11:26:59<34:00, 15.22s/it]

 96%|█████████▌| 2973/3106 [11:27:11<31:48, 14.35s/it]

 96%|█████████▌| 2974/3106 [11:27:27<32:22, 14.72s/it]

 96%|█████████▌| 2975/3106 [11:27:41<32:04, 14.69s/it]

 96%|█████████▌| 2976/3106 [11:27:57<32:50, 15.16s/it]

 96%|█████████▌| 2977/3106 [11:28:11<31:49, 14.80s/it]

 96%|█████████▌| 2978/3106 [11:28:25<30:42, 14.40s/it]

 96%|█████████▌| 2979/3106 [11:28:36<28:29, 13.46s/it]

 96%|█████████▌| 2980/3106 [11:28:48<27:10, 12.94s/it]

 96%|█████████▌| 2981/3106 [11:29:01<26:55, 12.92s/it]

 96%|█████████▌| 2982/3106 [11:29:14<26:55, 13.02s/it]

 96%|█████████▌| 2983/3106 [11:29:26<25:48, 12.59s/it]

 96%|█████████▌| 2984/3106 [11:29:38<25:47, 12.68s/it]

 96%|█████████▌| 2985/3106 [11:29:52<26:09, 12.97s/it]

 96%|█████████▌| 2986/3106 [11:30:05<25:45, 12.88s/it]

 96%|█████████▌| 2987/3106 [11:30:20<27:01, 13.63s/it]

 96%|█████████▌| 2988/3106 [11:30:34<26:40, 13.56s/it]

 96%|█████████▌| 2989/3106 [11:30:49<27:49, 14.27s/it]

 96%|█████████▋| 2990/3106 [11:31:02<26:39, 13.79s/it]

 96%|█████████▋| 2991/3106 [11:31:15<25:53, 13.51s/it]

 96%|█████████▋| 2992/3106 [11:31:27<24:54, 13.11s/it]

 96%|█████████▋| 2993/3106 [11:31:38<23:33, 12.51s/it]

 96%|█████████▋| 2994/3106 [11:31:51<23:25, 12.55s/it]

 96%|█████████▋| 2995/3106 [11:32:05<23:59, 12.97s/it]

 96%|█████████▋| 2996/3106 [11:32:20<25:03, 13.67s/it]


 97%|█████████▋| 2998/3106 [11:32:49<24:56, 13.85s/it]
{'loss': 0.9949, 'grad_norm': 0.26171598815892766, 'learning_rate': 6.337938728257054e-07, 'epoch': 0.96}

 97%|█████████▋| 2999/3106 [11:33:02<24:25, 13.70s/it]

 97%|█████████▋| 3000/3106 [11:33:19<26:00, 14.73s/it]/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.0372, 'grad_norm': 0.2480876009660709, 'learning_rate': 5.991068534617395e-07, 'epoch': 0.97}
 97%|█████████▋| 3001/3106 [11:33:49<33:53, 19.37s/it]

 97%|█████████▋| 3002/3106 [11:34:04<31:09, 17.97s/it]

 97%|█████████▋| 3003/3106 [11:34:15<27:15, 15.88s/it]

 97%|█████████▋| 3004/3106 [11:34:32<27:30, 16.18s/it]

 97%|█████████▋| 3005/3106 [11:34:44<25:24, 15.09s/it]

 97%|█████████▋| 3006/3106 [11:34:57<24:06, 14.47s/it]

 97%|█████████▋| 3007/3106 [11:35:10<23:05, 14.00s/it]

 97%|█████████▋| 3008/3106 [11:35:25<23:10, 14.18s/it]

 97%|█████████▋| 3009/3106 [11:35:36<21:20, 13.20s/it]

 97%|█████████▋| 3010/3106 [11:35:48<20:27, 12.79s/it]


 97%|█████████▋| 3012/3106 [11:36:14<20:06, 12.84s/it]

 97%|█████████▋| 3013/3106 [11:36:26<19:26, 12.54s/it]

 97%|█████████▋| 3014/3106 [11:36:39<19:49, 12.93s/it]

 97%|█████████▋| 3015/3106 [11:36:51<18:55, 12.48s/it]

 97%|█████████▋| 3016/3106 [11:37:07<20:17, 13.53s/it]

 97%|█████████▋| 3017/3106 [11:37:21<20:26, 13.79s/it]

 97%|█████████▋| 3018/3106 [11:37:35<19:59, 13.64s/it]

 97%|█████████▋| 3019/3106 [11:37:48<19:50, 13.68s/it]
{'loss': 1.043, 'grad_norm': 0.25864242323576436, 'learning_rate': 4.114341052498194e-07, 'epoch': 0.97}


 97%|█████████▋| 3021/3106 [11:38:23<21:40, 15.30s/it]
{'loss': 0.8524, 'grad_norm': 0.262268856217824, 'learning_rate': 3.927472756951489e-07, 'epoch': 0.97}


 97%|█████████▋| 3023/3106 [11:38:47<19:10, 13.86s/it]
{'loss': 0.7928, 'grad_norm': 0.25606460825784033, 'learning_rate': 3.744938977362056e-07, 'epoch': 0.97}


 97%|█████████▋| 3025/3106 [11:39:17<19:37, 14.54s/it]

 97%|█████████▋| 3026/3106 [11:39:30<18:30, 13.88s/it]

 97%|█████████▋| 3027/3106 [11:39:42<17:50, 13.55s/it]

 97%|█████████▋| 3028/3106 [11:39:59<18:56, 14.57s/it]

 98%|█████████▊| 3029/3106 [11:40:14<18:52, 14.71s/it]

 98%|█████████▊| 3030/3106 [11:40:29<18:36, 14.69s/it]

 98%|█████████▊| 3031/3106 [11:40:40<17:06, 13.69s/it]

 98%|█████████▊| 3032/3106 [11:40:52<16:09, 13.11s/it]

 98%|█████████▊| 3033/3106 [11:41:04<15:26, 12.69s/it]
{'loss': 0.8626, 'grad_norm': 0.2737991631080506, 'learning_rate': 2.897314959442232e-07, 'epoch': 0.98}


 98%|█████████▊| 3035/3106 [11:41:31<15:54, 13.44s/it]

 98%|█████████▊| 3036/3106 [11:41:43<15:12, 13.03s/it]

 98%|█████████▊| 3037/3106 [11:41:58<15:38, 13.60s/it]

 98%|█████████▊| 3038/3106 [11:42:11<15:09, 13.37s/it]

 98%|█████████▊| 3039/3106 [11:42:24<14:37, 13.10s/it]

 98%|█████████▊| 3040/3106 [11:42:42<16:01, 14.57s/it]

 98%|█████████▊| 3041/3106 [11:42:55<15:28, 14.29s/it]

 98%|█████████▊| 3042/3106 [11:43:11<15:47, 14.80s/it]

 98%|█████████▊| 3043/3106 [11:43:23<14:30, 13.81s/it]

 98%|█████████▊| 3044/3106 [11:43:37<14:22, 13.91s/it]

 98%|█████████▊| 3045/3106 [11:43:49<13:45, 13.53s/it]

 98%|█████████▊| 3046/3106 [11:44:04<13:46, 13.77s/it]

 98%|█████████▊| 3047/3106 [11:44:19<13:50, 14.07s/it]

 98%|█████████▊| 3048/3106 [11:44:30<12:46, 13.22s/it]

 98%|█████████▊| 3049/3106 [11:44:43<12:27, 13.11s/it]

 98%|█████████▊| 3050/3106 [11:44:57<12:28, 13.37s/it]

 98%|█████████▊| 3051/3106 [11:45:10<12:14, 13.36s/it]

 98%|█████████▊| 3052/3106 [11:45:25<12:34, 13.97s/it]

 98%|█████████▊| 3053/3106 [11:45:38<12:01, 13.62s/it]

 98%|█████████▊| 3054/3106 [11:45:52<11:57, 13.80s/it]

 98%|█████████▊| 3055/3106 [11:46:12<13:16, 15.62s/it]

 98%|█████████▊| 3056/3106 [11:46:25<12:19, 14.79s/it]

 98%|█████████▊| 3057/3106 [11:46:42<12:30, 15.31s/it]

 98%|█████████▊| 3058/3106 [11:46:54<11:33, 14.45s/it]

 98%|█████████▊| 3059/3106 [11:47:06<10:44, 13.71s/it]

 99%|█████████▊| 3060/3106 [11:47:18<10:00, 13.06s/it]

 99%|█████████▊| 3061/3106 [11:47:35<10:48, 14.41s/it]

 99%|█████████▊| 3062/3106 [11:47:48<10:11, 13.90s/it]

 99%|█████████▊| 3063/3106 [11:47:59<09:23, 13.11s/it]

 99%|█████████▊| 3064/3106 [11:48:11<08:49, 12.61s/it]

 99%|█████████▊| 3065/3106 [11:48:24<08:42, 12.75s/it]

 99%|█████████▊| 3066/3106 [11:48:36<08:29, 12.73s/it]

 99%|█████████▊| 3067/3106 [11:48:48<08:07, 12.50s/it]

 99%|█████████▉| 3068/3106 [11:49:02<08:07, 12.83s/it]

 99%|█████████▉| 3069/3106 [11:49:14<07:51, 12.74s/it]

 99%|█████████▉| 3070/3106 [11:49:26<07:28, 12.45s/it]

 99%|█████████▉| 3071/3106 [11:49:43<08:07, 13.92s/it]

 99%|█████████▉| 3072/3106 [11:49:56<07:38, 13.47s/it]

 99%|█████████▉| 3073/3106 [11:50:18<08:53, 16.17s/it]

 99%|█████████▉| 3074/3106 [11:50:31<07:59, 15.00s/it]

 99%|█████████▉| 3075/3106 [11:50:42<07:13, 13.97s/it]

 99%|█████████▉| 3076/3106 [11:51:02<07:49, 15.66s/it]
[2024-05-29 08:44:04,591] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 99%|█████████▉| 3077/3106 [11:51:14<07:01, 14.52s/it]

 99%|█████████▉| 3078/3106 [11:51:26<06:24, 13.75s/it]

 99%|█████████▉| 3079/3106 [11:51:41<06:23, 14.20s/it]

 99%|█████████▉| 3080/3106 [11:51:55<06:08, 14.17s/it]

 99%|█████████▉| 3081/3106 [11:52:09<05:51, 14.06s/it]

 99%|█████████▉| 3082/3106 [11:52:24<05:45, 14.41s/it]

 99%|█████████▉| 3083/3106 [11:52:39<05:37, 14.68s/it]

 99%|█████████▉| 3084/3106 [11:52:51<05:05, 13.87s/it]

 99%|█████████▉| 3085/3106 [11:53:05<04:51, 13.89s/it]

 99%|█████████▉| 3086/3106 [11:53:17<04:25, 13.29s/it]

 99%|█████████▉| 3087/3106 [11:53:32<04:24, 13.90s/it]

 99%|█████████▉| 3088/3106 [11:53:51<04:33, 15.18s/it]

 99%|█████████▉| 3089/3106 [11:54:04<04:08, 14.63s/it]

 99%|█████████▉| 3090/3106 [11:54:16<03:42, 13.93s/it]

100%|█████████▉| 3091/3106 [11:54:30<03:27, 13.83s/it]

100%|█████████▉| 3092/3106 [11:54:44<03:13, 13.85s/it]

100%|█████████▉| 3093/3106 [11:54:57<02:58, 13.75s/it]

100%|█████████▉| 3094/3106 [11:55:11<02:46, 13.87s/it]

100%|█████████▉| 3095/3106 [11:55:24<02:29, 13.55s/it]

100%|█████████▉| 3096/3106 [11:55:41<02:23, 14.39s/it]

100%|█████████▉| 3097/3106 [11:55:52<02:01, 13.55s/it]

100%|█████████▉| 3098/3106 [11:56:07<01:51, 13.99s/it]

100%|█████████▉| 3099/3106 [11:56:20<01:36, 13.78s/it]

100%|█████████▉| 3100/3106 [11:56:34<01:22, 13.77s/it]

100%|█████████▉| 3101/3106 [11:56:46<01:06, 13.23s/it]

100%|█████████▉| 3102/3106 [11:56:58<00:50, 12.65s/it]

100%|█████████▉| 3103/3106 [11:57:11<00:39, 13.01s/it]

100%|█████████▉| 3104/3106 [11:57:23<00:24, 12.49s/it]

100%|█████████▉| 3105/3106 [11:57:36<00:12, 12.87s/it]

100%|██████████| 3106/3106 [11:57:50<00:00, 13.87s/it]
{'loss': 0.8878, 'grad_norm': 0.2483753057521469, 'learning_rate': 0.0, 'epoch': 1.0}
{'train_runtime': 43086.3019, 'train_samples_per_second': 9.229, 'train_steps_per_second': 0.072, 'train_loss': 0.9872743113149924, 'epoch': 1.0}
/mnt/petrelfs/liaoyusheng/miniconda3/envs/ming/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /mnt/petrelfs/liaoyusheng/oss/download_models/Qwen1.5-1.8B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(